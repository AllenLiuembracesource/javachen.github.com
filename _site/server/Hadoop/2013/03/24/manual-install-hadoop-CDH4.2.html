<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    	<link rel="alternate" type="application/rss+xml" title="RSS 2.0 - all posts" href="http://blog.javachen.com/atom.xml" />
    	<link REL="SHORTCUT ICON" HREF="http://blog.javachen.com/favicon.ico"/>
		<meta name="keywords" content="html,xhtml,css,js,javascript,ajax,jQuery,java,struts,struts2,hibernate,spring,jpa,maven,ant,git,github,jekyll,markdown,wiki,
    java,jboss,JDG,EDS,bi,pentaho,kettle,nosql,cassandra,hadoop,bigdata,cloud,opensource,openstack" />
		<meta name="description" content="javachen" />

		<meta property="wb:webmaster" content="61eb31a6e636506d" />
    	<meta name="ujianVerification" content="f8b60286538bf86567069598d8a5d6cc" />
    	<meta name="wumiiVerification" content="eec4ca3c-ccdb-4c0f-9fe3-4499d87649a3" />
		<title>手动安装Cloudera Hadoop CDH4</title>
		
		<link rel="stylesheet" href="/css/main.css" />
		<link rel="stylesheet" href="/css/pygments_native.css" />
		<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Handlee">
	</head>
	<body>
		<header id="header">
			<div class="header-info fix">
				<h1><a href="/">JavaChen Blog</a></h1>
				<p class="describe">&lt; Dive into Java ... /&gt;</p>
				<nav class="navigation">
					<ul>
						<li><a href="/">Home</a></li>
						<li><a href="/archive.html">Archive</a></li>
						<!--<li><a href="/sitemap.txt">网站地图</a></li>-->
						<li><a href="/about.html">About</a></li>
						<li><a href="/atom.xml">RSS</a></li>
					</ul>
				</nav>
			</div>
		</header><!--/header end-->

		<section id="content" class="fix">
			<article id="post">
	<a href="#" class="icon-fullscreen r" title="点击全屏显示"></a>
	<div class="c9">
		Categories：
			
			<a href="/category.html#Hadoop">Hadoop</a>
			
			
		&emsp;&emsp;&emsp;&emsp;
		Tages：hadoop
		&emsp;&emsp;&emsp;&emsp;
		Time：<time date="2013-03-24 15:00:00 +0800">2013-03-24 15:03</time>
		&emsp;&emsp;&emsp;&emsp;
		<a href='#comment' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>

	<h1>手动安装Cloudera Hadoop CDH4</h1>

	<h2 id="toc_0">安装版本</h2>
<div class="highlight"><pre><code class="text">hadoop-2.0.0-cdh4.2.0
hbase-0.94.2-cdh4.2.0
hive-0.10.0-cdh4.2.0
jdk1.6.0_38
</code></pre></div>
<h2 id="toc_1">安装前说明</h2>

<ul>
<li>安装目录为/opt</li>
<li>检查hosts文件</li>
<li>关闭防火墙</li>
<li>设置时钟同步</li>
</ul>

<h2 id="toc_2">使用说明</h2>

<ul>
<li>启动dfs和mapreduce
desktop1上执行start-dfs.sh和start-yarn.sh</li>
<li>启动hbase
desktop3上执行start-hbase.xml</li>
<li>启动hive
desktop1上执行hive</li>
</ul>

<h2 id="toc_3">规划</h2>
<div class="highlight"><pre><code class="text">192.168.0.1             NameNode、Hive、ResourceManager
192.168.0.2             SSNameNode
192.168.0.3             DataNode、HBase、NodeManager
192.168.0.4             DataNode、HBase、NodeManager
192.168.0.6             DataNode、HBase、NodeManager
192.168.0.7             DataNode、HBase、NodeManager
192.168.0.8             DataNode、HBase、NodeManager
</code></pre></div>
<h2 id="toc_4">部署过程</h2>

<h3 id="toc_5">系统和网络配置</h3>

<ol>
<li><p>修改每台机器的名称
<pre>
[root@desktop1 ~]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=desktop1
</pre></p></li>
<li><p>在各个节点上修改/etc/hosts增加以下内容:
<pre>
[root@desktop1 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.0.1     desktop1
192.168.0.2     desktop2
192.168.0.3     desktop3
192.168.0.4     desktop4
192.168.0.6     desktop6
192.168.0.7     desktop7
192.168.0.8     desktop8
</pre></p></li>
<li><p>配置ssh无密码登陆
<pre>
[root@desktop1 ~]# ssh-keygen
[root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop2
[root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop3
[root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop4
[root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop6
[root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop7
[root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop8
</pre></p></li>
<li><p>每台机器上关闭防火墙：</p>

<p>[root@desktop1 ~]# service iptables stop</p></li>
</ol>

<h3 id="toc_6">安装Hadoop</h3>

<h4 id="toc_7">配置Hadoop</h4>

<p>将jdk1.6.0_38.zip上传到/opt，并解压缩
将hadoop-2.0.0-cdh4.2.0.zip上传到/opt，并解压缩</p>

<p>在NameNode上配置以下文件：</p>
<div class="highlight"><pre><code class="text">core-site.xml fs.defaultFS指定NameNode文件系统，开启回收站功能。
hdfs-site.xml 
    dfs.namenode.name.dir指定NameNode存储meta和editlog的目录，
    dfs.datanode.data.dir指定DataNode存储blocks的目录，
    dfs.namenode.secondary.http-address指定Secondary NameNode地址。
    开启WebHDFS。
slaves 添加DataNode节点主机
</code></pre></div>
<ol>
<li><p>core-site.xml</p>

<p>[root@desktop1 hadoop]# pwd
/opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop
[root@desktop1 hadoop]# cat core-site.xml 
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
<configuration>
&lt;!--fs.default.name for MRV1 ,fs.defaultFS for MRV2(yarn) --&gt;
<property>
     <name>fs.defaultFS</name>
     &lt;!--这个地方的值要和hdfs-site.xml文件中的dfs.federation.nameservices一致--&gt;
     <value>hdfs://desktop1</value>
</property>
<property>
<name>fs.trash.interval</name>
<value>10080</value>
</property>
<property>
<name>fs.trash.checkpoint.interval</name>
<value>10080</value>
</property>
</configuration></p></li>
<li><p>hdfs-site.xml</p>

<p>[root@desktop1 hadoop]# cat hdfs-site.xml 
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
<configuration>
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
<property>
  <name>hadoop.tmp.dir</name>
  <value>/opt/data/hadoop-${user.name}</value>
</property>
<property>
<name>dfs.namenode.http-address</name>
<value>desktop1:50070</value>
</property>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>desktop2:50090</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
</configuration></p></li>
<li><p>masters</p>

<p>[root@desktop1 hadoop]# cat masters 
desktop1
desktop2</p></li>
<li><p>slaves</p>

<p>[root@desktop1 hadoop]# cat slaves 
desktop3
desktop4
desktop6
desktop7
desktop8</p></li>
</ol>

<h4 id="toc_8">配置MapReduce</h4>

<ol>
<li><p>mapred-site.xml</p>

<p>[root@desktop1 hadoop]# cat mapred-site.xml
&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
<configuration>
<property>
 <name>mapreduce.framework.name</name>
 <value>yarn</value>
</property>
<property>
 <name>mapreduce.jobhistory.address</name>
 <value>desktop1:10020</value>
</property>
<property>
 <name>mapreduce.jobhistory.webapp.address</name>
 <value>desktop1:19888</value>
</property>
</configuration></p></li>
<li><p>yarn-site.xml</p>

<p>[root@desktop1 hadoop]# cat yarn-site.xml 
&lt;?xml version=&quot;1.0&quot;?&gt;
<configuration>
<property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>desktop1:8031</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>desktop1:8032</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>desktop1:8030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>desktop1:8033</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>desktop1:8088</value>
  </property>
  <property>
    <description>Classpath for typical applications.</description>
    <name>yarn.application.classpath</name>
    <value>$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$YARN_HOME/share/hadoop/yarn/*,$YARN_HOME/share/hadoop/yarn/lib/*,$YARN_HOME/share/hadoop/mapreduce/*,$YARN_HOME/share/hadoop/mapreduce/lib/*</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce.shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.nodemanager.local-dirs</name>
    <value>/opt/data/yarn/local</value>
  </property>
  <property>
    <name>yarn.nodemanager.log-dirs</name>
    <value>/opt/data/yarn/logs</value>
  </property>
  <property>
    <description>Where to aggregate logs</description>
    <name>yarn.nodemanager.remote-app-log-dir</name>
    <value>/opt/data/yarn/logs</value>
  </property>
  <property>
    <name>yarn.app.mapreduce.am.staging-dir</name>
    <value>/user</value>
 </property>
</configuration></p></li>
</ol>

<h4 id="toc_9">同步配置文件</h4>

<p>修改.bashrc环境变量，并将其同步到其他几台机器，并且source .bashrc</p>
<div class="highlight"><pre><code class="text">[root@desktop1 ~]# cat .bashrc 
# .bashrc
alias rm=&#39;rm -i&#39;
alias cp=&#39;cp -i&#39;
alias mv=&#39;mv -i&#39;
# Source global definitions
if [ -f /etc/bashrc ]; then
    . /etc/bashrc
fi
# User specific environment and startup programs
export LANG=zh_CN.utf8
export JAVA_HOME=/opt/jdk1.6.0_38
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=./:$JAVA_HOME/lib:$JRE_HOME/lib:$JRE_HOME/lib/tools.jar
export HADOOP_HOME=/opt/hadoop-2.0.0-cdh4.2.0
export HIVE_HOME=/opt/hive-0.10.0-cdh4.2.0
export HBASE_HOME=/opt/hbase-0.94.2-cdh4.2.0
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export HADOOP_YARN_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$ANT_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/bin:$HIVE_HOME/bin
[root@desktop1 ~]# source .bashrc 
</code></pre></div><div class="highlight"><pre><code class="text">将desktop1上的/opt/hadoop-2.0.0-cdh4.2.0拷贝到其他机器上

#### 启动脚本
第一次启动hadoop需要先格式化NameNode，该操作只做一次。当修改了配置文件时，需要重新格式化

    [root@desktop1 hadoop]hadoop namenode -format

在desktop1上启动hdfs：

    [root@desktop1 hadoop]#start-dfs.sh

在desktop1上启动mapreduce：

    [root@desktop1 hadoop]#start-yarn.sh

在desktop1上启动historyserver：
    [root@desktop1 hadoop]#mr-jobhistory-daemon.sh start historyserver

查看MapReduce：

    http://desktop1:8088/cluster

查看节点：
    http://desktop2:8042/
    http://desktop2:8042/node

#### 检查集群进程 

    [root@desktop1 ~]# jps
    5389 NameNode
    5980 Jps
    5710 ResourceManager
    7032 JobHistoryServer
    [root@desktop2 ~]# jps
    3187 Jps
    3124 SecondaryNameNode
    [root@desktop3 ~]# jps
    3187 Jps
    3124 DataNode
    5711 NodeManager

### 安装HBase
HBase安装在desktop3、desktop4、desktop6、desktop7、desktop8机器上。

1. 上传文件
上传hbase-0.94.2-cdh4.2.0.zip到desktop3上，先在desktop3上修改好配置文件，在同步到其他机器上。

2. hbase-site.xml 

    [root@desktop3 conf]# pwd
    /opt/hbase-0.94.2-cdh4.2.0/conf
    [root@desktop3 conf]# cat hbase-site.xml 
    &lt;?xml version=&quot;1.0&quot;?&gt;
    &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
    &lt;configuration&gt;
    &lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://desktop1/hbase-${user.name}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
    &lt;value&gt;/opt/data/hbase-${user.name}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;desktop3,desktop4,desktop6,desktop7,desktop8&lt;/value&gt;
    &lt;/property&gt;
    &lt;/configuration&gt;

3. regionservers

    [root@desktop3 conf]# cat regionservers 
    desktop3
    desktop4
    desktop6
    desktop7
    desktop8

4. 环境变量
参考hadoop中环境变量的设置

5. 同步文件
同步文件到其他4台机器上

6. 启动脚本
可以在desktop3上配置无密码登陆到其他机器，然后在desktop3上启动hbase，这样其他节点上hbase都可以启动，否则，需要每台机器上单独启动hbase

    [root@desktop3 ~]# start-hbase.sh 

7. HBase 

    [root@desktop3 ~]# hbase 
    HBase ; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands.
    Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase 
    Version 0.94.2-cdh4.2.0, r, Fri Feb 15 11:37:00 PST 2013
    hbase(main):001:0&gt; 

### 安装hive
hive安装在desktop1上

####  上传文件
上传hive-0.10.0-cdh4.2.0.tar到desktop1的/opt，并解压缩

#### 安装postgres
1. 创建数据库

    psql -U postgres
    CREATE DATABASE metastore;
     \c metastore;
    CREATE USER hiveuser WITH PASSWORD &#39;password&#39;;
    GRANT ALL ON DATABASE metastore TO hiveuser;
    \q

2. 初始化数据库

    psql  -U hiveuser -d metastore
     \i /opt/hive-0.10.0-cdh4.2.0/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql 

3. 编辑配置文件

    [root@desktop1 ~]# vi /opt/PostgreSQL/9.1/data/pg_hba.conf
    # IPv4 local connections:
    host    all             all             0.0.0.0/0            md5
    [root@desktop1 ~]# vi postgresql.conf
    standard_conforming_strings = off

4. 重起postgres

    su -c &#39;/opt/PostgreSQL/9.1/bin/pg_ctl -D /opt/PostgreSQL/9.1/data restart&#39; postgres

5. 拷贝postgres 的jdbc驱动到/opt/hive-0.10.0-cdh4.2.0/lib

####  修改配置文件
1. hive-site.xml 
注意修改下面配置文件中postgres数据库的密码

    [root@desktop1 ~]# cd /opt/hive-0.10.0-cdh4.2.0/conf/
    [root@desktop1 conf]# cat hive-site.xml 
    &lt;?xml version=&quot;1.0&quot;?&gt;
    &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
    &lt;configuration&gt;
    &lt;property&gt;
      &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
      &lt;value&gt;jdbc:postgresql://127.0.0.1/metastore&lt;/value&gt;
      &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
      &lt;value&gt;org.postgresql.Driver&lt;/value&gt;
      &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
      &lt;value&gt;hiveuser&lt;/value&gt;
      &lt;description&gt;username to use against metastore database&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
      &lt;value&gt;redhat&lt;/value&gt;
      &lt;description&gt;password to use against metastore database&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
     &lt;name&gt;mapred.job.tracker&lt;/name&gt;
     &lt;value&gt;desktop1:8031&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
     &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.aux.jars.path&lt;/name&gt;
      &lt;value&gt;file:///opt/hive-0.10.0-cdh4.2.0/lib/zookeeper-3.4.5-cdh4.2.0.jar,file:///opt/hive-0.10.0-cdh4.2.0/lib/hive-hbase-handler-0.10.0-cdh4.2.0.jar,file:///opt/hive-0.10.0-cdh4.2.0/lib/hbase-0.94.2-cdh4.2.0.jar,file:///opt/hive-0.10.0-cdh4.2.0/lib/guava-11.0.2.jar&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
      &lt;value&gt;/opt/data/warehouse-${user.name}&lt;/value&gt;
      &lt;description&gt;location of default database for the warehouse&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;
      &lt;value&gt;/opt/data/hive-${user.name}&lt;/value&gt;
      &lt;description&gt;Scratch space for Hive jobs&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.querylog.location&lt;/name&gt;
      &lt;value&gt;/opt/data/querylog-${user.name}&lt;/value&gt;
      &lt;description&gt;
        Location of Hive run time structured log file
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.support.concurrency&lt;/name&gt;
      &lt;description&gt;Enable Hive&#39;s Table Lock Manager Service&lt;/description&gt;
      &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;
      &lt;description&gt;Zookeeper quorum used by Hive&#39;s Table Lock Manager&lt;/description&gt;
      &lt;value&gt;desktop3,desktop4,desktop6,desktop7,desktop8&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.hwi.listen.host&lt;/name&gt;
      &lt;value&gt;desktop1&lt;/value&gt;
      &lt;description&gt;This is the host address the Hive Web Interface will listen on&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.hwi.listen.port&lt;/name&gt;
      &lt;value&gt;9999&lt;/value&gt;
      &lt;description&gt;This is the port the Hive Web Interface will listen on&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hive.hwi.war.file&lt;/name&gt;
      &lt;value&gt;lib/hive-hwi-0.10.0-cdh4.2.0.war&lt;/value&gt;
      &lt;description&gt;This is the WAR file with the jsp content for Hive Web Interface&lt;/description&gt;
    &lt;/property&gt;
    &lt;/configuration&gt;

2. 环境变量
参考hadoop中环境变量的设置

3. 启动脚本

    [root@desktop1 ~] hive

4. hive与hbase集成
在hive-site.xml中配置hive.aux.jars.path
在环境变量中配置hadoop、mapreduce的环境变量


### 异常说明
1. FAILED: Error in metadata: MetaException(message:org.apache.hadoop.hbase.ZooKeeperConnectionException: An error is preventing HBase from connecting to ZooKeeper
hadoop配置文件没有zk

2. FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: Error executing JDOQL query &quot;SELECT &quot;THIS&quot;.&quot;TBL_NAME&quot; AS NUCORDER0 FROM &quot;TBLS&quot; &quot;THIS&quot; LEFT OUTER JOIN &quot;DBS&quot; &quot;THIS_DATABASE_NAME&quot; ON &quot;THIS&quot;.&quot;DB_ID&quot; = &quot;THIS_DATABASE_NAME&quot;.&quot;DB_ID&quot; WHERE &quot;THIS_DATABASE_NAME&quot;.&quot;NAME&quot; = ? AND (LOWER(&quot;THIS&quot;.&quot;TBL_NAME&quot;) LIKE ? ESCAPE &#39;\\&#39; ) ORDER BY NUCORDER0 &quot; : ERROR: invalid escape string
  建议：Escape string must be empty or one character..

---&gt; https://issues.apache.org/jira/browse/HIVE-3994

3. hive&gt; select count(*) from hive_userinfo; 没反应

4. 2013-03-18 14:26:00,261 INFO  zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(966)) - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (无法定位登录配置)
hive中没有设置zk

5. hbase 中提示：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

6. Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/hadoop/mapreduce/v2/app/MRAppMaster
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.mapreduce.v2.app.MRAppMaster
检查环境变量以及yarn的classpath
</code></pre></div>

	<div class="eof">-<strong>原创文章，转载请注明：</strong>转载自：<a href='/Hadoop/2013/03/24/manual-install-hadoop-CDH4.2.html'>JavaChen Blog</a>-
		<br/>
		<br/>
		<!-- JiaThis Button BEGIN -->
		<div class="jiathis_style_32x32">
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_tqq"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_twitter"></a>
		<a class="jiathis_button_fb"></a>
		<a class="jiathis_button_googleplus"></a>
		<a class="jiathis_button_translate"></a>
		<a class="jiathis_button_delicious"></a>
		<a class="jiathis_button_sdonote"></a>
		<a class="jiathis_button_ydnote"></a>
		<a class="jiathis_button_qingbiji"></a>
		<a class="jiathis_button_fav"></a>
		<a class="jiathis_button_ishare"></a>
		<a class="jiathis_button_copy"></a>
		<a class="jiathis_button_email"></a>
		<a class="jiathis_button_print"></a>
		<a class="jiathis_button_printfriendly"></a>
		<a class="jiathis_button_pdfonline"></a>
		<a href="http://www.jiathis.com/share?uid=1709061" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
		<a class="jiathis_counter_style"></a>
		</div>
		<script type="text/javascript" >
		var jiathis_config={
			data_track_clickback:true,
			summary:"",
			hideMore:false
		}
		</script>
		<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1709061" charset="utf-8"></script>
		<!-- JiaThis Button END -->



		<!-- UJian Button BEGIN -->
		<div class="ujian-hook"></div>
		<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?uid=1709061"></script>
		<a href="http://www.ujian.cc" style="border:0;"><img src="http://img.ujian.cc/pixel.png" alt="友荐云推荐" style="border:0;padding:0;margin:0;" /></a>
		<!-- UJian Button END -->
	</div>
	
	<hr/>
	<div class="page fix">
		
		<span class="prev"><a href="/Hadoop/2013/03/08/note-about-installing-hadoop-cluster.html">← 【笔记】Hadoop安装部署</a></span>
		
		
	</div>
	<hr/>
</article>

<div id="comment">
	<!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread"></div>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"javachen"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END -->
</div>

<script src="/js/jquery-min.js"></script>
<script src="/js/Fullscreen.js"></script>
<script type="text/javascript">
$(function() {
	// =============== 全屏显示 ==================
	(function() {
		var icon = $( 'a.icon-fullscreen' ),
			fs, fsCallback;
		
		fsCallback = function(isFullscreen) {
				if (isFullscreen) {
					icon.addClass('expand').attr('title', 'ESC 退出全屏');
				}
				else {
					icon.removeClass('expand').attr('title', '点击全屏显示');
				}
			};
			
		fs = new Fullscreen({
				element: $('#post'),
				noSafari: true,
				callback: fsCallback
			});

		if (fs.fullscreenEnabled) {
			icon.on('click', function() {
				fs.toggleFullscreen();
				return false;
			});
		}
		else {
			icon.hide();
		}
	})();


	// ============== 目录提取 ===============
	(function() {
		// 设置无目录时，不显示
		if (!parseInt('', 10)) {
			return;
		}

		var dom = $('<fieldset id="catalogue"><legend>目录</legend></fieldset>'),
			count = 0;
		
		$('#post').find('h2,h3,h4,h5').each(function() {
			var name = 'catalogue_' + count++;
			dom.append('<div class="txt_' + this.tagName + '">' +
				'<a href="#' + name + '">' +
					this.innerHTML +
				'</a></div>');
			this.id = name;
		});

		dom.appendTo('body');
	})();
});
</script>
<!-- UJian Button BEGIN -->
<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?type=slide&btn=4&fade=1&uid=1709061"></script>
<!-- UJian Button END -->


		</section><!--/content end-->

		<footer id="footer">
			<p class="l">
				&copy; 2013 <a href="http://blog.javachen.com">JavaChen</a>. | Powered by <a href="https://github.com/mojombo/jekyll">Jekyll</a> and <a href="http://pages.github.com/">GitHub Pages</a>
			</p>
			<!--Templates from <a href='https://github.com/calefy/calefy.github.com' target='_blank'>calefy</a>.-->
			<p class="r">
				<script language="javascript" type="text/javascript" src="http://js.users.51.la/12111481.js"></script>
<noscript><a href="http://www.51.la/?12111481" target="_blank"><img alt="Statistic" src="http://img.users.51.la/12111481.asp" style="border:none" /></a></noscript>
			</p>
			<p class="tac">
				<small>『纸上得来终觉浅，绝知此事要躬行』</small>
			</p>
		</footer><!--/footer end-->



	</body>
</html>
