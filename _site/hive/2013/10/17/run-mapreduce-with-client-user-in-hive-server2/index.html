
<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="pragma" content="no-cache" />
    <title>hive-server2中使用jdbc客户端用户运行mapreduce - JavaChen Blog</title>
    <meta name="description" content="为了实现mapreduce任务中资源按用户调度，需要hive查询自动绑定当前用户、将该用户传到yarn服务端并使mapreduce程序以该用户运行" />
    <meta name="author" content="JavaChen">
    <meta name="copyright" content="© http://blog.javachen.com" />
    <meta property="wb:webmaster" content="61eb31a6e636506d" />
    <meta name="wumiiVerification" content="eec4ca3c-ccdb-4c0f-9fe3-4499d87649a3" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap-responsive.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/favicon.ico">
	<!-- Update these with your own images
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	-->
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Handlee">
    <script src="/assets/themes/twitter/js/jquery.js"></script>
    <script src="/assets/themes/twitter/js/main.js"></script>
  </head>

  <body data-spy="scroll" data-target=".navbar" data-offset="100">

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">JavaChen Blog</a>
          <div class="nav-collapse">
	    <ul class="nav">


              <li><a href="/sitemap.xml">Sitemap</a></li>
              <li><a href="/about.html">About</a></li>
              <li><a href="/archive.html">Archive</a></li>
              <li><a href="/tags.html">Tags</a></li>
	    </ul>
            <ul class="nav pull-right" data-subscription="rss">
                 <li>
			    <!-- my custom google search -->
			    <form class="pull-right navbar-search" id="search-form">
				<input type="text" id="google-search" class="search-query" placeholder="Search">
			    </form>
		 </li>
	 	 <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
	    </ul>
          </div>
        </div>
      </div>
    </div>

    <div class="container">

      <div class="content">
        

<div class="page-header">
  	<h1>hive-server2中使用jdbc客户端用户运行mapreduce </h1>
	<div class="info">
		Categories：<a href="/categories.html#hive-ref">hive</a>
		| Tags：<a href="/tags.html#hive-ref">hive</a>,<a href="/tags.html#hive-server2-ref">hive-server2</a>,<a href="/tags.html#hwi-ref">hwi</a>
		| Time：<time date="2013-10-17">2013-10-17</time>
		<a href='#comments' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>
</div>


<div class="row">
  <div class="span9">
    
    <p>最近做了个web系统访问hive数据库，类似于官方自带的hwi、安居客的<a href="https://github.com/anjuke/hwi">hwi改进版</a>和大众点评的<a href="http://blog.csdn.net/lalaguozhe/article/details/9614061">polestar</a>(<a href="https://github.com/dianping/polestar">github地址</a>)系统，但是和他们的实现不一样，查询Hive语句走的不是cli而是通过jdbc连接hive-server2。为了实现mapreduce任务中资源按用户调度，需要hive查询自动绑定当前用户、将该用户传到yarn服务端并使mapreduce程序以该用户运行。本文主要是记录实现该功能过程中遇到的一些问题以及解决方法,如果你有更好的方法和建议，欢迎留言发表您的看法！</p>

<h1>hive-server2的启动</h1>

<p>先从hive-server2服务的启动开始说起。</p>

<p>如果你是以服务的方式启动hive-server2进程，则启动hive-server2的用户为hive,运行mapreduce的用户也为hive，启动脚本如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">/etc/init.d/hive-server2 start
</code></pre></div>
<p>如果你以命令行方式启动hive-server2进程，则启动hive-server2的用户为root,运行mapreduce的用户也为root，启动脚本如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hive --service hiveserver2
</code></pre></div>
<p>为什么是上面的结论？这要从hive-server2的启动过程开始说明。</p>

<!-- more -->

<p>查看HiveServer2.java的代码可以看到，hive-server2启动时会依次启动<code>cliService</code>和<code>thriftCLIService</code>，查看cliService的init()方法，可以看到如下代码：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">public synchronized void init(HiveConf hiveConf) {
    this.hiveConf = hiveConf;

    sessionManager = new SessionManager();
    addService(sessionManager);
    try {
      HiveAuthFactory.loginFromKeytab(hiveConf);
      serverUserName = ShimLoader.getHadoopShims().
          getShortUserName(ShimLoader.getHadoopShims().getUGIForConf(hiveConf));
    } catch (IOException e) {
      throw new ServiceException(&quot;Unable to login to kerberos with given principal/keytab&quot;, e);
    } catch (LoginException e) {
      throw new ServiceException(&quot;Unable to login to kerberos with given principal/keytab&quot;, e);
    }
    super.init(hiveConf);
  }
</code></pre></div>
<p>从上面的代码可以看到在cliService初始化过程中会做登陆（从kertab中登陆）和获取用户名的操作：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">ShimLoader.getHadoopShims().getUGIForConf(hiveConf)
</code></pre></div>
<p>上面代码最终会调用HadoopShimsSecure类的getUGIForConf方法：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">@Override
public UserGroupInformation getUGIForConf(Configuration conf) throws IOException {
  return UserGroupInformation.getCurrentUser();
}
</code></pre></div>
<p>UserGroupInformation.getCurrentUser()代码如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text"> public synchronized
  static UserGroupInformation getCurrentUser() throws IOException {
    AccessControlContext context = AccessController.getContext();
    Subject subject = Subject.getSubject(context);
    if (subject == null || subject.getPrincipals(User.class).isEmpty()) {
      return getLoginUser();
    } else {
      return new UserGroupInformation(subject);
    }
  }
</code></pre></div>
<p>因为这时候服务刚启动，subject为空，故if分支会调用<code>getLoginUser()</code>方法，其代码如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">  public synchronized 
  static UserGroupInformation getLoginUser() throws IOException {
    if (loginUser == null) {
      try {
        Subject subject = new Subject();
        LoginContext login;
        if (isSecurityEnabled()) {
          login = newLoginContext(HadoopConfiguration.USER_KERBEROS_CONFIG_NAME,
              subject, new HadoopConfiguration());
        } else {
          login = newLoginContext(HadoopConfiguration.SIMPLE_CONFIG_NAME, 
              subject, new HadoopConfiguration());
        }
        login.login();
        loginUser = new UserGroupInformation(subject);
        loginUser.setLogin(login);
        loginUser.setAuthenticationMethod(isSecurityEnabled() ?
                                          AuthenticationMethod.KERBEROS :
                                          AuthenticationMethod.SIMPLE);
        loginUser = new UserGroupInformation(login.getSubject());
        String fileLocation = System.getenv(HADOOP_TOKEN_FILE_LOCATION);
        if (fileLocation != null) {
          // Load the token storage file and put all of the tokens into the
          // user. Don&#39;t use the FileSystem API for reading since it has a lock
          // cycle (HADOOP-9212).
          Credentials cred = Credentials.readTokenStorageFile(
              new File(fileLocation), conf);
          loginUser.addCredentials(cred);
        }
        loginUser.spawnAutoRenewalThreadForUserCreds();
      } catch (LoginException le) {
        LOG.debug(&quot;failure to login&quot;, le);
        throw new IOException(&quot;failure to login&quot;, le);
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(&quot;UGI loginUser:&quot;+loginUser);
      }
    }
    return loginUser;
  }
</code></pre></div>
<p>因为是第一次调用getLoginUser(),故loginUser为空，接下来会创建LoginContext并调用其login方法，login方法最终会调用HadoopLoginModule的commit()方法。</p>

<p>下图是从hive-server2启动到执行HadoopLoginModule的commit()方法的调用图：</p>

<p><img src="files/2013/hive-server2-invoke.png" alt="hive-server2启动过程"></p>

<p>获取登陆用户的关键代码就在commit()，逻辑如下：</p>

<ul>
<li>如果使用了kerberos，则为kerberos登陆用户。hive-server2中如何使用kerberos登陆，请查看官方文档。</li>
<li>如果kerberos用户为空并且没有开启security，则从系统环境变量中取<code>HADOOP_USER_NAME</code>的值</li>
<li>如果环境变量中没有设置HADOOP<em>USER</em>NAME，则使用系统用户，即启动hive-server2进程的用户。</li>
</ul>

<h2>小结</h2>

<p>hive-server2启动过程中会做登陆操作并获取到登陆用户，启动之后再次调用<code>UserGroupInformation.getCurrentUser()</code>取到的用户就为登陆用户了，这样会导致所有请求到hive-server2的hql最后都会以这个用户来运行mapreduce。</p>

<h1>提交hive任务</h1>

<p>现在来看hive任务是怎么提交到yarn服务端然后运行mapreduce的。</p>

<p>为了调试简单，我在本机eclipse的hive源代码中配置<code>hive-site.xml、core-site.xml、mapred.xml、yarn-site.xml</code>连接测试集群,添加缺少的yarn依赖并解决hive-builtins中报错的问题，然后运行HiveServer2类的main方法。<em>注意</em>，我的电脑当前登陆用户为june，故启动hive-server2的用户为june。</p>

<p>然后，在运行jdbc测试类，运行一个简单的sql语句，大概如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">public static void test() {
    try {
        Class.forName(&quot;org.apache.hive.jdbc.HiveDriver&quot;);

        Connection conn = DriverManager.getConnection(
                &quot;jdbc:hive2://june-mint:10000/default&quot;, &quot;&quot;, &quot;&quot;);

        Statement stmt = conn.createStatement();

        ResultSet rs = stmt.executeQuery(&quot;select count(1) from t&quot;);

        while (rs.next())
            System.out.println(rs.getString(1));

        rs.close();
        stmt.close();
        conn.close();
    } catch (SQLException se) {
        se.printStackTrace();
    } catch (Exception e) {
        e.printStackTrace();
    }
}
</code></pre></div>
<p>查看yarn监控地址<code>http://192.168.56.101:8088/cluster</code>，可以看到提交的mapreduce任务由june用户来运行。</p>

<p><img src="files/2013/20131017-01.png" alt="yarn cluster monitor page"></p>

<p>如何修改mapreduce任务的运行用户呢？如果了解hive提交mapreduce任务的过程的话，就应该知道hive任务会通过<code>org.apache.hadoop.mapred.JobClient</code>来提交。在JobClient的init方法中有如下代码：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">  public void init(JobConf conf) throws IOException {
    setConf(conf);
    cluster = new Cluster(conf);
    clientUgi = UserGroupInformation.getCurrentUser();
  }
</code></pre></div>
<p>JobClient类中提交mapreduce任务的代码如下，见submitJobInternal方法：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">Job job = clientUgi.doAs(new PrivilegedExceptionAction&lt;Job&gt; () {
    @Override
    public Job run() throws IOException, ClassNotFoundException, 
      InterruptedException {
      Job job = Job.getInstance(conf);
      job.submit();
      return job;
    }
});
</code></pre></div>
<p>从前面知道，hive-server2启动中会进行登陆操作并且登陆用户为june，故clientUgi对应的登陆用户也为june，故提交的mapreduce任务也通过june用户来运行。</p>

<h1>如何修改源代码</h1>

<p>从上面代码可以知道，修改clientUgi的获取方式就可以改变提交任务的用户。UserGroupInformation中存在如下静态方法：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">  public static UserGroupInformation createRemoteUser(String user) {
    if (user == null || &quot;&quot;.equals(user)) {
      throw new IllegalArgumentException(&quot;Null user&quot;);
    }
    Subject subject = new Subject();
    subject.getPrincipals().add(new User(user));
    UserGroupInformation result = new UserGroupInformation(subject);
    result.setAuthenticationMethod(AuthenticationMethod.SIMPLE);
    return result;
  }
</code></pre></div>
<p>故可以尝试使用该方法，修改JobClient的init方法如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text"> public void init(JobConf conf) throws IOException {
    setConf(conf);
    cluster = new Cluster(conf);
    if(UserGroupInformation.isSecurityEnabled()){
        clientUgi = UserGroupInformation.getCurrentUser();
    }else{
        String user = conf.get(&quot;myExecuteName&quot;,&quot;NoName&quot;);
        clientUgi = UserGroupInformation.createRemoteUser(user);
    }
  }
</code></pre></div>
<p>编译代码、替换class文件，然后重新运行HiveServer2以及jdbc测试类，查看yarn监控地址<code>http://192.168.56.101:8088/cluster</code>，截图如下：</p>

<p><img src="files/2013/20131017-02.png" alt="yarn cluster monitor page"></p>

<p>这时候mapreduce的运行用户变为NoName，这是因为从JobConf环境变量中找不到myExecuteName变量而使用默认值NoName的原因。</p>

<p>查看hive-server2运行日志，会发现任务运行失败，关键异常信息如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=NoName, access=WRITE, inode=&quot;/tmp/hive-june/hive_2013-10-18_21-18-12_812_378750610917949668/_tmp.-ext-10001&quot;:june:hadoop:drwxr-xr-x
    at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:224)
    at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:204)
    at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:149)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4705)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4687)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:4661)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameToInternal(FSNamesystem.java:2696)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameToInt(FSNamesystem.java:2663)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2642)
    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename(NameNodeRpcServer.java:610)
    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename
</code></pre></div>
<p>出现上述异常是因为，mapreduce任务在运行过程中会生成一些临时文件，而NoName用户对临时文件没有写的权限，这些临时文件属于june用户。查看hdfs文件如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">[root@edh1 lib]# hadoop fs -ls /tmp/
Found 6 items
drwx------   - june hadoop          0 2013-10-15 01:33 /tmp/hadoop-yarn
drwxr-xr-x   - june hadoop          0 2013-10-16 06:52 /tmp/hive-june
</code></pre></div>
<p><code>/tmp/hive-june</code>是hive执行过程中保存在hdfs的路径，由<code>hive.exec.scratchdir</code>定义，其默认值为<code>/tmp/hive-${user.name}</code>，而且这个文件是在<code>org.apache.hadoop.hive.ql.Context</code>类的构造方法中获取并在ExecDriver类的execute(DriverContext driverContext)方法中创建的。</p>

<p>类似这样的权限问题还会出现在hdfs文件<code>重命名、删除临时目录的时候</code>。为了避免出现这样的异常，需要修改<code>hive.exec.scratchdir</code>为当前用户对应的临时目录路径，并使用当前登陆用户创建、重命名、删除临时目录。</p>

<p>修改获取<code>hive.exec.scratchdir</code>对应的临时目录代码如下，在Context类的够找方法中修改：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">    String user = conf.get(myExecuteName，“”);

    if (user != null &amp;&amp; user.trim().length() &gt; 0) {
      nonLocalScratchPath =
          new Path(&quot;/tmp/hive-&quot; + user, executionId);
    } else {
      nonLocalScratchPath =
          new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR),
              executionId);
    }
</code></pre></div>
<p>找到这些操作对应的代码似乎太过复杂了，修改的地方也有很多，因为这里是使用的hive-server2，故在对应的jdbc代码中修改似乎会简单很多，例如修改HiveSessionImpl类的以下三个方法：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">public OperationHandle executeStatement(String statement, Map&lt;String, String&gt; confOverlay) throws HiveSQLException{}

public void cancelOperation(final OperationHandle opHandle) throws HiveSQLException {}

public void closeOperation(final OperationHandle opHandle) throws HiveSQLException {}
</code></pre></div>
<p>第一个方法是运行sql语句，第二个方法是取消运行，第三个方法是关闭连接。</p>

<p>executeStatement中所做的修改如下，将<code>operation.run();</code>改为：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">    if (operation instanceof SQLOperation) {
        try {
          String user = hiveConf.getVar(ConfVars.HIVE_SERVER2_MAPREDUCE_USERNAME);
          ugi = UserGroupInformation.createRemoteUser(user);
          ugi.doAs(new PrivilegedExceptionAction&lt;CommandProcessorResponse&gt;() {
            @Override
            public CommandProcessorResponse run() throws HiveSQLException {
              operation.run();
              return null;
            }
          });
        } catch (IOException e) {
          e.printStackTrace();
        } catch (InterruptedException e) {
          e.printStackTrace();
        }
      } else {
        operation.run();
      }
</code></pre></div>
<p>这里添加了判断，当operation操作时，才执行下面代码，这是为了保证从hive环境变量中获取myExecuteName的值不为空时才创建UserGroupInformation。</p>

<p>myExecuteName是新定义的hive变量，主要是用于jdbc客户端通过set语句设置myExecuteName的值为当前登陆用户名称，然后在执行sql语句。代码如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">Statement stmt = conn.createStatement();

stmt.execute(&quot;set myExecuteName=aaaa&quot;);
ResultSet rs = stmt.executeQuery(&quot;select count(1) from t&quot;);

while (rs.next())
    System.out.println(rs.getString(1));
</code></pre></div>
<h2>小结</h2>

<p>上面修改的类包括：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">org.apache.hadoop.mapred.JobClient //从环境变量获取从jdbc客户端传过来的用户，即myExecuteName的值，然后以该值运行mapreduce用户
org.apache.hadoop.hive.ql.Context  //修改hive.exec.scratchdir的地址为从jdbc客户端传过来的用户对应的临时目录
org.apache.hive.service.cli.session.HiveSessionImpl //修改运行sql、取消操作、关闭连接对应的方法
</code></pre></div>
<h1>测试</h1>

<p>是用javachen用户测试,hdfs上的临时目录如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">[root@edh1 lib]# hadoop fs -ls /tmp/
Found 7 items
drwx------   - june         hadoop          0 2013-10-15 01:33 /tmp/hadoop-yarn
drwxr-xr-x   - javachen.com hadoop          0 2013-10-16 07:30 /tmp/hive-javachen.com
drwxr-xr-x   - june         hadoop          0 2013-10-16 06:52 /tmp/hive-june
drwxr-xr-x   - root         hadoop          0 2013-10-15 14:13 /tmp/hive-root
drwxrwxrwt   - yarn         mapred          0 2013-10-16 07:30 /tmp/logs
</code></pre></div>
<p>监控页面截图：</p>

<p><img src="files/2013/20131017-03.png" alt="yarn cluster monitor page"></p>

<p>除了简单测试之外，还需要测试修改后的代码是否影响源代码的运行以及hive cli的运行。</p>

<h1>Enjoy it ！</h1>


    <br/>
    <div class="copyright">
	<p><strong>本文固定链接：</strong><a href='/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2'>http://blog.javachen.com/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2</a></p>
	<p><strong>原创文章,转载请注明出处：</strong><a href='/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2'>JavaChen Blog</a></p>
    </div>
     
    <div style="float:right">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style_32x32">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_cqq"></a>
	<a class="jiathis_button_sdonote"></a>
	<a class="jiathis_button_ydnote"></a>
	<a class="jiathis_button_qingbiji"></a>
	<a href="http://www.jiathis.com/share?uid=1709061" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
	</div>
	<script type="text/javascript" >
	var jiathis_config={
		data_track_clickback:true,
		summary:"",
		hideMore:false
	}
	</script>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1709061" charset="utf-8"></script>
	<!-- JiaThis Button END -->
    </div>

    <!-- wumi Button BEGIN -->
    <script type="text/javascript" id="wumiiRelatedItems"></script>
    <!-- wumi Button END -->
    <hr>
    <div class="pagination">
      <ul>
      
        <li class="prev"><a href="/hive/2013/10/17/cartesian-product-in-hive-inner-join" title="hive连接产生笛卡尔集">&larr; Previous</a></li>
      
        <li><a href="/archive.html">Archive</a></li>
      
        <li class="next disabled"><a>Next &rarr;</a>
      
      </ul>
    </div>
    <hr>
    
  </div>
  <div class="span3">
  <section>
  
    <h2>Tags</h2>
    <ul class="tag_box">
    
    


  
     
    	<li><a href="/tags.html#hive-ref">hive <span>9</span></a></li>
     
    	<li><a href="/tags.html#hive-server2-ref">hive-server2 <span>1</span></a></li>
     
    	<li><a href="/tags.html#hwi-ref">hwi <span>1</span></a></li>
    
  



    </ul>
  
  </section>  

  <section>
  
    <h2>Categories</h2>
    <ul id="category-list">
      
      


  
     
    	<li><a href="/categories.html#cloud-ref">
    		cloud <span>(9)</span>
    	</a></li>
     
    	<li><a href="/categories.html#javascript-ref">
    		javascript <span>(7)</span>
    	</a></li>
     
    	<li><a href="/categories.html#pentaho-ref">
    		pentaho <span>(3)</span>
    	</a></li>
     
    	<li><a href="/categories.html#kettle-ref">
    		kettle <span>(8)</span>
    	</a></li>
     
    	<li><a href="/categories.html#java-ref">
    		java <span>(3)</span>
    	</a></li>
     
    	<li><a href="/categories.html#cassandra-ref">
    		cassandra <span>(2)</span>
    	</a></li>
     
    	<li><a href="/categories.html#work-ref">
    		work <span>(3)</span>
    	</a></li>
     
    	<li><a href="/categories.html#hadoop-ref">
    		hadoop <span>(12)</span>
    	</a></li>
     
    	<li><a href="/categories.html#hbase-ref">
    		hbase <span>(1)</span>
    	</a></li>
     
    	<li><a href="/categories.html#hive-ref">
    		hive <span>(5)</span>
    	</a></li>
     
    	<li><a href="/categories.html#post-ref">
    		post <span>(1)</span>
    	</a></li>
    
  



    </ul>
  
  </section>

  <section>
  <h2>Related Posts</h2>
  <ul>
   
   <li><a href="/hive/2013/10/17/cartesian-product-in-hive-inner-join">hive连接产生笛卡尔集</a></li>
   
   <li><a href="/work/2013/09/08/recent-work">最近的工作</a></li>
   
   <li><a href="/hive/2013/09/04/how-to-decide-map-number">hive中如何确定map数</a></li>
   
   <li><a href="/post/2013/08/31/my-jekyll-config">我的jekyll配置和修改</a></li>
   
   <li><a href="/hadoop/2013/08/23/publish-proerties-using-zookeeper">使用ZooKeeper实现配置同步</a></li>
   
   <li><a href="/hive/2013/08/22/hive-Driver">hive Driver类运行过程</a></li>
   
   <li><a href="/hive/2013/08/21/hive-CliDriver">hive cli的入口类</a></li>
   
   <li><a href="/hadoop/2013/08/17/some-problems-about-hadoop">使用hadoop中遇到的一些问题</a></li>
   
   <li><a href="/hadoop/2013/08/02/hadoop-install-script">hadoop自动化安装shell脚本</a></li>
   
   <li><a href="/hadoop/2013/08/01/remote-debug-hadoop">远程调试hadoop各组件</a></li>
   
  </ul>
  </section>  
  <section>
    <h2>Recent Posts</h2>
    <ul id="recent_posts">
    
      <li class="post" >
        <a href="/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2">hive-server2中使用jdbc客户端用户运行mapreduce</a>
      </li>
    
      <li class="post" >
        <a href="/hive/2013/10/17/cartesian-product-in-hive-inner-join">hive连接产生笛卡尔集</a>
      </li>
    
      <li class="post" >
        <a href="/work/2013/09/08/recent-work">最近的工作</a>
      </li>
    
      <li class="post" >
        <a href="/hive/2013/09/04/how-to-decide-map-number">hive中如何确定map数</a>
      </li>
    
      <li class="post" >
        <a href="/post/2013/08/31/my-jekyll-config">我的jekyll配置和修改</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/08/23/publish-proerties-using-zookeeper">使用ZooKeeper实现配置同步</a>
      </li>
    
      <li class="post" >
        <a href="/hive/2013/08/22/hive-Driver">hive Driver类运行过程</a>
      </li>
    
      <li class="post" >
        <a href="/hive/2013/08/21/hive-CliDriver">hive cli的入口类</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/08/17/some-problems-about-hadoop">使用hadoop中遇到的一些问题</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/08/02/hadoop-install-script">hadoop自动化安装shell脚本</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/08/01/remote-debug-hadoop">远程调试hadoop各组件</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/07/20/install-rhadoop">安装RHadoop</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/06/24/install-cdh-by-cloudera-manager">通过Cloudera Manager安装CDH</a>
      </li>
    
      <li class="post" >
        <a href="/hbase/2013/04/17/access-idh-2.3-hbase-in-kettle">kettle访问IDH2.3中的HBase</a>
      </li>
    
      <li class="post" >
        <a href="/kettle/2013/04/07/add-a-field-from-paramter-to-output">kettle中添加一个参数字段到输出</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/04/06/install-cloudera-cdh-by-yum">从yum安装Cloudera CDH集群</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/03/29/install-impala">安装impala过程</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH">手动安装Cloudera Hive CDH</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH">手动安装Cloudera HBase CDH</a>
      </li>
    
      <li class="post" >
        <a href="/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH">手动安装Cloudera Hadoop CDH</a>
      </li>
    
    </ul>
  </section>
  
  </div>
</div>

<div id="comments">
	<!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread" data-title="hive-server2中使用jdbc客户端用户运行mapreduce" ></div>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"javachen"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END -->
</div>

<!-- wumi Button BEGIN -->
<script type="text/javascript">
    var wumiiPermaLink = ""; //请用代码生成文章永久的链接
    var wumiiTitle = "/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2"; //请用代码生成文章标题
    var wumiiTags = "hivehive-server2hwi"; //请用代码生成文章标签，以英文逗号分隔，如："标签1,标签2"
    var wumiiCategories = []; //请用代码生成文章分类，分类名放在 JSONArray 中，如: ["分类1", "分类2"]
    var wumiiSitePrefix = "http://blog.javachen.com/";
    var wumiiParams = "&num=7&mode=2&pf=JAVASCRIPT";
</script>
<script type="text/javascript" src="http://widget.wumii.cn/ext/relatedItemsWidget"></script>
<a href="http://www.wumii.com/widget/relatedItems" style="border:0;">
    <img src="http://static.wumii.cn/images/pixel.png" alt="无觅相关文章插件，快速提升流量" style="border:0;padding:0;margin:0;" />
</a>
<!-- wumi Button END -->


      </div>

      <footer>
        <p>&copy; JavaChen 2013 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a> | <script language="javascript" type="text/javascript" src="http://js.users.51.la/12111481.js"></script>
<noscript><a href="http://www.51.la/?12111481" target="_blank"><img alt="Statistic" src="http://img.users.51.la/12111481.asp" style="border:none" /></a></noscript>
        </p>
      </footer>
      <div id="toTop"><a href="#">▲</a><a href="#footer">▼</a></div>
    </div> <!-- /container -->
    
  </body>
</html>

