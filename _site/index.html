
<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>JavaChen Blog</title>
    <meta name="author" content="JavaChen">
    <meta property="wb:webmaster" content="61eb31a6e636506d" />
    <meta name="ujianVerification" content="f8b60286538bf86567069598d8a5d6cc" />
    <meta name="wumiiVerification" content="eec4ca3c-ccdb-4c0f-9fe3-4499d87649a3" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap-responsive.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/favicon.ico">
	<!-- Update these with your own images
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	-->
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Handlee">
  </head>

  <body data-spy="scroll" data-target=".subnav" data-offset="100">

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">JavaChen Blog</a>
          <div class="nav-collapse">
            <ul class="nav">


              <li><a href="/categories.html">Categories</a></li>
              <li><a href="/about.html">About me</a></li>
              <li><a href="/archive.html">Archive</a></li>
              <li><a href="/tags.html">Tags</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>

    <div class="container">

      <div class="content">
        


<div class="row">
  <div class="span12">
    


<div class="row">
  <div class="span8">
  
  
  <section id="hadoop20130624install-cdh-by-cloudera-manager">
    <article>
      <header>
      <h3><a href="/hadoop/2013/06/24/install-cdh-by-cloudera-manager">通过Cloudera Manager安装CDH</a></h3>
      <div class="c9">
     		Author: JavaChen
     		&emsp;&emsp;
		Categories：
			
			<a href="/categories.html#hadoop">hadoop</a>
			
			
		&emsp;&emsp;
		Tags：
			
			<a href="/tags.html#hadoop-ref">hadoop</a>
			
			,
			
			
			<a href="/tags.html#cdh-ref">cdh</a>
			
			
		&emsp;&emsp;
		<a href='/hadoop/2013/06/24/install-cdh-by-cloudera-manager#comment' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>
    </header>
    <div class="content"><p>你可以从<a href="https://ccp.cloudera.com/display/SUPPORT/Downloads">https://ccp.cloudera.com/display/SUPPORT/Downloads</a>下载cloudera-manager-installer.bin，然后修改执行权限并执行该脚本。
该脚本中配置的rhel6的yum源为：<a href="http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/4/">http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/4/</a>，下载的过程必须连网并且rpm的过程会非常慢，这种方法对虚拟机或者是无法连网的内网机器来说根本无法使用。</p>

<p>因为知道所有的rpm都在上面网址可以下载到，故你可以手动下载这些rpm然后手动安装，详细过程请参考：<a href="http://dreamyue.com/post/41090075449/cloudera-manager-hadoop">通过cloudera-manager来安装hadoop</a>。</p>

<p>这里还有一种方法，就是手动下载<code>Cloudera Manager</code>的yum tar包，在虚拟机中搭建一个本地yum源，然后修改hosts文件，使<code>archive.cloudera.com</code>域名映射到本地ip。</p>

<p>出于好奇，想破解<code>cloudera-manager-installer.bin</code>，然后看看其中做了哪些操作。通过以下脚本即可解压该文件：</p>

<pre><code>[june@june-fedora cdh]$ mv cloudera-manager-installer.bin cloudera-manager-installer.zip
[june@june-fedora cdh]$ unzip cloudera-manager-installer.zip 
</code></pre>

<p>解压之后的目录如下：</p>

<pre><code>[june@june-fedora cloudera-manager-installer]$ ll
总用量 512
-rwxrwxr-x. 1 june june 501698 5月  25 09:53 cloudera-manager-installer.zip
drwxr-xr-x. 2 june june   4096 5月  23 03:05 data
drwxr-xr-x. 2 june june   4096 5月  22 21:48 guis
drwxr-xr-x. 2 june june   4096 5月  22 21:48 meta
drwxr-xr-x. 2 june june   4096 5月  22 21:48 scripts
</code></pre>

<p>查看解压之后的文件可以看到安装脚本是用lua编写并用MojoSetup编译的，从scripts/config.lua脚本中大概可以看出安装脚本的执行过程。</p>

<p>整理下该脚本逻辑，主要是做了以下操作：</p>

<pre><code>yum install -y jdk.x86_64 
yum install -y cloudera-manager-server 
yum install -y cloudera-manager-server-db
/etc/init.d/cloudera-scm-server start
/etc/init.d/cloudera-scm-server-db start
</code></pre>

<p>知道了上面这点之后，就可以在本地的cloudera-manager yum中，执行以上操作完成cloudera-manager的安装，安装成功之后即可以访问web界面。</p>
</div>
    </article>
  </section>
  
  
  <section id="hadoop20130417access-idh-2.3-hbase-in-kettle">
    <article>
      <header>
      <h3><a href="/hadoop/2013/04/17/access-idh-2.3-hbase-in-kettle">kettle访问IDH2.3中的HBase</a></h3>
      <div class="c9">
     		Author: JavaChen
     		&emsp;&emsp;
		Categories：
			
			<a href="/categories.html#hadoop">hadoop</a>
			
			
		&emsp;&emsp;
		Tags：
			
			<a href="/tags.html#kettle-ref">kettle</a>
			
			,
			
			
			<a href="/tags.html#idh-ref">idh</a>
			
			,
			
			
			<a href="/tags.html#hadoop-ref">hadoop</a>
			
			,
			
			
			<a href="/tags.html#bigdata-ref">bigdata</a>
			
			,
			
			
			<a href="/tags.html#hbase-ref">hbase</a>
			
			
		&emsp;&emsp;
		<a href='/hadoop/2013/04/17/access-idh-2.3-hbase-in-kettle#comment' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>
    </header>
    <div class="content"><p>Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，绿色无需安装，数据抽取高效稳定。<a href="https://github.com/pentaho/big-data-plugin">big-data-plugin</a>是kettle中用于访问bigdata，包括hadoop、cassandra、mongodb等nosql数据库的一个插件。</p>

<p>截至目前，kettle的版本为4.4.1，<code>big-data-plugin</code>插件支持<code>cloudera CDH3u4、CDH4.1</code>，暂不支持Intel的hadoop发行版本IDH。</p>

<p>本文主要介绍如何让kettle支持IDH的hadoop版本。</p>

<p>假设你已经安装好IDH-2.3的集群，并已经拷贝出<code>/usr/lib/</code>下的hadoop、hbase、zookeeper目录。</p>

<p>首先，下载一个kettle版本，如社区版data-integration，然后进入<code>data-integration/plugins/pentaho-big-data-plugin</code>目录，修改plugin.properties文件中的<code>active.hadoop.configuration</code>属性，将其值改为cdh4</p>

<pre><code>active.hadoop.configuration=cdh4
</code></pre>

<p>修改kettle的log4j日志等级，并启动kettle，检查启动过程中是否报错，如有错误，请修正错误。</p>

<p>进入hadoop-configurations目录，copy and paste cdh3u4并命名为idh2.3。</p>

<p>因为IDH和CDH的hadoop版本不一致，故需要替换hadoop和hbase、zookeeper为IDH的版本，涉及到需要替换、增加的jar有，这些jar文件从IDH安装后的目录中拷贝即可：</p>

<pre><code>data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/hbase-0.94.1-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/protobuf-java-2.4.0a.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/zookeeper-3.4.5-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-ant-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-core-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-examples-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-test-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-tools-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libthrift-0.8.0.jar
</code></pre>

<p>其他依赖包可以尝试添加，并删除多版本的jar文件。</p>

<p>需要删除CDH的jar有：</p>

<pre><code>data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/hbase-0.90.6-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/zookeeper-3.3.5-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-client-0.20.2-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-core-0.20.2-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libfb303-0.5.0-cdh.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libthrift-0.5.0-cdh.jar
</code></pre>

<p>修改plugin.properties文件中的active.hadoop.configuration属性，将其值改为idh2.3。重起kettle，观察启动过程中是否报错。</p>

<h3>验证是否可以访问IDH2.3中的hbase。</h3>

<ol>
<li>打开hbase output组件，配置zookeeper的host和port</li>
</ol>


<p><img src="/files/2013/hbase-output-setup-for-idh-2.3.png" alt="hbase-output-setup-for-idh-2.3" /></p>

<ol>
<li><p>在<code>Create/Edit mappings</code> tab页点击<code>Get table names</code>，发现该组件卡住，kettle控制台提示异常则需要检查客户端jar版本和服务端是否一致：</p>

<p> 13/04/17 10:22:13 INFO client.HConnectionManager$HConnectionImplementation: getMaster attempt 0 of 10 failed;
 retrying after sleep of 1000
 java.io.IOException: Call to OS-GZP2308-04/192.168.40.84:60000 failed on local exception: java.io.EOFException
     at org.apache.hadoop.hbase.ipc.HBaseClient.wrapException(HBaseClient.java:1110)
     at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:1079)
     at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:150)
     at $Proxy5.getProtocolVersion(Unknown Source)
     at org.apache.hadoop.hbase.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:183)
     at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:335)
     at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:312)
     at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:364)
     at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:710)
     at org.apache.hadoop.hbase.client.HBaseAdmin.&lt; init>(HBaseAdmin.java:141)
     at com.intel.hbase.test.createtable.TableBuilder.main(TableBuilder.java:48)
 Caused by: java.io.EOFException
     at java.io.DataInputStream.readInt(DataInputStream.java:375)
     at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:605)
     at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:538)</p></li>
</ol>

</div>
    </article>
  </section>
  
  
  <section id="kettle20130407add-a-field-from-paramter-to-output">
    <article>
      <header>
      <h3><a href="/kettle/2013/04/07/add-a-field-from-paramter-to-output">kettle中添加一个参数字段到输出</a></h3>
      <div class="c9">
     		Author: JavaChen
     		&emsp;&emsp;
		Categories：
			
			<a href="/categories.html#kettle">kettle</a>
			
			
		&emsp;&emsp;
		Tags：
			
			<a href="/tags.html#kettle-ref">kettle</a>
			
			
		&emsp;&emsp;
		<a href='/kettle/2013/04/07/add-a-field-from-paramter-to-output#comment' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>
    </header>
    <div class="content"><p>kettle可以将输入流中的字段输出到输出流中，输入输出流可以为数据库、文件或其他，通常情况下输入流中字段为已知确定的，如果我想在输出流中添加一个来自转换的命令行参数的一个字段，该如何操作？</p>

<p>上述问题可以拆分为两个问题：</p>

<ol>
<li>从命令行接受一个参数作为一个字段</li>
<li>合并输入流和这个字段</li>
</ol>


<h3>问题1</h3>

<p>第一个问题可以使用kettle中<code>获取系统信息</code>组件，定义一个变量，该值来自命令行参数，见下图：</p>

<p><img src="/files/2013/get-a-field-from-paramter.png" alt="get-a-field-from-paramter" /></p>

<h3>问题2</h3>

<p>第二个问题可以使用kettle中<code>记录关联 (笛卡尔输出)</code>组件将两个组件关联起来，输出一个笛卡尔结果集，关联条件设定恒为true，在运行前设置第一个参数的值，然后运行即可。</p>

<p><img src="/files/2013/run-kettle-for-join-two-inputs.png" alt="run-kettle-for-join-two-inputs" /></p>

<h3>下载脚本</h3>

<p>最后，kettle转换文件下载地址：<a href="/files/2013/join-a-paramter-to-input-in-kettle.zip">在这里</a>。</p>
</div>
    </article>
  </section>
  
  
  <section id="hadoop20130406install-cloudera-cdh4.2-by-yum">
    <article>
      <header>
      <h3><a href="/hadoop/2013/04/06/install-cloudera-cdh4.2-by-yum">从yum安装Cloudera CDH4.2</a></h3>
      <div class="c9">
     		Author: JavaChen
     		&emsp;&emsp;
		Categories：
			
			<a href="/categories.html#hadoop">hadoop</a>
			
			
		&emsp;&emsp;
		Tags：
			
			<a href="/tags.html#hadoop-ref">hadoop</a>
			
			,
			
			
			<a href="/tags.html#impala-ref">impala</a>
			
			,
			
			
			<a href="/tags.html#cloudera-ref">cloudera</a>
			
			
		&emsp;&emsp;
		<a href='/hadoop/2013/04/06/install-cloudera-cdh4.2-by-yum#comment' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>
    </header>
    <div class="content"><p>记录使用yum通过rpm方式安装Cloudera CDH4.2中的hadoop、yarn、HBase，需要注意初始化namenode之前需要手动创建一些目录并设置权限。</p>

<h2>目录</h2>

<ol>
<li>安装jdk</li>
<li>设置yum源</li>
<li>安装HDFS</li>
<li>配置hadoop</li>
<li>安装YARN</li>
<li>安装zookeeper</li>
<li>安装HBase</li>
<li>安装Hive</li>
<li>参考文章</li>
</ol>


<h2>1. 安装jdk</h2>

<p>安装jdk并设置环境变量</p>

<pre><code>export JAVA_HOME=&lt; jdk-install-dir&gt;
export PATH=$JAVA_HOME/bin:$PATH
</code></pre>

<p>检查环境变量中是否有设置JAVA_HOME</p>

<pre><code>sudo env | grep JAVA_HOME
</code></pre>

<p>如果env中没有JAVA_HOME变量，则修改/etc/sudoers文件</p>

<pre><code>vi /etc/sudoers
Defaults env_keep+=JAVA_HOME
</code></pre>

<h2>2. 设置yum源</h2>

<p>从http://archive.cloudera.com/cdh4/repo-as-tarball/4.2.0/cdh4.2.0-centos6.tar.gz 下载压缩包解压并设置本地或ftp yum源，可以参考<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_30.html">Creating a Local Yum Repository</a></p>

<h2>3. 安装HDFS</h2>

<h3>在NameNode节点yum安装</h3>

<pre><code>yum list hadoop
yum install hadoop-hdfs-namenode
yum install hadoop-hdfs-secondarynamenode
yum install hadoop-yarn-resourcemanager
yum install hadoop-mapreduce-historyserver
</code></pre>

<h3>在DataNode节点yum安装</h3>

<pre><code>yum list hadoop
yum install hadoop-hdfs-datanode
yum install hadoop-yarn-nodemanager
yum install hadoop-mapreduce
yum install zookeeper-server
yum install hadoop-httpfs
yum install hadoop-debuginfo
</code></pre>

<h2>4. 配置hadoop</h2>

<h3>修改配置文件</h3>

<p>hadoop的默认配置文件在/etc/hadoop/conf</p>

<ol>
<li>core-site.xml:</li>
</ol>


<pre><code>    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://node1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;fs.trash.interval&lt;/name&gt;
        &lt;value&gt;10080&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;
        &lt;value&gt;10080&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;io.bytes.per.checksum&lt;/name&gt;
      &lt;value&gt;4096&lt;/value&gt;
    &lt;/property&gt;
</code></pre>

<ol>
<li>hdfs-site.xml:</li>
</ol>


<pre><code>    &lt;property&gt;
      &lt;name&gt;dfs.replication&lt;/name&gt;
      &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
      &lt;value&gt;/opt/data/hadoop&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.block.size&lt;/name&gt;
        &lt;value&gt;268435456&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;dfs.permissions.superusergroup&lt;/name&gt;
      &lt;value&gt;hadoop&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;
      &lt;value&gt;100&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt;
      &lt;value&gt;100&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt;
      &lt;value&gt;1048576&lt;/value&gt;
      &lt;description&gt;
        Specifies the maximum amount of bandwidth that each datanode
        can utilize for the balancing purpose in term of
        the number of bytes per second.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
        &lt;value&gt;node1:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;node1:50090&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
</code></pre>

<ol>
<li>修改master和slaves文件</li>
</ol>


<h3>NameNode HA</h3>

<p>https://ccp.cloudera.com/display/CDH4DOC/Introduction+to+HDFS+High+Availability</p>

<h3>Secondary NameNode Parameters</h3>

<p>在hdfs-site.xml中可以配置以下参数：</p>

<pre><code>dfs.namenode.checkpoint.check.period
dfs.namenode.checkpoint.txns
dfs.namenode.checkpoint.dir
dfs.namenode.checkpoint.edits.dir
dfs.namenode.num.checkpoints.retained
</code></pre>

<h4>multi-host-secondarynamenode-configuration</h4>

<p>http://blog.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/.</p>

<h3>Config list</h3>

<pre><code>Directory                       Owner       Permissions Default Path
hadoop.tmp.dir                  hdfs:hdfs   drwx------  /var/hadoop
dfs.namenode.name.dir               hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir               hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir         hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/namesecondary
yarn.nodemanager.local-dirs         yarn:yarn   drwxr-xr-x  ${hadoop.tmp.dir}/nm-local-dir
yarn.nodemanager.log-dirs           yarn:yarn   drwxr-xr-x  ${yarn.log.dir}/userlogs
yarn.nodemanager.remote-app-log-dir                     /tmp/logs
</code></pre>

<p>my set:</p>

<pre><code>hadoop.tmp.dir                  /opt/data/hadoop
dfs.namenode.name.dir               ${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir               ${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir         ${hadoop.tmp.dir}/dfs/namesecondary
yarn.nodemanager.local-dirs         /opt/data/yarn/local
yarn.nodemanager.log-dirs           /var/log/hadoop-yarn/logs
yarn.nodemanager.remote-app-log-dir         /var/log/hadoop-yarn/app
</code></pre>

<h3>Create the data Directory in the Cluster</h3>

<p>在namenode节点创建name目录</p>

<pre><code>mkdir -p /opt/data/hadoop/dfs/name
chown -R hdfs:hdfs /opt/data/hadoop/dfs/name
chmod 700 /opt/data/hadoop/dfs/name
</code></pre>

<p>在所有datanode节点创建data目录</p>

<pre><code>mkdir -p /opt/data/hadoop/dfs/data
chown -R hdfs:hdfs /opt/data/hadoop/dfs/data
chmod 700 /opt/data/hadoop/dfs/data
</code></pre>

<p>在secondarynode节点创建namesecondary目录</p>

<pre><code>mkdir -p /opt/data/hadoop/dfs/namesecondary
chown -R hdfs:hdfs /opt/data/hadoop/dfs/namesecondary
chmod 700 /opt/data/hadoop/dfs/namesecondary
</code></pre>

<p>在所有datanode节点创建yarn的local目录</p>

<pre><code>mkdir -p /opt/data/hadoop/yarn/local
chown -R yarn:yarn /opt/data/hadoop/yarn/local
chmod 700 /opt/data/hadoop/yarn/local
</code></pre>

<h3>同步配置文件到整个集群</h3>

<pre><code>sudo scp -r /etc/hadoop/conf root@nodeX:/etc/hadoop/conf
</code></pre>

<h3>格式化NameNode</h3>

<pre><code>sudo -u hdfs hdfs namenode -format
</code></pre>

<h3>在每个节点启动hdfs</h3>

<pre><code>for x in `cd /etc/init.d ; ls hadoop-hdfs-*` ; do sudo service $x restart ; done
</code></pre>

<h2>5. 安装YARN</h2>

<p>先在一台机器上配置好，然后在做同步。</p>

<ol>
<li>mapred-site.xml:</li>
</ol>


<pre><code>    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;node1:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;node1:19888&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;mapreduce.task.io.sort.factor&lt;/name&gt;
      &lt;value&gt;100&lt;/value&gt;
      &lt;description&gt;The number of streams to merge at once while sorting
      files.  This determines the number of open file handles.&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;mapreduce.task.io.sort.mb&lt;/name&gt;
      &lt;value&gt;200&lt;/value&gt;
      &lt;description&gt;The total amount of buffer memory to use while sorting 
      files, in megabytes.  By default, gives each merge stream 1MB, which
      should minimize seeks.&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;mapreduce.reduce.shuffle.parallelcopies&lt;/name&gt;
      &lt;value&gt;16&lt;/value&gt;
       &lt;!-- 一般介于节点数开方和节点数一半之间，小于20节点，则为节点数--&gt;
      &lt;description&gt;The default number of parallel transfers run by reduce
      during the copy(shuffle) phase.
      &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;mapreduce.task.timeout&lt;/name&gt;
      &lt;value&gt;1800000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;mapreduce.tasktracker.map.tasks.maximum&lt;/name&gt;
      &lt;value&gt;4&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
      &lt;name&gt;mapreduce.tasktracker.reduce.tasks.maximum&lt;/name&gt;
      &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
</code></pre>

<ol>
<li>yarn-site.xml:</li>
</ol>


<pre><code>    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
        &lt;value&gt;node1:8031&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
        &lt;value&gt;node1:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
        &lt;value&gt;node1:8030&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
        &lt;value&gt;node1:8033&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
        &lt;value&gt;node1:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce.shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;description&gt;Classpath for typical applications.&lt;/description&gt;
        &lt;name&gt;yarn.application.classpath&lt;/name&gt;
        &lt;value&gt;
        $HADOOP_CONF_DIR,
        $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
        $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,
        $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,
        $YARN_HOME/*,$YARN_HOME/lib/*
        &lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;
        &lt;value&gt;/opt/hadoop/yarn/local&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
        &lt;value&gt;/var/log/hadoop-yarn/logs&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
        &lt;value&gt;/var/log/hadoop-yarn/apps&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;
        &lt;value&gt;/user&lt;/value&gt;
    &lt;/property&gt;
</code></pre>

<h3>HDFS创建临时目录</h3>

<pre><code>sudo -u hdfs hadoop fs -mkdir /tmp
sudo -u hdfs hadoop fs -chmod -R 1777 /tmp
</code></pre>

<h3>创建日志目录</h3>

<pre><code>sudo -u hdfs hadoop fs -mkdir /user/history
sudo -u hdfs hadoop fs -chmod -R 1777 /user/history
sudo -u hdfs hadoop fs -chown yarn /user/history
sudo -u hdfs hadoop fs -mkdir /var/log/hadoop-yarn
sudo -u hdfs hadoop fs -chown yarn:mapred /var/log/hadoop-yarn
</code></pre>

<h3>验证hdfs结构是否正确</h3>

<pre><code>[root@node1 data]# sudo -u hdfs hadoop fs -ls -R /
drwxrwxrwt   - hdfs supergroup          0 2012-04-19 14:31 /tmp
drwxr-xr-x   - hdfs supergroup          0 2012-05-31 10:26 /user
drwxrwxrwt   - yarn supergroup          0 2012-04-19 14:31 /user/history
drwxr-xr-x   - hdfs   supergroup        0 2012-05-31 15:31 /var
drwxr-xr-x   - hdfs   supergroup        0 2012-05-31 15:31 /var/log
drwxr-xr-x   - yarn   mapred            0 2012-05-31 15:31 /var/log/hadoop-yarn
</code></pre>

<h3>启动mapred-historyserver</h3>

<pre><code>/etc/init.d/hadoop-mapreduce-historyserver start
</code></pre>

<h3>在每个节点启动YARN</h3>

<pre><code>for x in `cd /etc/init.d ; ls hadoop-yarn-*` ; do sudo service $x start ; done
</code></pre>

<h3>为每个MapReduce用户创建主目录</h3>

<pre><code>sudo -u hdfs hadoop fs -mkdir /user/$USER
sudo -u hdfs hadoop fs -chown $USER /user/$USER
</code></pre>

<h3>Set HADOOP_MAPRED_HOME</h3>

<pre><code>export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
</code></pre>

<h3>Configure the Hadoop Daemons to Start at Boot Time</h3>

<p>https://ccp.cloudera.com/display/CDH4DOC/Maintenance+Tasks+and+Notes#MaintenanceTasksandNotes-ConfiguringinittoStartCoreHadoopSystemServices</p>

<h2>6. 安装Zookeeper</h2>

<p>安装zookeeper</p>

<pre><code>yum install zookeeper*
</code></pre>

<p>设置crontab</p>

<pre><code>crontab -e
15 * * * * java -cp $classpath:/usr/lib/zookeeper/lib/log4j-1.2.15.jar:\
/usr/lib/zookeeper/lib/jline-0.9.94.jar:\   
/usr/lib/zookeeper/zookeeper.jar:/usr/lib/zookeeper/conf\
org.apache.zookeeper.server.PurgeTxnLog /var/zookeeper/ -n 5
</code></pre>

<p>在每个需要安装zookeeper的节点上创建zookeeper的目录</p>

<pre><code>mkdir -p /opt/data/zookeeper
chown -R zookeeper:zookeeper /opt/data/zookeeper
</code></pre>

<p>设置zookeeper配置：/etc/zookeeper/conf/zoo.cfg，并同步到其他机器</p>

<pre><code>tickTime=2000
initLimit=10
syncLimit=5
dataDir=/opt/data/zookeeper
clientPort=2181
server.1=node1:2888:3888
server.2=node2:2888:3888
server.3=node3:2888:3888
</code></pre>

<p>在每个节点上初始化并启动zookeeper，注意修改n值</p>

<pre><code>service zookeeper-server init --myid=n
service zookeeper-server restart
</code></pre>

<h2>7. 安装HBase</h2>

<pre><code>yum install hbase*
</code></pre>

<h3>在hdfs中创建/hbase</h3>

<pre><code>sudo -u hdfs hadoop fs -mkdir /hbase
sudo -u hdfs hadoop fs -chown hbase:hbase /hbase
</code></pre>

<h3>设置crontab：</h3>

<pre><code>crontab -e
* 10 * * * cd /var/log/hbase/; rm -rf\
`ls /var/log/hbase/|grep -P 'hbase\-hbase\-.+\.log\.[0-9]'\`&gt;&gt; /dev/null &amp;
</code></pre>

<h3>修改配置文件并同步到其他机器：</h3>

<pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;hbase.distributed&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.rootdir&lt;/name&gt;
    &lt;value&gt;hdfs://node1:8020/hbase&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;
    &lt;value&gt;/opt/data/hbase&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;node1,node2,node3&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt;
    &lt;value&gt;536870912&lt;/value&gt;
    &lt;description&gt;
    Maximum HStoreFile size. If any one of a column families' HStoreFiles has
    grown to exceed this value, the hosting HRegion is split in two.
    Default: 10G.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt;
    &lt;value&gt;67108864&lt;/value&gt;
    &lt;description&gt;
    Memstore will be flushed to disk if size of the memstore
    exceeds this number of bytes.  Value is checked by a thread that runs
    every hbase.server.thread.wakefrequency.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.lease.period&lt;/name&gt;
    &lt;value&gt;600000&lt;/value&gt;
    &lt;description&gt;HRegion server lease period in milliseconds. Default is
    60 seconds. Clients must report in within this period else they are
    considered dead.&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.client.retries.number&lt;/name&gt;
    &lt;value&gt;3&lt;/value&gt;
  &lt;/property&gt; 
  &lt;property&gt;
    &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt;
    &lt;value&gt;100&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.property.maxClientCnxns&lt;/name&gt;
    &lt;value&gt;2000&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hfile.block.cache.size&lt;/name&gt;
    &lt;value&gt;0.1&lt;/value&gt;
    &lt;description&gt;
    Percentage of maximum heap (-Xmx setting) to allocate to block cache
    used by HFile/StoreFile. Default of 0.25 means allocate 25%.
    Set to 0 to disable but it's not recommended.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.regions.slop&lt;/name&gt;
    &lt;value&gt;0&lt;/value&gt;
    &lt;description&gt;Rebalance if any regionserver has average + (average * slop) regions.
    Default is 20% slop.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hstore.compactionThreshold&lt;/name&gt;
    &lt;value&gt;10&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.hstore.blockingStoreFiles&lt;/name&gt;
    &lt;value&gt;30&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3>修改regionserver文件</h3>

<h3>启动HBase</h3>

<pre><code>service hbase-master start
service hbase-regionserver start
</code></pre>

<h2>8. 安装hive</h2>

<h3>在一个节点上安装hive</h3>

<pre><code>sudo yum install hive*
</code></pre>

<h3>安装metastore</h3>

<h3>修改配置文件</h3>

<pre><code>&lt;configuration&gt;
&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://node1:8020&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
  &lt;value&gt;jdbc:postgresql://node1/metastore&lt;/value&gt;
  &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
  &lt;value&gt;org.postgresql.Driver&lt;/value&gt;
  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
  &lt;value&gt;hiveuser&lt;/value&gt;
  &lt;description&gt;username to use against metastore database&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
  &lt;value&gt;redhat&lt;/value&gt;
  &lt;description&gt;password to use against metastore database&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;mapred.job.tracker&lt;/name&gt;
 &lt;value&gt;node1:8031&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
 &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;datanucleus.fixedDatastore&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;
    &lt;value&gt;/user/hive/warehouse&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hive.metastore.uris&lt;/name&gt;
    &lt;value&gt;thrift://node1:9083&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;hive.metastore.local&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.support.concurrency&lt;/name&gt;
  &lt;description&gt;Enable Hive's Table Lock Manager Service&lt;/description&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt;
  &lt;description&gt;Zookeeper quorum used by Hive's Table Lock Manager&lt;/description&gt;
  &lt;value&gt;node2,node3,node1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.hwi.listen.host&lt;/name&gt;
  &lt;value&gt;node1&lt;/value&gt;
  &lt;description&gt;This is the host address the Hive Web Interface will listen on&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.hwi.listen.port&lt;/name&gt;
  &lt;value&gt;9999&lt;/value&gt;
  &lt;description&gt;This is the port the Hive Web Interface will listen on&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.hwi.war.file&lt;/name&gt;
  &lt;value&gt;lib/hive-hwi-0.10.0-cdh4.2.0.war&lt;/value&gt;
  &lt;description&gt;This is the WAR file with the jsp content for Hive Web Interface&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;hive.merge.mapredfiles&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
  &lt;description&gt;Merge small files at the end of a map-reduce job&lt;/description&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h3>在hdfs中创建hive数据仓库目录</h3>

<ul>
<li>hive的数据仓库在hdfs中默认为<code>/user/hive/warehouse</code>,建议修改其访问权限为1777，以便其他所有用户都可以创建、访问表，但不能删除不属于他的表。</li>
<li>每一个查询hive的用户都必须有一个hdfs的home目录(/user目录下，如root用户的为<code>/user/root</code>)</li>
<li><p>hive所在节点的 /tmp必须是world-writable权限的。</p>

<p>  sudo -u hdfs hadoop fs -mkdir /user/hive/warehouse
  sudo -u hdfs hadoop fs -chown hive /user/hive/warehouse</p></li>
</ul>


<h3>启动hive</h3>

<pre><code>service hive-metastore start
service hive-server start
service hive-server2 start
</code></pre>

<h3>访问beeline</h3>

<pre><code>$ /usr/lib/hive/bin/beeline
beeline&gt; !connect jdbc:hive2://localhost:10000 username password org.apache.hive.jdbc.HiveDriver
0: jdbc:hive2://localhost:10000&gt; SHOW TABLES;
show tables;
+-----------+
| tab_name  |
+-----------+
+-----------+
No rows selected (0.238 seconds)
0: jdbc:hive2://localhost:10000&gt; 
</code></pre>

<p>其 sql语法参考<a href="http://sqlline.sourceforge.net/">SQLLine CLI</a>，在这里，你不能使用HiveServer的sql语句</p>

<h3>与hbase集成</h3>

<p>需要在hive里添加以下jar包：</p>

<pre><code>ADD JAR /usr/lib/hive/lib/zookeeper.jar;
ADD JAR /usr/lib/hive/lib/hbase.jar;
ADD JAR /usr/lib/hive/lib/hive-hbase-handler-0.10.0-cdh4.2.0.jar
ADD JAR /usr/lib/hive/lib/guava-11.0.2.jar;
</code></pre>

<h2>9. 参考文章</h2>

<ul>
<li><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_30.html">Creating a Local Yum Repository</a></li>
<li><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_29.html">Java Development Kit Installation</a></li>
<li><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_11_2.html">Deploying HDFS on a Cluster</a></li>
<li><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_20.html">HBase Installation</a></li>
<li><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_21.html">ZooKeeper Installation</a></li>
<li><a href="http://roserouge.iteye.com/blog/1558498">hadoop cdh 安装笔记</a></li>
</ul>

</div>
    </article>
  </section>
  
  
  <section id="hadoop20130329install-impala">
    <article>
      <header>
      <h3><a href="/hadoop/2013/03/29/install-impala">安装impala过程</a></h3>
      <div class="c9">
     		Author: JavaChen
     		&emsp;&emsp;
		Categories：
			
			<a href="/categories.html#hadoop">hadoop</a>
			
			
		&emsp;&emsp;
		Tags：
			
			<a href="/tags.html#hadoop-ref">hadoop</a>
			
			,
			
			
			<a href="/tags.html#impala-ref">impala</a>
			
			,
			
			
			<a href="/tags.html#cloudera-ref">cloudera</a>
			
			
		&emsp;&emsp;
		<a href='/hadoop/2013/03/29/install-impala#comment' title='分享文章、查看评论' style="float:right;margin-right:.5em;">Comments</a>
	</div>
    </header>
    <div class="content"><p>与Hive类似，Impala也可以直接与HDFS和HBase库直接交互。只不过Hive和其它建立在MapReduce上的框架适合需要长时间运行的批处理任务。例如那些批量提取，转化，加载（ETL）类型的Job。而Impala主要用于实时查询。</p>

<h3>install</h3>

<p>下载 impala，目前最新版本为0.6-1，<a href="http://beta.cloudera.com/impala/redhat/6/x86_64/impala/0/RPMS/x86_64/">下载地址</a>。</p>

<h3>安装过程</h3>

<p>安装前提：先安装好hadoop集群以及hive，可以参考我的文章：</p>

<ul>
<li><a href="http://blog.javachen.com/Hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH4.2.html">手动安装Cloudera Hadoop CDH4.2</a></li>
<li><p><a href="http://blog.javachen.com/Hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2.html">手动安装Cloudera Hive CDH4.2</a></p></li>
<li><p>DataNode节点</p>

<p> yum install -y impala-0.6-1.p0.548.el6.x86_64.rpm   impala-server-0.6-1.p0.548.el6.x86_64.rpm impala-state-store-0.6-1.p0.548.el6.x86_64.rpm    impala-shell-0.6-1.p0.548.el6.x86_64.rpm libevent-1.4.13-4.el6.x86_64.rpm bigtop-utils-0.4+300-1.cdh4.0.1.p0.1.el6.noarch.rpm --skip-broken</p></li>
<li><p>在hive节点上</p>

<p> yum install -y impala-0.6-1.p0.548.el6.x86_64.rpm   impala-server-0.6-1.p0.548.el6.x86_64.rpm \
 impala-state-store-0.6-1.p0.548.el6.x86_64.rpm  impala-shell-0.6-1.p0.548.el6.x86_64.rpm \
 libevent-1.4.13-4.el6.x86_64.rpm    bigtop-utils-0.4+300-1.cdh4.0.1.p0.1.el6.noarch.rpm</p></li>
</ul>


<h3>配置Impala</h3>

<h4>查看安装路径</h4>

<pre><code>[root@desktop1 conf]# find / -name impala
/var/run/impala
/var/lib/alternatives/impala
/var/log/impala
/usr/lib/impala
/etc/alternatives/impala
/etc/default/impala
/etc/impala
</code></pre>

<h4>添加配置文件</h4>

<p>impalad的配置文件路径由环境变量<code>IMPALA_CONF_DIR</code>指定，默认为<code>/usr/lib/impala/conf</code></p>

<p>在节点desktop1上 拷贝<code>hive-site.xml</code>、<code>core-site.xml</code>、<code>hdfs-site.xml</code>至<code>/usr/lib/impala/conf</code>目录下:</p>

<pre><code>[root@desktop1 conf]# mkdir /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/log4j.properties /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/core-site.xml /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/hdfs-site.xml /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hive-0.10.0-cdh4.2.0/conf/hive-site.xml /usr/lib/impala/conf/
</code></pre>

<p>并作下面修改在<code>hdfs-site.xml</code>文件中添加如下内容：</p>

<pre><code>&lt;property&gt;
    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;
    &lt;value&gt;/var/run/hadoop-hdfs/dn._PORT&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<p>同步以上文件到其他节点</p>

<pre><code>[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop3:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop4:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop6:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop7:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop8:/usr/lib/impala/
</code></pre>

<h4>hadoop中添加native包</h4>

<p>拷贝hadoop native包到hadoop安装路径下，并同步hadoop文件到其他节点：</p>

<pre><code>[root@desktop1 ~]# cp /usr/lib/impala/lib/*.so* /opt/hadoop-2.0.0-cdh4.2.0/lib/native/
</code></pre>

<h4>创建socket path</h4>

<p>在每个节点上创建/var/run/hadoop-hdfs:</p>

<pre><code>[root@desktop1 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop3 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop4 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop6 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop7 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop8 ~]# mkdir -p /var/run/hadoop-hdfs
</code></pre>

<p>拷贝postgres jdbc jar：</p>

<pre><code>cp /opt/hive-0.10.0-cdh4.2.0/lib/postgresql-9.1-903.jdbc* /usr/lib/impala/lib/
</code></pre>

<h3>启动服务</h3>

<ol>
<li><p>在hive所在节点启动statestored（默认端口为24000）:</p>

<p> GLOG_v=1 nohup statestored -state_store_port=24000 &amp;</p></li>
</ol>


<p>如果statestore正常启动，可以在/tmp/statestored.INFO查看。如果出现异常，可以查看/tmp/statestored.ERROR定位错误信息。</p>

<ol>
<li><p>在所有impalad节点上：</p>

<p> HADOOP_CONF_DIR="/usr/lib/impala/conf" nohup impalad -state_store_host=desktop1 -nn=desktop1 \
     -nn_port=8020 -hostname=desktop3 -ipaddress=192.168.0.3 &amp;</p></li>
</ol>


<p>注意： 其中的<code>-hostname</code>和<code>-ipaddress</code>表示当前启动impalad实例所在机器的主机名和ip地址。</p>

<p>如果impalad正常启动，可以在<code>/tmp/ impalad.INFO</code>查看。如果出现异常，可以查看<code>/tmp/impalad.ERROR</code>定位错误信息。</p>

<h3>使用shell</h3>

<p>使用<code>impala-shell</code>启动Impala Shell，分别连接各Impalad主机(desktop3、desktop4、desktop6、desktop7、desktop8)，刷新元数据，之后就可以执行shell命令。相关的命令如下(可以在任意节点执行)：</p>

<pre><code>&gt;impala-shell
[Not connected] &gt;connect desktop3:21000
[desktop3:21000] &gt;refresh
[desktop3:21000] &gt;connect desktop4:21000
[desktop4:21000] &gt;refresh
</code></pre>

<h3>注意：</h3>

<ol>
<li>如果hive使用mysql或postgres数据库作为metastore的存储，则需要拷贝相应的jdbc jar到<code>/usr/lib/impala/lib</code>目录下</li>
<li>E0325 11:04:19.937718  7239 statestored-main.cc:52] Could not start webserver on port: 25010</li>
</ol>


<p>可能是已经启动了statestored进程</p>

<h3>参考文章</h3>

<ul>
<li><a href="http://yuntai.1kapp.com/?p=904">Impala安装文档完整版</a></li>
<li><a href="http://tech.uc.cn/?p=817">Impala入门笔记</a></li>
<li><a href="https://ccp.cloudera.com/display/IMPALA10BETADOC/Installing+and+Using+Cloudera+Impala">Installing and Using Cloudera Impala</a></li>
</ul>

</div>
    </article>
  </section>
  
  <div class="pagination">
      <ul>
        <li><a href="/archive.html">Archive</a></li>
        <li class="prev"><a href='/page2'>Next &rarr;</a></li>
      </ul>
  </div>
  </div>

  <aside class="span4">
    <section>
   	 <h4>TODO</h4>
   	 <ul style="margin-top: -3px">
		<li>hadoop权威指南</li>
       </ul>
    </section>

    <section>
    <h4>Recent Posts</h4>
    <ul id="recent_posts">
      <li class="post">
        <a href="/hadoop/2013/06/24/install-cdh-by-cloudera-manager">通过Cloudera Manager安装CDH</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/04/17/access-idh-2.3-hbase-in-kettle">kettle访问IDH2.3中的HBase</a>
      </li>
      <li class="post">
        <a href="/kettle/2013/04/07/add-a-field-from-paramter-to-output">kettle中添加一个参数字段到输出</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/04/06/install-cloudera-cdh4.2-by-yum">从yum安装Cloudera CDH4.2</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/03/29/install-impala">安装impala过程</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH4.2">手动安装Cloudera Hadoop CDH4.2</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH4.2">手动安装Cloudera HBase CDH4.2</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2">手动安装Cloudera Hive CDH4.2</a>
      </li>
      <li class="post">
        <a href="/hadoop/2013/03/08/note-about-installing-hadoop-cluster">【笔记】Hadoop安装部署</a>
      </li>
      <li class="post">
        <a href="/work/2013/02/20/summary-of-the-work-in-2012">2012年度总结</a>
      </li>
    </ul>
    </section>
    
    <script type="text/javascript">
	var duoshuoQuery = {short_name:"javachen"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	
	<section>
		<h3>Recent Comments</h3>
		<ul class="ds-recent-comments" data-num-items="5" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="70"></ul>
	<script>if (typeof DUOSHUO !== 'undefined')	DUOSHUO.RecentComments('.ds-recent-visitors');</script>
	</section>
	
	<section>
		<h3>Recent Vistors</h3>
		 <ul class="ds-recent-visitors" data-num-items="16"></ul>
		<script>if (typeof DUOSHUO !== 'undefined')	DUOSHUO.RecentVisitors('.ds-recent-visitors');</script>
	</section>
	 
     <section>
   	 <h4>WeiBo</h4>
   	 <iframe id="sina_widget_1222789964" style="width:100%; height:500px;" frameborder="0" scrolling="no" src="http://v.t.sina.com.cn/widget/widget_blog.php?uid=1222789964&height=500&skin=wd_01&showpic=0"></iframe>
    </section>
    
    <section>
	  
	    <h4>Categories</h4>
	    <ul class="tag_box">
	      
	      


  
     
    	<li><a href="/categories.html#cloud-ref">
    		cloud <span>9</span>
    	</a></li>
     
    	<li><a href="/categories.html#javascript-ref">
    		javascript <span>4</span>
    	</a></li>
     
    	<li><a href="/categories.html#pentaho-ref">
    		pentaho <span>2</span>
    	</a></li>
     
    	<li><a href="/categories.html#extjs-ref">
    		extjs <span>2</span>
    	</a></li>
     
    	<li><a href="/categories.html#xml-ref">
    		xml <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#mondrian-ref">
    		mondrian <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#kettle-ref">
    		kettle <span>8</span>
    	</a></li>
     
    	<li><a href="/categories.html#jsf-ref">
    		jsf <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#seam-ref">
    		seam <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#java-ref">
    		java <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#cassandra-ref">
    		cassandra <span>2</span>
    	</a></li>
     
    	<li><a href="/categories.html#github-ref">
    		github <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#work-ref">
    		work <span>1</span>
    	</a></li>
     
    	<li><a href="/categories.html#hadoop-ref">
    		hadoop <span>8</span>
    	</a></li>
    
  


	    </ul>
	  
     </section>
       <section>
    <h4>Links</h4>
   	<ul>
	<li>Java开发
			<ul>
				<li><a href="http://blog.frankel.ch/" target="_blank">A Java geek</a></li>
				<li><a href="http://xinwang.osdn.cn/" target="_blank">辛望的开发日志</a></li>
				<li><a href="http://kohsuke.org/" target="_blank">Kohsuke Kawaguchi</a></li>
				<li><a href="http://www.longtask.com/blog/" target="_blank">龙浩的blog</a>就职于阿里巴巴云计算</li>
				<li><a href="http://jdkcn.com/" target="_blank">莫多泡泡</a>A Java programmeri</li>
				<li><a href="http://hackfisher.info/" target="_blank">HackFisher</a></li>
				<li><a href="http://bluedash.net/categories/%E7%BC%96%E7%A8%8B/spaces" target="_blank">蓝点</a></li>
				<li><a href="http://javafans.info/" target="_blank">Java爱好者</a></li>
				<li><a href="http://www.yankay.com/" target="_blank">我自然</a>颜开的博客</li>
			</ul>
		</li>
		<li>前端开发
			<ul>
				<li><a href="http://panweizeng.com/" target="_blank">潘魏增</a>美团网前端工程师</li>
				<li><a href="http://14px.com/" target="_blank">十四像素</a></li>
			</ul>
		</li>
		<li>其他
			<ul>
				<li><a href="http://blog.boluotou.com/" target="_blank">圆木菠萝罐</a>一个大学学长</li>
				<li><a href="http://blog.codingnow.com/" target="_blank">云风的BLOG</a></li>
				<li><a href="http://www.yy42.net/blog/" target="_blank">程显峰</a></li>
				<li><a href="http://coolshell.cn/" target="_blank">酷壳–CoolShell.cn</a></li>
				<li><a href="http://www.coder4.com/" target="_blank">四号程序员</a></li>
				<li><a href="http://timyang.net/" target="_blank">Tim[后端技术]</a></li>

				<li><a href="http://www.agiledon.com/" target="_blank">捷道</a>Thoughtworks架构师</li>
				<li><a href="http://log4d.com/" target="_blank">Log4D</a></li>

				<li><a href="http://dev.ymeng.net/" target="_blank">Dev Notes</a></li>
				<li><a href="http://www.dbanotes.net/" target="_blank">DBA Notes</a></li>		
			</ul>
		</li>
	</ul>
  </section>
  </aside>
</div>

  </div>
</div>


      </div>

      <footer>
        <p>&copy; JavaChen 2013 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a> | <script language="javascript" type="text/javascript" src="http://js.users.51.la/12111481.js"></script>
<noscript><a href="http://www.51.la/?12111481" target="_blank"><img alt="Statistic" src="http://img.users.51.la/12111481.asp" style="border:none" /></a></noscript>
        </p>
      </footer>

    </div> <!-- /container -->
    
  </body>
</html>

