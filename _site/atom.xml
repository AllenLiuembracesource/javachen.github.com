<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>JavaChen Blog</title>
 <link href="http://blog.javachen.com/atom.xml" rel="self"/>
 <link href="http://blog.javachen.com"/>
 <updated>2013-10-18T22:12:21+08:00</updated>
 <id>http://blog.javachen.com</id>
 <author>
   <name>JavaChen</name>
   <email>june.chan@foxmail.com</email>
 </author>

 
 <entry>
   <title>hive-server2中使用jdbc客户端用户运行mapreduce</title>
   <link href="http://blog.javachen.com/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2"/>
   <updated>2013-10-17T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hive/2013/10/17/run-mapreduce-with-client-user-in-hive-server2</id>
   <content type="html">&lt;p&gt;最近做了个web系统访问hive数据库，类似于官方自带的hwi、安居客的&lt;a href=&quot;https://github.com/anjuke/hwi&quot;&gt;hwi改进版&lt;/a&gt;和大众点评的&lt;a href=&quot;http://blog.csdn.net/lalaguozhe/article/details/9614061&quot;&gt;polestar&lt;/a&gt;(&lt;a href=&quot;https://github.com/dianping/polestar&quot;&gt;github地址&lt;/a&gt;)系统，但是和他们的实现不一样，查询Hive语句走的不是cli而是通过jdbc连接hive-server2。为了实现mapreduce任务中资源按用户调度，需要hive查询自动绑定当前用户、将该用户传到yarn服务端并使mapreduce程序以该用户运行。本文主要是记录实现该功能过程中遇到的一些问题以及解决方法,如果你有更好的方法和建议，欢迎留言发表您的看法！&lt;/p&gt;

&lt;h1&gt;hive-server2的启动&lt;/h1&gt;

&lt;p&gt;先从hive-server2服务的启动开始说起。&lt;/p&gt;

&lt;p&gt;如果你是以服务的方式启动hive-server2进程，则启动hive-server2的用户为hive,运行mapreduce的用户也为hive，启动脚本如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;/etc/init.d/hive-server2 start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你以命令行方式启动hive-server2进程，则启动hive-server2的用户为root,运行mapreduce的用户也为root，启动脚本如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive --service hiveserver2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;为什么是上面的结论？这要从hive-server2的启动过程开始说明。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;查看HiveServer2.java的代码可以看到，hive-server2启动时会依次启动&lt;code&gt;cliService&lt;/code&gt;和&lt;code&gt;thriftCLIService&lt;/code&gt;，查看cliService的init()方法，可以看到如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public synchronized void init(HiveConf hiveConf) {
    this.hiveConf = hiveConf;

    sessionManager = new SessionManager();
    addService(sessionManager);
    try {
      HiveAuthFactory.loginFromKeytab(hiveConf);
      serverUserName = ShimLoader.getHadoopShims().
          getShortUserName(ShimLoader.getHadoopShims().getUGIForConf(hiveConf));
    } catch (IOException e) {
      throw new ServiceException(&amp;quot;Unable to login to kerberos with given principal/keytab&amp;quot;, e);
    } catch (LoginException e) {
      throw new ServiceException(&amp;quot;Unable to login to kerberos with given principal/keytab&amp;quot;, e);
    }
    super.init(hiveConf);
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从上面的代码可以看到在cliService初始化过程中会做登陆（从kertab中登陆）和获取用户名的操作：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ShimLoader.getHadoopShims().getUGIForConf(hiveConf)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面代码最终会调用HadoopShimsSecure类的getUGIForConf方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;@Override
public UserGroupInformation getUGIForConf(Configuration conf) throws IOException {
  return UserGroupInformation.getCurrentUser();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;UserGroupInformation.getCurrentUser()代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt; public synchronized
  static UserGroupInformation getCurrentUser() throws IOException {
    AccessControlContext context = AccessController.getContext();
    Subject subject = Subject.getSubject(context);
    if (subject == null || subject.getPrincipals(User.class).isEmpty()) {
      return getLoginUser();
    } else {
      return new UserGroupInformation(subject);
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因为这时候服务刚启动，subject为空，故if分支会调用&lt;code&gt;getLoginUser()&lt;/code&gt;方法，其代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;  public synchronized 
  static UserGroupInformation getLoginUser() throws IOException {
    if (loginUser == null) {
      try {
        Subject subject = new Subject();
        LoginContext login;
        if (isSecurityEnabled()) {
          login = newLoginContext(HadoopConfiguration.USER_KERBEROS_CONFIG_NAME,
              subject, new HadoopConfiguration());
        } else {
          login = newLoginContext(HadoopConfiguration.SIMPLE_CONFIG_NAME, 
              subject, new HadoopConfiguration());
        }
        login.login();
        loginUser = new UserGroupInformation(subject);
        loginUser.setLogin(login);
        loginUser.setAuthenticationMethod(isSecurityEnabled() ?
                                          AuthenticationMethod.KERBEROS :
                                          AuthenticationMethod.SIMPLE);
        loginUser = new UserGroupInformation(login.getSubject());
        String fileLocation = System.getenv(HADOOP_TOKEN_FILE_LOCATION);
        if (fileLocation != null) {
          // Load the token storage file and put all of the tokens into the
          // user. Don&amp;#39;t use the FileSystem API for reading since it has a lock
          // cycle (HADOOP-9212).
          Credentials cred = Credentials.readTokenStorageFile(
              new File(fileLocation), conf);
          loginUser.addCredentials(cred);
        }
        loginUser.spawnAutoRenewalThreadForUserCreds();
      } catch (LoginException le) {
        LOG.debug(&amp;quot;failure to login&amp;quot;, le);
        throw new IOException(&amp;quot;failure to login&amp;quot;, le);
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(&amp;quot;UGI loginUser:&amp;quot;+loginUser);
      }
    }
    return loginUser;
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因为是第一次调用getLoginUser(),故loginUser为空，接下来会创建LoginContext并调用其login方法，login方法最终会调用HadoopLoginModule的commit()方法。&lt;/p&gt;

&lt;p&gt;下图是从hive-server2启动到执行HadoopLoginModule的commit()方法的调用图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;files/2013/hive-server2-invoke.png&quot; alt=&quot;hive-server2启动过程&quot;&gt;&lt;/p&gt;

&lt;p&gt;获取登陆用户的关键代码就在commit()，逻辑如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果使用了kerberos，则为kerberos登陆用户。hive-server2中如何使用kerberos登陆，请查看官方文档。&lt;/li&gt;
&lt;li&gt;如果kerberos用户为空并且没有开启security，则从系统环境变量中取&lt;code&gt;HADOOP_USER_NAME&lt;/code&gt;的值&lt;/li&gt;
&lt;li&gt;如果环境变量中没有设置HADOOP&lt;em&gt;USER&lt;/em&gt;NAME，则使用系统用户，即启动hive-server2进程的用户。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;小结&lt;/h2&gt;

&lt;p&gt;hive-server2启动过程中会做登陆操作并获取到登陆用户，启动之后再次调用&lt;code&gt;UserGroupInformation.getCurrentUser()&lt;/code&gt;取到的用户就为登陆用户了，这样会导致所有请求到hive-server2的hql最后都会以这个用户来运行mapreduce。&lt;/p&gt;

&lt;h1&gt;提交hive任务&lt;/h1&gt;

&lt;p&gt;现在来看hive任务是怎么提交到yarn服务端然后运行mapreduce的。&lt;/p&gt;

&lt;p&gt;为了调试简单，我在本机eclipse的hive源代码中配置&lt;code&gt;hive-site.xml、core-site.xml、mapred.xml、yarn-site.xml&lt;/code&gt;连接测试集群,添加缺少的yarn依赖并解决hive-builtins中报错的问题，然后运行HiveServer2类的main方法。&lt;em&gt;注意&lt;/em&gt;，我的电脑当前登陆用户为june，故启动hive-server2的用户为june。&lt;/p&gt;

&lt;p&gt;然后，在运行jdbc测试类，运行一个简单的sql语句，大概如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public static void test() {
    try {
        Class.forName(&amp;quot;org.apache.hive.jdbc.HiveDriver&amp;quot;);

        Connection conn = DriverManager.getConnection(
                &amp;quot;jdbc:hive2://june-mint:10000/default&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;);

        Statement stmt = conn.createStatement();

        ResultSet rs = stmt.executeQuery(&amp;quot;select count(1) from t&amp;quot;);

        while (rs.next())
            System.out.println(rs.getString(1));

        rs.close();
        stmt.close();
        conn.close();
    } catch (SQLException se) {
        se.printStackTrace();
    } catch (Exception e) {
        e.printStackTrace();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看yarn监控地址&lt;code&gt;http://192.168.56.101:8088/cluster&lt;/code&gt;，可以看到提交的mapreduce任务由june用户来运行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;files/2013/20131017-01.png&quot; alt=&quot;yarn cluster monitor page&quot;&gt;&lt;/p&gt;

&lt;p&gt;如何修改mapreduce任务的运行用户呢？如果了解hive提交mapreduce任务的过程的话，就应该知道hive任务会通过&lt;code&gt;org.apache.hadoop.mapred.JobClient&lt;/code&gt;来提交。在JobClient的init方法中有如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;  public void init(JobConf conf) throws IOException {
    setConf(conf);
    cluster = new Cluster(conf);
    clientUgi = UserGroupInformation.getCurrentUser();
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;JobClient类中提交mapreduce任务的代码如下，见submitJobInternal方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Job job = clientUgi.doAs(new PrivilegedExceptionAction&amp;lt;Job&amp;gt; () {
    @Override
    public Job run() throws IOException, ClassNotFoundException, 
      InterruptedException {
      Job job = Job.getInstance(conf);
      job.submit();
      return job;
    }
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从前面知道，hive-server2启动中会进行登陆操作并且登陆用户为june，故clientUgi对应的登陆用户也为june，故提交的mapreduce任务也通过june用户来运行。&lt;/p&gt;

&lt;h1&gt;如何修改源代码&lt;/h1&gt;

&lt;p&gt;从上面代码可以知道，修改clientUgi的获取方式就可以改变提交任务的用户。UserGroupInformation中存在如下静态方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;  public static UserGroupInformation createRemoteUser(String user) {
    if (user == null || &amp;quot;&amp;quot;.equals(user)) {
      throw new IllegalArgumentException(&amp;quot;Null user&amp;quot;);
    }
    Subject subject = new Subject();
    subject.getPrincipals().add(new User(user));
    UserGroupInformation result = new UserGroupInformation(subject);
    result.setAuthenticationMethod(AuthenticationMethod.SIMPLE);
    return result;
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;故可以尝试使用该方法，修改JobClient的init方法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt; public void init(JobConf conf) throws IOException {
    setConf(conf);
    cluster = new Cluster(conf);
    if(UserGroupInformation.isSecurityEnabled()){
        clientUgi = UserGroupInformation.getCurrentUser();
    }else{
        String user = conf.get(&amp;quot;myExecuteName&amp;quot;,&amp;quot;NoName&amp;quot;);
        clientUgi = UserGroupInformation.createRemoteUser(user);
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;编译代码、替换class文件，然后重新运行HiveServer2以及jdbc测试类，查看yarn监控地址&lt;code&gt;http://192.168.56.101:8088/cluster&lt;/code&gt;，截图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;files/2013/20131017-02.png&quot; alt=&quot;yarn cluster monitor page&quot;&gt;&lt;/p&gt;

&lt;p&gt;这时候mapreduce的运行用户变为NoName，这是因为从JobConf环境变量中找不到myExecuteName变量而使用默认值NoName的原因。&lt;/p&gt;

&lt;p&gt;查看hive-server2运行日志，会发现任务运行失败，关键异常信息如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=NoName, access=WRITE, inode=&amp;quot;/tmp/hive-june/hive_2013-10-18_21-18-12_812_378750610917949668/_tmp.-ext-10001&amp;quot;:june:hadoop:drwxr-xr-x
    at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:224)
    at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:204)
    at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:149)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4705)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:4687)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:4661)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameToInternal(FSNamesystem.java:2696)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameToInt(FSNamesystem.java:2663)
    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2642)
    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename(NameNodeRpcServer.java:610)
    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.rename
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;出现上述异常是因为，mapreduce任务在运行过程中会生成一些临时文件，而NoName用户对临时文件没有写的权限，这些临时文件属于june用户。查看hdfs文件如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@edh1 lib]# hadoop fs -ls /tmp/
Found 6 items
drwx------   - june hadoop          0 2013-10-15 01:33 /tmp/hadoop-yarn
drwxr-xr-x   - june hadoop          0 2013-10-16 06:52 /tmp/hive-june
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;/tmp/hive-june&lt;/code&gt;是hive执行过程中保存在hdfs的路径，由&lt;code&gt;hive.exec.scratchdir&lt;/code&gt;定义，其默认值为&lt;code&gt;/tmp/hive-${user.name}&lt;/code&gt;，而且这个文件是在&lt;code&gt;org.apache.hadoop.hive.ql.Context&lt;/code&gt;类的构造方法中获取并在ExecDriver类的execute(DriverContext driverContext)方法中创建的。&lt;/p&gt;

&lt;p&gt;类似这样的权限问题还会出现在hdfs文件&lt;code&gt;重命名、删除临时目录的时候&lt;/code&gt;。为了避免出现这样的异常，需要修改&lt;code&gt;hive.exec.scratchdir&lt;/code&gt;为当前用户对应的临时目录路径，并使用当前登陆用户创建、重命名、删除临时目录。&lt;/p&gt;

&lt;p&gt;修改获取&lt;code&gt;hive.exec.scratchdir&lt;/code&gt;对应的临时目录代码如下，在Context类的够找方法中修改：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    String user = conf.get(myExecuteName，“”);

    if (user != null &amp;amp;&amp;amp; user.trim().length() &amp;gt; 0) {
      nonLocalScratchPath =
          new Path(&amp;quot;/tmp/hive-&amp;quot; + user, executionId);
    } else {
      nonLocalScratchPath =
          new Path(HiveConf.getVar(conf, HiveConf.ConfVars.SCRATCHDIR),
              executionId);
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;找到这些操作对应的代码似乎太过复杂了，修改的地方也有很多，因为这里是使用的hive-server2，故在对应的jdbc代码中修改似乎会简单很多，例如修改HiveSessionImpl类的以下三个方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public OperationHandle executeStatement(String statement, Map&amp;lt;String, String&amp;gt; confOverlay) throws HiveSQLException{}

public void cancelOperation(final OperationHandle opHandle) throws HiveSQLException {}

public void closeOperation(final OperationHandle opHandle) throws HiveSQLException {}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第一个方法是运行sql语句，第二个方法是取消运行，第三个方法是关闭连接。&lt;/p&gt;

&lt;p&gt;executeStatement中所做的修改如下，将&lt;code&gt;operation.run();&lt;/code&gt;改为：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    if (operation instanceof SQLOperation) {
        try {
          String user = hiveConf.getVar(ConfVars.HIVE_SERVER2_MAPREDUCE_USERNAME);
          ugi = UserGroupInformation.createRemoteUser(user);
          ugi.doAs(new PrivilegedExceptionAction&amp;lt;CommandProcessorResponse&amp;gt;() {
            @Override
            public CommandProcessorResponse run() throws HiveSQLException {
              operation.run();
              return null;
            }
          });
        } catch (IOException e) {
          e.printStackTrace();
        } catch (InterruptedException e) {
          e.printStackTrace();
        }
      } else {
        operation.run();
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里添加了判断，当operation操作时，才执行下面代码，这是为了保证从hive环境变量中获取myExecuteName的值不为空时才创建UserGroupInformation。&lt;/p&gt;

&lt;p&gt;myExecuteName是新定义的hive变量，主要是用于jdbc客户端通过set语句设置myExecuteName的值为当前登陆用户名称，然后在执行sql语句。代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Statement stmt = conn.createStatement();

stmt.execute(&amp;quot;set myExecuteName=aaaa&amp;quot;);
ResultSet rs = stmt.executeQuery(&amp;quot;select count(1) from t&amp;quot;);

while (rs.next())
    System.out.println(rs.getString(1));
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;小结&lt;/h2&gt;

&lt;p&gt;上面修改的类包括：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;org.apache.hadoop.mapred.JobClient //从环境变量获取从jdbc客户端传过来的用户，即myExecuteName的值，然后以该值运行mapreduce用户
org.apache.hadoop.hive.ql.Context  //修改hive.exec.scratchdir的地址为从jdbc客户端传过来的用户对应的临时目录
org.apache.hive.service.cli.session.HiveSessionImpl //修改运行sql、取消操作、关闭连接对应的方法
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;测试&lt;/h1&gt;

&lt;p&gt;是用javachen用户测试,hdfs上的临时目录如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@edh1 lib]# hadoop fs -ls /tmp/
Found 7 items
drwx------   - june         hadoop          0 2013-10-15 01:33 /tmp/hadoop-yarn
drwxr-xr-x   - javachen.com hadoop          0 2013-10-16 07:30 /tmp/hive-javachen.com
drwxr-xr-x   - june         hadoop          0 2013-10-16 06:52 /tmp/hive-june
drwxr-xr-x   - root         hadoop          0 2013-10-15 14:13 /tmp/hive-root
drwxrwxrwt   - yarn         mapred          0 2013-10-16 07:30 /tmp/logs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;监控页面截图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;files/2013/20131017-03.png&quot; alt=&quot;yarn cluster monitor page&quot;&gt;&lt;/p&gt;

&lt;p&gt;除了简单测试之外，还需要测试修改后的代码是否影响源代码的运行以及hive cli的运行。&lt;/p&gt;

&lt;h1&gt;Enjoy it ！&lt;/h1&gt;
</content>
 </entry>
 
 <entry>
   <title>hive连接产生笛卡尔集</title>
   <link href="http://blog.javachen.com/hive/2013/10/17/cartesian-product-in-hive-inner-join"/>
   <updated>2013-10-17T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hive/2013/10/17/cartesian-product-in-hive-inner-join</id>
   <content type="html">&lt;p&gt;在使用hive过程中遇到这样的一个异常：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;FAILED: ParseException line 1:18 Failed to recognize predicate &amp;#39;a&amp;#39;. Failed rule: &amp;#39;kwInner&amp;#39; in join type specifier
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;执行的hql语句如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@javachen.com ~]# hive -e &amp;#39;select a.* from t a, t b where a.id=b.id&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从异常信息中很难看出出错原因，hive.log中也没有打印出详细的异常对战信息。改用jdbc连接hive-server2，可以看到hive-server2中提示如下异常信息：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;13/10/17 09:57:48 ERROR ql.Driver: FAILED: ParseException line 1:18 Failed to recognize predicate &amp;#39;a&amp;#39;. Failed rule: &amp;#39;kwInner&amp;#39; in join type specifier

org.apache.hadoop.hive.ql.parse.ParseException: line 1:18 Failed to recognize predicate &amp;#39;a&amp;#39;. Failed rule: &amp;#39;kwInner&amp;#39; in join type specifier

    at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:446)
    at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:441)
    at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:349)
    at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:355)
    at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:95)
    at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:76)
    at org.apache.hive.service.cli.operation.SQLOperation.run(SQLOperation.java:114)
    at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:194)
    at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:155)
    at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:191)
    at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1193)
    at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1)
    at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
    at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
    at org.apache.hive.service.cli.thrift.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:38)
    at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:662)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;p&gt;从异常信息可以看到是在编译hql语句进行语法解析时出现了错误，到底为什么会出现&lt;code&gt;Failed rule: &amp;#39;kwInner&amp;#39; in join type specifier&lt;/code&gt;这样的异常信息呢？&lt;/p&gt;

&lt;p&gt;在eclipse中查找关键字并没有找到相应代码，在&lt;a href=&quot;http://svn.apache.org/repos/asf/hive/tags/release-0.10.0/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g&quot;&gt;Hive.g&lt;/a&gt; 中查找关键字“kwInner”，可以看到如下内容：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;joinToken
@init { msgs.push(&amp;quot;join type specifier&amp;quot;); }
@after { msgs.pop(); }
    :
      KW_JOIN                     -&amp;gt; TOK_JOIN
    | kwInner  KW_JOIN            -&amp;gt; TOK_JOIN
    | KW_CROSS KW_JOIN            -&amp;gt; TOK_CROSSJOIN
    | KW_LEFT  KW_OUTER KW_JOIN   -&amp;gt; TOK_LEFTOUTERJOIN
    | KW_RIGHT KW_OUTER KW_JOIN   -&amp;gt; TOK_RIGHTOUTERJOIN
    | KW_FULL  KW_OUTER KW_JOIN   -&amp;gt; TOK_FULLOUTERJOIN
    | KW_LEFT  KW_SEMI  KW_JOIN   -&amp;gt; TOK_LEFTSEMIJOIN
    ;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从上面可以看出hive支持的连接包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;join&lt;/li&gt;
&lt;li&gt;inner join&lt;/li&gt;
&lt;li&gt;cross join (as of Hive 0.10)&lt;/li&gt;
&lt;li&gt;left outer join&lt;/li&gt;
&lt;li&gt;right outer join&lt;/li&gt;
&lt;li&gt;full outer join&lt;/li&gt;
&lt;li&gt;left semi join&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;kwInner为什么是小写呢，其含义是什么呢？搜索关键字，找到如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;kwInner
:
{input.LT(1).getText().equalsIgnoreCase(&amp;quot;inner&amp;quot;)}? Identifier;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面的大概意思是找到输入左边的内容并判断其值在忽略大小写情况下是否等于inner，大概意思是hql语句中缺少inner关键字吧？修改下hql语句如下，然后执行：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@javachen.com ~]#  hive -e &amp;#39;select a.* from t a inner join t b where a.id=b.id&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改后的hql语句能够正常运行，并且变成了内连接。&lt;code&gt;在JION接连查询中没有ON连接key而通过WHERE条件语句会产生笛卡尔集。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Hive本身是不支持笛卡尔集的，不能用&lt;code&gt;select T1.*, T2.* from table1, table2&lt;/code&gt;这种语法。但有时候确实需要用到笛卡尔集的时候，可以用下面的语法来实现同样的效果：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;select T1.*, T2.* from table1 T1 join table2 T2 where 1=1;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意在Hive的Strict模式下不能用这种语法，因为这样会产生笛卡尔集，而这种模式禁止产生笛卡尔集。需要先用&lt;code&gt;set hive.mapred.mode=nonstrict;&lt;/code&gt;设为非strict模式就可以用了，或者将where改为on连接。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;select T1.*, T2.* from table1 T1 join table2 T2 on  T1.id=T2.id;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;关于Strict Mode&lt;/h1&gt;

&lt;p&gt;Hive中的严格模式可以防止用户发出（可以有问题）的查询无意中造成不良的影响。 将&lt;code&gt;hive.mapred.mode&lt;/code&gt;设置成strict可以禁止三种类型的查询： &lt;/p&gt;

&lt;p&gt;1）、在一个分区表上，如果没有在WHERE条件中指明具体的分区，那么这是不允许的，换句话说，不允许在分区表上全表扫描。这种限制的原因是分区表通常会持非常大的数据集并且可能数据增长迅速，对这样的一个大表做全表扫描会消耗大量资源，必须要再WHERE过滤条件中具体指明分区才可以执行成功的查询。&lt;/p&gt;

&lt;p&gt;2）、第二种是禁止执行有ORDER BY的排序要求但没有LIMIT语句的HiveQL查询。因为ORDER BY全局查询会导致有一个单一的reducer对所有的查询结果排序，如果对大数据集做排序，这将导致不可预期的执行时间，必须要加上limit条件才可以执行成功的查询。&lt;/p&gt;

&lt;p&gt;3）、第三种是禁止产生笛卡尔集。在JION接连查询中没有ON连接key而通过WHERE条件语句会产生笛卡尔集，需要改为JOIN...ON语句。&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;[1] &lt;a href=&quot;http://flyingdutchman.iteye.com/blog/1871983&quot;&gt;深入学习《Programing Hive》：Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href=&quot;http://blog.hesey.net/2012/04/hive-tips.html&quot;&gt;Hive Tips&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>最近的工作</title>
   <link href="http://blog.javachen.com/work/2013/09/08/recent-work"/>
   <updated>2013-09-08T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/work/2013/09/08/recent-work</id>
   <content type="html">&lt;p&gt;最近一直在构思这篇博客的内容，到现在还是不知道从何下手。自从将博客从wordpress迁移到github上之后，就很少在博客写一些关于工作和生活的文章，所以想写一篇关于工作的博客，记录最近做过的事情以及一些当时的所思所想。&lt;/p&gt;

&lt;p&gt;最近半年多一直在做hadoop方面的工作，也就是接触hadoop才半年多时间。最开始接触hadoop是去年的11月21日，那天去Intel公司参加了两天的hadoop培训。培训的内容很多干货也有很多枯燥的东西，所以边听边瞌睡的听完了两天的培训内容。培训的ppt打印出来了，时不时地会翻看上面讲述的内容，然后在网上搜索些相关的资料。&lt;/p&gt;

&lt;p&gt;最先接触的hadoop发行版是Intel的IDH，刚开始使用IDH也就是用他的管理界面安装、部署hadoop集群，然后在8节点的集群上作hive两表关联的测试。测试结果不是很满意，但是对IDH倒是印象深刻。IDH的前端使用GWT开发，界面简洁，操作也比较方便，只是同步配置文件有时候非常慢，要等上一杯咖啡的时间。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;IDH的源代码不开源，所以遇到一些问题的时候，只能先自己摸索。我不喜欢闭源也不喜欢许可证以及混淆代码什么的。虽然java代码的混淆了，但是shell和puppet脚本还是能够很容易读懂的。参考IDH的部署安装脚本，我在试着用shell编写一个hadoop的安装部署脚本，这个工作还在慢慢进行中。也许在弄懂puppet的原理和代码之后，我会简化、改进IDH的脚本；也许会使用公司使用的saltstack来完善这个部署脚本。&lt;/p&gt;

&lt;p&gt;IDH实现了hive over hbase，这是一个很不错的特性，其基于hbase的协作器，代码实现并不复杂。IDH中有个hmon用于监控hadoop，我已经把这部分代码反编译了。&lt;/p&gt;

&lt;p&gt;在hadoop版本选择的过程中，体验了Cloudera的CDH。首先是CDH的压缩包手动安装hadoop集群，一点点的修改配置文件，直到最后集群能够成功启动，这种方式安装的hadoop集群不包含本地lib文件；然后又试着解压缩Cloudera-manager.bin文件，尝试在虚拟机中不连接网络的情况下通过Cloudera-manager来安装配置集群，在使用了一段时间之后，发现Cloudera-manager没有使用操作系统的service服务来管理hadoop组件的启动和停止，而是有自己一套实现来管理集群，再加上Cloudera-manager也不开源，故放弃了使用Cloudera-manager来安装集群的方式；最后，最后是使用rpm方式来安装hadoop，安装过程倒是不复杂，只是以后如果自己修改了源代码时候升级不是很方便了，Cloudera的github上有个cdh-package项目，这个其实就是apache的bigtop项目，试过通过这个来编译出hadoop的rpm包，没有成功。&lt;/p&gt;

&lt;p&gt;IDH通过本地文件来保存集群的配置信息，而CDH将这些信息保存到数据库了。CDH的Cloudera-manager的web界面基于bootstrap和jquery插件，ui做的很不错，通过反编译java代码，已经知道了其web界面的实现方式以及编译成功了部分java代码。CDH的Cloudera-manager和IDH-manager也很大不同，我想在这两个的基础上也实现一个hadoop的manager，这是我个人想法，还需要研究、整理出他们的实现思路，然后一点点的构思自己该怎么做。Cloudera-manager免费版简称CMF。&lt;/p&gt;

&lt;p&gt;差不多两个月前，公司想做个hive的查询界面，这个东西其实就是和hwi、hue差不多的个东西。基于Spring，我很快搭好了框架，然后把CMF其中的css和js都迁移过来了。这是我第一次接触bootstrap，稍微修改下代码一个前台框架就弄好了，CMF最主要是使用了require.js使javascript代码模块化，这东西改起来也很简单，我把CMF中大部分基础javascript代码都移到了我搭好的框架中。搭好这个框架没花多少时间，但后来公司不打算使用这一套框架，以后有时间我会继续基于这个框架开发个hadoop的管理界面。&lt;/p&gt;

&lt;p&gt;在使用ganglia监控hadoop的过程中，有时候需要找一个监控指标需要花好长时间，而且一个页面上显示的指标太多的时候，这个页面会反应不过来。hortonworks的HDP发行版中似乎对ganglia做了些修改，具体不知道改了什么。HDP发行版没有使用和研究过，只是下载了1.3和2.0两个版本的VM，然后看了看其中的hue，觉得做的很不错，只可惜是python写的。&lt;/p&gt;

&lt;p&gt;在使用hadoop的过程中，觉得hadoop的门槛对于用户来说还是有点高。用户需要学习hive语法，写出的sql语句通常都不是最优sql，如果有个sql优化器自动帮用户优化sql语句就好了。hbase用于监控业务日志，数据建模和编写代码查询数据对于业务人员来说难度也太大了，如果能够适度封装，让业务人员不用关心hadoop的细节，只需要编写sql语句就能查询数据该多好啊！&lt;/p&gt;

&lt;p&gt;其他工作：hive和mapreduce调优。&lt;/p&gt;

&lt;p&gt;上面是最近在做的一些事情，包括暂停没做的、正在做的以及还未做的。有时候觉得有些事情很简单，但没有时间、没有精力也没有自由一下子做完，有些时候人在江湖，身不由己。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>hive中如何确定map数</title>
   <link href="http://blog.javachen.com/hive/2013/09/04/how-to-decide-map-number"/>
   <updated>2013-09-04T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hive/2013/09/04/how-to-decide-map-number</id>
   <content type="html">&lt;p&gt;hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。当运行一个hql语句的时候，map数是如何计算出来的呢？有哪些方法可以调整map数呢？&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1&gt;hive默认的input format&lt;/h1&gt;

&lt;p&gt;在&lt;code&gt;cdh-4.3.0&lt;/code&gt;的hive中查看&lt;code&gt;hive.input.format&lt;/code&gt;值（为什么是&lt;code&gt;hive.input.format&lt;/code&gt;？）：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive&amp;gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以看到默认值为CombineHiveInputFormat，如果你使用的是&lt;code&gt;IDH&lt;/code&gt;的hive，则默认值为：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive&amp;gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;CombineHiveInputFormat类继承自HiveInputFormat，而HiveInputFormat实现了org.apache.hadoop.mapred.InputFormat接口，关于InputFormat的分析，可以参考&lt;a href=&quot;http://flyingdutchman.iteye.com/blog/1876400&quot;&gt;Hadoop深入学习：InputFormat组件&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;InputFormat接口功能&lt;/h1&gt;

&lt;p&gt;简单来说，InputFormat主要用于描述输入数据的格式，提供了以下两个功能： &lt;/p&gt;

&lt;p&gt;1)、数据切分，按照某个策略将输入数据且分成若干个split，以便确定Map Task的个数即Mapper的个数，在MapReduce框架中，一个split就意味着需要一个Map Task; &lt;/p&gt;

&lt;p&gt;2)、为Mapper提供输入数据，即给定一个split(使用其中的RecordReader对象)将之解析为一个个的key/value键值对。 &lt;/p&gt;

&lt;p&gt;该类接口定义如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public interface InputFormat&amp;lt;K,V&amp;gt;{
    public InputSplit[] getSplits(JobConf job,int numSplits) throws IOException; 
    public RecordReader&amp;lt;K,V&amp;gt; getRecordReader(InputSplit split,JobConf job,Reporter reporter) throws IOException; 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中，getSplit()方法主要用于切分数据，每一份数据由，split只是在逻辑上对数据分片，并不会在磁盘上将数据切分成split物理分片，实际上数据在HDFS上还是以block为基本单位来存储数据的。InputSplit只记录了Mapper要处理的数据的元数据信息，如起始位置、长度和所在的节点。&lt;/p&gt;

&lt;p&gt;MapReduce自带了一些InputFormat的实现类： &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg&quot; alt=&quot;InputFormat实现类&quot;&gt;&lt;/p&gt;

&lt;p&gt;hive中有一些InputFormat的实现类，如：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;AvroContainerInputFormat
RCFileBlockMergeInputFormat
RCFileInputFormat
FlatFileInputFormat
OneNullRowInputFormat
ReworkMapredInputFormat
SymbolicInputFormat
SymlinkTextInputFormat
HiveInputFormat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;HiveInputFormat的子类有：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/implement-of-hiveinputformat.png&quot; alt=&quot;HiveInputFormat的子类&quot;&gt;&lt;/p&gt;

&lt;h1&gt;HiveInputFormat&lt;/h1&gt;

&lt;p&gt;以HiveInputFormat为例，看看其getSplit()方法逻辑：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;for (Path dir : dirs) {
  PartitionDesc part = getPartitionDescFromPath(pathToPartitionInfo, dir);
  // create a new InputFormat instance if this is the first time to see this
  // class
  Class inputFormatClass = part.getInputFileFormatClass();
  InputFormat inputFormat = getInputFormatFromCache(inputFormatClass, job);
  Utilities.copyTableJobPropertiesToConf(part.getTableDesc(), newjob);

  // Make filter pushdown information available to getSplits.
  ArrayList&amp;lt;String&amp;gt; aliases =
      mrwork.getPathToAliases().get(dir.toUri().toString());
  if ((aliases != null) &amp;amp;&amp;amp; (aliases.size() == 1)) {
    Operator op = mrwork.getAliasToWork().get(aliases.get(0));
    if ((op != null) &amp;amp;&amp;amp; (op instanceof TableScanOperator)) {
      TableScanOperator tableScan = (TableScanOperator) op;
      pushFilters(newjob, tableScan);
    }
  }

  FileInputFormat.setInputPaths(newjob, dir);
  newjob.setInputFormat(inputFormat.getClass());
  InputSplit[] iss = inputFormat.getSplits(newjob, numSplits / dirs.length);
  for (InputSplit is : iss) {
    result.add(new HiveInputSplit(is, inputFormatClass.getName()));
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面代码主要过程是：&lt;/p&gt;

&lt;blockquote&gt;遍历每个输入目录，然后获得PartitionDesc对象，从该对象调用getInputFileFormatClass方法得到实际的InputFormat类，并调用其`getSplits(newjob, numSplits / dirs.length)`方法。
&lt;/blockquote&gt;

&lt;p&gt;按照上面代码逻辑，似乎hive中每一个表都应该有一个InputFormat实现类。在hive中运行下面代码，可以查看建表语句：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive&amp;gt; show create table info; 
OK
CREATE  TABLE info(
  statist_date string, 
  statistics_date string, 
  inner_code string, 
  office_no string, 
  window_no string, 
  ticket_no string, 
  id_kind string, 
  id_no string, 
  id_name string, 
  area_center_code string)
ROW FORMAT DELIMITED 
  FIELDS TERMINATED BY &amp;#39;\;&amp;#39; 
  LINES TERMINATED BY &amp;#39;\n&amp;#39; 
STORED AS INPUTFORMAT 
  &amp;#39;org.apache.hadoop.mapred.TextInputFormat&amp;#39; 
OUTPUTFORMAT 
  &amp;#39;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&amp;#39;
LOCATION
  &amp;#39;hdfs://node:8020/user/hive/warehouse/info&amp;#39;
TBLPROPERTIES (
  &amp;#39;numPartitions&amp;#39;=&amp;#39;0&amp;#39;, 
  &amp;#39;numFiles&amp;#39;=&amp;#39;1&amp;#39;, 
  &amp;#39;transient_lastDdlTime&amp;#39;=&amp;#39;1378245263&amp;#39;, 
  &amp;#39;numRows&amp;#39;=&amp;#39;0&amp;#39;, 
  &amp;#39;totalSize&amp;#39;=&amp;#39;301240320&amp;#39;, 
  &amp;#39;rawDataSize&amp;#39;=&amp;#39;0&amp;#39;)
Time taken: 0.497 seconds
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从上面可以看到info表的INPUTFORMAT为&lt;code&gt;org.apache.hadoop.mapred.TextInputFormat&lt;/code&gt;，TextInputFormat继承自FileInputFormat。FileInputFormat是一个抽象类，它最重要的功能是为各种InputFormat提供统一的getSplits()方法，该方法最核心的是文件切分算法和Host选择算法。&lt;/p&gt;

&lt;p&gt;算法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;long length = file.getLen();
long goalSize = totalSize / (numSplits == 0 ? 1 : numSplits);
long minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.
FileInputFormat.SPLIT_MINSIZE, 1), minSplitSize);

long blockSize = file.getBlockSize();
long splitSize = computeSplitSize(goalSize, minSize, blockSize);
long bytesRemaining = length;
while (((double) bytesRemaining)/splitSize &amp;gt; SPLIT_SLOP) {
String[] splitHosts = getSplitHosts(blkLocations, 
    length-bytesRemaining, splitSize, clusterMap);
    splits.add(makeSplit(path, length-bytesRemaining, splitSize, 
               splitHosts));
    bytesRemaining -= splitSize;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr&gt;

&lt;p&gt;&lt;code&gt;华丽的分割线&lt;/code&gt;：以下摘抄自&lt;a href=&quot;http://flyingdutchman.iteye.com/blog/1876400&quot;&gt;Hadoop深入学习：InputFormat组件&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1）、文件切分算法&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;文件切分算法主要用于确定InputSplit的个数以及每个InputSplit对应的数据段，FileInputSplit以文件为单位切分生成InputSplit。有三个属性值来确定InputSplit的个数：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;goalSize：该值由totalSize/numSplits来确定InputSplit的长度，它是根据用户的期望的InputSplit个数计算出来的；numSplits为用户设定的Map Task的个数，默认为1。 &lt;/li&gt;
&lt;li&gt;minSize：由配置参数mapred.min.split.size（或者 &lt;code&gt;mapreduce.input.fileinputformat.split.minsize&lt;/code&gt;）决定的InputFormat的最小长度，默认为1。 &lt;/li&gt;
&lt;li&gt;blockSize：HDFS中的文件存储块block的大小，默认为64MB。&lt;/li&gt;
&lt;li&gt;numSplits=&lt;code&gt;mapred.map.tasks&lt;/code&gt; 或者 &lt;code&gt;mapreduce.job.maps&lt;/code&gt; &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这三个参数决定一个InputFormat分片的最终的长度，计算方法如下： &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;splitSize = max{minSize,min{goalSize,blockSize}} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;计算出了分片的长度后，也就确定了InputFormat的数目。 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2）、host选择算法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;InputFormat的切分方案确定后，接下来就是要确定每一个InputSplit的元数据信息。InputSplit元数据通常包括四部分，&lt;code&gt;&amp;lt;file,start,length,hosts&amp;gt;&lt;/code&gt;其意义为： &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;file标识InputSplit分片所在的文件； &lt;/li&gt;
&lt;li&gt;InputSplit分片在文件中的的起始位置； &lt;/li&gt;
&lt;li&gt;InputSplit分片的长度； &lt;/li&gt;
&lt;li&gt;分片所在的host节点的列表。 &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
InputSplit的host列表的算作策略直接影响到运行作业的本地性。&lt;br/&gt;

我们知道，由于大文件存储在HDFS上的block可能会遍布整个Hadoop集群，而一个InputSplit分片的划分算法可能会导致一个split分片对应多个不在同一个节点上的blocks，这就会使得在Map Task执行过程中会涉及到读其他节点上的属于该Task的block中的数据，从而不能实现数据本地性，而造成更多的网络传输开销。&lt;br/&gt;
 
一个InputSplit分片对应的blocks可能位于多个数据节点地上，但是基于任务调度的效率，通常情况下，不会把一个分片涉及的所有的节点信息都加到其host列表中，而是选择包含该分片的数据总量的最大的前几个节点，作为任务调度时判断是否具有本地性的主要凭证。&lt;br/&gt;
 
FileInputFormat使用了一个启发式的host选择算法：首先按照rack机架包含的数据量对rack排序，然后再在rack内部按照每个node节点包含的数据量对node排序，最后选取前N个(N为block的副本数)node的host作为InputSplit分片的host列表。当任务地调度Task作业时，只要将Task调度给host列表上的节点，就可以认为该Task满足了本地性。 &lt;br/&gt;

从上面的信息我们可以知道，当InputSplit分片的大小大于block的大小时，Map Task并不能完全满足数据的本地性，总有一本分的数据要通过网络从远程节点上读数据，故为了提高Map Task的数据本地性，减少网络传输的开销，应尽量是InputFormat的大小和HDFS的block块大小相同。
&lt;/blockquote&gt;

&lt;hr&gt;

&lt;h1&gt;CombineHiveInputFormat&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;getSplits(JobConf job, int numSplits)&lt;/code&gt;代码运行过程如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;init(job);
CombineFileInputFormatShim combine = ShimLoader.getHadoopShims().getCombineFileInputFormat();
    ShimLoader.loadShims(HADOOP_SHIM_CLASSES, HadoopShims.class);
        Hadoop23Shims
            HadoopShimsSecure.getCombineFileInputFormat()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;CombineFileInputFormatShim继承了&lt;code&gt;org.apache.hadoop.mapred.lib.CombineFileInputFormat&lt;/code&gt;,CombineFileInputFormatShim的getSplits方法代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public InputSplitShim[] getSplits(JobConf job, int numSplits) throws IOException {
  long minSize = job.getLong(&amp;quot;mapred.min.split.size&amp;quot;, 0);

  // For backward compatibility, let the above parameter be used
  if (job.getLong(&amp;quot;mapred.min.split.size.per.node&amp;quot;, 0) == 0) {
    super.setMinSplitSizeNode(minSize);
  }

  if (job.getLong(&amp;quot;mapred.min.split.size.per.rack&amp;quot;, 0) == 0) {
    super.setMinSplitSizeRack(minSize);
  }

  if (job.getLong(&amp;quot;mapred.max.split.size&amp;quot;, 0) == 0) {
    super.setMaxSplitSize(minSize);
  }

  InputSplit[] splits = (InputSplit[]) super.getSplits(job, numSplits);

  InputSplitShim[] isplits = new InputSplitShim[splits.length];
  for (int pos = 0; pos &amp;lt; splits.length; pos++) {
    isplits[pos] = new InputSplitShim((CombineFileSplit)splits[pos]);
  }

  return isplits;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从上面代码可以看出，如果为CombineHiveInputFormat，则以下四个参数起作用：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mapred.min.split.size 或者 mapreduce.input.fileinputformat.split.minsize&lt;/li&gt;
&lt;li&gt;mapred.max.split.size 或者 mapreduce.input.fileinputformat.split.maxsize&lt;/li&gt;
&lt;li&gt;mapred.min.split.size.per.rack 或者 mapreduce.input.fileinputformat.split.minsize.per.rack&lt;/li&gt;
&lt;li&gt;mapred.min.split.size.per.node 或者 mapreduce.input.fileinputformat.split.minsize.per.node&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CombineFileInputFormatShim的getSplits方法最终会调用父类的getSplits方法，拆分算法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;long left = locations[i].getLength();
long myOffset = locations[i].getOffset();
long myLength = 0;
do {
    if (maxSize == 0) {
        myLength = left;
    } else {
    if (left &amp;gt; maxSize &amp;amp;&amp;amp; left &amp;lt; 2 * maxSize) {
      myLength = left / 2;
    } else {
      myLength = Math.min(maxSize, left);
    }
    }
    OneBlockInfo oneblock = new OneBlockInfo(path, myOffset,
      myLength, locations[i].getHosts(), locations[i]
          .getTopologyPaths());
    left -= myLength;
    myOffset += myLength;

    blocksList.add(oneblock);
} while (left &amp;gt; 0);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;hive中如何确定map数&lt;/h1&gt;

&lt;p&gt;总上总结如下：&lt;/p&gt;

&lt;p&gt;如果&lt;code&gt;hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat&lt;/code&gt;，则这时候的参数如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive&amp;gt; set mapred.min.split.size;
mapred.min.split.size=1
hive&amp;gt; set mapred.map.tasks;
mapred.map.tasks=2
hive&amp;gt; set dfs.blocksize;
dfs.blocksize=134217728
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面参数中mapred.map.tasks为2，dfs.blocksize（使用的是cdh-4.3.0版本的hadoop，这里block和size之间没有逗号）为128M。&lt;/p&gt;

&lt;p&gt;假设有一个文件为200M，则按上面HiveInputFormat的split算法：&lt;/p&gt;

&lt;p&gt;1、文件总大小为200M，goalSize=200M /2 =100M，minSize=1 ，splitSize = max{1,min{100M,128M}} =100M&lt;/p&gt;

&lt;p&gt;2、200M / 100M &amp;gt;1.1,故第一块大小为100M&lt;/p&gt;

&lt;p&gt;3、剩下文件大小为100M，小于128M，故第二块大小为100M。&lt;/p&gt;

&lt;p&gt;如果&lt;code&gt;hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&lt;/code&gt;，则这时候的参数如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive&amp;gt; set mapred.min.split.size;
mapred.min.split.size=1
hive&amp;gt; set mapred.max.split.size;
mapred.max.split.size=67108864
hive&amp;gt; set mapred.min.split.size.per.rack;
mapred.min.split.size.per.rack=1
hive&amp;gt; set mapred.min.split.size.per.node;
mapred.min.split.size.per.node=1
hive&amp;gt; set dfs.blocksize;
dfs.blocksize=134217728
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面参数中mapred.max.split.size为64M，dfs.blocksize（使用的是cdh-4.3.0版本的hadoop，这里block和size之间没有逗号）为128M。&lt;/p&gt;

&lt;p&gt;假设有一个文件为200M，则按上面CombineHiveInputFormat的split算法：&lt;/p&gt;

&lt;p&gt;1、128M &amp;lt; 200M &amp;lt;128M X 2，故第一个block大小为128M&lt;/p&gt;

&lt;p&gt;2、剩下文件大小为200M-128M=72M，72M &amp;lt; 128M,故第二块大小为72M&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;网上有一些文章关于hive中如何控制map数的文章是否考虑的不够全面，没有具体情况具体分析。简而言之，当InputFormat的实现类为不同类时，拆分块算法都不一样，相关设置参数也不一样，需要具体分析。&lt;/p&gt;

&lt;h2&gt;1. map数不是越多越好&lt;/h2&gt;

&lt;p&gt;如果一个任务有很多小文件（远远小于块大小128m）,则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。
而且，同时可执行的map数是受限的。&lt;/p&gt;

&lt;h2&gt;2. 如何适当的增加map数？&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;将数据导入到hive前，手动将大文件拆分为小文件&lt;/li&gt;
&lt;li&gt;指定map数，使用insert或者create as select语句将一个表导入到另一个表，然后对另一张表做查询&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;3. 一些经验&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;合并小文件可以减少map数，但是会增加网络IO。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;尽量使拆分块大小和hdfs的块大小接近，避免一个拆分块大小上的多个hdfs块位于不同数据节点，从而降低网络IO。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;根据实际情况，控制map数量需要遵循两个原则：&lt;code&gt;使大数据量利用合适的map数&lt;/code&gt;；&lt;code&gt;使单个map任务处理合适的数据量。&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;[1] &lt;a href=&quot;http://f.dataguru.cn/thread-149820-1-1.html&quot;&gt;【hive】hive的查询注意事项以及优化总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href=&quot;http://blog.sina.com.cn/s/blog_6ff05a2c010178qd.html&quot;&gt;Hadoop中map数的计算&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href=&quot;http://blog.sina.com.cn/s/blog_6ff05a2c0101aqvv.html&quot;&gt;[Hive]从一个经典案例看优化mapred.map.tasks的重要性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[4] &lt;a href=&quot;http://superlxw1234.iteye.com/blog/1582880&quot;&gt;hive优化之------控制hive任务中的map数和reduce数&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[5] &lt;a href=&quot;http://www.searchtb.com/2010/12/hadoop-job-tuning.html&quot;&gt;Hadoop Job Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[6] &lt;a href=&quot;http://www.tuicool.com/articles/77f2Af&quot;&gt;Hive配置项的含义详解（2）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[7] &lt;a href=&quot;http://blog.csdn.net/lalaguozhe/article/details/9053645&quot;&gt;Hive小文件合并调研&lt;/a&gt;
&lt;a href=&quot;http://flyingdutchman.iteye.com/blog/1876400&quot;&gt;Hadoop深入学习：InputFormat组件&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>我的jekyll配置和修改</title>
   <link href="http://blog.javachen.com/post/2013/08/31/my-jekyll-config"/>
   <updated>2013-08-31T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/post/2013/08/31/my-jekyll-config</id>
   <content type="html">&lt;p&gt;主要记录使用jekyll搭建博客时的一些配置和修改。&lt;/p&gt;

&lt;p&gt;注意：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;使用时请删除{和%以及{和{之间的空格。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;预览文章&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;source ~/.bash_profile
jekyll server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;添加about me 边栏&lt;/h1&gt;

&lt;p&gt;参考&lt;a href=&quot;http://www.the5fire.com/&quot;&gt;the5fire的技术博客&lt;/a&gt;在index.html页面加入如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;section&amp;gt;
&amp;lt;h4&amp;gt;About me&amp;lt;/h4&amp;gt;
&amp;lt;div&amp;gt;
 一个Java方案架构师，主要从事hadoop相关工作。&amp;lt;a href=&amp;quot;/about.html&amp;quot;&amp;gt;更多信息&amp;lt;/a&amp;gt; 
&amp;lt;br/&amp;gt;
&amp;lt;br/&amp;gt;
&amp;lt;strong&amp;gt;&amp;lt;font color=&amp;quot;red&amp;quot;&amp;gt;&amp;lt;a href=&amp;quot;/atom.xml&amp;quot; target=&amp;quot;_blank&amp;quot;&amp;gt;订阅本站&amp;lt;/a&amp;gt;&amp;lt;/font&amp;gt;&amp;lt;/strong&amp;gt;
&amp;lt;br/&amp;gt;&amp;lt;br/&amp;gt;
联系博主：javachen.june[a]gmail.com
&amp;lt;/div&amp;gt;
&amp;lt;/section&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;h1&gt;添加about页面&lt;/h1&gt;

&lt;p&gt;在根目录创建about.md并修改，注意：文件开头几行内容如下&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;title: About
layout: page
group: navigation
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;设置固定链接&lt;/h1&gt;

&lt;p&gt;在 _config.yml 里，找到 permalink，设置如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;permalink: /:categories/:year/:month/:day/:title 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;修改，markdown实现为redcarpet&lt;/h1&gt;

&lt;p&gt;首先通过gem安装redcarpet，然后修改_config.yml：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;markdown: redcarpet
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;首页添加最近文章&lt;/h1&gt;

&lt;p&gt;在index.html页面&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;section&amp;gt;
&amp;lt;h4&amp;gt;Recent Posts&amp;lt;/h4&amp;gt;
&amp;lt;ul id=&amp;quot;recent_posts&amp;quot;&amp;gt;{ % for rpost in site.posts limit: 15 %}
&amp;lt;li class=&amp;quot;post&amp;quot;&amp;gt;
&amp;lt;a href=&amp;quot;&amp;quot;&amp;gt;&amp;lt;/a&amp;gt;
&amp;lt;/li&amp;gt;{ % endfor %}
&amp;lt;/ul&amp;gt;
&amp;lt;/section&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;首页为每篇文章添加分类、标签、发表日期以及评论连接&lt;/h1&gt;

&lt;p&gt;在index.html页面找到&lt;code&gt;&amp;lt;h3&amp;gt;&amp;lt;a href=&amp;quot;{ { BASE_PATH }}{ { post.url }}&amp;quot;&amp;gt;{ { post.title }}&amp;lt;/a&amp;gt;&amp;lt;/h3&amp;gt;&lt;/code&gt;，在下面添加：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt; &amp;lt;div class=&amp;quot;c9&amp;quot;&amp;gt;
    Categories：
        { %for cg in post.categories % }
        &amp;lt;a href=&amp;quot;/categories.html#-ref&amp;quot;&amp;gt;&amp;lt;/a&amp;gt;
        { %if forloop.index &amp;lt; forloop.length % }
        ,
        { %endif%}
        { %endfor%}
    |
    Tags：
        { %for cg in post.tags %}
        &amp;lt;a href=&amp;quot;/tags.html#-ref&amp;quot;&amp;gt;&amp;lt;/a&amp;gt;
        { %if forloop.index &amp;lt; forloop.length %}
        ,
        { %endif%}
        { %endfor%}
    |
    Time：&amp;lt;time date=&amp;quot;{ { post.date|date: &amp;#39;%Y-%m-%d&amp;#39; }}&amp;quot;&amp;gt;&amp;lt;/time&amp;gt;
    &amp;lt;a href=&amp;#39;#comments&amp;#39; title=&amp;#39;分享文章、查看评论&amp;#39; style=&amp;quot;float:right;margin-right:.5em;&amp;quot;&amp;gt;Comments&amp;lt;/a&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;修改h1、h2等标题字体&lt;/h1&gt;

&lt;p&gt;主要是参考&lt;a href=&quot;http://www.ituring.com.cn/&quot;&gt;图灵社区&lt;/a&gt;的css，在&lt;code&gt;assets/themes/twitter/css/style.css&lt;/code&gt;中添加如下css代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;h1,h2,h3,h4,h5,h6{margin:18px 0 9px;font-family:inherit;font-weight:normal;color:inherit;text-rendering:optimizelegibility;}h1 small,h2 small,h3 small,h4 small,h5 small,h6 small{font-weight:normal;color:#999999;}
h1{font-size:30px;line-height:36px;}h1 small{font-size:18px;}
h2{font-size:24px;line-height:36px;}h2 small{font-size:18px;}
h3{font-size:18px;line-height:27px;}h3 small{font-size:14px;}
h4,h5,h6{line-height:18px;}
h4{font-size:14px;}h4 small{font-size:12px;}
h5{font-size:12px;}
h6{font-size:11px;color:#999999;text-transform:uppercase;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;添加返回顶部功能&lt;/h1&gt;

&lt;p&gt;同样是参考了&lt;a href=&quot;http://www.ituring.com.cn/&quot;&gt;图灵社区&lt;/a&gt;的css和网上的一篇js实现。在&lt;code&gt;assets/themes/twitter/css/style.css&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;.backToTop {
    display: block;
    width: 40px;
    height: 32px;
    font-size: 26px;
    line-height: 32px;
    font-family: verdana, arial;
    padding: 5px 0;
    background-color: #000;
    color: #fff;
    text-align: center;
    position: fixed;
    _position: absolute;
    right: 10px;
    bottom: 100px;
    _bottom: &amp;quot;auto&amp;quot;;
    cursor: pointer;
    opacity: .6;
    filter: Alpha(opacity=60);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在&lt;code&gt;assets/themes/twitter/js&lt;/code&gt;添加jquery和main.js，main.js内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;jQuery.noConflict();
jQuery(document).ready(function(){
    var backToTopTxt = &amp;quot;▲&amp;quot;, backToTopEle = jQuery(&amp;#39;&amp;lt;div class=&amp;quot;backToTop&amp;quot;&amp;gt;&amp;lt;/div&amp;gt;&amp;#39;).appendTo(jQuery(&amp;quot;body&amp;quot;)).text(backToTopTxt).attr(&amp;quot;title&amp;quot;,&amp;quot;Back top top&amp;quot;).click(function() {
        jQuery(&amp;quot;html, body&amp;quot;).animate({ scrollTop: 0 }, 120);
    }), backToTopFun = function() {
        var st = jQuery(document).scrollTop(), winh = jQuery(window).height();
        (st &amp;gt; 200)? backToTopEle.show(): backToTopEle.hide();    
        //IE6下的定位
        if (!window.XMLHttpRequest) {
            backToTopEle.css(&amp;quot;top&amp;quot;, st + winh - 166); 
        }
    };

    backToTopEle.hide(); 
        jQuery(window).bind(&amp;quot;scroll&amp;quot;, backToTopFun);
    jQuery(&amp;#39;div.main a,div.pic a&amp;#39;).attr(&amp;#39;target&amp;#39;, &amp;#39;_blank&amp;#39;);
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;添加文章版权说明&lt;/h1&gt;

&lt;p&gt;在&lt;code&gt;_includes/themes/twitter/post.html&lt;/code&gt;中文章主体下面添加如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;hr&amp;gt;
&amp;lt;div class=&amp;quot;copyright&amp;quot;&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;本文固定链接：&amp;lt;/strong&amp;gt;&amp;lt;a href=&amp;#39;{ {page.url}}&amp;#39;&amp;gt;http://blog.javachen.com/post/2013/08/31/my-jekyll-config&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;原创文章,转载请注明出处：&amp;lt;/strong&amp;gt;&amp;lt;a href=&amp;#39;{ {page.url}}&amp;#39;&amp;gt;JavaChen Blog&amp;lt;/a&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;并在&lt;code&gt;assets/themes/twitter/css/style.css&lt;/code&gt;中添加如下css代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;.copyright {
margin: 10px 0;
padding: 10px 20px;
line-height: 1;
border-radius: 5px;
background: #f5f5f5;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;添加read more功能&lt;/h1&gt;

&lt;p&gt;参考&lt;a href=&quot;http://truongtx.me/2013/05/01/jekyll-read-more-feature-without-any-plugin/&quot;&gt;Jekyll - Read More without plugin&lt;/a&gt;，在index.html找到 ，然后修改为：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;{ % if post.content contains &amp;quot;&amp;lt;!-- more --&amp;gt;&amp;quot; %}
{ { post.content | split:&amp;quot;&amp;lt;!-- more --&amp;gt;&amp;quot; | first % }}
&amp;lt;h4&amp;gt;&amp;lt;a href=&amp;#39;{ {post.url}}&amp;#39; title=&amp;#39;Read more...&amp;#39;&amp;gt;Read more...&amp;lt;/a&amp;gt;&amp;lt;/h4&amp;gt;
{ % else %}
{ { post.content}}
{ % endif %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后，在文章中添加&lt;code&gt;&amp;lt;!-- more --&amp;gt;&lt;/code&gt;即可。&lt;/p&gt;

&lt;h1&gt;添加搜索栏&lt;/h1&gt;

&lt;p&gt;参考&lt;a href=&quot;http://truongtx.me/2012/12/28/jekyll-create-simple-search-box/&quot;&gt;Jekyll Bootstrap - Create Simple Search box&lt;/a&gt;，在&lt;code&gt;_includes/themes/twitter/default.html&lt;/code&gt;导航菜单下面添加：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;form class=&amp;quot;navbar-search pull-left&amp;quot; id=&amp;quot;search-form&amp;quot;&amp;gt;
  &amp;lt;input type=&amp;quot;text&amp;quot; id=&amp;quot;google-search&amp;quot; class=&amp;quot;search-query&amp;quot; placeholder=&amp;quot;Search&amp;quot;&amp;gt;
&amp;lt;/form
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;添加js：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;jQuery(&amp;quot;#search-form&amp;quot;).submit(function(){
    var query = document.getElementById(&amp;quot;google-search&amp;quot;).value;
    window.open(&amp;quot;http://google.com/search?q=&amp;quot; + query+ &amp;quot;%20site:&amp;quot; + &amp;quot;http://blog.javachen.com&amp;quot;);
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;其他&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;添加404页面&lt;/li&gt;
&lt;li&gt;使用多说评论&lt;/li&gt;
&lt;li&gt;修改博客主体为宽屏模式&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;TODO&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;添加语法高亮，参考&lt;a href=&quot;http://truongtx.me/2012/12/28/jekyll-bootstrap-syntax-highlighting/&quot;&gt;Jekyll - Syntax highlighting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>使用ZooKeeper实现配置同步</title>
   <link href="http://blog.javachen.com/hadoop/2013/08/23/publish-proerties-using-zookeeper"/>
   <updated>2013-08-23T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/08/23/publish-proerties-using-zookeeper</id>
   <content type="html">&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;应用项目中都会有一些配置信息，这些配置信息数据量少，一般会保存到内存、文件或者数据库，有时候需要动态更新。当需要在多个应用服务器中修改这些配置文件时，需要做到快速、简单、不停止应用服务器的方式修改并同步配置信息到所有应用中去。本篇文章就是介绍如何使用ZooKeeper来实现配置的动态同步。&lt;/p&gt;

&lt;h1&gt;ZooKeeper&lt;/h1&gt;

&lt;p&gt;在《&lt;a href=&quot;&quot;&gt;hive Driver类运行过程&lt;/a&gt;》一文中可以看到hive为了支持并发访问引入了ZooKeeper来实现分布式锁。参考《&lt;a href=&quot;http://rdc.taobao.com/team/jm/archives/1232&quot;&gt;ZooKeeper典型应用场景一览&lt;/a&gt;》一文，ZooKeeper还可以用作其他用途，例如：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据发布与订阅（配置中心）&lt;/li&gt;
&lt;li&gt;负载均衡&lt;/li&gt;
&lt;li&gt;命名服务(Naming Service)&lt;/li&gt;
&lt;li&gt;分布式通知/协调&lt;/li&gt;
&lt;li&gt;集群管理与Master选举&lt;/li&gt;
&lt;li&gt;分布式锁&lt;/li&gt;
&lt;li&gt;分布式队列&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- more --&gt;

&lt;p&gt;一些在线系统在运行中，需要在不停止程序的情况下能够动态调整某一个变量的值并且能够及时生效。特别是当部署了多台应用服务器的时候，需要能够做到在一台机器上修改配置文件，然后在同步到所有应用服务器。这时候使用ZooKeeper来实现就很合适了。&lt;/p&gt;

&lt;h1&gt;数据发布与订阅&lt;/h1&gt;

&lt;p&gt;发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，服务式服务框架的服务地址列表等就非常适合使用。&lt;/p&gt;

&lt;p&gt;使用ZooKeeper的发布与订阅模型，可以将应用中用到的一些配置信息放到ZK上进行集中管理。这类场景通常是这样：应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。这样的场景适合数据量很小，但是数据更新可能会比较快的需求。&lt;/p&gt;

&lt;h1&gt;配置存储方案&lt;/h1&gt;

&lt;p&gt;配置文件通常有如下几种保存方式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;将配置信息保存在程序代码中
这种方案简单，但每次修改配置都要重新编译、部署应用程序。显然这种方案很不方便，也不可靠，更无法做到修改的实时生效。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将配置信息保存在xml文件或者属性文件中
在参数信息保存在xml或者属性文件中，当需要修改参数时，直接修改 xml 文件。这样无需重新编译，只需重新部署修改的文件即可。但然后对所有的应用进行重新部署。这样做的缺点显而易见，要往上百台机器上重新部署应用，简直是一个噩梦。同时该方案还有一个缺点，就是配置修改无法做到实时生效。修改后往往过一段时间才能生效。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将配置信息保存在数据库中
当需要修改参数时，直接修改数据库，然后重启分布式应用程序，或者刷新分布式应用的缓存。尽管这种做法比以上两种方案简单，但却面临着单点失效问题。如果数据库服务器停机，则分布式应用程序的配置信息将无法更新。另外这种方案的配置修改生效实时性虽然比第二种方案好些，但仍然不能达到某些情况下的要求。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;基于ZooKeeper的配置信息同步方案&lt;/h1&gt;

&lt;p&gt;如果使用ZooKeeper来实现，就可以直接把配置信息保存到ZooKeeper中，或者把属性文件内容保存到ZooKeeper中，当属性文件内容发生变化时，就通知监听者如应用程序去重新读取配置文件。&lt;/p&gt;

&lt;p&gt;在网上搜索了一下，很能找到好用的现成的代码实现。有的基于ZooKeeper来扩张jdk的hashmap来存储配置参数，如：&lt;a href=&quot;http://melin.iteye.com/blog/899435&quot;&gt;使用ZooKeeper实现静态数据中心化配置管理&lt;/a&gt;，也有人直接实现了一个基于java并发框架的工具包，如：&lt;a href=&quot;https://github.com/openUtility/menagerie&quot;&gt;menagerie&lt;/a&gt;。&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;code&gt;注意&lt;/code&gt;:以下部分文字和图来自：&lt;a href=&quot;http://www.code365.org/wp-content/uploads/2012/02/%E5%9F%BA%E4%BA%8EZooKeeper%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B01.pdf&quot;&gt;基于ZooKeeper的配置信息存储方案的设计与实现1.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;基于ZooKeeper的特性,借助ZooKeeper可以实现一个可靠的、简单的、修改配置能够实时生效的配置信息存储方案,整体的设计方案如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/zookeeper-01.jpg&quot; alt=&quot;基于zookeeper的方案&quot;&gt;&lt;/p&gt;

&lt;p&gt;整个配置信息存储方案由三部分组成:ZooKeeper服务器集群、配置管理程序、分布式应用程序。&lt;/p&gt;

&lt;p&gt;ZooKeeper服务器集群存储配置信息,在服务器上创建一个保存数据的节点(创建节点操作);配置管理程序提供一个配置管理的UI界面或者命令行方式,用户通过配置界面修改ZooKeeper服务器节点上配置信息(设置节点数据操作);分布式应用连接到ZooKeeper集群上(创建ZooKeeper客户端操作),监听配置信息的变化(使用获取节点数据操作,并注册一个watcher)。&lt;/p&gt;

&lt;p&gt;当配置信息发生变化时,分布式应用会更新程序中使用配置信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/zookeeper-02.jpg&quot; alt=&quot;修改配置的时许图&quot;&gt;&lt;/p&gt;

&lt;h1&gt;源代码&lt;/h1&gt;

&lt;p&gt;找到一个淘宝工程师写的实现方式，待整理下之后，提交到github上去。&lt;/p&gt;

&lt;h1&gt;优点&lt;/h1&gt;

&lt;p&gt;借助 ZooKeeper我们实现的配置信息存储方案具有的优点如下:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;简单。尽管前期搭建ZooKeeper服务器集群较为麻烦,但是实现该方案后,修改配置整个过程变得简单很多。用户只要修改配置,无需进行其他任何操作,配置自动生效。&lt;/li&gt;
&lt;li&gt;可靠。ZooKeeper服务集群具有无单点失效的特性,使整个系统更加可靠。即使ZooKeeper 集群中的一台机器失效,也不会影响整体服务,更不会影响分布式应用配置信息的更新。&lt;/li&gt;
&lt;li&gt;实时。ZooKeeper的数据更新通知机制,可以在数据发生变化后,立即通知给分布式应用程序,具有很强的变化响应能力。&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;本文参考了网上的一些文章，给出了基于ZooKeeper的配置信息同步方案,解决了传统配置信息同步方案的缺点如实时性差、可靠性差、复杂等。&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://rdc.taobao.com/team/jm/archives/1232&quot;&gt;ZooKeeper典型应用场景一览&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://melin.iteye.com/blog/899435&quot;&gt;使用ZooKeeper实现静态数据中心化配置管理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/openUtility/menagerie&quot;&gt;menagerie&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.code365.org/wp-content/uploads/2012/02/%E5%9F%BA%E4%BA%8EZooKeeper%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B01.pdf&quot;&gt;基于ZooKeeper的配置信息存储方案的设计与实现1.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>hive Driver类运行过程</title>
   <link href="http://blog.javachen.com/hive/2013/08/22/hive-Driver"/>
   <updated>2013-08-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hive/2013/08/22/hive-Driver</id>
   <content type="html">&lt;h1&gt;概括&lt;/h1&gt;

&lt;p&gt;从《&lt;a href=&quot;hive/2013/08/21/hive-CliDriver/&quot;&gt;hive cli的入口类&lt;/a&gt;》中可以知道hive中处理hive命令的处理器一共有以下几种：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;（1）set       SetProcessor，设置修改参数,设置到SessionState的HiveConf里。 
（2）dfs       DfsProcessor，使用hadoop的FsShell运行hadoop的命令。 
（3）add       AddResourceProcessor，添加到SessionState的resource_map里，运行提交job的时候会写入Hadoop的Distributed Cache。 
（4）delete    DeleteResourceProcessor，从SessionState的resource_map里删除。 
（5）其他       Driver 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Driver类的主要作用是用来编译并执行hive命令，然后返回执行结果。这里主要分析Driver类的运行逻辑。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1&gt;分析&lt;/h1&gt;

&lt;p&gt;Driver类入口如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Driver.run(String command) // 处理一条命令 
{ 
    int ret = compile(command);  // 分析命令，生成Task。 
    ret = execute();  // 运行Task。 
} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行命令之前，先编译命令，然后在运行任务。&lt;/p&gt;

&lt;h2&gt;compile方法过程&lt;/h2&gt;

&lt;p&gt;1、创建Context上下文&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;command = new VariableSubstitution().substitute(conf,command);
ctx = new Context(conf);
ctx.setTryCount(getTryCount());
ctx.setCmd(command);
ctx.setHDFSCleanup(true);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、创建ParseDriver对象，然后解析命令、生成AST树。语法和词法分析内容，不是本文重点故不做介绍。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ParseDriver pd = new ParseDriver();
ASTNode tree = pd.parse(command, ctx);
tree = ParseUtils.findRootNonNullToken(tree);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;简单归纳来说，解析程包括如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;词法分析，生成AST树，ParseDriver完成。 &lt;/li&gt;
&lt;li&gt;分析AST树，AST拆分成查询子块，信息记录在QB，这个QB在下面几个阶段都需要用到，SemanticAnalyzer.doPhase1完成。 &lt;/li&gt;
&lt;li&gt;从metastore中获取表的信息，SemanticAnalyzer.getMetaData完成。 &lt;/li&gt;
&lt;li&gt;生成逻辑执行计划，SemanticAnalyzer.genPlan完成。 &lt;/li&gt;
&lt;li&gt;优化逻辑执行计划，Optimizer完成，ParseContext作为上下文信息进行传递。 &lt;/li&gt;
&lt;li&gt;生成物理执行计划，SemanticAnalyzer.genMapRedTasks完成。 &lt;/li&gt;
&lt;li&gt;物理计划优化，PhysicalOptimizer完成，PhysicalContext作为上下文信息进行传递。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3、读取环境变量，如果配置了语法分析的hook，参数为：&lt;code&gt;hive.semantic.analyzer.hook&lt;/code&gt;，则:先用反射得到&lt;code&gt;AbstractSemanticAnalyzerHook&lt;/code&gt;的集合，调用&lt;code&gt;hook.preAnalyze(hookCtx, tree)&lt;/code&gt;方法,然后再调用&lt;code&gt;sem.analyze(tree, ctx)&lt;/code&gt;方法，该方法才是用来作语法分析的,最后再调用&lt;code&gt;hook.postAnalyze(hookCtx, tree)&lt;/code&gt;方法执行一些用户定义的后置操作；&lt;/p&gt;

&lt;p&gt;否则，直接调用&lt;code&gt;sem.analyze(tree, ctx)&lt;/code&gt;进行语法分析。&lt;/p&gt;

&lt;p&gt;4、校验执行计划：&lt;code&gt;sem.validate()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;5、创建查询计划QueryPlan。&lt;/p&gt;

&lt;p&gt;6、初始化FetchTask。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;if (plan.getFetchTask() != null) {
   plan.getFetchTask().initialize(conf, plan, null);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;7、授权校验工作。&lt;/p&gt;

&lt;h2&gt;run方法过程&lt;/h2&gt;

&lt;p&gt;1、运行HiveDriverRunHook的前置方法preDriverRun&lt;/p&gt;

&lt;p&gt;2、运行&lt;code&gt;compile(command)&lt;/code&gt;方法，并根据返回值判断是否该释放Hive锁。hive中可以配置&lt;code&gt;hive.support.concurrency&lt;/code&gt;值为true并设置zookeeper的服务器地址和端口，基于zookeeper实现分布式锁以支持hive的多并发访问。这部分内容不是本文重点故不做介绍。&lt;/p&gt;

&lt;p&gt;3、调用execute()方法执行任务。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;先运行ExecuteWithHookContext的前置hook方法，ExecuteWithHookContext类型有三种：前置、运行失败、后置。&lt;/li&gt;
&lt;li&gt;然后创建DriverContext用于维护正在运行的task任务，正在运行的task任务会添加到队列runnable中去。&lt;/li&gt;
&lt;li&gt;其次，在while循环中遍历队列中的任务，然后启动任务让其执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    while (runnable.peek() != null &amp;amp;&amp;amp; running.size() &amp;lt; maxthreads) {
      Task&amp;lt;? extends Serializable&amp;gt; tsk = runnable.remove();
      launchTask(tsk, queryId, noName, running, jobname, jobs, driverCxt);
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;在launchTask方法中，先判断是否支持并发执行，如果支持则调用线程的start()方法，否则调用&lt;code&gt;tskRun.runSequential()&lt;/code&gt;方法顺序执行，只有当是MapReduce任务时，才执行并发执行：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    if (HiveConf.getBoolVar(conf, HiveConf.ConfVars.EXECPARALLEL) &amp;amp;&amp;amp; tsk.isMapRedTask()) {
          // Launch it in the parallel mode, as a separate thread only for MR tasks
          tskRun.start();
    } else {
          tskRun.runSequential();
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;最后任务的运行，交给具体的Task去执行了。&lt;/li&gt;
&lt;li&gt;如果任务运行失败，则会创建一个备份任务，重新加入队列，然后再次运行；如果备份任务运行完成，则运行ExecuteWithHookContext的hook方法，这时候的hook为失败类型的hook。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4、运行HiveDriverRunHook的后置方法postDriverRun&lt;/p&gt;

&lt;h2&gt;hive中支持的hook&lt;/h2&gt;

&lt;p&gt;上面分析中，提到了hive的hook机制，hive中一共存在以下几种hook。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive.semantic.analyzer.hook
hive.exec.filter.hook
hive.exec.driver.run.hooks
hive.server2.session.hook
hive.exec.pre.hooks
hive.exec.post.hooks
hive.exec.failure.hooks
hive.client.stats.publishers
hive.metastore.ds.connection.url.hook
hive.metastore.init.hooks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过hook机制，可以在运行前后做一些用户想做的事情。如：你可以在语法分析的hook中对hive的操作做一些超级管理员级别的权限判断；你可以对hive-server2做一些session级别的控制。&lt;/p&gt;

&lt;p&gt;cloudera的github仓库&lt;a href=&quot;https://github.com/cloudera/access&quot;&gt;access&lt;/a&gt;中关于hive的访问控制就是使用了hive的hook机制。&lt;/p&gt;

&lt;p&gt;twitter的mapreduce可视化项目监控项目&lt;a href=&quot;https://github.com/twitter/ambrose&quot;&gt;ambrose&lt;/a&gt;也利用了hive的hook机制，有兴趣的话，你可以去看看其是如何使用hive的hook并且你也可以扩增hook做些自己想做的事情。&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;本文主要介绍了hive运行过程，其中简单提到了hive语法词法解析以及hook机制，没有详细分析。&lt;/p&gt;

&lt;p&gt;hive Driver类的执行过程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/hive-driver.jpg&quot; alt=&quot;hive-driver&quot;&gt;&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/end/archive/2012/12/19/2825320.html&quot;&gt;hive 初始化运行流程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/access&quot;&gt;Cloudera access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/twitter/ambrose&quot;&gt;twitter ambrose&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>hive cli的入口类</title>
   <link href="http://blog.javachen.com/hive/2013/08/21/hive-CliDriver"/>
   <updated>2013-08-21T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hive/2013/08/21/hive-CliDriver</id>
   <content type="html">&lt;h1&gt;启动脚本&lt;/h1&gt;

&lt;p&gt;从shell脚本&lt;code&gt;/usr/lib/hive/bin/ext/cli.sh&lt;/code&gt;可以看到hive cli的入口类为&lt;code&gt;org.apache.hadoop.hive.cli.CliDriver&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;cli () {
  CLASS=org.apache.hadoop.hive.cli.CliDriver
  execHiveCmd $CLASS &amp;quot;$@&amp;quot;
}
cli_help () {
  CLASS=org.apache.hadoop.hive.cli.CliDriver
  execHiveCmd $CLASS &amp;quot;--help&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;h1&gt;入口类&lt;/h1&gt;

&lt;p&gt;java中的类如果有main方法就能运行，故直接查找&lt;code&gt;org.apache.hadoop.hive.cli.CliDriver&lt;/code&gt;中的main方法即可。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public static void main(String[] args) throws Exception {
    int ret = run(args);
    System.exit(ret);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;阅读run函数可以看到，主要做了以下几件事情：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取main方法的参数&lt;/li&gt;
&lt;li&gt;重置默认的log4j配置并为hive重新初始化log4j，注意，在这里是读取hive-log4j.properties来初始化log4j。&lt;/li&gt;
&lt;li&gt;创建CliSessionState，并初始化in、out、info、error等stream流。CliSessionState是一次命令行操作的session会话，其继承了SessionState。&lt;/li&gt;
&lt;li&gt;重命令行参数中读取参数并设置到CliSessionState中。&lt;/li&gt;
&lt;li&gt;启动SessionState并连接到hive server&lt;/li&gt;
&lt;li&gt;如果cli是本地模式运行，则加载&lt;code&gt;hive.aux.jars.path&lt;/code&gt;参数配置的jar包到classpath&lt;/li&gt;
&lt;li&gt;创建一个CliDriver对象，并设置当前选择的数据库。可以在命令行参数添加&lt;code&gt;-database database&lt;/code&gt;来选择连接那个数据库，默认为default数据库。&lt;/li&gt;
&lt;li&gt;加载初始化文件&lt;code&gt;.hiverc&lt;/code&gt;，该文件位于当前用户主目录下，读取该文件内容后，然后调用processFile方法处理文件内容。&lt;/li&gt;
&lt;li&gt;如果命令行中有-e参数，则运行指定的sql语句；如果有-f参数，则读取该文件内容并运行。注意：不能同时指定这两个参数。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    hive -e &amp;#39;show tables&amp;#39;
    hive -f /root/hive.sql
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;如果没有指定上面两个参数，则从当前用户主目录读取&lt;code&gt;.hivehistory&lt;/code&gt;文件，如果不存在则创建。该文件保存了当前用户所有运行的hive命令。&lt;/li&gt;
&lt;li&gt;在while循环里不断读取控制台的输入内容，每次读取一行，如果行末有分号，则调用CliDriver的processLine方法运行读取到的内容。&lt;/li&gt;
&lt;li&gt;每次调用processLine方法时，都会创建SignalHandler用于捕捉用户的输入，当用户输入Ctrl+C时，会kill当前正在运行的任务以及kill掉当前进程。kill当前正在运行的job的代码如下.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    HadoopJobExecHelper.killRunningJobs();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;处理hive命令。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;处理hive命令过程&lt;/h2&gt;

&lt;p&gt;如果输入的是quit或者exit,则程序退出。&lt;/p&gt;

&lt;p&gt;如果命令开头是source，则会读取source 后面文件内容，然后执行该文件内容。通过这种方式，你可以在hive命令行模式运行一个文件中的hive命令。&lt;/p&gt;

&lt;p&gt;如果命令开头是感叹号，执行操作系统命令（如&lt;code&gt;!ls&lt;/code&gt;，列出当前目录的文件信息）。通过以下代码来运行：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Process executor = Runtime.getRuntime().exec(shell_cmd);
StreamPrinter outPrinter = new StreamPrinter(executor.getInputStream(), null, ss.out);
StreamPrinter errPrinter = new StreamPrinter(executor.getErrorStream(), null, ss.err);

outPrinter.start();
errPrinter.start();

ret = executor.waitFor();
if (ret != 0) {
  console.printError(&amp;quot;Command failed with exit code = &amp;quot; + ret);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;shell_cmd的内容大概如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;shell_cmd = &amp;quot;/bin/bash -c \&amp;#39;&amp;quot; + shell_cmd + &amp;quot;\&amp;#39;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果命令开头是list，列出jar/file/archive&lt;/p&gt;

&lt;p&gt;如果是远程模式运行命令行，则通过HiveClient来运行命令；否则，调用processLocalCmd方法运行本地命令。&lt;/p&gt;

&lt;p&gt;以本地模式运行时，会通过CommandProcessorFactory工厂解析输入的语句来获得一个CommandProcessor。&lt;code&gt;set/dfs/add/delete&lt;/code&gt;指令交给指定的CommandProcessor处理，其余的交给&lt;code&gt;org.apache.hadoop.hive.ql.Driver.run()&lt;/code&gt;处理。
故，CommandProcessor接口的实现类有：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;AddResourceProcessor
DeleteResourceProcessor
DfsProcessor
Driver
ResetProcessor
SetProcessor
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;org.apache.hadoop.hive.ql.Driver&lt;/code&gt;类是查询的起点，run()方法会先后调用compile()和execute()两个函数来完成查询，所以一个command的查询分为compile和execute两个阶段。&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;作为尝试，第一次使用思维导图分析代码逻辑，简单整理了一下CliDriver类的运行逻辑，如下图。以后还需要加强画图和表达能力。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/hive-cli-clidriver.jpg&quot; alt=&quot;hive-cli-clidriver&quot;&gt;&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/end/archive/2012/12/19/2825320.html&quot;&gt;hive 初始化运行流程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>使用hadoop中遇到的一些问题</title>
   <link href="http://blog.javachen.com/hadoop/2013/08/17/some-problems-about-hadoop"/>
   <updated>2013-08-17T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/08/17/some-problems-about-hadoop</id>
   <content type="html">&lt;p&gt;本文主要记录安装hadoop过程需要注意的一些细节以及使用hadoop过程中发现的一些问题以及对应解决办法，有些地方描述的不是很清楚可能还会不准确，之后会重现问题然后修改完善这篇文章。&lt;/p&gt;

&lt;h1&gt;安装hadoop过程中需要注意以下几点：&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;每个节点配置hosts&lt;/li&gt;
&lt;li&gt;每个节点配置时钟同步&lt;/li&gt;
&lt;li&gt;如果没有特殊要求，关闭防火墙&lt;/li&gt;
&lt;li&gt;hadoop需要在&lt;code&gt;/tmp&lt;/code&gt;目录下存放一些日志和临时文件，要求&lt;code&gt;/tmp&lt;/code&gt;目录权限必须为&lt;code&gt;1777&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr&gt;

&lt;!-- more --&gt;

&lt;h1&gt;使用intel的hadoop发行版IDH过程遇到问题：&lt;/h1&gt;

&lt;p&gt;1、 IDH集群中需要配置管理节点到集群各节点的无密码登录，公钥文件存放路径为&lt;code&gt;/etc/intelcloud&lt;/code&gt;目录下，文件名称为&lt;code&gt;idh-id_rsa&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;如果在管理界面发现不能启动/停止hadoop组件的进程，请检查ssh无密码登录是否有问题。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ssh -i /etc/intelcloud/idh-id_rsa nodeX
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果存在问题，请重新配置无密码登录：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;scp -i /etc/intelcloud/idh-id_rsa nodeX
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、 IDH使用puppt和shell脚本来管理hadoop集群，shell脚本中有一处调用puppt的地方存在问题，详细说明待整理！！&lt;/p&gt;

&lt;hr&gt;

&lt;h1&gt;使用CDH4.3.0的hadoop（通过rpm安装）过程中发现如下问题：&lt;/h1&gt;

&lt;h2&gt;说明：以下问题不局限于CDH的hadoop版本。&lt;/h2&gt;

&lt;p&gt;1、 在hive运行过程中会打印如下日志&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Starting Job = job_1374551537478_0001, Tracking URL = http://june-fedora:8088/proxy/application_1374551537478_0001/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1374551537478_0001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过上面的&lt;code&gt;kill command&lt;/code&gt;可以killjob，但是运行过程中发现提示错误，错误原因：&lt;code&gt;HADOOP_LIBEXEC_DIR&lt;/code&gt;未做设置&lt;/p&gt;

&lt;p&gt;解决方法：在hadoop-env.sh中添加如下代码&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HADOOP_LIBEXEC_DIR=$HADOOP_COMMON_HOME/libexec
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、 查看java进程中发现，JVM参数中-Xmx重复出现&lt;/p&gt;

&lt;p&gt;解决办法：&lt;code&gt;/etc/hadoop/conf/hadoop-env.sh&lt;/code&gt;去掉第二行。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HADOOP_OPTS=&amp;quot;-Djava.net.preferIPv4Stack=true $HADOOP_OPTS&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3、 hive中mapreduce运行为本地模式，而不是远程模式&lt;/p&gt;

&lt;p&gt;解决办法：&lt;code&gt;/etc/hadoop/conf/hadoop-env.sh&lt;/code&gt;设置&lt;code&gt;HADOOP_MAPRED_HOME&lt;/code&gt;变量&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4、 如何设置hive的jvm启动参数&lt;/p&gt;

&lt;p&gt;hive脚本运行顺序：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive--&amp;gt;hive-config.sh--&amp;gt;hive-env.sh--&amp;gt;hadoop-config.sh--&amp;gt;hadoop-env.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;故如果hadoop-env.sh中设置了&lt;code&gt;HADOOP_HEAPSIZE&lt;/code&gt;，则hive-env.sh中设置的无效&lt;/p&gt;

&lt;p&gt;5、如何设置JOB_HISTORYSERVER的jvm参数&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;/etc/hadoop/conf/hadoop-env.sh&lt;/code&gt;添加如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=256
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>hadoop自动化安装shell脚本</title>
   <link href="http://blog.javachen.com/hadoop/2013/08/02/hadoop-install-script"/>
   <updated>2013-08-02T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/08/02/hadoop-install-script</id>
   <content type="html">&lt;p&gt;之前写过一些如何安装Cloudera Hadoop的文章，安装hadoop过程中，最开始是手动安装apache版本的hadoop，其次是使用Intel的IDH管理界面安装IDH的hadoop，再然后分别手动和通过cloudera manager安装hadoop，也使用bigtop-util yum方式安装过apache的hadoop。&lt;/p&gt;

&lt;p&gt;安装过程中参考了很多网上的文章，解压缩过cloudera的&lt;code&gt;cloudera-manager-installer.bin&lt;/code&gt;，发现并修复了IDH shell脚本中关于puppt的自认为是bug的一个bug，最后整理出了一个自动安装hadoop的shell脚本，脚本托管在github上面: &lt;a href=&quot;https://github.com/javachen/hadoop-install&quot;&gt;hadoop-install&lt;/a&gt;。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1&gt;hadoop安装文章&lt;/h1&gt;

&lt;p&gt;博客中所有关于安装hadoop的文章列出如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/03/08/note-about-installing-hadoop-cluster/&quot;&gt;【笔记】Hadoop安装部署&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH/&quot;&gt;手动安装Cloudera Hive CDH&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH/&quot;&gt;手动安装Cloudera HBase CDH&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH/&quot;&gt;手动安装Cloudera Hadoop CDH&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/03/29/install-impala/&quot;&gt;安装impala过程&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/04/06/install-cloudera-cdh-by-yum/&quot;&gt;从yum安装Cloudera CDH集群&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/06/24/install-cdh-by-cloudera-manager/&quot;&gt;通过Cloudera Manager安装CDH&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;hadoop-install&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/javachen/hadoop-install&quot;&gt;hadoop-install&lt;/a&gt;上脚本，all-in-one-install.sh是在一个节点上安装hdfs、hive、yarn、zookeeper和hbase，编写该脚本是为了在本机（fedora19系统）上调试mapreduce、hive和hbase；cluster-install.sh是在多个节点上安装hadoop集群，同样目前完成了hdfs、hive、yarn、zookeeper和hbase的自动安装。&lt;/p&gt;

&lt;h1&gt;脚本片段&lt;/h1&gt;

&lt;p&gt;IDH安装脚本中有一些写的比较好的shell代码片段，摘出如下，供大家学习。&lt;/p&gt;

&lt;h2&gt;检测操作系统版本&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;( grep -i &amp;quot;CentOS&amp;quot; /etc/issue &amp;gt; /dev/null ) &amp;amp;&amp;amp; OS_DISTRIBUTOR=centos
( grep -i &amp;quot;Red[[:blank:]]*Hat[[:blank:]]*Enterprise[[:blank:]]*Linux&amp;quot; /etc/issue &amp;gt; /dev/null ) &amp;amp;&amp;amp; OS_DISTRIBUTOR=rhel
( grep -i &amp;quot;Oracle[[:blank:]]*Linux&amp;quot; /etc/issue &amp;gt; /dev/null ) &amp;amp;&amp;amp; OS_DISTRIBUTOR=oel
( grep -i &amp;quot;Asianux[[:blank:]]*Server&amp;quot; /etc/issue &amp;gt; /dev/null ) &amp;amp;&amp;amp; OS_DISTRIBUTOR=an
( grep -i &amp;quot;SUSE[[:blank:]]*Linux[[:blank:]]*Enterprise[[:blank:]]*Server&amp;quot; /etc/issue &amp;gt; /dev/null ) &amp;amp;&amp;amp; OS_DISTRIBUTOR=sles
( grep -i &amp;quot;Fedora&amp;quot; /etc/issue &amp;gt; /dev/null ) &amp;amp;&amp;amp; OS_DISTRIBUTOR=fedora

major_revision=`grep -oP &amp;#39;\d+&amp;#39; /etc/issue | sed -n &amp;quot;1,1p&amp;quot;`
minor_revision=`grep -oP &amp;#39;\d+&amp;#39; /etc/issue | sed -n &amp;quot;2,2p&amp;quot;`
OS_RELEASE=&amp;quot;$major_revision.$minor_revision&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;生成ssh公要&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yes|ssh-keygen -t rsa -f /root/.ssh/id_rsa -N &amp;quot;&amp;quot;
[ ! -d /root/.ssh ] &amp;amp;&amp;amp; ( mkdir /root/.ssh ) &amp;amp;&amp;amp; ( chmod 700 /root/.ssh )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;ssh设置无密码登陆&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;set timeout 20

set host [lindex $argv 0]
set password [lindex $argv 1]
set pubkey [exec cat /root/.ssh/id_rsa.pub]
set localsh [exec cat ./config_ssh_local.sh]

#spawn ssh-copy-id -i /root/.ssh/id_rsa.pub root@$host
spawn ssh root@$host &amp;quot;
umask 022
mkdir -p  /root/.ssh
echo \&amp;#39;$pubkey\&amp;#39; &amp;gt; /root/.ssh/authorized_keys
echo \&amp;#39;$localsh\&amp;#39; &amp;gt;  /root/.ssh/config_ssh_local.sh
cd /root/.ssh/; sh config_ssh_local.sh
&amp;quot;
expect {
    timeout exit
    yes/no  {send &amp;quot;yes\r&amp;quot;;exp_continue}
    assword {send &amp;quot;$password\r&amp;quot;}
}
expect eof
#interact
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;配置JAVA_HOME&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;# set JAVA_HOME and PATH
if [ -f /root/.bashrc ] ; then
    sed -i &amp;#39;/^export[[:space:]]\{1,\}JAVA_HOME[[:space:]]\{0,\}=/d&amp;#39; /root/.bashrc
    sed -i &amp;#39;/^export[[:space:]]\{1,\}CLASSPATH[[:space:]]\{0,\}=/d&amp;#39; /root/.bashrc
    sed -i &amp;#39;/^export[[:space:]]\{1,\}PATH[[:space:]]\{0,\}=/d&amp;#39; /root/.bashrc
fi
echo &amp;quot;&amp;quot; &amp;gt;&amp;gt;/root/.bashrc
echo &amp;quot;export JAVA_HOME=/usr/java/latest&amp;quot; &amp;gt;&amp;gt;/root/.bashrc
echo &amp;quot;export CLASSPATH=.:\$JAVA_HOME/lib/tools.jar:\$JAVA_HOME/lib/dt.jar&amp;quot;&amp;gt;&amp;gt;/root/.bashrc
echo &amp;quot;export PATH=\$JAVA_HOME/bin:\$PATH&amp;quot; &amp;gt;&amp;gt; /root/.bashrc
source /root/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;格式化集群&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;su -s /bin/bash hdfs -c &amp;#39;yes Y | hadoop namenode -format &amp;gt;&amp;gt; /tmp/format.log 2&amp;gt;&amp;amp;1&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;创建hadoop目录&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;su -s /bin/bash hdfs -c &amp;quot;hadoop fs -chmod a+rw /&amp;quot;
while read dir user group perm
do
     su -s /bin/bash hdfs -c &amp;quot;hadoop fs -mkdir -R $dir &amp;amp;&amp;amp; hadoop fs -chmod -R $perm $dir &amp;amp;&amp;amp; hadoop fs -chown -R $user:$group $dir&amp;quot;
     echo &amp;quot;.&amp;quot;
done &amp;lt;&amp;lt; EOF
/tmp hdfs hadoop 1777 
/tmp/hadoop-yarn mapred mapred 777
/var hdfs hadoop 755 
/var/log yarn mapred 1775 
/var/log/hadoop-yarn/apps yarn mapred 1777
/hbase hbase hadoop 755
/user hdfs hadoop 777
/user/history mapred hadoop 1777
/user/root root hadoop 777
/user/hive hive hadoop 777
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;hive中安装并初始化postgresql&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install postgresql-server postgresql-jdbc -y &amp;gt;/dev/null
chkconfig postgresql on
rm -rf /var/lib/pgsql/data
rm -rf /var/run/postgresql/.s.PGSQL.5432
service postgresql initdb

sed -i &amp;#39;/listen/s/#//;/listen/s/localhost/*/&amp;#39; /var/lib/pgsql/data/postgresql.conf
sed -i &amp;quot;s|#standard_coffforming_strings = on|standard_conforming_strings = off|g&amp;quot; /var/lib/pgsql/data/postgresql.conf
echo &amp;quot;local    all             all                                 trust&amp;quot; &amp;gt; /var/lib/pgsql/data/pg_hba.conf
echo &amp;quot;host     all             all             0.0.0.0/0           trust&amp;quot; &amp;gt;&amp;gt; /var/lib/pgsql/data/pg_hba.conf

sudo cat /var/lib/pgsql/data/postgresql.conf | grep -e listen -e standard_conforming_strings

rm -rf /usr/lib/hive/lib/postgresql-jdbc.jar
ln -s /usr/share/java/postgresql-jdbc.jar /usr/lib/hive/lib/postgresql-jdbc.jar

su -c &amp;quot;cd ; /usr/bin/pg_ctl start -w -m fast -D /var/lib/pgsql/data&amp;quot; postgres
su -c &amp;quot;cd ; /usr/bin/psql --command \&amp;quot;create user hiveuser with password &amp;#39;redhat&amp;#39;; \&amp;quot; &amp;quot; postgres
su -c &amp;quot;cd ; /usr/bin/psql --command \&amp;quot;CREATE DATABASE metastore owner=hiveuser;\&amp;quot; &amp;quot; postgres
su -c &amp;quot;cd ; /usr/bin/psql --command \&amp;quot;GRANT ALL privileges ON DATABASE metastore TO hiveuser;\&amp;quot; &amp;quot; postgres
su -c &amp;quot;cd ; /usr/bin/psql -U hiveuser -d metastore -f /usr/lib/hive/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql&amp;quot; postgres
su -c &amp;quot;cd ; /usr/bin/pg_ctl restart -w -m fast -D /var/lib/pgsql/data&amp;quot; postgres
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;更多脚本，请关注github：&lt;a href=&quot;https://github.com/javachen/hadoop-install&quot;&gt;hadoop-install&lt;/a&gt;，你可以下载、使用并修改其中代码！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>远程调试hadoop各组件</title>
   <link href="http://blog.javachen.com/hadoop/2013/08/01/remote-debug-hadoop"/>
   <updated>2013-08-01T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/08/01/remote-debug-hadoop</id>
   <content type="html">&lt;p&gt;远程调试对应用程序开发十分有用。例如，为不能托管开发平台的低端机器开发程序，或在专用的机器上（比如服务不能中断的 Web 服务器）调试程序。其他情况包括：运行在内存小或 CUP 性能低的设备上的 Java 应用程序（比如移动设备），或者开发人员想要将应用程序和开发环境分开，等等。&lt;/p&gt;

&lt;p&gt;为了进行远程调试，必须使用 Java Virtual Machine (JVM) V5.0 或更新版本。&lt;/p&gt;

&lt;h1&gt;JPDA 简介&lt;/h1&gt;

&lt;p&gt;Sun Microsystem 的 Java Platform Debugger Architecture (JPDA) 技术是一个多层架构，使您能够在各种环境中轻松调试 Java 应用程序。JPDA 由两个接口（分别是 JVM Tool Interface 和 JDI）、一个协议（Java Debug Wire Protocol）和两个用于合并它们的软件组件（后端和前端）组成。它的设计目的是让调试人员在任何环境中都可以进行调试。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;更详细的介绍，您可以参考&lt;a href=&quot;http://www.ibm.com/developerworks/cn/opensource/os-eclipse-javadebug/&quot;&gt;使用 Eclipse 远程调试 Java 应用程序&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;JDWP 设置&lt;/h1&gt;

&lt;p&gt;JVM本身就支持远程调试，Eclipse也支持JDWP，只需要在各模块的JVM启动时加载以下参数：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;-Xdebug -Xrunjdwp:transport=dt_socket, address=8000,server=y,suspend=y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;各参数的含义：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;-Xdebug
启用调试特性
-Xrunjdwp
启用JDWP实现，包含若干子选项：
transport=dt_socket
JPDA front-end和back-end之间的传输方法。dt_socket表示使用套接字传输。
address=8000
JVM在8000端口上监听请求，这个设定为一个不冲突的端口即可。
server=y
y表示启动的JVM是被调试者。如果为n，则表示启动的JVM是调试器。
suspend=y
y表示启动的JVM会暂停等待，直到调试器连接上才继续执行。suspend=n，则JVM不会暂停等待。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;配置hbase远程调试&lt;/h1&gt;

&lt;p&gt;打开&lt;code&gt;/etc/hbase/conf/hbase-env.sh&lt;/code&gt;，找到以下内容：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;# Enable remote JDWP debugging of major HBase processes. Meant for Core Developers 
# export HBASE_MASTER_OPTS=&amp;quot;$HBASE_MASTER_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8070&amp;quot;
# export HBASE_REGIONSERVER_OPTS=&amp;quot;$HBASE_REGIONSERVER_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8071&amp;quot;
# export HBASE_THRIFT_OPTS=&amp;quot;$HBASE_THRIFT_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8072&amp;quot;
# export HBASE_ZOOKEEPER_OPTS=&amp;quot;$HBASE_ZOOKEEPER_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8073&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果想远程调式hbase-master进程，请去掉对&lt;code&gt;HBASE_MASTER_OPTS&lt;/code&gt;的注释，其他依次类推。注意，我这里使用的是cdh-4.3.0中的hbase。&lt;/p&gt;

&lt;hr&gt;

&lt;h2&gt;注意（20130817更新）：&lt;/h2&gt;

&lt;p&gt;如果启动hbase时提示&lt;code&gt;check your java command line for duplicate jdwp options&lt;/code&gt;，请把上面参数加到/usr/lib/hbase/bin/hbase中if else对应分支中去。&lt;/p&gt;

&lt;p&gt;例如，如果你想调试regionserver，请把下面代码加到&lt;code&gt;elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;regionserver&amp;quot; ] ; then&lt;/code&gt;中去：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HBASE_REGIONSERVER_OPTS=&amp;quot;$HBASE_REGIONSERVER_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8071&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;配置hive远程调试&lt;/h1&gt;

&lt;p&gt;停止hive-server2进程，然后以下面命令启动hive-server2&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hive --service hiveserver --debug
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;进程会监听在8000端口等待调试连接。如果想更改监听端口，可以修改配置文件:&lt;code&gt;${HIVE_HOME}bin/ext/debug.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;如果Hadoop是0.23以上版本，debug模式启动Cli会报错：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ERROR: Cannot load this JVM TI agent twice, check your java command line for duplicate jdwp options.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;打开&lt;code&gt;${Hadoop_HOME}/bin/hadoop&lt;/code&gt;，注释掉以下代码&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;# Always respect HADOOP_OPTS and HADOOP_CLIENT_OPTS
HADOOP_OPTS=&amp;quot;$HADOOP_OPTS $HADOOP_CLIENT_OPTS&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;配置yarn远程调试&lt;/h1&gt;

&lt;p&gt;请在以下代码添加调试参数：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;if [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;classpath&amp;quot; ] ; then
if $cygwin; then
CLASSPATH=`cygpath -p -w &amp;quot;$CLASSPATH&amp;quot;`
fi
echo $CLASSPATH
exit
elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;rmadmin&amp;quot; ] ; then
CLASS=&amp;#39;org.apache.hadoop.yarn.client.RMAdmin&amp;#39;
YARN_OPTS=&amp;quot;$YARN_OPTS $YARN_CLIENT_OPTS&amp;quot;
elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;application&amp;quot; ] ; then
class=&amp;quot;org&amp;quot;.apache.hadoop.yarn.client.cli.ApplicationCLI
YARN_OPTS=&amp;quot;$YARN_OPTS $YARN_CLIENT_OPTS&amp;quot;
elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;node&amp;quot; ] ; then
class=&amp;quot;org&amp;quot;.apache.hadoop.yarn.client.cli.NodeCLI
YARN_OPTS=&amp;quot;$YARN_OPTS $YARN_CLIENT_OPTS&amp;quot;
elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;resourcemanager&amp;quot; ] ; then
CLASSPATH=${CLASSPATH}:$YARN_CONF_DIR/rm-config/log4j.properties
CLASS=&amp;#39;org.apache.hadoop.yarn.server.resourcemanager.ResourceManager&amp;#39;
YARN_OPTS=&amp;quot;$YARN_OPTS $YARN_RESOURCEMANAGER_OPTS&amp;quot;
if [ &amp;quot;$YARN_RESOURCEMANAGER_HEAPSIZE&amp;quot; != &amp;quot;&amp;quot; ]; then
JAVA_HEAP_MAX=&amp;quot;-Xmx&amp;quot;&amp;quot;$YARN_RESOURCEMANAGER_HEAPSIZE&amp;quot;&amp;quot;m&amp;quot;
fi
elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;nodemanager&amp;quot; ] ; then
CLASSPATH=${CLASSPATH}:$YARN_CONF_DIR/nm-config/log4j.properties
CLASS=&amp;#39;org.apache.hadoop.yarn.server.nodemanager.NodeManager&amp;#39;
YARN_OPTS=&amp;quot;$YARN_OPTS -server $YARN_NODEMANAGER_OPTS&amp;quot;
if [ &amp;quot;$YARN_NODEMANAGER_HEAPSIZE&amp;quot; != &amp;quot;&amp;quot; ]; then
JAVA_HEAP_MAX=&amp;quot;-Xmx&amp;quot;&amp;quot;$YARN_NODEMANAGER_HEAPSIZE&amp;quot;&amp;quot;m&amp;quot;
fi
elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;proxyserver&amp;quot; ] ; then
CLASS=&amp;#39;org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer&amp;#39;
YARN_OPTS=&amp;quot;$YARN_OPTS $YARN_PROXYSERVER_OPTS&amp;quot;
if [ &amp;quot;$YARN_PROXYSERVER_HEAPSIZE&amp;quot; != &amp;quot;&amp;quot; ]; then
JAVA_HEAP_MAX=&amp;quot;-Xmx&amp;quot;&amp;quot;$YARN_PROXYSERVER_HEAPSIZE&amp;quot;&amp;quot;m&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;例如：
如果你想调试resourcemanager代码，请在&lt;code&gt;elif [ &amp;quot;$COMMAND&amp;quot; = &amp;quot;resourcemanager&amp;quot; ]&lt;/code&gt; 分支内添加如下代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;YARN_RESOURCEMANAGER_OPTS=&amp;quot;$YARN_RESOURCEMANAGER_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=6001&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其他进程，参照上面即可。&lt;/p&gt;

&lt;p&gt;注意：端口不要冲突。&lt;/p&gt;

&lt;h1&gt;配置mapreduce远程调试&lt;/h1&gt;

&lt;p&gt;如果想要调试Map 或Reduce Task，则修改&lt;code&gt;bin/hadoop&lt;/code&gt;已经没用了，因为&lt;code&gt;bin/hadoop&lt;/code&gt;中没有Map Task的启动参数。&lt;/p&gt;

&lt;p&gt;此时需要修改mapred-site.xml&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;property&amp;gt; 
    &amp;lt;name&amp;gt;mapred.child.java.opts&amp;lt;/name&amp;gt; 
    &amp;lt;value&amp;gt;-Xmx800m -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000&amp;lt;/value&amp;gt; 
&amp;lt;/property
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在一个TaskTracker上，只能启动一个Map Task或一个Reduce Task，否则启动时会有端口冲突。因此要修改所有TaskTracker上的&lt;code&gt;conf/hadoop-site.xml&lt;/code&gt;中的配置项：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;mapred.tasktracker.map.tasks.maximum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;mapred.tasktracker.reduce.tasks.maximum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;0&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;在Eclipse中使用方法：&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;打开eclipse，找到&lt;code&gt;Debug Configurations...&lt;/code&gt;，添加一个Remout Java Application:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在source中可以关联到hive的源代码,然后，单击Debug按钮进入远程debug模式。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;编写个jdbc的测试类，运行代码，这时候因为hive-server2端没有设置端点，故程序可以正常运行直到结束。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在hive代码中设置一个断点，如&lt;code&gt;ExecDriver.java&lt;/code&gt;的&lt;code&gt;execute&lt;/code&gt;方法中设置断点，然后再运行jdbc测试类。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://zhangjie.me/eclipse-debug-hadoop/&quot;&gt;在Eclipse中远程调试Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://long-xie.iteye.com/blog/1779072&quot;&gt;hive远程调试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ibm.com/developerworks/cn/opensource/os-eclipse-javadebug/&quot;&gt;使用 Eclipse 远程调试 Java 应用程序&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>安装RHadoop</title>
   <link href="http://blog.javachen.com/hadoop/2013/07/20/install-rhadoop"/>
   <updated>2013-07-20T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/07/20/install-rhadoop</id>
   <content type="html">&lt;h1&gt;1. R Language Install&lt;/h1&gt;

&lt;h2&gt;安装相关依赖&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install -y perl* pcre-devel tcl-devel zlib-devel bzip2-devel libX11-devel tk-devel tetex-latex *gfortran*  compat-readline5
yum install libRmath-*
rpm -Uvh --force --nodeps  R-core-2.10.0-2.el5.x86_64.rpm
rpm -Uvh R-2.10.0-2.el5.x86_64.rpm R-devel-2.10.0-2.el5.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- more --&gt;

&lt;h2&gt;编译安装：R-3.0.1&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;tar -zxvf R-3.0.1 
./configure
make 
make install #R运行
export HADOOP_CMD=/usr/bin/hadoop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;排错&lt;/h2&gt;

&lt;p&gt;1、错误1&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;error: --with-readline=yes (default) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装readline &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install readline*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、错误2&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;error: No F77 compiler found 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装gfortran&lt;/p&gt;

&lt;p&gt;3、错误3&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;error: –with-x=yes (default) and X11 headers/libs are not available 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install libXt*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4、错误4&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;error: C++ preprocessor &amp;quot;/lib/cpp&amp;quot; fails sanity check 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装g++或build-essential（redhat6.2安装gcc-c++和glibc-headers）&lt;/p&gt;

&lt;h2&gt;验证是否安装成功&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@node1 bin]# R
R version 3.0.1 (2013-05-16) -- &amp;quot;Good Sport&amp;quot;
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R是自由软件，不带任何担保。
在某些条件下你可以将其自由散布。
用&amp;#39;license()&amp;#39;或&amp;#39;licence()&amp;#39;来看散布的详细条件。

R是个合作计划，有许多人为之做出了贡献.
用&amp;#39;contributors()&amp;#39;来看合作者的详细情况
用&amp;#39;citation()&amp;#39;会告诉你如何在出版物中正确地引用R或R程序包。

用&amp;#39;demo()&amp;#39;来看一些示范程序，用&amp;#39;help()&amp;#39;来阅读在线帮助文件，或
用&amp;#39;help.start()&amp;#39;通过HTML浏览器来看帮助文件。
用&amp;#39;q()&amp;#39;退出R.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;2. 安装Rhadoop&lt;/h1&gt;

&lt;h2&gt;安装rhdfs，rmr2&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;cd Rhadoop/
R CMD javareconf
R CMD INSTALL &amp;#39;plyr_1.8.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;stringr_0.6.2.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;reshape2_1.2.2.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;digest_0.6.3.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;functional_0.4.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;iterators_1.0.6.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;itertools_0.1-1.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;Rcpp_0.10.3.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;rJava_0.9-4.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;RJSONIO_1.0-3.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;reshape2_1.2.2.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;rhdfs_1.0.5.tar.gz&amp;#39;
R CMD INSTALL &amp;#39;rmr2_2.2.0.tar.gz&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;R library(rhdfs)检查是否能正常工作&lt;/p&gt;

&lt;h2&gt;验证测试&lt;/h2&gt;

&lt;p&gt;Rmr测试命令： &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;gt; train.mr&amp;lt;-mapreduce( + train.hdfs, + map = function(k, v) { + keyval(k,v$item) + } + ,reduce=function(k,v){ + m&amp;lt;-merge(v,v) + keyval(m$x,m$y) + } + )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;出现如下错误：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;packageJobJar: [/tmp/RtmpCuhs7d/rmr-local-env18916b6f86b3, /tmp/RtmpCuhs7d/rmr-global-env18913824c681, /tmp/RtmpCuhs7d/rmr-streaming-map18912d6c2b1c, /tmp/RtmpCuhs7d/rmr-streaming-reduce1891179bb645, /tmp/hadoop-root/hadoop-unjar4575094085541826184/] [] /tmp/streamjob2910108622786868147.jar tmpDir=null 13/06/05 18:22:28
WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same. 13/06/05 18:22:28 INFO mapred.FileInputFormat: Total input paths to process : 1 13/06/05 18:22:29
INFO streaming.StreamJob: getLocalDirs(): [/tmp/hadoop-root/mapred/local] 13/06/05 18:22:29 INFO streaming.StreamJob: Running job: job_201306050931_0004 13/06/05 18:22:29
INFO streaming.StreamJob: To kill this job, run: 13/06/05 18:22:29
INFO streaming.StreamJob: /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=cdh1:8021 -kill job_201306050931_0004 13/06/05 18:22:29 INFO streaming.StreamJob: Tracking URL: http://cdh1:50030/jobdetails.jsp?jobid=job_201306050931_0004 13/06/05 18:22:30 
INFO streaming.StreamJob:  map 0%  reduce 0% 13/06/05 18:22:56
INFO streaming.StreamJob:  map 100%  reduce 100% 13/06/05 18:22:56
INFO streaming.StreamJob: To kill this job, run: 13/06/05 18:22:56
INFO streaming.StreamJob: /usr/lib/hadoop/bin/hadoop job  -Dmapred.job.tracker=cdh1:8021 -kill job_201306050931_0004 13/06/05 18:22:56
INFO streaming.StreamJob: Tracking URL: http://cdh1:50030/jobdetails.jsp?jobid=job_201306050931_0004 13/06/05 18:22:56 
ERROR streaming.StreamJob: Job not successful. Error: NA 13/06/05 18:22:56
INFO streaming.StreamJob: killJob... Streaming Command Failed! Error in mr(map = map, reduce = reduce, combine = combine, vectorized.reduce,  :   hadoop streaming failed with error code 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;错误解决方法： 通过查看日志，hadoop没有在&lt;code&gt;/usr/bin&lt;/code&gt;下找到Rscript,于是从R的安装目录&lt;code&gt;/usr/local/bin&lt;/code&gt;下做R和Rscript的符号链接到&lt;code&gt;/usr/bin&lt;/code&gt;下，再次执行即可解决次错。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#ln -s /usr/loca/bin/R  /usr/bin
#ln -s /usr/local/bin/Rscript  /usr/bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;3. 安装rhbase&lt;/h1&gt;

&lt;h2&gt;安装依赖&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#yum install boost*
#yum install openssl*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;安装thrift&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#tar -zxvf thrift-0.9.0.tar.gz
#mv thrift-0.9.0/lib/cpp/src/thrift/qt/moc_TQTcpServer.cpp  thrift-0.9.0/lib/cpp/src/thrift/qt/moc_TQTcpServer.cpp.bak
#cd thrift-0.9.0
#./configure --with-boost=/usr/include/boost JAVAC=/usr/java/jdk1.6.0_31/bin/javac
#make
#make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果报错：error: &amp;quot;Error: libcrypto required.&amp;quot;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#yum install openssl*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果报错：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;src/thrift/qt/moc_TQTcpServer.cpp:14:2: error: #error &amp;quot;This file was generated using the moc from 4.8.1. It&amp;quot;
src/thrift/qt/moc_TQTcpServer.cpp:15:2: error: #error &amp;quot;cannot be used with the include files from this version of Qt.&amp;quot;
src/thrift/qt/moc_TQTcpServer.cpp:16:2: error: #error &amp;quot;(The moc has changed too much.)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;则运行下面命令：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#mv thrift-0.9.0/lib/cpp/src/thrift/qt/moc_TQTcpServer.cpp  thrift-0.9.0/lib/cpp/src/thrift/qt/moc_TQTcpServer.cpp.bak
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;配置PKG&lt;em&gt;CONFIG&lt;/em&gt;PATH&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig/
pkg-config --cflags thrift    #返回：-I/usr/local/include/thrift为正确
cp /usr/local/lib/libthrift-0.9.0.so /usr/lib/
cp /usr/local/lib/libthrift-0.9.0.so /usr/lib64/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动hbase：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;/usr/lib/hbase/bin/hbase-daemon.sh  start  thrift 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用jps查看thrift进程&lt;/p&gt;

&lt;h2&gt;安装rhbase&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;R CMD INSTALL &amp;#39;rhbase_1.1.1.tar.gz&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;验证并测试&lt;/h2&gt;

&lt;p&gt;在R命令行中输入library(rmr2)、library(rhdfs)、library(rhbase)，载入成功即表示安装成功&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop27 hadoop]# R
R version 3.0.1 (2013-05-16) -- &amp;quot;Good Sport&amp;quot;
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type &amp;#39;license()&amp;#39; or &amp;#39;licence()&amp;#39; for distribution details.
Natural language support but running in an English locale
R is a collaborative project with many contributors.
Type &amp;#39;contributors()&amp;#39; for more information and
&amp;#39;citation()&amp;#39; on how to cite R or R packages in publications.
Type &amp;#39;demo()&amp;#39; for some demos, &amp;#39;help()&amp;#39; for on-line help, or
&amp;#39;help.start()&amp;#39; for an HTML browser interface to help.
Type &amp;#39;q()&amp;#39; to quit R.
&amp;gt; library(rhdfs)
Loading required package: rJava
HADOOP_CMD=/usr/bin/hadoop
Be sure to run hdfs.init()
&amp;gt; library(rmr2)
Loading required package: Rcpp
Loading required package: RJSONIO
Loading required package: digest
Loading required package: functional
Loading required package: stringr
Loading required package: plyr
Loading required package: reshape2
&amp;gt; library(rhbase)
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;4. 装RHive&lt;/h1&gt;

&lt;h2&gt;环境变量&lt;/h2&gt;

&lt;p&gt;设置环境变量 &lt;code&gt;vim /etc/profile&lt;/code&gt;,末行添加如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HADOOP_CMD=/usr/bin/hadoop
export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig/
export HADOOP_STREAMING=/usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.2.1.jar
export HADOOP_HOME=/usr/lib/hadoop
export RHIVE_DATA=/hadoop/dfs/rhive/data
export HIVE_HOME=/usr/lib/hive
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;安装Rserve：&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#R CMD INSTALL &amp;#39;Rserve_1.7-1.tar.gz&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在安装Rsever用户下，创建一目录，并创建Rserv.conf文件，写入``remote enable&amp;#39;&amp;#39;保存并退出。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#cd /usr/local/lib64/R/
#echo remote enable &amp;gt; Rserv.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动Rserve：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#R CMD Rserve --RS-conf /usr/local/lib64/R/Rserv.conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;检查Rserve启动是否正常：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#telnet localhost 6311
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;显示 Rsrv0103QAP1 则表示连接成功&lt;/p&gt;

&lt;h2&gt;安装RHive&lt;/h2&gt;

&lt;p&gt;创建数据目录：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#R CMD INSTALL RHive_0.0-7.tar.gz
#cd /usr/local/lib64/R/
mkdir -p rhive/data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在上传rhive_udf.jar到hdfs上：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hadoop fs -mkdir /rhive/lib
cd /usr/local/lib64/R/library/RHive/java
hadoop fs -put rhive_udf.jar /rhive/lib
hadoop fs -chmod a+rw /rhive/lib/rhive_udf.jar
cd /usr/lib/hadoop
ln -s /etc/hadoop/conf conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;测试RHive安装是否成功：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;R
library（RHive）
rhive.connect(&amp;#39;192.168.0.27&amp;#39;)【hive的地址】
rhive.env()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>通过Cloudera Manager安装CDH</title>
   <link href="http://blog.javachen.com/hadoop/2013/06/24/install-cdh-by-cloudera-manager"/>
   <updated>2013-06-24T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/06/24/install-cdh-by-cloudera-manager</id>
   <content type="html">&lt;h1&gt;1 方法一&lt;/h1&gt;

&lt;p&gt;你可以从&lt;a href=&quot;https://ccp.cloudera.com/display/SUPPORT/Downloads&quot;&gt;https://ccp.cloudera.com/display/SUPPORT/Downloads&lt;/a&gt;下载&lt;code&gt;cloudera-manager-installer.bin&lt;/code&gt;，然后修改执行权限并执行该脚本。&lt;/p&gt;

&lt;p&gt;该脚本中配置的rhel6的yum源为：&lt;a href=&quot;http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/4/&quot;&gt;http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/4/&lt;/a&gt;，下载的过程必须连网并且rpm的过程会非常慢，这种方法对虚拟机或者是无法连网的内网机器来说根本无法使用。&lt;/p&gt;

&lt;p&gt;因为知道所有的rpm都在上面网址可以下载到，故你可以手动下载这些rpm然后手动安装，详细过程请参考：&lt;a href=&quot;http://dreamyue.com/post/41090075449/cloudera-manager-hadoop&quot;&gt;通过cloudera-manager来安装hadoop&lt;/a&gt;。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h1&gt;2 方法二&lt;/h1&gt;

&lt;p&gt;这里还有一种方法，就是手动下载&lt;code&gt;Cloudera Manager&lt;/code&gt;的yum tar包，在虚拟机中搭建一个本地yum源，然后修改hosts文件，使&lt;code&gt;archive.cloudera.com&lt;/code&gt;域名映射到本地ip。&lt;/p&gt;

&lt;h1&gt;3 方法三&lt;/h1&gt;

&lt;p&gt;出于好奇，想破解&lt;code&gt;cloudera-manager-installer.bin&lt;/code&gt;，然后看看其中做了哪些操作。通过以下脚本即可解压该文件：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[june@june-fedora cdh]$ mv cloudera-manager-installer.bin cloudera-manager-installer.zip
[june@june-fedora cdh]$ unzip cloudera-manager-installer.zip 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;解压之后的目录如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[june@june-fedora cloudera-manager-installer]$ ll
总用量 512
-rwxrwxr-x. 1 june june 501698 5月  25 09:53 cloudera-manager-installer.zip
drwxr-xr-x. 2 june june   4096 5月  23 03:05 data
drwxr-xr-x. 2 june june   4096 5月  22 21:48 guis
drwxr-xr-x. 2 june june   4096 5月  22 21:48 meta
drwxr-xr-x. 2 june june   4096 5月  22 21:48 scripts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看解压之后的文件可以看到安装脚本是用lua编写并用MojoSetup编译的，从&lt;code&gt;scripts/config.lua&lt;/code&gt;脚本中大概可以看出安装脚本的执行过程。&lt;/p&gt;

&lt;p&gt;整理下该脚本逻辑，主要是做了以下操作：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install -y jdk.x86_64 
yum install -y cloudera-manager-server 
yum install -y cloudera-manager-server-db
/etc/init.d/cloudera-scm-server start
/etc/init.d/cloudera-scm-server-db start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;知道了上面这点之后，就可以在本地的cloudera-manager yum中，执行以上操作完成cloudera-manager的安装，安装成功之后查看7180端口是否打开：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;netstat -na| grep 7180
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过浏览器访问&lt;code&gt;http://IP:7180&lt;/code&gt;登录cloudera manager界面：用户名/密码：&lt;code&gt;admin/admin&lt;/code&gt;,按照界面提示完成hadoop集群安装。&lt;/p&gt;

&lt;h1&gt;4 排错&lt;/h1&gt;

&lt;p&gt;在执行下面一个命令时候可能会出现如下异常&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;/etc/init.d/cloudera-scm-server-db start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;异常信息如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    [root@cdh1 cloudera-scm-server-db]# /etc/init.d/cloudera-scm-server-db start
    属于此数据库系统的文件宿主为用户 &amp;quot;cloudera-scm&amp;quot;.
    此用户也必须为服务器进程的宿主.
    数据库簇将带有 locale en_US.UTF8 初始化.
    缺省的文本搜索配置将会被设置到&amp;quot;english&amp;quot;

    修复已存在目录 /var/lib/cloudera-scm-server-db/data 的权限 ... initdb: 无法改变目录 &amp;quot;/var/lib/cloudera-scm-server-db/data&amp;quot; 的权限: 权限不够
    Could not initialize database server.
      This usually means that your PostgreSQL installation failed or isn&amp;#39;t working properly.
      PostgreSQL is installed using the set of repositories found on this machine. Please
      ensure that PostgreSQL can be installed. Please also uninstall any other instances of
      PostgreSQL and then try again., giving up
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这时候，请执行如下命令：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;su -s /bin/bash cloudera-scm -c &amp;quot;touch /var/log/cloudera-scm-server/db.log; /usr/share/cmf/bin/initialize_embedded_db.sh /var/lib/cloudera-scm-server-db/data /var/log/cloudera-scm-server/db.log&amp;quot;
su -s /bin/bash cloudera-scm -c &amp;quot;pg_ctl start -w -D /var/lib/cloudera-scm-server-db/data -l /var/log/cloudera-scm-server/db.log&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>kettle访问IDH2.3中的HBase</title>
   <link href="http://blog.javachen.com/hbase/2013/04/17/access-idh-2.3-hbase-in-kettle"/>
   <updated>2013-04-17T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hbase/2013/04/17/access-idh-2.3-hbase-in-kettle</id>
   <content type="html">&lt;h1&gt;摘要&lt;/h1&gt;

&lt;p&gt;Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，绿色无需安装，数据抽取高效稳定。&lt;a href=&quot;https://github.com/pentaho/big-data-plugin&quot;&gt;big-data-plugin&lt;/a&gt;是kettle中用于访问bigdata，包括hadoop、cassandra、mongodb等nosql数据库的一个插件。&lt;/p&gt;

&lt;p&gt;截至目前，kettle的版本为4.4.1，&lt;code&gt;big-data-plugin&lt;/code&gt;插件支持&lt;code&gt;cloudera CDH3u4、CDH4.1&lt;/code&gt;，暂不支持Intel的hadoop发行版本IDH。&lt;/p&gt;

&lt;p&gt;本文主要介绍如何让kettle支持IDH的hadoop版本。&lt;/p&gt;

&lt;h1&gt;方法&lt;/h1&gt;

&lt;p&gt;假设你已经安装好IDH-2.3的集群，并已经拷贝出&lt;code&gt;/usr/lib/&lt;/code&gt;下的hadoop、hbase、zookeeper目录。&lt;/p&gt;

&lt;p&gt;首先，下载一个kettle版本，如社区版data-integration，然后进入&lt;code&gt;data-integration/plugins/pentaho-big-data-plugin&lt;/code&gt;目录，修改plugin.properties文件中的&lt;code&gt;active.hadoop.configuration&lt;/code&gt;属性，将其值改为cdh4&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;active.hadoop.configuration=cdh4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改kettle的log4j日志等级，并启动kettle，检查启动过程中是否报错，如有错误，请修正错误。&lt;/p&gt;

&lt;p&gt;进入hadoop-configurations目录，copy and paste cdh3u4并命名为idh2.3。&lt;/p&gt;

&lt;p&gt;因为IDH和CDH的hadoop版本不一致，故需要替换hadoop和hbase、zookeeper为IDH的版本，涉及到需要替换、增加的jar有，这些jar文件从IDH安装后的目录中拷贝即可：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/hbase-0.94.1-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/protobuf-java-2.4.0a.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/zookeeper-3.4.5-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-ant-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-core-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-examples-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-test-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-tools-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libthrift-0.8.0.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其他依赖包可以尝试添加，并删除多版本的jar文件。&lt;/p&gt;

&lt;p&gt;需要删除CDH的jar有：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/hbase-0.90.6-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/zookeeper-3.3.5-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-client-0.20.2-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-core-0.20.2-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libfb303-0.5.0-cdh.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libthrift-0.5.0-cdh.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改plugin.properties文件中的active.hadoop.configuration属性，将其值改为idh2.3。重起kettle，观察启动过程中是否报错。&lt;/p&gt;

&lt;h3&gt;验证&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;打开hbase output组件，配置zookeeper的host和port&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/hbase-output-setup-for-idh-2.3.png&quot; alt=&quot;hbase-output-setup-for-idh-2.3&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在&lt;code&gt;Create/Edit mappings&lt;/code&gt; tab页点击&lt;code&gt;Get table names&lt;/code&gt;，发现该组件卡住，kettle控制台提示异常则需要检查客户端jar版本和服务端是否一致：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;INFO client.HConnectionManager$HConnectionImplementation: getMaster attempt 0 of 10 failed; 
retrying after sleep of 1000
java.io.IOException: Call to OS-GZP2308-04/192.168.40.84:60000 failed on local exception: java.io.EOFException
at org.apache.hadoop.hbase.ipc.HBaseClient.wrapException(HBaseClient.java:1110)
at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:1079)
at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:150)
at $Proxy5.getProtocolVersion(Unknown Source)
at org.apache.hadoop.hbase.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:183)
at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:335)
at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:312)
at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:364)
at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:710)
at org.apache.hadoop.hbase.client.HBaseAdmin.&amp;lt; init&amp;gt;(HBaseAdmin.java:141)
at com.intel.hbase.test.createtable.TableBuilder.main(TableBuilder.java:48)
Caused by: java.io.EOFException
at java.io.DataInputStream.readInt(DataInputStream.java:375)
at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:605)
at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:538)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>kettle中添加一个参数字段到输出</title>
   <link href="http://blog.javachen.com/kettle/2013/04/07/add-a-field-from-paramter-to-output"/>
   <updated>2013-04-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2013/04/07/add-a-field-from-paramter-to-output</id>
   <content type="html">&lt;p&gt;kettle可以将输入流中的字段输出到输出流中，输入输出流可以为数据库、文件或其他，通常情况下输入流中字段为已知确定的，如果我想在输出流中添加一个来自转换的命令行参数的一个字段，该如何操作？&lt;/p&gt;

&lt;p&gt;上述问题可以拆分为两个问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从命令行接受一个参数作为一个字段&lt;/li&gt;
&lt;li&gt;合并输入流和这个字段&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;问题1&lt;/h2&gt;

&lt;p&gt;第一个问题可以使用kettle中&lt;code&gt;获取系统信息&lt;/code&gt;组件，定义一个变量，该值来自命令行参数，见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/get-a-field-from-paramter.png&quot; alt=&quot;get-a-field-from-paramter&quot;&gt;&lt;/p&gt;

&lt;h2&gt;问题2&lt;/h2&gt;

&lt;p&gt;第二个问题可以使用kettle中&lt;code&gt;记录关联 (笛卡尔输出)&lt;/code&gt;组件将两个组件关联起来，输出一个笛卡尔结果集，关联条件设定恒为true，在运行前设置第一个参数的值，然后运行即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/run-kettle-for-join-two-inputs.png&quot; alt=&quot;run-kettle-for-join-two-inputs&quot;&gt;&lt;/p&gt;

&lt;h2&gt;下载脚本&lt;/h2&gt;

&lt;p&gt;最后，kettle转换文件下载地址：&lt;a href=&quot;/files/2013/join-a-paramter-to-input-in-kettle.zip&quot;&gt;在这里&lt;/a&gt;。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>从yum安装Cloudera CDH集群</title>
   <link href="http://blog.javachen.com/hadoop/2013/04/06/install-cloudera-cdh-by-yum"/>
   <updated>2013-04-06T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/04/06/install-cloudera-cdh-by-yum</id>
   <content type="html">&lt;p&gt;记录使用yum通过rpm方式安装Cloudera CDH中的hadoop、yarn、HBase，需要注意初始化namenode之前需要手动创建一些目录并设置权限。&lt;/p&gt;

&lt;h1&gt;0.环境准备&lt;/h1&gt;

&lt;p&gt;1.设置hosts
临时设置hostname，以node1为例&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt; sudo hostname node1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;确保&lt;code&gt;/etc/hosts&lt;/code&gt;中包含ip和FQDN，如果你在使用DNS，保存这些信息到&lt;code&gt;/etc/hosts&lt;/code&gt;不是必要的，却是最佳实践。
确保&lt;code&gt;/etc/sysconfig/network&lt;/code&gt;中包含hostname=node1
检查网络，运行下面命令检查是否配置了hostname以及其对应的ip是否正确。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;host -v -t A `hostname` 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;hadoop的配置文件&lt;code&gt;core-site.xml&lt;/code&gt;、&lt;code&gt;mapred-site.xml&lt;/code&gt;和&lt;code&gt;yarn-site.xml&lt;/code&gt;配置节点时，请使用hostname和不是ip&lt;/p&gt;

&lt;p&gt;2.关闭防火墙&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;setenforce 0
vim /etc/sysconfig/selinux #修改SELINUX=disabled
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3.清空iptables &lt;code&gt;iptables -F&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;4.检查每个节点上的&lt;code&gt;/tmp&lt;/code&gt;目录权限是否为&lt;code&gt;1777&lt;/code&gt;，如果不是请修改。&lt;/p&gt;

&lt;p&gt;5.设置时钟同步服务&lt;/p&gt;

&lt;p&gt;在所有节点安装ntp&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install ntp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;设置开机启动&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;chkconfig ntpd on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在所有节点启动ntp&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;/etc/init.d/ntpd start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;是client使用local NTP server，修改/etc/ntp.conf，添加以下内容：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;server $LOCAL_SERVER_IP OR HOSTNAME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;1. 安装jdk&lt;/h1&gt;

&lt;p&gt;检查jdk版本&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;java -version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果其版本低于v1.6 update 31，则将其卸载&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;rpm -qa | grep java
yum remove {java-1.*}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;验证默认的jdk是否被卸载&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;which java
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装jdk，使用yum安装或者手动下载安装jdk-6u31-linux-x64.bin，下载地址：&lt;a href=&quot;http://www.oracle.com/technetwork/java/javasebusiness/downloads/java-archive-downloads-javase6-419409.html#jdk-6u31-oth-JPR&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install jdk -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;创建符号连接&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ln -s XXXXX/jdk1.6.0_31 /usr/java/default
ln -s /usr/java/default/bin/java /usr/bin/java
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;设置环境变量:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;echo &amp;quot;export JAVA_HOME=/usr/java/latest&amp;quot; &amp;gt;&amp;gt;/root/.bashrc
echo &amp;quot;export PATH=\$JAVA_HOME/bin:\$PATH&amp;quot; &amp;gt;&amp;gt; /root/.bashrc
source /root/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;验证版本&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;java -version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你将看到以下输出：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;java version &amp;quot;1.6.0_31&amp;quot;
Java(TM) SE Runtime Environment (build 1.6.0_31-b04)
Java HotSpot(TM) 64-Bit Server VM (build 20.6-b01, mixed mode)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;检查环境变量中是否有设置&lt;code&gt;JAVA_HOME&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo env | grep JAVA_HOME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果env中没有&lt;code&gt;JAVA_HOM&lt;/code&gt;E变量，则修改&lt;code&gt;/etc/sudoers&lt;/code&gt;文件&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;vi /etc/sudoers
Defaults env_keep+=JAVA_HOME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;2. 设置yum源&lt;/h1&gt;

&lt;p&gt;从&lt;a href=&quot;http://archive.cloudera.com/cdh4/repo-as-tarball/4.2.0/cdh4.2.0-centos6.tar.gz&quot;&gt;这里&lt;/a&gt; 下载压缩包解压并设置本地或ftp yum源，可以参考&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_30.html&quot;&gt;Creating a Local Yum Repository&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;3. 安装HDFS&lt;/h1&gt;

&lt;h2&gt;在NameNode节点yum安装&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum list hadoop
yum install hadoop-hdfs-namenode
yum install hadoop-hdfs-secondarynamenode
yum install hadoop-yarn-resourcemanager
yum install hadoop-mapreduce-historyserver
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;在DataNode节点yum安装&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum list hadoop
yum install hadoop-hdfs-datanode
yum install hadoop-yarn-nodemanager
yum install hadoop-mapreduce
yum install zookeeper-server
yum install hadoop-httpfs
yum install hadoop-debuginfo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;4. 配置hadoop&lt;/h1&gt;

&lt;h2&gt;自定义hadoop配置文件&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo cp -r /etc/hadoop/conf.dist /etc/hadoop/conf.my_cluster
sudo alternatives --verbose --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.my_cluster 50 
sudo alternatives --set hadoop-conf /etc/hadoop/conf.my_cluster
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;hadoop默认使用&lt;code&gt;/etc/hadoop/conf&lt;/code&gt;路径读取配置文件，经过上述配置之后，&lt;code&gt;/etc/hadoop/conf&lt;/code&gt;会软连接到&lt;code&gt;/etc/hadoop/conf.my_cluster&lt;/code&gt;目录&lt;/p&gt;

&lt;h2&gt;修改配置文件&lt;/h2&gt;

&lt;p&gt;进入/etc/hadoop/conf编辑配置文件。&lt;/p&gt;

&lt;p&gt;修改core-site.xml配置:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    &amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hdfs://node1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;fs.trash.interval&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;10080&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;fs.trash.checkpoint.interval&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;10080&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;io.bytes.per.checksum&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;4096&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改hdfs-site.xml:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    &amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/opt/data/hadoop&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.block.size&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;268435456&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.permissions.superusergroup&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;hadoop&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.handler.count&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.datanode.handler.count&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.datanode.balance.bandwidthPerSec&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;1048576&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.http-address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:50070&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:50090&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改master和slaves文件&lt;/p&gt;

&lt;p&gt;注意：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The value of NameNode new generation size should be 1/8 of maximum heap size (-Xmx). Please check, as the default setting may not be accurate.
To change the default value, edit the /etc/hadoop/conf/hadoop-env.sh file and change the value of the -XX:MaxnewSize parameter to 1/8th the value of the maximum heap size (-Xmx) parameter.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;配置NameNode HA&lt;/h2&gt;

&lt;p&gt;请参考&lt;a href=&quot;https://ccp.cloudera.com/display/CDH4DOC/Introduction+to+HDFS+High+Availability&quot;&gt;Introduction to HDFS High Availability&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;配置Secondary NameNode&lt;/h2&gt;

&lt;p&gt;在hdfs-site.xml中可以配置以下参数：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;dfs.namenode.checkpoint.check.period
dfs.namenode.checkpoint.txns
dfs.namenode.checkpoint.dir
dfs.namenode.checkpoint.edits.dir
dfs.namenode.num.checkpoints.retained
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;多个secondarynamenode的配置&lt;/h2&gt;

&lt;p&gt;设置多个secondarynamenode，请参考&lt;a href=&quot;http://blog.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/&quot;&gt;multi-host-secondarynamenode-configuration&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;文件路径配置清单&lt;/h2&gt;

&lt;p&gt;在hadoop中默认的文件路径以及权限要求如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;目录                          所有者       权限      默认路径
hadoop.tmp.dir                  hdfs:hdfs   drwx------  /var/hadoop
dfs.namenode.name.dir               hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir               hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir         hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/namesecondary
yarn.nodemanager.local-dirs         yarn:yarn   drwxr-xr-x  ${hadoop.tmp.dir}/nm-local-dir
yarn.nodemanager.log-dirs           yarn:yarn   drwxr-xr-x  ${yarn.log.dir}/userlogs
yarn.nodemanager.remote-app-log-dir                     /tmp/logs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我的配置如下:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hadoop.tmp.dir                  /opt/data/hadoop
dfs.namenode.name.dir               ${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir               ${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir         ${hadoop.tmp.dir}/dfs/namesecondary
yarn.nodemanager.local-dirs         /opt/data/yarn/local
yarn.nodemanager.log-dirs           /var/log/hadoop-yarn/logs
yarn.nodemanager.remote-app-log-dir         /var/log/hadoop-yarn/app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在hadoop中&lt;code&gt;dfs.permissions.superusergroup&lt;/code&gt;默认为hdfs，我的&lt;code&gt;hdfs-site.xml&lt;/code&gt;配置文件将其修改为了hadoop。&lt;/p&gt;

&lt;h2&gt;配置CDH4组件端口&lt;/h2&gt;

&lt;p&gt;请参考&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/latest/CDH4-Installation-Guide/cdh4ig_topic_9.html&quot;&gt;Configuring Ports for CDH4&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;创建数据目录&lt;/h2&gt;

&lt;p&gt;在namenode节点创建name目录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mkdir -p /opt/data/hadoop/dfs/name
chown -R hdfs:hadoop /opt/data/hadoop/dfs/name
chmod 700 /opt/data/hadoop/dfs/name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在所有datanode节点创建data目录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mkdir -p /opt/data/hadoop/dfs/data
chown -R hdfs:hadoop /opt/data/hadoop/dfs/data
chmod 700 /opt/data/hadoop/dfs/data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在secondarynode节点创建namesecondary目录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mkdir -p /opt/data/hadoop/dfs/namesecondary
chown -R hdfs:hadoop /opt/data/hadoop/dfs/namesecondary
chmod 700 /opt/data/hadoop/dfs/namesecondary
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在所有datanode节点创建yarn的local目录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mkdir -p /opt/data/hadoop/yarn/local
chown -R yarn:yarn /opt/data/hadoop/yarn/local
chmod 700 /opt/data/hadoop/yarn/local
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;同步配置文件到整个集群&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo scp -r /etc/hadoop/conf root@nodeX:/etc/hadoop/conf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;格式化NameNode&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo -u hdfs hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;定期检查datanode状态&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#!/bin/bash
if ! jps | grep -q DataNode ; then
 echo ERROR: datanode not up
fi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;在每个节点启动hdfs&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;for x in `cd /etc/init.d ; ls hadoop-hdfs-*` ; do sudo service $x restart ; done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;验证测试&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;打开浏览器访问：http://node1:50070 &lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;5. 安装YARN&lt;/h1&gt;

&lt;p&gt;先在一台机器上配置好，然后在做同步。&lt;/p&gt;

&lt;p&gt;修改mapred-site.xml文件:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    &amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
      &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;mapreduce.jobtracker.staging.root.dir&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;/user&amp;lt;/value&amp;gt;
      &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:10020&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:19888&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
            &amp;lt;name&amp;gt;mapred.child.java.opts&amp;lt;/name&amp;gt;
            &amp;lt;value&amp;gt;-Xmx512m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=1 -XX:ParallelGCThreads=1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;mapreduce.task.io.sort.factor&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;mapreduce.task.io.sort.mb&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;200&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;mapreduce.reduce.shuffle.parallelcopies&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;16&amp;lt;/value&amp;gt;
       &amp;lt;!-- 一般介于节点数开方和节点数一半之间，小于20节点，则为节点数--&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;mapreduce.task.timeout&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;1800000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;mapreduce.tasktracker.map.tasks.maximum&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;4&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;mapreduce.tasktracker.reduce.tasks.maximum&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;2&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改yarn-site.xml文件:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    &amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.resource-tracker.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:8031&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:8032&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:8030&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.admin.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:8033&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;node1:8088&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce.shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.log-aggregation-enable&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.application.classpath&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;
        $HADOOP_CONF_DIR,
        $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
        $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,
        $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,
        $YARN_HOME/*,$YARN_HOME/lib/*
        &amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.local-dirs&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/opt/hadoop/yarn/local&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.log-dirs&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/var/log/hadoop-yarn/logs&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.remote-app-log-dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;/var/log/hadoop-yarn/apps&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
    &amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;HDFS创建临时目录&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo -u hdfs hadoop fs -mkdir /tmp
sudo -u hdfs hadoop fs -chmod -R 1777 /tmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;创建日志目录&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo -u hdfs hadoop fs -mkdir /user/history
sudo -u hdfs hadoop fs -chmod 1777 /user/history
sudo -u hdfs hadoop fs -chown yarn /user/history
sudo -u hdfs hadoop fs -mkdir /user/history/done
sudo -u hdfs hadoop fs -chmod 777 /user/history/done
sudo -u hdfs hadoop fs -chown yarn /user/history/done
sudo -u hdfs hadoop fs -mkdir /var/log/hadoop-yarn
sudo -u hdfs hadoop fs -chown yarn:mapred /var/log/hadoop-yarn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;验证hdfs结构是否正确&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@node1 data]# sudo -u hdfs hadoop fs -ls -R /
drwxrwxrwt   - hdfs   hadoop          0 2012-04-19 14:31 /tmp
drwxr-xr-x   - hdfs   hadoop          0 2012-05-31 10:26 /user
drwxrwxrwt   - yarn   hadoop          0 2012-04-19 14:31 /user/history
drwxrwxrwx   - yarn   hadoop          0 2012-04-19 14:31 /user/history/done
drwxr-xr-x   - hdfs   hadoop          0 2012-05-31 15:31 /var
drwxr-xr-x   - hdfs   hadoop          0 2012-05-31 15:31 /var/log
drwxr-xr-x   - yarn   mapred          0 2012-05-31 15:31 /var/log/hadoop-yarn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;启动mapred-historyserver&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;/etc/init.d/hadoop-mapreduce-historyserver start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;在每个节点启动YARN&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;for x in `cd /etc/init.d ; ls hadoop-yarn-*` ; do sudo service $x start ; done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;验证&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;打开浏览器：http://node1:8088/&lt;/li&gt;
&lt;li&gt;运行测试程序&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;为每个MapReduce用户创建主目录&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo -u hdfs hadoop fs -mkdir /user/$USER
sudo -u hdfs hadoop fs -chown $USER /user/$USER
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Set HADOOP&lt;em&gt;MAPRED&lt;/em&gt;HOME&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;设置开机启动&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo chkconfig hadoop-hdfs-namenode on
sudo chkconfig hadoop-hdfs-datanode on
sudo chkconfig hadoop-hdfs-secondarynamenode on
sudo chkconfig hadoop-yarn-resourcemanager on
sudo chkconfig hadoop-yarn-nodemanager on
sudo chkconfig hadoop-mapreduce-historyserver on
sudo chkconfig hbase-master on
sudo chkconfig hbase-regionserver on
sudo chkconfig hive-metastore  on
sudo chkconfig hive-server2 on
sudo chkconfig zookeeper-server on
sudo chkconfig hadoop-httpfs on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;6. 安装Zookeeper&lt;/h1&gt;

&lt;p&gt;安装zookeeper&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install zookeeper*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;设置crontab&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;crontab -e
15 * * * * java -cp $classpath:/usr/lib/zookeeper/lib/log4j-1.2.15.jar:\
/usr/lib/zookeeper/lib/jline-0.9.94.jar:\   
/usr/lib/zookeeper/zookeeper.jar:/usr/lib/zookeeper/conf\
org.apache.zookeeper.server.PurgeTxnLog /var/zookeeper/ -n 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在每个需要安装zookeeper的节点上创建zookeeper的目录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mkdir -p /opt/data/zookeeper
chown -R zookeeper:zookeeper /opt/data/zookeeper
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;设置zookeeper配置：/etc/zookeeper/conf/zoo.cfg，并同步到其他机器&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;tickTime=2000
initLimit=10
syncLimit=5
dataDir=/opt/data/zookeeper
clientPort=2181
server.1=node1:2888:3888
server.2=node2:2888:3888
server.3=node3:2888:3888
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在每个节点上初始化并启动zookeeper，注意修改n值&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;service zookeeper-server init --myid=n
service zookeeper-server restart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;7. 安装HBase&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install hbase*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;在hdfs中创建/hbase&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo -u hdfs hadoop fs -mkdir /hbase
sudo -u hdfs hadoop fs -chown hbase:hbase /hbase
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;设置crontab：&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;crontab -e
* 10 * * * cd /var/log/hbase/; rm -rf\
`ls /var/log/hbase/|grep -P &amp;#39;hbase\-hbase\-.+\.log\.[0-9]&amp;#39;\`&amp;gt;&amp;gt; /dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;修改配置文件并同步到其他机器：&lt;/h2&gt;

&lt;p&gt;修改hbase-site.xml文件：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://node1:8020/hbase&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/hbase&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;node1,node2,node3&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hregion.max.filesize&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;536870912&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hregion.memstore.flush.size&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;67108864&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regionserver.lease.period&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;600000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.client.retries.number&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt; 
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regionserver.handler.count&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.property.maxClientCnxns&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;2000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hfile.block.cache.size&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;0.1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regions.slop&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;0&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hstore.compactionThreshold&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;10&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hstore.blockingStoreFiles&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;30&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;修改regionserver文件&lt;/h2&gt;

&lt;h2&gt;启动HBase&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;service hbase-master start
service hbase-regionserver start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;8. 安装hive&lt;/h1&gt;

&lt;h2&gt;在一个节点上安装hive&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo yum install hive*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;安装postgresql&lt;/h2&gt;

&lt;p&gt;手动安装、配置postgresql数据库，请参考&lt;a href=&quot;http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2/&quot;&gt;手动安装Cloudera Hive CDH4.2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;yum方式安装：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo yum install postgresql-server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;初始化数据库：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt; sudo service postgresql initdb
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改配置文件postgresql.conf，修改完后内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo cat /var/lib/pgsql/data/postgresql.conf  | grep -e listen -e standard_conforming_strings
listen_addresses = &amp;#39;*&amp;#39;
standard_conforming_strings = off
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改 pg_hba.conf，添加以下一行内容：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;host    all         all         0.0.0.0         0.0.0.0               md5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动数据库&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo service postgresql start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;配置开启启动&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;chkconfig postgresql on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;安装jdbc驱动&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo yum install postgresql-jdbc
ln -s /usr/share/java/postgresql-jdbc.jar /usr/lib/hive/lib/postgresql-jdbc.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;创建数据库和用户&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;bash# sudo –u postgres psql
bash$ psql
postgres=# CREATE USER hiveuser WITH PASSWORD &amp;#39;redhat&amp;#39;;
postgres=# CREATE DATABASE metastore owner=hiveuser;
postgres=# GRANT ALL privileges ON DATABASE metastore TO hiveuser;
postgres=# \q;
bash$ psql  -U hiveuser -d metastore
postgres=# \i /usr/lib/hive/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql
SET
SET
..
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;修改配置文件&lt;/h2&gt;

&lt;p&gt;修改hive-site.xml文件：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://node1:8020&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;jdbc:postgresql://node1/metastore&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;org.postgresql.Driver&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;hiveuser&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;redhat&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapred.job.tracker&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;node1:8031&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;datanucleus.autoCreateSchema&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;datanucleus.fixedDatastore&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/user/hive/warehouse&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;thrift://node1:9083&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.local&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.support.concurrency&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.zookeeper.quorum&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;node2,node3,node1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.host&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;node1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.port&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;9999&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.war.file&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;lib/hive-hwi-0.10.0-cdh4.2.0.war&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.merge.mapredfiles&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;在hdfs中创建hive数据仓库目录&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;hive的数据仓库在hdfs中默认为&lt;code&gt;/user/hive/warehouse&lt;/code&gt;,建议修改其访问权限为1777，以便其他所有用户都可以创建、访问表，但不能删除不属于他的表。&lt;/li&gt;
&lt;li&gt;每一个查询hive的用户都必须有一个hdfs的home目录(&lt;code&gt;/user&lt;/code&gt;目录下，如root用户的为&lt;code&gt;/user/root&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;hive所在节点的 &lt;code&gt;/tmp&lt;/code&gt;必须是world-writable权限的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建目录并设置权限：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sudo -u hdfs hadoop fs -mkdir /user/hive/warehouse
sudo -u hdfs hadoop fs -chmod 1777 /user/hive/warehouse
sudo -u hdfs hadoop fs -chown hive /user/hive/warehouse
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;启动hive-server和metastore&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;service hive-metastore start
service hive-server start
service hive-server2 start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;访问beeline&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ /usr/lib/hive/bin/beeline
beeline&amp;gt; !connect jdbc:hive2://localhost:10000 username password org.apache.hive.jdbc.HiveDriver
0: jdbc:hive2://localhost:10000&amp;gt; SHOW TABLES;
show tables;
+-----------+
| tab_name  |
+-----------+
+-----------+
No rows selected (0.238 seconds)
0: jdbc:hive2://localhost:10000&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其 sql语法参考&lt;a href=&quot;http://sqlline.sourceforge.net/&quot;&gt;SQLLine CLI&lt;/a&gt;，在这里，你不能使用HiveServer的sql语句&lt;/p&gt;

&lt;h2&gt;与hbase集成&lt;/h2&gt;

&lt;p&gt;需要在hive里添加以下jar包：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ADD JAR /usr/lib/hive/lib/zookeeper.jar;
ADD JAR /usr/lib/hive/lib/hbase.jar;
ADD JAR /usr/lib/hive/lib/hive-hbase-handler-0.10.0-cdh4.2.0.jar
ADD JAR /usr/lib/hive/lib/guava-11.0.2.jar;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;9. 其他&lt;/h1&gt;

&lt;h2&gt;安装Snappy&lt;/h2&gt;

&lt;p&gt;cdh4.3 rpm中默认已经包含了snappy，可以再不用安装。&lt;/p&gt;

&lt;p&gt;在每个节点安装Snappy&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install snappy snappy-devel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使snappy对hadoop可用&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;安装LZO&lt;/h2&gt;

&lt;p&gt;cdh4.3 rpm中默认不包含了lzo，需要自己额外安装。&lt;/p&gt;

&lt;p&gt;在每个节点安装：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;yum install lzo lzo-devel hadoop-lzo hadoop-lzo-native
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;10. 参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;[1] &lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_30.html&quot;&gt;Creating a Local Yum Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[2] &lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_29.html&quot;&gt;Java Development Kit Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3] &lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_11_2.html&quot;&gt;Deploying HDFS on a Cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[4] &lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_20.html&quot;&gt;HBase Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[5] &lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_21.html&quot;&gt;ZooKeeper Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[6] &lt;a href=&quot;http://roserouge.iteye.com/blog/1558498&quot;&gt;hadoop cdh 安装笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>安装impala过程</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/29/install-impala"/>
   <updated>2013-03-29T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/29/install-impala</id>
   <content type="html">&lt;p&gt;与Hive类似，Impala也可以直接与HDFS和HBase库直接交互。只不过Hive和其它建立在MapReduce上的框架适合需要长时间运行的批处理任务。例如那些批量提取，转化，加载（ETL）类型的Job。而Impala主要用于实时查询。&lt;/p&gt;

&lt;h1&gt;install&lt;/h1&gt;

&lt;p&gt;下载 impala，目前最新版本为0.6-1，&lt;a href=&quot;http://beta.cloudera.com/impala/redhat/6/x86_64/impala/0/RPMS/x86_64/&quot;&gt;下载地址&lt;/a&gt;。&lt;/p&gt;

&lt;h1&gt;安装过程&lt;/h1&gt;

&lt;p&gt;安装前提：先安装好hadoop集群以及hive，可以参考我的文章：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.javachen.com/Hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH4.2.html&quot;&gt;手动安装Cloudera Hadoop CDH4.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.javachen.com/Hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2.html&quot;&gt;手动安装Cloudera Hive CDH4.2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;DataNode节点&lt;/p&gt;

&lt;p&gt;yum install -y impala-0.6-1.p0.548.el6.x86&lt;em&gt;64.rpm   impala-server-0.6-1.p0.548.el6.x86&lt;/em&gt;64.rpm impala-state-store-0.6-1.p0.548.el6.x86&lt;em&gt;64.rpm    impala-shell-0.6-1.p0.548.el6.x86&lt;/em&gt;64.rpm libevent-1.4.13-4.el6.x86_64.rpm bigtop-utils-0.4+300-1.cdh4.0.1.p0.1.el6.noarch.rpm --skip-broken&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在hive节点上&lt;/p&gt;

&lt;p&gt;yum install -y impala-0.6-1.p0.548.el6.x86&lt;em&gt;64.rpm   impala-server-0.6-1.p0.548.el6.x86&lt;/em&gt;64.rpm \
impala-state-store-0.6-1.p0.548.el6.x86&lt;em&gt;64.rpm  impala-shell-0.6-1.p0.548.el6.x86&lt;/em&gt;64.rpm \
libevent-1.4.13-4.el6.x86_64.rpm    bigtop-utils-0.4+300-1.cdh4.0.1.p0.1.el6.noarch.rpm&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1&gt;配置Impala&lt;/h1&gt;

&lt;h2&gt;查看安装路径&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 conf]# find / -name impala
/var/run/impala
/var/lib/alternatives/impala
/var/log/impala
/usr/lib/impala
/etc/alternatives/impala
/etc/default/impala
/etc/impala
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;添加配置文件&lt;/h2&gt;

&lt;p&gt;impalad的配置文件路径由环境变量&lt;code&gt;IMPALA_CONF_DIR&lt;/code&gt;指定，默认为&lt;code&gt;/usr/lib/impala/conf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在节点desktop1上 拷贝&lt;code&gt;hive-site.xml&lt;/code&gt;、&lt;code&gt;core-site.xml&lt;/code&gt;、&lt;code&gt;hdfs-site.xml&lt;/code&gt;至&lt;code&gt;/usr/lib/impala/conf&lt;/code&gt;目录下:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 conf]# mkdir /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/log4j.properties /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/core-site.xml /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/hdfs-site.xml /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hive-0.10.0-cdh4.2.0/conf/hive-site.xml /usr/lib/impala/conf/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;并作下面修改在&lt;code&gt;hdfs-site.xml&lt;/code&gt;文件中添加如下内容：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.client.read.shortcircuit&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.domain.socket.path&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/var/run/hadoop-hdfs/dn._PORT&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.datanode.hdfs-blocks-metadata.enabled&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.datanode.hdfs-blocks-metadata.enabled&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;同步以上文件到其他节点&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop3:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop4:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop6:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop7:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop8:/usr/lib/impala/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;hadoop中添加native包&lt;/h2&gt;

&lt;p&gt;拷贝hadoop native包到hadoop安装路径下，并同步hadoop文件到其他节点：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 ~]# cp /usr/lib/impala/lib/*.so* /opt/hadoop-2.0.0-cdh4.2.0/lib/native/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;创建socket path&lt;/h2&gt;

&lt;p&gt;在每个节点上创建/var/run/hadoop-hdfs:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop3 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop4 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop6 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop7 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop8 ~]# mkdir -p /var/run/hadoop-hdfs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;拷贝postgres jdbc jar：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;cp /opt/hive-0.10.0-cdh4.2.0/lib/postgresql-9.1-903.jdbc* /usr/lib/impala/lib/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;启动服务&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在hive所在节点启动statestored（默认端口为24000）:&lt;/p&gt;

&lt;p&gt;GLOG&lt;em&gt;v=1 nohup statestored -state&lt;/em&gt;store_port=24000 &amp;amp;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果statestore正常启动，可以在/tmp/statestored.INFO查看。如果出现异常，可以查看/tmp/statestored.ERROR定位错误信息。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在所有impalad节点上：&lt;/p&gt;

&lt;p&gt;HADOOP&lt;em&gt;CONF&lt;/em&gt;DIR=&amp;quot;/usr/lib/impala/conf&amp;quot; nohup impalad -state&lt;em&gt;store&lt;/em&gt;host=desktop1 -nn=desktop1 \
    -nn_port=8020 -hostname=desktop3 -ipaddress=192.168.0.3 &amp;amp;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意： 其中的&lt;code&gt;-hostname&lt;/code&gt;和&lt;code&gt;-ipaddress&lt;/code&gt;表示当前启动impalad实例所在机器的主机名和ip地址。&lt;/p&gt;

&lt;p&gt;如果impalad正常启动，可以在&lt;code&gt;/tmp/ impalad.INFO&lt;/code&gt;查看。如果出现异常，可以查看&lt;code&gt;/tmp/impalad.ERROR&lt;/code&gt;定位错误信息。&lt;/p&gt;

&lt;h1&gt;使用shell&lt;/h1&gt;

&lt;p&gt;使用&lt;code&gt;impala-shell&lt;/code&gt;启动Impala Shell，分别连接各Impalad主机(desktop3、desktop4、desktop6、desktop7、desktop8)，刷新元数据，之后就可以执行shell命令。相关的命令如下(可以在任意节点执行)：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;gt;impala-shell
[Not connected] &amp;gt;connect desktop3:21000
[desktop3:21000] &amp;gt;refresh
[desktop3:21000] &amp;gt;connect desktop4:21000
[desktop4:21000] &amp;gt;refresh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;注意：&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;如果hive使用mysql或postgres数据库作为metastore的存储，则需要拷贝相应的jdbc jar到&lt;code&gt;/usr/lib/impala/lib&lt;/code&gt;目录下&lt;/li&gt;
&lt;li&gt;E0325 11:04:19.937718  7239 statestored-main.cc:52] Could not start webserver on port: 25010&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;可能是已经启动了statestored进程&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://yuntai.1kapp.com/?p=904&quot;&gt;Impala安装文档完整版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://tech.uc.cn/?p=817&quot;&gt;Impala入门笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ccp.cloudera.com/display/IMPALA10BETADOC/Installing+and+Using+Cloudera+Impala&quot;&gt;Installing and Using Cloudera Impala&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>手动安装Cloudera Hive CDH</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH"/>
   <updated>2013-03-24T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH</id>
   <content type="html">&lt;p&gt;本文主要记录手动安装cloudera Hive cdh4.2.0集群过程，环境设置及Hadoop、HBase安装过程见上篇文章。&lt;/p&gt;

&lt;h1&gt;安装hive&lt;/h1&gt;

&lt;p&gt;hive安装在desktop1上，注意hive默认是使用derby数据库保存元数据，这里替换为postgresql，下面会提到postgresql的安装说明，并且需要拷贝postgres的jdbc jar文件导hive的lib目录下。&lt;/p&gt;

&lt;h2&gt;上传文件&lt;/h2&gt;

&lt;p&gt;上传&lt;code&gt;hive-0.10.0-cdh4.2.0.tar&lt;/code&gt;到desktop1的&lt;code&gt;/opt&lt;/code&gt;，并解压缩&lt;/p&gt;

&lt;h2&gt;安装postgres&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;创建数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里创建数据库metastore并创建hiveuser用户，其密码为redhat。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    bash# sudo –u postgres psql
    bash$ psql
    postgres=# CREATE USER hiveuser WITH PASSWORD &amp;#39;redhat&amp;#39;;
    postgres=# CREATE DATABASE metastore owner=hiveuser;
    postgres=# GRANT ALL privileges ON DATABASE metastore TO hiveuser;
    postgres=# \q;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;初始化数据库&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;psql  -U hiveuser -d metastore
 \i /opt/hive-0.10.0-cdh4.2.0/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;编辑postgresql配置文件(&lt;code&gt;/opt/PostgreSQL/9.1/data/pg_hba.conf&lt;/code&gt;)，修改访问权限&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;host    all             all             0.0.0.0/0            md5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改postgresql.conf&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;standard_conforming_strings = of
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;重起postgres&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;su -c &amp;#39;/opt/PostgreSQL/9.1/bin/pg_ctl -D /opt/PostgreSQL/9.1/data restart&amp;#39; postgres
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;拷贝postgres的jdbc驱动到&lt;code&gt;/opt/hive-0.10.0-cdh4.2.0/lib&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;修改配置文件&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;hive-site.xml 
注意修改下面配置文件中postgres数据库的密码，注意配置&lt;code&gt;hive.aux.jars.path&lt;/code&gt;，在hive集成hbase时候需要从该路径家在hbase的一些jar文件。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;hive-site.xml文件内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;jdbc:postgresql://127.0.0.1/metastore&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;JDBC connect string for a JDBC metastore&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;org.postgresql.Driver&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;Driver class name for a JDBC metastore&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;hiveuser&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;username to use against metastore database&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;redhat&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;password to use against metastore database&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapred.job.tracker&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;desktop1:8031&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.aux.jars.path&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;file:///opt/hive-0.10.0-cdh4.2.0/lib/zookeeper-3.4.5-cdh4.2.0.jar,
    file:///opt/hive-0.10.0-cdh4.2.0/lib/hive-hbase-handler-0.10.0-cdh4.2.0.jar,
    file:///opt/hive-0.10.0-cdh4.2.0/lib/hbase-0.94.2-cdh4.2.0.jar,
    file:///opt/hive-0.10.0-cdh4.2.0/lib/guava-11.0.2.jar&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/warehouse-${user.name}&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;location of default database for the warehouse&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.exec.scratchdir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/hive-${user.name}&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;Scratch space for Hive jobs&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.querylog.location&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/querylog-${user.name}&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;
    Location of Hive run time structured log file
  &amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.support.concurrency&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Enable Hive&amp;#39;s Table Lock Manager Service&amp;lt;/description&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.zookeeper.quorum&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Zookeeper quorum used by Hive&amp;#39;s Table Lock Manager&amp;lt;/description&amp;gt;
  &amp;lt;value&amp;gt;desktop3,desktop4,desktop6,desktop7,desktop8&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.host&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;desktop1&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the host address the Hive Web Interface will listen on&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.port&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;9999&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the port the Hive Web Interface will listen on&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.war.file&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;lib/hive-hwi-0.10.0-cdh4.2.0.war&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the WAR file with the jsp content for Hive Web Interface&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;环境变量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;参考hadoop中环境变量的设置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动脚本&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在启动完之后，执行一些sql语句可能会提示错误，如何解决错误可以参考&lt;a href=&quot;http://kicklinux.com/hive-deploy/&quot;&gt;Hive安装与配置&lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;hive与hbase集成
在&lt;code&gt;hive-site.xml&lt;/code&gt;中配置&lt;code&gt;hive.aux.jars.path&lt;/code&gt;,在环境变量中配置hadoop、mapreduce的环境变量&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;异常说明&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;异常1：&lt;/p&gt;

&lt;p&gt;FAILED: Error in metadata: MetaException(message:org.apache.hadoop.hbase.ZooKeeperConnectionException: An error is preventing HBase from connecting to ZooKeeper&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：hadoop配置文件没有zk&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;异常2&lt;/p&gt;

&lt;p&gt;FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: Error executing JDOQL query &amp;quot;SELECT &amp;quot;THIS&amp;quot;.&amp;quot;TBL&lt;em&gt;NAME&amp;quot; AS NUCORDER0 FROM &amp;quot;TBLS&amp;quot; &amp;quot;THIS&amp;quot; LEFT OUTER JOIN &amp;quot;DBS&amp;quot; &amp;quot;THIS&lt;/em&gt;DATABASE&lt;em&gt;NAME&amp;quot; ON &amp;quot;THIS&amp;quot;.&amp;quot;DB&lt;/em&gt;ID&amp;quot; = &amp;quot;THIS&lt;em&gt;DATABASE&lt;/em&gt;NAME&amp;quot;.&amp;quot;DB&lt;em&gt;ID&amp;quot; WHERE &amp;quot;THIS&lt;/em&gt;DATABASE&lt;em&gt;NAME&amp;quot;.&amp;quot;NAME&amp;quot; = ? AND (LOWER(&amp;quot;THIS&amp;quot;.&amp;quot;TBL&lt;/em&gt;NAME&amp;quot;) LIKE ? ESCAPE &amp;#39;\&amp;#39; ) ORDER BY NUCORDER0 &amp;quot; : ERROR: invalid escape string 建议：Escape string must be empty or one character..&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;参考：https://issues.apache.org/jira/browse/HIVE-3994&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;异常3，以下语句没反应
&lt;code&gt;
select count(*) from hive_userinfo
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;异常4&lt;/p&gt;

&lt;p&gt;zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(966)) - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (无法定位登录配置)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：hive中没有设置zk&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;异常5&lt;/p&gt;

&lt;p&gt;hbase 中提示：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：cloudera hadoop lib中没有hadoop的native jar&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;异常6&lt;/p&gt;

&lt;p&gt;Exception in thread &amp;quot;main&amp;quot; java.lang.NoClassDefFoundError: org/apache/hadoop/mapreduce/v2/app/MRAppMaster&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原因：classpath没有配置正确，检查环境变量以及yarn的classpath&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://kicklinux.com/hive-deploy/&quot;&gt;Hive安装与配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ccp.cloudera.com/display/CDH4DOC/Hive+Installation&quot;&gt;Hive Installation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>手动安装Cloudera HBase CDH</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH"/>
   <updated>2013-03-24T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH</id>
   <content type="html">&lt;p&gt;本文主要记录手动安装cloudera HBase cdh4.2.0集群过程，环境设置及Hadoop安装过程见上篇文章。&lt;/p&gt;

&lt;h1&gt;安装HBase&lt;/h1&gt;

&lt;p&gt;HBase安装在desktop3、desktop4、desktop6、desktop7、desktop8机器上。&lt;/p&gt;

&lt;p&gt;上传hbase-0.94.2-cdh4.2.0.zip到desktop3上的/opt目录，先在desktop3上修改好配置文件，在同步到其他机器上。&lt;/p&gt;

&lt;p&gt;hbase-site.xml内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://desktop1/hbase-${user.name}&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/hbase-${user.name}&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop3,desktop4,desktop6,desktop7,desktop8&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;regionservers内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;desktop3
desktop4
desktop6
desktop7
desktop8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;环境变量&lt;/h1&gt;

&lt;p&gt;参考hadoop中环境变量的设置&lt;/p&gt;

&lt;p&gt;然后，同步文件到其他4台机器上，可以在desktop3上配置无密码登陆到其他机器，然后在desktop3上启动hbase，这样其他节点上hbase都可以启动，否则，需要每台机器上单独启动hbase&lt;/p&gt;

&lt;h1&gt;启动脚本&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;#start-hbase.sh 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>手动安装Cloudera Hadoop CDH</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH"/>
   <updated>2013-03-24T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH</id>
   <content type="html">&lt;h1&gt;安装版本&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hadoop-2.0.0-cdh4.2.0
hbase-0.94.2-cdh4.2.0
hive-0.10.0-cdh4.2.0
jdk1.6.0_38
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;安装前说明&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;安装目录为/opt&lt;/li&gt;
&lt;li&gt;检查hosts文件&lt;/li&gt;
&lt;li&gt;关闭防火墙&lt;/li&gt;
&lt;li&gt;设置时钟同步&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;使用说明&lt;/h1&gt;

&lt;p&gt;安装hadoop、hbase、hive成功之后启动方式为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动dfs和mapreduce: desktop1上执行start-dfs.sh和start-yarn.sh&lt;/li&gt;
&lt;li&gt;启动hbase: desktop3上执行start-hbase.xml&lt;/li&gt;
&lt;li&gt;启动hive: desktop1上执行hive&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;规划&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    192.168.0.1             NameNode、Hive、ResourceManager
    192.168.0.2             SSNameNode
    192.168.0.3             DataNode、HBase、NodeManager
    192.168.0.4             DataNode、HBase、NodeManager
    192.168.0.6             DataNode、HBase、NodeManager
    192.168.0.7             DataNode、HBase、NodeManager
    192.168.0.8             DataNode、HBase、NodeManager
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;部署过程&lt;/h1&gt;

&lt;h2&gt;系统和网络配置&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;修改每台机器的名称&lt;/p&gt;

&lt;p&gt;[root@desktop1 ~]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=desktop1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在各个节点上修改/etc/hosts增加以下内容:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    [root@desktop1 ~]# cat /etc/hosts
    127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
    192.168.0.1     desktop1
    192.168.0.2     desktop2
    192.168.0.3     desktop3
    192.168.0.4     desktop4
    192.168.0.6     desktop6
    192.168.0.7     desktop7
    192.168.0.8     desktop8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;配置ssh无密码登陆
以下是设置desktop1上可以无密码登陆到其他机器上。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    [root@desktop1 ~]# ssh-keygen
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop2
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop3
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop4
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop6
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop7
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;每台机器上关闭防火墙：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    [root@desktop1 ~]# service iptables stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;安装Hadoop&lt;/h1&gt;

&lt;h2&gt;配置Hadoop&lt;/h2&gt;

&lt;p&gt;将jdk1.6.0_38.zip上传到/opt，并解压缩。
将hadoop-2.0.0-cdh4.2.0.zip上传到/opt，并解压缩。&lt;/p&gt;

&lt;p&gt;在NameNode上配置以下文件：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;core-site.xml fs.defaultFS指定NameNode文件系统，开启回收站功能。
hdfs-site.xml 
    dfs.namenode.name.dir指定NameNode存储meta和editlog的目录，
    dfs.datanode.data.dir指定DataNode存储blocks的目录，
    dfs.namenode.secondary.http-address指定Secondary NameNode地址。
    开启WebHDFS。
slaves 添加DataNode节点主机
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;core-site.xml
该文件指定fs.defaultFS连接desktop1，即NameNode节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]# pwd
/opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop
[root@desktop1 hadoop]# cat core-site.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;!--fs.default.name for MRV1 ,fs.defaultFS for MRV2(yarn) --&amp;gt;
&amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
         &amp;lt;!--这个地方的值要和hdfs-site.xml文件中的dfs.federation.nameservices一致--&amp;gt;
     &amp;lt;value&amp;gt;hdfs://desktop1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;fs.trash.interval&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;10080&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;fs.trash.checkpoint.interval&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;10080&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;hdfs-site.xml
该文件主要设置数据副本保存份数，以及namenode、datanode数据保存路径以及http-address。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]# cat hdfs-site.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/hadoop-${user.name}&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.namenode.http-address&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;desktop1:50070&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;desktop2:50090&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;masters
设置namenode和secondary namenode节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]# cat masters 
desktop1
desktop2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;slaves
设置哪些机器上安装datanode节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]# cat slaves 
desktop3
desktop4
desktop6
desktop7
desktop8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;配置MapReduce&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;mapred-site.xml
配置使用yarn计算框架，以及jobhistory的地址。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]# cat mapred-site.xml
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&amp;quot;text/xsl&amp;quot; href=&amp;quot;configuration.xsl&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;desktop1:10020&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;desktop1:19888&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;yarn-site.xml
主要配置resourcemanager地址以及&lt;code&gt;yarn.application.classpath&lt;/code&gt;（这个路径很重要，要不然集成hive时候会提示找不到class）&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]# cat yarn-site.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.resource-tracker.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8031&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8032&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8030&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.admin.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8033&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8088&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;description&amp;gt;Classpath for typical applications.&amp;lt;/description&amp;gt;
    &amp;lt;name&amp;gt;yarn.application.classpath&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,
    $HADOOP_COMMON_HOME/share/hadoop/common/lib/*,
    $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,
    $YARN_HOME/share/hadoop/yarn/*,$YARN_HOME/share/hadoop/yarn/lib/*,
    $YARN_HOME/share/hadoop/mapreduce/*,$YARN_HOME/share/hadoop/mapreduce/lib/*&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;mapreduce.shuffle&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.local-dirs&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/yarn/local&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.log-dirs&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/yarn/logs&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;description&amp;gt;Where to aggregate logs&amp;lt;/description&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.remote-app-log-dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/yarn/logs&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.app.mapreduce.am.staging-dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/user&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;同步配置文件&lt;/h2&gt;

&lt;p&gt;修改.bashrc环境变量，并将其同步到其他几台机器，并且source .bashrc&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 ~] # cat .bashrc 
# .bashrc
alias rm=&amp;#39;rm -i&amp;#39;
alias cp=&amp;#39;cp -i&amp;#39;
alias mv=&amp;#39;mv -i&amp;#39;
# Source global definitions
if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi
# User specific environment and startup programs
export LANG=zh_CN.utf8
export JAVA_HOME=/opt/jdk1.6.0_38
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=./:$JAVA_HOME/lib:$JRE_HOME/lib:$JRE_HOME/lib/tools.jar
export HADOOP_HOME=/opt/hadoop-2.0.0-cdh4.2.0
export HIVE_HOME=/opt/hive-0.10.0-cdh4.2.0
export HBASE_HOME=/opt/hbase-0.94.2-cdh4.2.0
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export HADOOP_YARN_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/bin:$HIVE_HOME/bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改配置文件之后，使其生效。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 ~]# source .bashrc 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将desktop1上的/opt/hadoop-2.0.0-cdh4.2.0拷贝到其他机器上&lt;/p&gt;

&lt;h2&gt;启动脚本&lt;/h2&gt;

&lt;p&gt;第一次启动hadoop需要先格式化NameNode，该操作只做一次。当修改了配置文件时，需要重新格式化&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]hadoop namenode -format
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在desktop1上启动hdfs：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]#start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在desktop1上启动mapreduce：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]#start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在desktop1上启动historyserver：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 hadoop]#mr-jobhistory-daemon.sh start historyserver
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看MapReduce：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;http://desktop1:8088/cluster
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看节点：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;http://desktop2:8042/
http://desktop2:8042/node
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;检查集群进程&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[root@desktop1 ~]# jps
5389 NameNode
5980 Jps
5710 ResourceManager
7032 JobHistoryServer
[root@desktop2 ~]# jps
3187 Jps
3124 SecondaryNameNode
[root@desktop3 ~]# jps
3187 Jps
3124 DataNode
5711 NodeManager
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>【笔记】Hadoop安装部署</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/08/note-about-installing-hadoop-cluster"/>
   <updated>2013-03-08T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/08/note-about-installing-hadoop-cluster</id>
   <content type="html">&lt;h1&gt;安装虚拟机&lt;/h1&gt;

&lt;p&gt;VirtualBox安装rhel6.3，存储为30G，内存为1G，并复制2份&lt;/p&gt;

&lt;h1&gt;配置网络&lt;/h1&gt;

&lt;p&gt;a. VirtualBox全局设定-网络中添加一个新的连接：vboxnet0&lt;/p&gt;

&lt;p&gt;b. 设置每一个虚拟机的网络为Host-Only&lt;/p&gt;

&lt;p&gt;c.分别修改每个虚拟机的ip，DHCP或手动设置&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;vim /etc/sysconfig/network-scripts/ifcfg-eth0
vim /etc/udev/rules.d/70-persistent-net.rules  #删掉第一个，修改第二个名字为eth0
start_udev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;d.修改主机名&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;vim /etc/sysconfig/network
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;e.每个虚拟机中修改hosts：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;192.168.56.100 rhel-june
192.168.56.101 rhel-june-1
192.168.56.102 rhel-june-2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最后机器列表为：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;rhel-june:   192.168.56.100
rhel-june-1: 192.168.56.101
rhel-june-2: 192.168.56.102
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;机群规划&lt;/h1&gt;

&lt;p&gt;版本：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hadoop:1.1.1
JDK:1.6.0_38
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;集群各节点：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;NameNode:192.168.56.100
NameSecondary:192.168.56.100
DataNode:192.168.56.101
DataNode:192.168.56.102
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;安装过程&lt;/h1&gt;

&lt;p&gt;a.解压缩到/opt&lt;/p&gt;

&lt;p&gt;b.设置配置文件：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;core-site.xml
hdfs-site.sml
mapred-site.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;c.设置master、slaves&lt;/p&gt;

&lt;p&gt;d.设置环境变量&lt;/p&gt;

&lt;p&gt;方便执行java命令及hadoop命令. 使用root登录，vi ~/.bash_profile 追加下列信息&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export JAVA_HOME=/opt/jdk1.6.0_38
export HADOOP_INSTALL=/opt/hadoop-1.1.1
export PATH=$PATH:$HADOOP_INSTALL/bin:$JAVA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;e.修改hadoop脚本中&lt;code&gt;JAVA_HOME&lt;/code&gt;：/opt/hadoop-1.1.1/conf/hadoop-env.sh&lt;/p&gt;

&lt;p&gt;f.格式化namenode&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;hadoop namenode -format
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;g.启动hdfs集群&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;sh /opt/hadoop-1.1.1/bin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;h.查看节点进程&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;jps
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;查看状态&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;http://rhel-june:50030/
http://rhel-june:50070/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>2012年度总结</title>
   <link href="http://blog.javachen.com/work/2013/02/20/summary-of-the-work-in-2012"/>
   <updated>2013-02-20T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/work/2013/02/20/summary-of-the-work-in-2012</id>
   <content type="html">&lt;p&gt;2012年是在公司工作的第二年，在总结2012年的得与失的时候，有必要和《2011的度年终总结》相比较，在比较中审视自己在2012年是否有改进2011年存在的不足、是否有实现2011年定下的2012年工作计划。
以下是2012年相对于2011年的一些变化。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; 2011年，在调研云计算产品过程中，深刻的意识到自身在linux方面存在的不足；2012年，熟悉了基本的linux命令，能够读懂并编写简单shell脚本；&lt;/li&gt;
&lt;li&gt;  2011年，工作环境是win7+fedora；2012年，一直使用fedora操作系统工作、编码；&lt;/li&gt;
&lt;li&gt;  2011年，较多的时间花在编写代码、完成开发任务上；2012年，更多的时间花在学习架构的设计、系统的运维、项目的管理上，视野不再局限于开发、精力不再局限于编码。&lt;/li&gt;
&lt;li&gt;  2011年，在工作中没有及时提交项目周报，没有及时的跟踪、检查分配下去的任务完成情况，对新人的指导不够；2012年，没有写过项目周报，做到了及是跟踪、检查分配下去的任务完成情况；&lt;/li&gt;
&lt;li&gt;  2011年，博客文章篇数较少，平时的总结与分享不够积极；2012年，很少有时间写技术方面的博客；&lt;/li&gt;
&lt;li&gt;  2011年，在与客户的交流中底气不足、表达能力不够；2012年，还是发现自己与客户交流中胆怯、没有底气；&lt;/li&gt;
&lt;li&gt;  2011年，希望能够将Pentaho的咨询服务工作更多交给其他人完成；2012年，发现大部分的工作还是落在自己身上一个人去完成，没有发挥其他人员的作用；&lt;/li&gt;
&lt;li&gt;  2011年，希望2012年能够深入理解Spring、Jboss、Pentaho、缓存、云计算、架构等技术；2012年，了解gemfire、infinispan、jboss cache、cassandra等分布式缓存的实现及原理，但每一个方面都没有时间去深入研究和学习；&lt;/li&gt;
&lt;li&gt;  2011年，公司在代码复查方面做的不够；2012年，这方面还是做的不够；&lt;/li&gt;
&lt;li&gt;  2011年，项目开发方面没有形成一套成型的开发框架；2012年，还是没有看到一个成熟、易用、简单的开发框架以及相配套开发文档；&lt;/li&gt;
&lt;li&gt;  2011年，项目于项目之间在一些同时使用的相关技术上面的沟通于交流做的不够；2012年，团队在项目上还是缺少沟通交流，尤其体现在XXXX项目网站开发上。&lt;/li&gt;
&lt;li&gt;  2011年，花了一些时间在Pentaho上，并希望2012年能够创建一个Pentaho社区、一个QQ分享群；2012年，Pentaho方面基本上没有投入；&lt;/li&gt;
&lt;li&gt;  2011年，编写文档时候，没有可参考的模版，导致文档编写不规范；2012年，每次写文档时都要去找文档模版；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2012年参与了XXXXX项目、cassandra项目，。。。。。。此处省略314.15926个字。&lt;/p&gt;

&lt;p&gt;2012年，公司也存在一些不足：上级对下级、项目经理对团队人员了解不足，不知道其工作上、生活上的内心想法以及遇到何种困难；多数情况下，团队自我要求低，积极性不高，没有生机与活力；对新人能力审核不够，对新人培养不够重视，对新人的存在感不够关注；在各个项目的人员安排及使用上、任务分配和工作计划上不合理，导致经常被动加班、熬夜等等。&lt;/p&gt;

&lt;h3&gt;2013年工作计划：&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;通过CE考试，熟练掌握shell编程；&lt;/li&gt;
&lt;li&gt;做好项目管理者的角色，培养新人，提高团队人员编码、处理问题的能力；&lt;/li&gt;
&lt;li&gt;深入理解、学习cassandra源码、原理以及cassandra的运维；&lt;/li&gt;
&lt;li&gt;学习hadoop的安装、部署、原理、开发及运维，掌握kettle和nosql的集成，希望积累几个hadoop项目经验；&lt;/li&gt;
&lt;li&gt;学习分布式缓存理论知识，阅读源代码，完善缓存系统的监控及运维&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在经历了2011年和2012年之后，2013年希望自己能够专注细节，深入理解，在技术、管理、交际方面有所成长；希望公司能够重视对团队的培养，能够规范各种规章制度，能够更上一层楼！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>使用Octopress将博客从wordpress迁移到GitHub上</title>
   <link href="http://blog.javachen.com/work/2012/06/03/migrate-blog-form-wordpress-to-github-with-octopress"/>
   <updated>2012-06-03T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/work/2012/06/03/migrate-blog-form-wordpress-to-github-with-octopress</id>
   <content type="html">&lt;h1&gt;Step1 - 在本机安装Octopress&lt;/h1&gt;

&lt;p&gt;首先，必须先在本机安装配置&lt;a href=&quot;http://git-scm.com/&quot;&gt;Git&lt;/a&gt;和&lt;a href=&quot;https://rvm.beginrescueend.com/rvm/install/&quot;&gt;Ruby&lt;/a&gt;,Octopress需要Ruby版本至少为1.9.2。你可以使用&lt;a href=&quot;http://rvm.beginrescueend.com/&quot;&gt;RVM&lt;/a&gt;或&lt;a href=&quot;https://github.com/sstephenson/rbenv&quot;&gt;rbenv&lt;/a&gt;安装ruby，安装方法见Octopress官方文档：&lt;a href=&quot;http://octopress.org/docs/setup/&quot;&gt;http://octopress.org/docs/setup/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我使用rvm安装：
    rvm install 1.9.2 &amp;amp;&amp;amp; rvm use 1.9.2
安装完之后可以查看ruby版本：
    ruby --version
结果为：
    ruby 1.9.2p320 (2012-04-20 revision 35421) [x86_64-linux]&lt;/p&gt;

&lt;p&gt;然后需要从github下载Octopress：
    git clone git://github.com/imathis/octopress.git octopress&lt;/p&gt;

&lt;p&gt;因为我fork了Octopress，并在配置文件上做了一些修改，故我从我的仓库地址下载Octopress，命令如下：
    git clone git@github.com:javachen/octopress.git
运行上面的代码后，你会看到：
    Cloning into &amp;#39;octopress&amp;#39;...
    remote: Counting objects: 6579, done.
    remote: Compressing objects: 100% (2361/2361), done.
    remote: Total 6579 (delta 3773), reused 6193 (delta 3610)
    Receiving objects: 100% (6579/6579), 1.34 MiB | 35 KiB/s, done.
    Resolving deltas: 100% (3773/3773), done.&lt;/p&gt;

&lt;p&gt;接下来进入octopress：
    cd octopress&lt;/p&gt;

&lt;p&gt;接下来安装依赖：
    gem install bundler
    rbenv rehash    # If you use rbenv, rehash to be able to run the bundle command
    bundle install&lt;/p&gt;

&lt;p&gt;安装Octopress默认的主题：
    rake install&lt;/p&gt;

&lt;p&gt;你也可以安装自定义的主题，blog为主题名称：
    rake install[&amp;#39;blog&amp;#39;]&lt;/p&gt;

&lt;p&gt;至此，Octopress所需的环境已经搭建成功。&lt;/p&gt;

&lt;h1&gt;Step2 - 连接GitHub Pages&lt;/h1&gt;

&lt;p&gt;首先，你得有一个GitHub的帐号，并且已经创建了一个新的Repository。如果你准备用自己的域名的话，Repository的名称可以随便取，不过正常人在正常情况下，一般都是以域名取名的。如果你没有自己的域名，GitHub是提供二级域名使用的，但是你得把Repository取名为&lt;code&gt;你的帐号.github.com&lt;/code&gt;，并且，部署的时候会占用你的master分支。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Tips：&lt;/em&gt;
如果用自己的一级域名，记得把source/CNAME文件内的域名改成你的一级域名，还有在dns管理中把域名的A Record指向IP：207.97.227.245；
如果用自己的二级域名，记得把source/CNAME文件内的域名改成你的二级域名，还有在dns管理中把域名的CNAME Record指向网址：charlie.github.com；
    echo &amp;#39;your-domain.com&amp;#39; &amp;gt;&amp;gt; source/CNAME
如果用GitHub提供的二级域名，记得把source/CNAME删掉。&lt;/p&gt;

&lt;p&gt;完成上述准备工作后，运行：
    rake setup&lt;em&gt;github&lt;/em&gt;pages
它会提示你输入有读写权限的Repository Url，这个在GitHub上可以找到。Url形如：https://github.com/javachen/javachen.github.com.git，javachen.github.com是我的Repository的名称。&lt;/p&gt;

&lt;h1&gt;Step3 - 配置你的博客&lt;/h1&gt;

&lt;p&gt;需要配置博客url、名称、作者、rss等信息。
    url: http://javachen.github.com
    title: JavaChen on Java
    subtitle: Just some random thoughts about technology,Java and life.
    author: javachen
    simple_search: http://google.com/search
    description:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;date_format: &amp;quot;%Y年%m月%d日&amp;quot;

subscribe_rss: /atom.xml
subscribe_email:
email:

# 如果你使用的是一个子目录，如http://site.com/project，则设置为&amp;#39;root: /project&amp;#39;
root: /
# 文章标题格式
permalink: /:year/:month/:day/:title/
source: source
destination: public
plugins: plugins
code_dir: downloads/code
# 分类存放路径
category_dir: categories
markdown: rdiscount
pygments: false # default python pygments have been replaced by pygments.rb
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Step4 - 部署&lt;/h1&gt;

&lt;p&gt;先把整个项目静态化，然后再部署到GitHub：
    rake generate
    rake deploy
当你看到“Github Pages deploy complete”后，就表示你大功已成。Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Tips：&lt;/em&gt;
Octopress提供的所有rake方法，可以运行&lt;code&gt;rake -T&lt;/code&gt;查看。
如果在执行上述命令中ruby报错，则需要一一修复错误，这一步是没有接触过ruby的人比较苦恼的。&lt;/p&gt;

&lt;h1&gt;Step5 - 从Wordpress迁移到Octopress&lt;/h1&gt;

&lt;h2&gt;备份&lt;/h2&gt;

&lt;h3&gt;备份评论内容&lt;/h3&gt;

&lt;p&gt;Octopress由于是纯静态，所以没有办法存储用户评论了，我们可以使用DISQUS提供的“云评论”服务。首先安装DISQUS的WordPress插件，在插件设置中我们可以将现有的评论内容导入到DISQUS中。DISQUS处理导入数据的时间比较长，往往需要24小时甚至以上的时间。&lt;/p&gt;

&lt;h3&gt;备份文章内容&lt;/h3&gt;

&lt;p&gt;在WordPress后台我们可以将整站数据备份成一个.xml文件下载下来。同时，我原先文章中的图片都是直接在Wordpress后台上传的，所以要把服务器上&lt;code&gt;wp-content/uploads&lt;/code&gt;下的所有文件备份下来。&lt;/p&gt;

&lt;h2&gt;迁移&lt;/h2&gt;

&lt;h3&gt;迁移文章&lt;/h3&gt;

&lt;p&gt;jekyll本身提供了一个从WordPress迁移文章的工具，不过对中文实在是不太友好。这里我使用了YORKXIN的修改版本。将上面备份的wordpress.xml放到Octopress根目录，把脚本放到新建的utils目录中，然后运行：
    ruby -r &amp;quot;./utils/wordpressdotcom.rb&amp;quot; -e &amp;quot;Jekyll::WordpressDotCom.process&amp;quot;
于是转换好的文章都放进source目录了。&lt;/p&gt;

&lt;h3&gt;迁移URL&lt;/h3&gt;

&lt;p&gt;迁移URL，便是要保证以前的文章链接能够自动重定向到新的链接上。这样既能保证搜索引擎的索引不受影响，也是一项对读者负责任的行为是吧。不过这是一项挺麻烦的事情。&lt;/p&gt;

&lt;p&gt;幸好我当初建立WordPress的时候就留下了后路。原先网站的链接是这样的：
    http://XXXXXXXXX.com/[year]/[month]/[the-long-long-title].html
    http://XXXXXXXXX.com/page/xx/
    http://XXXXXXXXX.com/category/[category-name]/
这样的格式是比较容易迁移的。如果原先的文章URL是带有数字ID的话，只能说声抱歉了。到&lt;em&gt;config.yml里面设置一下新站点的文章链接格式，跟原先的格式保持一致：
    permalink: /:year/:month/:title/
    category&lt;/em&gt;dir: category
    pagination_dir:  # 留空&lt;/p&gt;

&lt;h3&gt;迁移评论&lt;/h3&gt;

&lt;p&gt;既然做好了301，那么迁移评论就显得非常简单了。登录DISQUS后台，进入站点管理后台的“Migrate Threads”栏目，那里有一个“Redirect Crawler”的功能，便是自动跟随301重定向，将评论指向新的网址。点一下那个按钮就大功告成。&lt;/p&gt;

&lt;h3&gt;迁移图片&lt;/h3&gt;

&lt;p&gt;可以参考&lt;a href=&quot;http://log4d.com/2012/05/image-host/&quot;&gt;使用独立图床子域名&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;Step6 - 再次部署&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;rake generate
rake deploy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Octopress Setup： http://octopress.org/docs/setup/&lt;/li&gt;
&lt;li&gt;Octopress Deploying：http://octopress.org/docs/deploying/&lt;/li&gt;
&lt;li&gt;Blog = GitHub + Octopress：http://mrzhang.me/blog/blog-equals-github-plus-octopress.html&lt;/li&gt;
&lt;li&gt;从Wordpress迁移到Octopress：http://blog.dayanjia.com/2012/04/migration-to-octopress-from-wordpress/&lt;/li&gt;
&lt;li&gt;使用独立图床子域名：http://log4d.com/2012/05/image-host/ http://log4d.com/2012/05/image-host/&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Kettle dependency management</title>
   <link href="http://blog.javachen.com/kettle/2012/04/13/kettle-dependency-management"/>
   <updated>2012-04-13T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/04/13/kettle-dependency-management</id>
   <content type="html">&lt;p&gt;pentaho的项目使用了ant和ivy解决项目依赖,所以必须编译源码需要ivy工具.直接使用ivy编译pentaho的bi server项目,一直没有编译成功.&lt;br /&gt;
使用ivy编译kettle的源代码却是非常容易的事情.&lt;/p&gt;

&lt;p&gt;该篇文章翻译并参考了Will Gorman在pentaho的wiki上添加的&lt;a href=&quot;http://wiki.pentaho.com/display/EAI/Kettle+dependency+management&quot; target=&quot;_blank&quot;&gt;Kettle dependency management&lt;/a&gt;,文章标题没作修改.&lt;br /&gt;
编写此文,是为了记录编译kettle源码的方法和过程.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;以下是对原文的一个简单翻译.&lt;/strong&gt;
将kettle作为一个产品发行是一个很有趣的事情.有很多来自于pentaho其他项目(其中有一些有依赖于kettle)的jar包被导入到kettle.这些jar包必须在发行的时候构建并且加入到kettle中.如果一个核心的库被更新了,我们必须将其导入到kettle中(如果有必要).bi服务器,pentaho报表以及pentaho元数据编辑器都将kettle作为一个服务/引擎资源而被构建的.自从我们已经将这些jar导入到我们的源码仓库,这些项目必须使用ivy明确列出kettle以及他的依赖.当kettle的依赖变化的时候,我们必须审查libext文件是否需要更新.&lt;/p&gt;

&lt;p&gt;pentaho创建了一系列的脚本来自动化的安装ivy,解决jar(或者是artifacts),构建并发行artifacts.kettle已经升级使用subfloor(简单的意味着build.xml继承自subfloor的构建脚本).subfloor使用ivy从pentaho仓库()或者ibiblio maven2仓库来获取跟新jar.ibiblio仓库用于大多数第三方的jar文件(如apache-commons).pentaho仓库用于在线的pentaho项目或者一些比在ibiblio的三方库.为了解决kettle的依赖,我们不得不在ivy.xml里创建一个清单.这个文件明确地列出每一个没有传递依赖的jar文件.这意味着libext文件的映射在ivy.xml中是一对一的.
&lt;!--more--&gt;
&lt;strong&gt;关于Ivy&lt;/strong&gt;
&lt;a href=&quot;http://ant.apache.org/ivy/&quot; target=&quot;_blank&quot;&gt;Apache Ivy™&lt;/a&gt;是一个流行的致力于灵活性和简单性的依赖管理工具.更多的参考:&lt;a href=&quot;http://ant.apache.org/ivy/features.html&quot; target=&quot;_blank&quot;&gt;enterprise features&lt;/a&gt;, &lt;a href=&quot;http://ant.apache.org/ivy/testimonials.html&quot; target=&quot;_blank&quot;&gt;what people say about it&lt;/a&gt;, 以及 &lt;a href=&quot;http://ant.apache.org/ivy/history/latest-milestone/index.html&quot; target=&quot;_blank&quot;&gt;how it can improve your build system&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在kettle中使用ivyIDE&lt;/strong&gt;
首先,从svn上下载kettle的源代码:
&lt;pre&gt;
svn://source.pentaho.org/svnkettleroot/Kettle/trunk
&lt;/pre&gt;
如果你想在Eclipse上使用&lt;a href=&quot;http://ant.apache.org/ivy/ivyde/download.cgi&quot; target=&quot;_blank&quot;&gt;ivyde plugin&lt;/a&gt;.&lt;br /&gt;
请参考相关文章安装该插件.&lt;/p&gt;

&lt;p&gt;如果你不想使用ivyde,你可以简单快速并且容易的开始并编译代码.&lt;br /&gt;
1.执行&lt;code&gt;ant resolve&lt;/code&gt;,这个命令将会创建一个叫做resolved-libs的文件夹.&lt;br /&gt;
2.使用下面命令更新classpath &lt;br /&gt;
  a.手动的添加这些jar文件到你的ide的classpath&lt;br /&gt;
  b.执行ant create-dot-classpath,将会修改你的.classpath文件(注意刷新项目以使改变生效)&lt;br /&gt;
注意:kettle项目中的构建脚本会自动安装ivy插件.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;构建Kettle&lt;/strong&gt;
你可以下载kettle源代码然后立即执行&lt;code&gt;ant distrib&lt;/code&gt;命令&lt;br /&gt;
或者你可以在ide中导入下载的kettle工程,然后按照你的操作系统(默认的是Windows 32-bit)版本修改依赖的swt.jar文件.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ivy中未完成的&lt;/strong&gt;
&lt;strong&gt;pentaho-database-&lt;/strong&gt;这是一个依赖kettle-db的常用项目,但又被kettle-ui使用.这样会导致循环依赖,将来可能会将其引入到kettle项目或是从该项目中去掉对kettle的依赖.
&lt;strong&gt;swt-&lt;/strong&gt;swt文件目前没有包括在ivy.xml文件中
&lt;strong&gt;library configurations-&lt;/strong&gt;每一个kettle库(kettle-db,kettle-core等等)应该在ivy.xml中有他自己的依赖.这些库应该继承一些特定的依赖,而取代继承整个kettle依赖.
&lt;strong&gt;checked-in plugins-&lt;/strong&gt;当前引入的插件如;DummyJob, DummyPlugin, S3CsvInput, ShapeFileReader3,versioncheck应该都移到ivy的plugin配置中.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;
&lt;a href=&quot;http://wiki.pentaho.com/display/EAI/Kettle+dependency+management&quot; target=&quot;_blank&quot;&gt;Kettle dependency management&lt;/a&gt;
&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Getting Started Using the Cassandra CLI</title>
   <link href="http://blog.javachen.com/cassandra/2012/04/09/getting-started-using-the-cassandra-cli"/>
   <updated>2012-04-09T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cassandra/2012/04/09/getting-started-using-the-cassandra-cli</id>
   <content type="html">&lt;p&gt;这仅仅是一个Cassandra CLI使用方法的清单。&lt;/p&gt;

&lt;p&gt;Cassandra CLI 客户端用于处理集群中基本的数据定义（DDL）和数据维护（DML）。其处于&lt;code&gt;/usr/bin/cassandra-cli&lt;/code&gt;，如果是试用包安装，或者是&lt;code&gt;$CASSANDRA_HOME/bin/cassandra-cli&lt;/code&gt;，如果使用二进制文件安装。&lt;/p&gt;

&lt;h1&gt;Starting the CLI&lt;/h1&gt;

&lt;p&gt;使用&lt;code&gt;cassandra-cli&lt;/code&gt; &lt;code&gt;-host&lt;/code&gt; &lt;code&gt;-port&lt;/code&gt; 命令启动 Cassandra CLI，他将会连接&lt;code&gt;cassandra.yaml&lt;/code&gt;文件中定义的集群名称，默认为“&lt;em&gt;Test Cluster&lt;/em&gt;”。
如果你有一个但节点的集群，则使用以下命令：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cassandra-cli -host localhost -port 9160
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果想连接多节点集群中的一个节点，可以使用以下命令:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cassandra-cli -host 110.123.4.5 -port 9160
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;或者，可以直接执行以下命令：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cassandra-cli
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;登录成功之后，可以看到：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;Welcome to cassandra CLI.
Type &amp;#39;help;&amp;#39; or &amp;#39;?&amp;#39; for help. Type &amp;#39;quit;&amp;#39; or &amp;#39;exit;&amp;#39; to quit.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你必须指定连接一个节点：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown]connect localhost/9160;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Creating a Keyspace&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown] CREATE KEYSPACE demo;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面的一个例子，创建一个叫demo的Keyspace,并且复制因子为1，使用&lt;code&gt;SimpleStrategy&lt;/code&gt;复制替换策略。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown] CREATE KEYSPACE demo with 
    placement_strategy =&amp;#39;org.apache.cassandra.locator.SimpleStrategy&amp;#39; 
    and strategy_options = [{replication_factor:1}];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以使用&lt;code&gt;SHOW KEYSPACES&lt;/code&gt;来查看所有系统的和你创建的Keyspace&lt;/p&gt;

&lt;h1&gt;Use a keyspace&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown] USE demo;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Creating a Column Family&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] CREATE COLUMN FAMILY users
WITH comparator = UTF8Type
AND key_validation_class=UTF8Type
AND column_metadata = [
{column_name: full_name, validation_class: UTF8Type}
{column_name: email, validation_class: UTF8Type}
{column_name: state, validation_class: UTF8Type}
{column_name: gender, validation_class: UTF8Type}
{column_name: birth_year, validation_class: LongType}
];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我们使用demo keyspace创建了一个column family，其名称为users，并包括5个静态列：full&lt;em&gt;name，email,state,gender,birth&lt;/em&gt;year.comparator, key&lt;em&gt;validation&lt;/em&gt;class和validation&lt;em&gt;class，用于设置；列名称，行key的值，列值的编码。comparator还定义了列名称的排序方式。
下面命令创建一个名称为 blog&lt;/em&gt;entry的动态column family，我们不需要定义列，而由应用程序稍后定义。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] CREATE COLUMN FAMILY blog_entry WITH comparator = TimeUUIDType AND key_validation_class=UTF8Type AND default_validation_class = UTF8Type;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Creating a Counter Column Family&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] CREATE COLUMN FAMILY page_view_counts WITH 
      default_validation_class=CounterColumnType 
      AND key_validation_class=UTF8Type AND comparator=UTF8Type;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;插入一行和计数列：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] INCR page_view_counts[&amp;#39;www.datastax.com&amp;#39;][home] BY 0;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;增加计数：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] INCR page_view_counts[&amp;#39;www.datastax.com&amp;#39;][home] BY 1;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Inserting Rows and Columns&lt;/h1&gt;

&lt;p&gt;以下命令以一个特点的行key值插入列到users中&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] SET users[&amp;#39;bobbyjo&amp;#39;][&amp;#39;full_name&amp;#39;]=&amp;#39;Robert Jones&amp;#39;;
[default@demo] SET users[&amp;#39;bobbyjo&amp;#39;][&amp;#39;email&amp;#39;]=&amp;#39;bobjones@gmail.com&amp;#39;;
[default@demo] SET users[&amp;#39;bobbyjo&amp;#39;][&amp;#39;state&amp;#39;]=&amp;#39;TX&amp;#39;;
[default@demo] SET users[&amp;#39;bobbyjo&amp;#39;][&amp;#39;gender&amp;#39;]=&amp;#39;M&amp;#39;;
[default@demo] SET users[&amp;#39;bobbyjo&amp;#39;][&amp;#39;birth_year&amp;#39;]=&amp;#39;1975&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;更新数据： &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;set users[&amp;#39;bobbyjo&amp;#39;][&amp;#39;full_name&amp;#39;] = &amp;#39;Jack&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;获取数据： &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;get users[&amp;#39;bobbyjo&amp;#39;];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;get命令用法参考：&lt;a href=&quot;http://wiki.apache.org/cassandra/API#get_slice&quot; target=&quot;_blank&quot;&gt;API#get_slice&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;查询数据： &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;get users where gender= &amp;#39;M&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面命令在 blog_entry中创建了一行，其行key为“yomama”，并指定了一列：timeuuid()的值为 &amp;#39;I love my new shoes!&amp;#39;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] SET blog_entry[&amp;#39;yomama&amp;#39;][timeuuid()] = &amp;#39;I love my new shoes!&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Reading Rows and Columns&lt;/h1&gt;

&lt;p&gt;使用List命令查询记录，默认查询100条记录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] LIST users;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Cassandra 默认以16进制数组的格式存储数据 为了返回可读的数据格式，可以指定编码：
&lt;li&gt;ascii&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;integer (a generic variable-length integer type)&lt;/li&gt;
&lt;li&gt;lexicalUUID&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;utf8&lt;/li&gt;
例如：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] GET users[utf8(&amp;#39;bobby&amp;#39;)][utf8(&amp;#39;full_name&amp;#39;)];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你也可以使用&lt;code&gt;ASSUME&lt;/code&gt;命令指定编码，例如，指定行key，行名称，行值显示ascii码格式：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] ASSUME users KEYS AS ascii;
[default@demo] ASSUME users COMPARATOR AS ascii;
[default@demo] ASSUME users VALIDATOR AS ascii;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Setting an Expiring Column&lt;/h1&gt;

&lt;p&gt;例如，假设我们正在跟踪我们的用户，到期后10天的优惠券代码。我们可以定义coupon_code的列和设置该列的过期日期。例如：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] SET users[&amp;#39;bobbyjo&amp;#39;] [utf8(&amp;#39;coupon_code&amp;#39;)] = utf8(&amp;#39;SAVE20&amp;#39;) WITH ttl=864000;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;自该列被设置值之后，经过10天或864,000秒后，其值将被标记为删除，不再由读操作返回。然而，请注意，直到Cassandra的处理过程完成，该值才会从硬盘中删除。&lt;/p&gt;

&lt;h1&gt;Indexing a Column&lt;/h1&gt;

&lt;p&gt;给birth_year添加一个二级索引：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] UPDATE COLUMN FAMILY users 
        WITH comparator = UTF8Type AND column_metadata = 
        [{column_name: birth_year, validation_class: LongType, index_type: KEYS}];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于该列被索引了，所以可以直接通过该列查询：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] GET users WHERE birth_date = 1969;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Deleting Rows and Columns&lt;/h1&gt;

&lt;p&gt;删除yomama索引的coupon_code列：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] DEL users [&amp;#39;yomama&amp;#39;][&amp;#39;coupon_code&amp;#39;];
[default@demo] GET users [&amp;#39;yomama&amp;#39;];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;或者删除整行：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] DEL users [&amp;#39;yomama&amp;#39;];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Dropping Column Families and Keyspaces&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@demo] DROP COLUMN FAMILY users;
[default@demo] DROP KEYSPACE demo;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;For help&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown]help;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;查看某一个命令的详细说明：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown] help SET;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;To Quit&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;[default@unknown]quit;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;To Execute Script&lt;/h1&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;bin/cassandra-cli -host localhost -port 9160 -f script.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.datastax.com/docs/0.8/dml/using_cli&quot; target=&quot;_blank&quot;&gt;Getting Started Using the Cassandra CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.apache.org/cassandra/CassandraCli&quot; target=&quot;_blank&quot;&gt;CassandraCli&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>使用DataStax Community Edition安装Cassandra单节点</title>
   <link href="http://blog.javachen.com/cassandra/2012/04/06/install_singlenode-with-datastax-community-editio"/>
   <updated>2012-04-06T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cassandra/2012/04/06/install_singlenode-with-datastax-community-editio</id>
   <content type="html">&lt;p&gt;本文主要记录使用DataStax Community Edition安装Cassandra单节点的过程.配置单节点的Cassandra,是为了方便快速的了解学习Cassandra.&lt;/p&gt;

&lt;h1&gt;检查java环境&lt;/h1&gt;

&lt;p&gt;Cassandra由java编写,需要运行中jvm虚拟机之上.如果用于生产环境,则需要jre 1.6.0-19或更高版本.
&lt;h3&gt;1.检查是否安装java:&lt;/h3&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;java -version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你没有安装java,可以参考网上相关文章.这里主要记录在RHEL系统上安装jdk的方法.
&lt;h3&gt;2.安装jdk&lt;/h3&gt;
下载&lt;a href=&quot;http://www.oracle.com/technetwork/java/javase/downloads/index.html&quot; target=&quot;_blank&quot;&gt;Oracle JRE&lt;/a&gt;
1）修改执行权限:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cd /tmp
$ chmod a+x jre-6u25-linux-x64-rpm.bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2）解压执行RPM文件,例如:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ sudo ./jre-6u25-linux-x64-rpm.bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样JRE会安装在/usr/java/&lt;/p&gt;

&lt;p&gt;3）配置Oracle JRE取代OpenJDK JRE
可以使用alternatives命令添加一个链接到Oracle JRE.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ sudo alternatives --install /usr/bin/java java /usr/java/jre1.6.0_25/bin/java 20000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4）确认是否安装JRE&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ java -version
  java version &amp;quot;1.6.0_25&amp;quot;
  Java(TM) SE Runtime Environment (build 1.6.0_25-b06)
  Java HotSpot(TM) 64-Bit Server VM (build 20.0-b11, mixed mode)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果OpenJDK JRE仍然被使用,可以使用alternatives命令切换到Oracle JRE.例如:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ sudo alternatives --config java
There are 2 programs which provide &amp;#39;java&amp;#39;.

Selection      Command
-----------------------------------------------
   1           /usr/lib/jvm/jre-1.6.0-openjdk.x86_64/bin/java
*+ 2           /usr/java/jre1.6.0_25/bin/java
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;在Linux系统上安装DataStax Community二进制文件&lt;/h1&gt;

&lt;h3&gt;1.在用户目录创建一个目录,如datas&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cd $HOME
$ mkdir datas
$ cd datas
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;2.下载cassandra(必须的)和OpsCenter包(可选的)&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ wget http://downloads.datastax.com/community/dsc.tar.gz
$ wget http://downloads.datastax.com/community/opscenter.tar.gz
$ wget http://downloads.datastax.com/community/dsc-1.0.1-demo-bin.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;3.解压&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ tar -xzvf dsc.tar.gz
$ tar -xzvf opscenter.tar.gz
$ tar -xzvf dsc-1.0.1-demo-bin.tar.gz
$ rm *.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.设置环境变量&lt;/h3&gt;

&lt;p&gt;1)编辑 .bashrc &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;vi $HOME/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2)添加以下代码&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;export CASSANDRA_HOME=$HOME/datas/dsc_package_name
export DSCDEMO_HOME=$HOME/datas/dsc-1.0.1/demos/portfolio_manager
export OPSC_HOME=$HOME/datas/opscenter_package_name
export PATH=&amp;quot;$PATH:$CASSANDRA_HOME/bin:$DSCDEMO_HOME/bin:$OPSC_HOME/bin&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意替换&lt;font color=&quot;red&quot;&gt;dsc&lt;em&gt;package&lt;/em&gt;name&lt;/font&gt;和&lt;font color=&quot;red&quot;&gt;opscenter&lt;em&gt;package&lt;/em&gt;name&lt;/font&gt;
3)保存退出
4)使该文件生效&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;source $HOME/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;5.创建保存Cassandra数据的文件和日志目录&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ mkdir $HOME/datas/cassandra-data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;配置并启动单节点&lt;/h1&gt;

&lt;h3&gt;1.编辑配置环境&lt;/h3&gt;

&lt;p&gt;修改$CASSANDRA_HOME/conf/cassandra.yaml&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ sed -i -e &amp;quot;s,initial_token:,initial_token: 0,&amp;quot; \
  $CASSANDRA_HOME/conf/cassandra.yaml
$ sed -i -e &amp;quot;s,- /var/lib/cassandra/data,- $HOME/datastax/cassandra-data,&amp;quot; \
  $CASSANDRA_HOME/conf/cassandra.yaml
$ sed -i -e &amp;quot;s,saved_caches_directory: /var/lib/cassandra/saved_caches, \
  saved_caches_directory: $HOME/datastax/cassandra-data/saved_caches,&amp;quot; \
  $CASSANDRA_HOME/conf/cassandra.yaml
$ sed -i -e &amp;quot;s,commitlog_directory: /var/lib/cassandra/commitlog,commitlog_directory: \
  $HOME/datastax/cassandra-data/commitlog,&amp;quot; $CASSANDRA_HOME/conf/cassandra.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;2.设置日志文件位置&lt;/h3&gt; 

&lt;p&gt;修改：$CASSANDRA_HOME/conf/log4j-server.properties&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ sed -i -e &amp;quot;s,log4j.appender.R.File=/var/log/cassandra/system.log, \
  log4j.appender.R.File=$HOME/datastax/cassandra-data/system.log,&amp;quot; \
  $CASSANDRA_HOME/conf/log4j-server.properties
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;3.配置DataStax示例程序指向Cassandra的安装位置&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ sed -i -e &amp;quot;s,/usr/share/cassandra,$HOME/datastax/dsc_package_name,&amp;quot; \
  $DSCDEMO_HOME/bin/pricer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4.后台启动Cassandra&lt;/h3&gt;

&lt;p&gt;$ cassandra&lt;/p&gt;

&lt;h3&gt;5.检查cassandra环是否在运行&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ nodetool ring -h localhost
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;6.运行Portfolio Demo示例程序&lt;/h3&gt;

&lt;p&gt;1)进入Portfolio目录&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cd $DSCDEMO_HOME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2)运行 ./bin/pricer工具生成数据&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;./bin/pricer --help
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面代码生成100天的历史数据&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;./bin/pricer -o INSERT_PRICES
./bin/pricer -o UPDATE_PORTFOLIOS
./bin/pricer -o INSERT_HISTORICAL_PRICES -n 100
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3)启动服务(必须在$DSCDEMO_HOME/website目录下启动)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;$ cd $DSCDEMO_HOME/website
$ java -jar start.jar &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4)浏览程序 &lt;code&gt;http://localhost:8983/portfolio&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;1.&lt;a href=&quot;http://www.datastax.com/docs/1.0/getting_started/install_singlenode&quot; target=&quot;_blank&quot;&gt;Installing a Single-Node Instance of Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>哈希表</title>
   <link href="http://blog.javachen.com/java/2012/03/26/hash-and-hash-functions"/>
   <updated>2012-03-26T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/java/2012/03/26/hash-and-hash-functions</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;定义 &lt;/strong&gt;
一般的线性表、树，数据在结构中的相对位置是&lt;code&gt;随机&lt;/code&gt;的，即和记录的关键字之间不存在确定的关系，因此，在结构中查找记录时需进行一系列和关键字的比较。这一类查找方法建立在“比较“的基础上，查找的效率依赖于查找过程中所进行的比较次数。 若想能直接找到需要的记录，必须在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使每个关键字和结构中一个唯一的存储位置相对应，这就是哈希表。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;哈希表&lt;/code&gt;又称散列表。
&lt;em&gt;哈希表存储的基本思想是&lt;/em&gt;：以数据表中的每个记录的关键字 k为自变量，通过一种函数H(k)计算出函数值。把这个值解释为一块连续存储空间（即&lt;code&gt;数组空间&lt;/code&gt;）的单元地址（即&lt;code&gt;下标&lt;/code&gt;），将该记录存储到这个单元中。在此称该函数H为哈希函数或散列函数。按这种方法建立的表称为&lt;code&gt;哈希表&lt;/code&gt;或&lt;code&gt;散列表&lt;/code&gt;。&lt;br /&gt;
哈希表是一种数据结构，它可以提供快速的插入操作和查找操作。&lt;br /&gt;
哈希表是基于&lt;code&gt;数组结构&lt;/code&gt;实现的，所以它也存在一些&lt;em&gt;缺点&lt;/em&gt;： 数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重。 这个问题是哈希表不可避免的，即&lt;code&gt;冲突现象&lt;/code&gt;：对不同的关键字可能得到同一哈希地址。 所以在以下情况下可以优先考虑使用哈希表： &lt;em&gt;不需要有序遍历数据，并且可以提前预测数据量的大小&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;冲突&lt;/strong&gt;
理想情况下，哈希函数在关键字和地址之间建立了一个一一对应关系，从而使得查找只需一次计算即可完成。由于关键字值的某种随机性，使得这种一一对应关系难以发现或构造。因而可能会出现不同的关键字对应一个存储地址。即k1≠k2，但H(k1)=H(k2)，这种现象称为冲突。&lt;br /&gt;
把这种具有不同关键字值而具有相同哈希地址的对象称&lt;code&gt;同义词&lt;/code&gt;。 在大多数情况下，冲突是不能完全避免的。这是因为所有可能的关键字的集合可能比较大，而对应的地址数则可能比较少。&lt;br /&gt;
对于哈希技术，主要研究两个问题：&lt;br /&gt;
（1）如何设计哈希函数以使冲突尽可能少地发生。&lt;br /&gt;
（2）发生冲突后如何解决。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;哈希函数的构造方法&lt;/strong&gt;
构造好的哈希函数的方法，应能使冲突尽可能地少，因而应具有较好的随机性。这样可使一组关键字的散列地址均匀地分布在整个地址空间。根据关键字的结构和分布的不同，可构造出许多不同的哈希函数。
&lt;strong&gt;1．直接定址法&lt;/strong&gt;
&lt;code&gt;直接定址法&lt;/code&gt;是以关键字k本身或关键字加上某个数值常量c作为哈希地址的方法。&lt;br /&gt;
该哈希函数H(k)为：&lt;br /&gt;
H(k)=k+c (c≥0)&lt;br /&gt;
这种哈希函数计算简单，并且不可能有冲突发生。当关键字的分布基本连续时，可使用直接定址法的哈希函数。否则，若关键字分布不连续将造成内存单元的大量浪费&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2．除留余数法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;取关键字k除以哈希表长度m所得余数作为哈希函数地址的方法。即：&lt;br /&gt;
H(k)=k％m&lt;br /&gt;
这是一种较简单、也是较常见的构造方法。&lt;br /&gt;
这种方法的关键是选择好哈希表的长度m。使得数据集合中的每一个关键字通过该函数转化后映射到哈希表的任意地址上的概率相等。&lt;br /&gt;
理论研究表明，在m取值为素数（质数）时，冲突可能性相对较少。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3．平方取中法&lt;/strong&gt;
取关键字平方后的中间几位作为哈希函数地址（若超出范围时，可再取模）。&lt;br /&gt;
设有一组关键字ABC，BCD,CDE，DEF，……其对应的机内码如表所示。假定地址空间的大小为1000，编号为0-999。现按平方取中法构造哈希函数，则可取关键字机内码平方后的中间三位作为存储位置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4．折叠法&lt;/strong&gt;
这种方法适合在关键字的位数较多，而地址区间较小的情况。&lt;br /&gt;
将关键字分隔成位数相同的几部分。然后将这几部分的叠加和作为哈希地址（若超出范围，可再取模）。&lt;br /&gt;
例如，假设关键字为某人身份证号码430104681015355，则可以用4位为一组进行叠加。即有5355+8101+1046+430=14932，舍去高位。 则有H(430104681015355)=4932 为该身份证关键字的哈希函数地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5．数值分析法&lt;/strong&gt;
若事先知道所有可能的关键字的取值时，可通过对这些关键字进行分析，发现其变化规律，构造出相应的哈希函数。&lt;br /&gt;
例：对如下一组关键字通过分析可知：每个关键字从左到右的第l，2，3位和第6位取值较集中，不宜作哈希地址。 剩余的第4，5，7和8位取值较分散，可根据实际需要取其中的若干位作为哈希地址。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. 随机数法&lt;/strong&gt;
选择一个随机函数，取关键字的随机函数值为它的哈希地址，即H(key)＝random(key)，其中random为随机函数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7. 斐波那契（Fibonacci）散列法&lt;/strong&gt;
平方散列法的缺点是显而易见的，所以我们能不能找出一个理想的乘数，而不是拿value本身当作乘数呢？答案是肯定的。&lt;br /&gt;
1，对于16位整数而言，这个乘数是40503&lt;br /&gt;
2，对于32位整数而言，这个乘数是2654435769&lt;br /&gt;
3，对于64位整数而言，这个乘数是11400714819323198485&lt;br /&gt;
这几个“理想乘数”是如何得出来的呢？这跟一个法则有关，叫黄金分割法则，而描述黄金分割法则的最经典表达式无疑就是著名的斐波那契数列，如果你还有兴趣，就到网上查找一下“斐波那契数列”等关键字，我数学水平有限，不知道怎么描述清楚为什么，另外斐波那契数列的值居然和太阳系八大行星的轨道半径的比例出奇吻合，很神奇，对么？&lt;br /&gt;
对我们常见的32位整数而言，公式：&lt;br /&gt;
index = (value * 2654435769) &amp;gt;&amp;gt; 28&lt;br /&gt;
如果用这种斐波那契散列法的话，那我上面的图就变成这样了：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;冲突的解决方法&lt;/strong&gt;
假设哈希表的地址范围为0～m-l，当对给定的关键字k，由哈希函数H(k)算出的哈希地址为i（0≤i≤m-1）的位置上已存有记录，这种情况就是&lt;code&gt;冲突现象&lt;/code&gt;。 处理冲突就是为该关键字的记录找到另一个“空”的哈希地址。即通过一个新的哈希函数得到一个新的哈希地址。如果仍然发生冲突，则再求下一个，依次类推。直至新的哈希地址不再发生冲突为止。&lt;br /&gt;
常用的处理冲突的方法有开放地址法、链地址法两大类
&lt;strong&gt;1．开放定址法&lt;/strong&gt;
用开放定址法处理冲突就是当冲突发生时，形成一个地址序列。沿着这个序列逐个探测，直到找出一个“空”的开放地址。将发生冲突的关键字值存放到该地址中去。&lt;br /&gt;
如 Hi=(H(k)+d（i）) % m, i=1，2，…k (k 其中H(k)为哈希函数，m为哈希表长，d为增量函数，d(i)=dl，d2…dn-l。&lt;br /&gt;
增量序列的取法不同，可得到不同的开放地址处理冲突探测方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1）线性探测法&lt;/strong&gt;
线性探测法是从发生冲突的地址（设为d）开始，依次探查d+l，d+2，…m-1（当达到表尾m-1时，又从0开始探查）等地址，直到找到一个空闲位置来存放冲突处的关键字。&lt;br /&gt;
若整个地址都找遍仍无空地址，则产生溢出。&lt;br /&gt;
线性探查法的数学递推描述公式为：&lt;br /&gt;
d0=H(k)&lt;br /&gt;
di=(di-1+1)% m (1≤i≤m-1)&lt;/p&gt;

&lt;p&gt;【例】已知哈希表地址区间为0～10，给定关键字序列（20，30，70，15，8，12，18，63，19）。哈希函数为H(k)=k％ll，采用线性探测法处理冲突，则将以上关键字依次存储到哈希表中。试构造出该哈希表，并求出等概率情况下的平均查找长度。&lt;br /&gt;
假设数组为A, 本题中各元素的存放过程如下：&lt;br /&gt;
H(20)=9，可直接存放到A[9]中去。&lt;br /&gt;
H(30)=8，可直接存放到A[8]中去。&lt;br /&gt;
H(70)=4，可直接存放到A[4]中去。&lt;br /&gt;
H(15)=4，冲突；&lt;br /&gt;
d0=4&lt;br /&gt;
d1=(4+1)%11=5，将15放入到A[5]中。&lt;br /&gt;
H(8)=8，冲突；&lt;br /&gt;
d0=8&lt;br /&gt;
d1=(8+1)%11=9，仍冲突；&lt;br /&gt;
d2=(8+2)%11=10，将8放入到A[10]中。&lt;/p&gt;

&lt;p&gt;在等概率情况下成功的平均查找长度为：&lt;br /&gt;
（1*5+2+3+4+6）/9 =20/9&lt;br /&gt;
利用线性探查法处理冲突容易造成关键字的&lt;code&gt;堆积&lt;/code&gt;问题。这是因为当连续n个单元被占用后，再散列到这些单元上的关键字和直接散列到后面一个空闲单元上的关键字都要占用这个空闲单元，致使该空闲单元很容易被占用，从而发生非同义冲突。造成平均查找长度的增加。&lt;br /&gt;
为了克服堆积现象的发生，可以用下面的方法替代线性探查法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（2）平方探查法&lt;/strong&gt;
设发生冲突的地址为d，则平方探查法的探查序列为：d+12，d+22，…直到找到一个空闲位置为止。&lt;br /&gt;
平方探查法的数学描述公式为：&lt;br /&gt;
d0=H(k)&lt;br /&gt;
di=(d0+i2) % m (1≤i≤m-1)&lt;br /&gt;
在等概率情况下成功的平均查找长度为：&lt;br /&gt;
（1*4+2*2+3+4+6）/9 =21/9&lt;br /&gt;
平方探查法是一种较好的处理冲突的方法，可以避免出现堆积问题。它的缺点是不能探查到哈希表上的所有单元，但至少能探查到一半单元。&lt;br /&gt;
例如，若表长m=13，假设在第3个位置发生冲突，则后面探查的位置依次为4、7、12、6、2、0，即可以探查到一半单元。&lt;br /&gt;
若解决冲突时，探查到一半单元仍找不到一个空闲单元。则表明此哈希表太满，需重新建立哈希表。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2．链地址法&lt;/strong&gt;
用链地址法解决冲突的方法是：把所有关键字为同义词的记录存储在一个线性链表中，这个链表称为同义词链表。并将这些链表的表头指针放在数组中（下标从0到m-1）。这类似于图中的邻接表和树中孩子链表的结构。&lt;br /&gt;
由于在各链表中的第一个元素的查找长度为l，第二个元素的查找长度为2，依此类推。因此，在等概率情况下成功的平均查找长度为：&lt;br /&gt;
(1*5+2*2+3*l+4*1)／9=16／9&lt;/p&gt;

&lt;p&gt;虽然链地址法要多费一些存储空间，但是彻底解决了“堆积”问题，大大提高了查找效率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. 再哈希法&lt;/strong&gt;：&lt;br /&gt;
Hi=R Hi(key)，&lt;br /&gt;
R Hi均是不同的哈希函数，即在同义词产生地址冲突时计算另一个哈希函数地址，直到冲突不再发生。这种方法不易产生&lt;code&gt;聚集&lt;/code&gt;，但增加了计算的时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.建立一个公共溢出区&lt;/strong&gt;
这也是处理冲突的一种方法。&lt;br /&gt;
假设哈希函数的值域为[0，m-1]，则设向量HashTable[0…m-1]为基本表，每个分量存放一个记录，另设立向量OverTable[0．．v]为溢出表。所有关键字和基本表中关键字为同义词的记录，不管它们由哈希函数得到的哈希地址是什么，一旦发生冲突，都填入溢出表。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;哈希表的查找及性能分析&lt;/strong&gt;
&lt;code&gt;哈希法&lt;/code&gt;是利用关键字进行计算后直接求出存储地址的。当哈希函数能得到均匀的地址分布时，不需要进行任何比较就可以直接找到所要查的记录。但实际上不可能完全避免冲突，因此查找时还需要进行探测比较。&lt;br /&gt;
在哈希表中，虽然冲突很难避免，但发生冲突的可能性却有大有小。这主要与三个因素有关。
&lt;strong&gt;第一:与装填因子有关&lt;/strong&gt;
所谓装填因子是指哈希表中己存入的元素个数n与哈希表的大小m的比值，即f=n/m。&lt;br /&gt;
当f越小时，发生冲突的可能性越小，越大（最大为1）时，发生冲突的可能性就越大。
&lt;strong&gt;第二:与所构造的哈希函数有关&lt;/strong&gt;
若哈希函数选择得当，就可使哈希地址尽可能均匀地分布在哈希地址空间上，从而减少冲突的发生。否则，若哈希函数选择不当，就可能使哈希地址集中于某些区域，从而加大冲突的发生。
&lt;strong&gt;第三:与解决冲突的哈希冲突函数有关&lt;/strong&gt;
哈希冲突函数选择的好坏也将减少或增加发生冲突的可能性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;思考&lt;/strong&gt;
&lt;em&gt;哈希算法的基本思想是什么？&lt;/em&gt;
&lt;em&gt;哈希算法的存储效率主要取决于什么？&lt;/em&gt;
&lt;em&gt;哈希算法解决冲突的方式有哪些？&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;java 哈希表实现&lt;/strong&gt;
java中哈希表的实现有多个，比如hashtable，hashmap，currenthashmap，也有其他公司实现的，如apache的FashHashmap,google的mapmarker,high-lib的NonBlockingHashMap,其中差别是：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hastable&lt;/strong&gt;:线程同步，比较慢
&lt;strong&gt;hashmap&lt;/strong&gt;：线程不同步，不同步时候读写最快（但是不能保证读到最新数据），加同步修饰的时候， 读写比较慢
&lt;strong&gt;currenthashmap&lt;/strong&gt;:线程同步，默认分成16块，写入的时候只锁要写入的快，读取一般不锁块，只有读到空的时候，才锁块，性能比较高，处于hashmap同步和不同步之间。
&lt;strong&gt;fashhashmap&lt;/strong&gt;:apache collection 将HashMap封装，读取的时候copy一个新的，写入比较慢（尤其是存入比较多对象每写一次都要复制一个对象，超级慢），读取快
&lt;strong&gt;NoBlockingHashMap&lt;/strong&gt;： high_scale_lib实现写入慢，读取较快
&lt;strong&gt;MiltigetHashMap&lt;/strong&gt;，MapMaker google collection，和CurrentHashMap性能相当，功能比较全，可以设置超时，重复的可以保存成list&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;
&lt;a href=&quot;http://course.onlinesjtu.com/mod/page/view.php?id=423&quot; target=&quot;_blank&quot;&gt; http://course.onlinesjtu.com/mod/page/view.php?id=423&lt;/a&gt;
&lt;a href=&quot;http://www.cnblogs.com/bigshuai/articles/2398116.html&quot; target=&quot;_blank&quot;&gt; http://www.cnblogs.com/bigshuai/articles/2398116.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;扩展阅读&lt;/strong&gt;
Hash碰撞的拒绝式服务攻击 &lt;a href=&quot;http://blog.jobbole.com/11454/&quot; target=&quot;_blank&quot;&gt;http://blog.jobbole.com/11454/&lt;/a&gt;
Berkeley DB Hash、Btree、Queue、Recno选择&lt;a href=&quot; http://www.webzone8.com/article/560.html&quot; target=&quot;_blank&quot;&gt; http://www.webzone8.com/article/560.html&lt;/a&gt;
Java Hashtable &lt;a href=&quot;http://javapapers.com/core-java/java-hashtable/#&amp;amp;slider1=1&quot; target=&quot;_blank&quot;&gt;http://javapapers.com/core-java/java-hashtable/#&amp;amp;slider1=1&lt;/a&gt;
Java Hashtable分析 &lt;a href=&quot;http://kantery.iteye.com/blog/441755&quot; target=&quot;_blank&quot;&gt;http://kantery.iteye.com/blog/441755&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>如何在kettle4.2上面实现cassandra的输入与输出</title>
   <link href="http://blog.javachen.com/kettle/2012/03/23/how-to-implement-cassandra-input-and-output-in-kettle4-2"/>
   <updated>2012-03-23T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/03/23/how-to-implement-cassandra-input-and-output-in-kettle4-2</id>
   <content type="html">&lt;p&gt;这是在QQ群里有人问到的一个问题.&lt;/p&gt;

&lt;p&gt;如何在pdi-ce-4.2.X-stable上面实现cassandra的输入与输出,或是实现hadoop,hbase,mapreduce,mongondb的输入输出?&lt;/p&gt;

&lt;p&gt;在kettle中实现cassandra的输入与输出有以下两种方式:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;第一种方式:自己编写cassandra输入输出组件&lt;/li&gt;
&lt;li&gt;第二种方式:使用别人编写好的插件,将其集成进来&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然还有第三种方法,直接使用4.3版本的pdi.&lt;/p&gt;

&lt;p&gt;第一种方法需要对cassandra很熟悉编写插件才可以做到,第二种方法可以通过拷贝pdi-ce-big-data-4.3.0-preview中的文件来完成.&lt;/p&gt;

&lt;p&gt;在pdi-ce-big-data-4.3.0-preview&lt;a href=&quot;http://ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/&quot; target=&quot;_blank&quot;&gt;(下载页面&lt;/a&gt;)版本中可以看到kettle开始支持cassandra的输入和输出.&lt;/p&gt;

&lt;p&gt;故我们可以将4.3版本中的cassandra相关文件拷贝到4.2.1中.我使用的是pdi-ce-4.2.1-stable.&lt;/p&gt;

&lt;p&gt;在pdi-ce-big-data-4.3.0-preview/plugins目录下有以下目录或文件:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;.
|-- databases
|-- hour-partitioner.jar
|-- jobentries
|-- kettle-gpload-plugin
|-- kettle-hl7-plugin
|-- kettle-palo-plugin
|-- pentaho-big-data-plugin
|-- repositories
|-- spoon
|-- steps
`-- versioncheck
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;pentaho-big-data-plugin目录是kettle对大数据的集成与支持,我们只需要将该目录拷贝到pdi-ce-4.2.1-stable/plugins目录下即可.最后的结构如下&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;.
|-- databases
|-- hour-partitioner.jar
|-- jobentries
|   `-- DummyJob
|       |-- DPL.png
|       |-- dummyjob.jar
|       `-- plugin.xml
|-- pentaho-big-data-plugin
|   |-- lib
|   |   |-- apache-cassandra-1.0.0.jar
|   |   |-- apache-cassandra-thrift-1.0.0.jar
|   |   |-- aws-java-sdk-1.0.008.jar
|   |   |-- commons-cli-1.2.jar
|   |   |-- guava-r08.jar
|   |   |-- hbase-comparators-TRUNK-SNAPSHOT.jar
|   |   |-- jline-0.9.94.jar
|   |   |-- libthrift-0.6.jar
|   |   |-- mongo-java-driver-2.7.2.jar
|   |   |-- pig-0.8.1.jar
|   |   |-- xpp3_min-1.1.4c.jar
|   |   `-- xstream-1.3.1.jar
|   `-- pentaho-big-data-plugin-TRUNK-SNAPSHOT.jar
|-- repositories
|-- spoon
|-- steps
|   |-- DummyPlugin
|   |   |-- DPL.png
|   |   |-- dummy.jar
|   |   `-- plugin.xml
|   |-- S3CsvInput
|   |   |-- jets3t-0.7.0.jar
|   |   |-- plugin.xml
|   |   |-- S3CIN.png
|   |   `-- s3csvinput.jar
|   `-- ShapeFileReader3
|       |-- plugin.xml
|       |-- SFR.png
|       `-- shapefilereader3.jar
`-- versioncheck
    |-- kettle-version-checker-0.2.0.jar
    `-- lib
    `-- pentaho-versionchecker.jar

13 directories, 29 files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;启动pdi-ce-4.2.1-stable之后,打开一个转换,在核心对象窗口就可以看到Big Data步骤目录了.
&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dr9zaa66nbj.jpg&quot; target=&quot;_blank&quot;&gt;
&lt;img alt=&quot;&quot; src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dr9zaa66nbj.jpg&quot; title=&quot;pdi big data plugin in kette 4.2&quot; class=&quot;aligncenter&quot; width=&quot;600&quot; height=&quot;375&quot; /&gt;
&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;获取pentaho-big-data-plugin源码&lt;/strong&gt;
如果想在eclipse中查看或修改pentaho-big-data-plugin源码,该怎么做呢?
你可以从&lt;a href=&quot;http://ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/pentaho-big-data-plugin-TRUNK-SNAPSHOT-sources.zip&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;下载到源码,然后将src下的文件拷贝到你的pdi-ce-4.2.1-stable源码工程中.&lt;/p&gt;

&lt;p&gt;然后,需要在kettle-steps.xml中注册步骤节点
例如,下面是MongoDbInput步骤的注册方法,请针对不同插件的不同类路径加以修改.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;step id=&amp;quot;MongoDbInput&amp;quot;&amp;gt;
&amp;lt;description&amp;gt;i18n:org.pentaho.di.trans.step:BaseStep.TypeLongDesc.MongoDbInput
&amp;lt;classname&amp;gt;org.pentaho.di.trans.steps.mongodbinput.MongoDbInputMeta
&amp;lt;category&amp;gt;i18n:org.pentaho.di.trans.step:BaseStep.Category.Input
&amp;lt;tooltip&amp;gt;i18n:org.pentaho.di.trans.step:BaseStep.TypeTooltipDesc.MongoDbInput
&amp;lt;iconfile&amp;gt;ui/images/mongodb-input.png
&amp;lt;/iconfile&amp;gt;&amp;lt;/tooltip&amp;gt;
&amp;lt;/category&amp;gt;
&amp;lt;/classname&amp;gt;
&amp;lt;/description&amp;gt;
&amp;lt;/step&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;note&quot;&gt;
&lt;h&gt;注意:
由于pdi-ce-4.2.1-stable中存在hive组件,故添加pentaho-big-data-plugin插件之后有可能会出现找不到类的情况,这是由于jar重复版本不一致导致的,按照异常信息,找到重复的jar并按情况删除一个jar包即可.
&lt;/h&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;扩展阅读:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Pentaho Big Data Plugin &lt;a href=&quot;http://wiki.pentaho.com/display/BAD/Getting+Started+for+Java+Developers&quot; target=&quot;_blank&quot;&gt;http://wiki.pentaho.com/display/BAD/Getting+Started+for+Java+Developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;pentaho-big-data-plugin ci
&lt;a href=&quot;http://ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/&quot; target=&quot;_blank&quot;&gt;http://- - ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pentaho Community Edition (CE) downloads &lt;a href=&quot;http://wiki.pentaho.com/display/BAD/Downloads&quot; target=&quot;_blank&quot;&gt;http://wiki.pentaho.com/display/BAD/Downloads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Seam的启动过程</title>
   <link href="http://blog.javachen.com/java/2012/02/23/the-process-of-seam-initiation"/>
   <updated>2012-02-23T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/java/2012/02/23/the-process-of-seam-initiation</id>
   <content type="html">&lt;p&gt;了解seam2的人知道，seam是通过在web. xml中配置监听器启动的。注意，本文中的seam是指的seam2，不是seam3. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;listener&amp;gt;
    &amp;lt;listenerclass&amp;gt;org. jboss. seam. servlet. SeamListener&amp;lt;/listenerclass&amp;gt;
&amp;lt;/listener&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;该监听器会做哪些事情呢？看看Gavin King对SeamListener类的描述。&lt;/p&gt;

&lt;blockquote&gt;Drives certain Seam functionality such as initialization and cleanup of application and session contexts from the web application lifecycle. &lt;/blockquote&gt;

&lt;p&gt;从描述中可以知道SeamListener主要完成应用以及web应用生命周期中的session上下文的初始化和清理工作。&lt;/p&gt;

&lt;p&gt;该类实现了ServletContextListener接口，在contextInitialized(ServletContextEvent event)方法内主要初始化生命周期并完成应用的初始化，在contextDestroyed(ServletContextEvent event)方法内结束应用的生命周期。&lt;/p&gt;

&lt;p&gt;该类实现了HttpSessionListener接口，主要是用于在生命周期中开始和结束session。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一步&lt;/strong&gt;，构造方法里从ServletContext获取一些路径信息：warRoot、warClassesDirectory、warLibDirectory、hotDeployDirectory。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二步&lt;/strong&gt;，扫描配置文件完成seam组件的初始化（Initialization的create方法）。
其中包括：添加命名空间、初始化组件、初始化Properties、初始化jndi信息。这一步，其实主要是读取一些配置文件,加载seam组件。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;添加命名空间&lt;/li&gt;
&lt;li&gt;从/WEBINF/components. xml加载组件&lt;/li&gt;
&lt;li&gt;从/WEBINF/events. xml加载组件&lt;/li&gt;
&lt;li&gt;从METAINF/components. xml加载组件&lt;/li&gt;
&lt;li&gt;从ServletContext初始化Properties&lt;/li&gt;
&lt;li&gt;从/seam. properties初始化Properties&lt;/li&gt;
&lt;li&gt;初始化jndi Properties&lt;/li&gt;
&lt;li&gt;从system加载Properties&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;第三步&lt;/strong&gt;，seam初始化过程（Initialization的init方法）。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ServletLifecycle开始初始化&lt;/li&gt;
&lt;li&gt;设置Application上下文&lt;/li&gt;
&lt;li&gt;添加Init组件&lt;/li&gt;
&lt;li&gt;通过standardDeploymentStrategy的注解和xml组件扫描组件&lt;/li&gt;
&lt;li&gt;判断jbpm是否安装&lt;/li&gt;
&lt;li&gt;检查默认拦截器&lt;/li&gt;
&lt;li&gt;添加特别组件&lt;/li&gt;
&lt;li&gt;添加war root部署、热部署&lt;/li&gt;
&lt;li&gt;安装组件&lt;/li&gt;
&lt;li&gt;导入命名空间&lt;/li&gt;
&lt;li&gt;ServletLifecycle结束初始化。启动生命周期为APPLICATION的组件。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果组件标注为startup，则会构造其实例进行初始化。例如seam于Hibernate的集成，就可以通过此方法初始化Hibernate，对应的组件类为org. jboss. seam. persistence. HibernateSessionFactory。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kettle运行作业之前的初始化过程</title>
   <link href="http://blog.javachen.com/kettle/2012/02/22/the-init-process-before-job-execution"/>
   <updated>2012-02-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/02/22/the-init-process-before-job-execution</id>
   <content type="html">&lt;p&gt;本文主要描述Kettle是如何通过GUI调用代码启动线程执行作业的。&lt;/p&gt;

&lt;p&gt;之前用英文写了一篇文章《&lt;a href=&quot;http://www.javachen.com/2012/02/the-execution-process-of-kettles-job/&quot; target=&quot;_blank&quot;&gt;The execution process of kettle’s job&lt;/a&gt;》 ，这篇文章只是用于英语写技术博客的一个尝试。由于很久没有使用英语写作了，故那篇文章只是简单的通过UML的序列图描述kettle运行job的一个java类调用过程。将上篇文章的序列图和这篇文章联系起来，会更加容易理解本文。&lt;/p&gt;

&lt;p&gt;在Spoon界面点击运行按钮，Spoon GUI会调用Spoon.runFile()方法，这可以从xul文件（ui/menubar.xul）中的描述看出来。关于kettle中的xul的使用，不是本文重点故不在此说明。&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;
public void runFile() {
    executeFile(true, false, false, false, false, null, false);
}

public void executeFile(boolean local, boolean remote, boolean cluster,
        boolean preview, boolean debug, Date replayDate, boolean safe) {
    TransMeta transMeta = getActiveTransformation();
    if (transMeta != null)
        executeTransformation(transMeta, local, remote, cluster, preview,
                debug, replayDate, safe);

    JobMeta jobMeta = getActiveJob();
    if (jobMeta != null)
        executeJob(jobMeta, local, remote, replayDate, safe, null, 0);
}

public void executeJob(JobMeta jobMeta, boolean local, boolean remote,
        Date replayDate, boolean safe, String startCopyName, int startCopyNr) {
    try {
        delegates.jobs.executeJob(jobMeta, local, remote, replayDate, safe,
                startCopyName, startCopyNr);
    } catch (Exception e) {
        new ErrorDialog(shell, &quot;Execute job&quot;,
                &quot;There was an error during job execution&quot;, e);
    }
}
&lt;/pre&gt;

&lt;p&gt;runFile()方法内部调用executeFile()方法，executeFile方法有以下几个参数：
- local：是否本地运行
- remote：是否远程运行
- cluster：是否集群环境运行
- preview：是否预览
- debug：是否调试
- replayDate：回放时间
- safe：是否安全模式&lt;/p&gt;

&lt;p&gt;executeFile方法会先获取当前激活的转换，如果获取结果不为空，则执行该转换；否则获取当前激活的作业，执行该作业。 本文主要讨论作业的执行过程，关于转换的执行过程，之后单独一篇文章进行讨论。&lt;/p&gt;

&lt;p&gt;executeJob委托SpoonJobDelegate执行其内部的executeJob方法，注意，其将JobMeta传递给了executeJob方法。SpoonJobDelegate还保存着对Spoon的引用。&lt;/p&gt;

&lt;p&gt;SpoonJobDelegate的executeJob方法主要完成以下操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.设置Spoon的执行配置JobExecutionConfiguration类，该类设置变量、仓库、是否执行安全模式、日志等级等等。&lt;/li&gt;
&lt;li&gt;2.获得当前Job对应的图形类JobGraph。&lt;/li&gt;
&lt;li&gt;3.将执行配置类JobExecutionConfiguration的变量、参数、命令行参数设置给jobMeta。&lt;/li&gt;
&lt;li&gt;4.如果本地执行，则调用jobGraph.startJob(executionConfiguration)，如果远程执行，则委托给SpoonSlaveDelegate执行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JobExecutionConfiguration类是保存job执行过程中的一些配置，该类会在Spoon、JobGraph类之间传递。&lt;/p&gt;

&lt;p&gt;本文只讨论本地执行的情况，故往下查看jobGraph.startJob(executionConfiguration)方法。该方法被synchronized关键字修饰。&lt;/p&gt;

&lt;p&gt;JobGraph类包含当前Spoon类的引用、以及对Job的引用。初始情况，Job的引用应该为null。该类会做以下操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.如果job为空或者没有运行或者没有激活，则先保存，然后往下执行作业。&lt;/li&gt;
&lt;li&gt;2.在仓库不为空的时候，通过仓库加载Job获得一个运行时的JobMeta对象，名称为runJobMeta；否则，通过文件名称直接new一个JobMeta对象，名称也为runJobMeta。&lt;/li&gt;
&lt;li&gt;3.通过仓库和runJobMeta对象构建一个Job对象，并将jobMeta对象（此对象通过JobGraph构造方法传入）的变量、参数共享给Job对象。&lt;/li&gt;
&lt;li&gt;4.Job对象添加JobEntry监听器、Job监听器。&lt;/li&gt;
&lt;li&gt;5.调用Job的start方法，启动线程开始执行一个job。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Job继承自Thread类，该类的run方法内部会递归执行该作业内部的作业项，限于篇幅，本文不做深究。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The execution process of kettle’s job</title>
   <link href="http://blog.javachen.com/kettle/2012/02/21/the-execution-process-of-kettles-job"/>
   <updated>2012-02-21T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/02/21/the-execution-process-of-kettles-job</id>
   <content type="html">&lt;p&gt;How to execute a kettle job in Spoon GUI or command line after we create a job in Spoon GUI? In Spoon GUI,the main class is &quot;org.pentaho.di.ui.spoon.Spoon.java&quot;.This class handles the main window of the Spoon graphical transformation editor.Many operations about a job or transformation such as run,debug,preview,zoomIn,etc,are all in this class.This post just writes about the code execution process.&lt;/p&gt;

&lt;p&gt;When we start a job or transformation,Spoon invokes the method runFile(),and then is distributed to executeTransformation() or executeJob().At now,we mainly study about executeJob() method.&lt;/p&gt;

&lt;p&gt;This is a simple sequence diagram below.It contains several classes for Starting to execute a job using execute(int nr, Result result) in Job.java.We can see the relation of these classes from it.&lt;/p&gt;

&lt;p&gt;&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://www.javachen.com/wp-content/uploads/2012/02/spoon-execute-sequence.jpg&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://www.javachen.com/wp-content/uploads/2012/02/spoon-execute-sequence-300x180.jpg&quot; alt=&quot;&quot; title=&quot;spoon execute sequence&quot; width=&quot;300&quot; height=&quot;180&quot; class=&quot;aligncenter size-medium wp-image-2511&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;What is the detail process of job execution? You should look into the Job.run() method for detail information.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>kettle中定义错误处理</title>
   <link href="http://blog.javachen.com/kettle/2012/02/17/step-error-handling-in-kettle"/>
   <updated>2012-02-17T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/02/17/step-error-handling-in-kettle</id>
   <content type="html">&lt;p&gt;在kettle执行的过程中，如果遇到错误，kettle会停止运行。在某些时候，并不希望kettle停止运行，这时候可以使用错误处理（Step Error Handling）。错误处理允许你配置一个步骤来取代出现错误时停止运行一个转换，出现错误的记录行将会传递给另一个步骤。在Step error handling settings对话框里，需要设置启用错误处理。&lt;/p&gt;

&lt;p&gt;下面例子中读取postgres数据库中的a0表数据，然后输出到a1表：
&lt;div class=&quot;pic&quot;&gt;
&lt;img alt=&quot;&quot; src=&quot;http://ww2.sinaimg.cn/mw600/48e24b4cjw1dq56wck3m7j.jpg&quot; class=&quot;alignnone&quot; width=&quot;600&quot; height=&quot;172&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;a1表结构如下：
&lt;pre lang=&quot;sql&quot;&gt;
CREATE TABLE a1
(
  a double precision,
  id integer NOT NULL,
  CONSTRAINT id&lt;em&gt;pk PRIMARY KEY (id ),
  CONSTRAINT id&lt;/em&gt;unin UNIQUE (id )
)
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;从表结构可以看出，a1表中id为主键、唯一。&lt;/p&gt;

&lt;p&gt;a0表数据预览：
&lt;div class=&quot;pic&quot;&gt;
&lt;img alt=&quot;&quot; src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dq56wcr6c2j.jpg&quot; class=&quot;alignnone&quot; width=&quot;553&quot; height=&quot;403&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;现在a1表数据为空，执行上面的转换，执行成功之后，a1表数据和a0表数据一致。
再次执行，上面的转换会报错，程序停止运行，会报主键重复的异常。&lt;/p&gt;

&lt;p&gt;现在，我想报错之后，程序继续往下执行，并记录错误的记录的相关信息，这时候可以使用“定义错误处理”的功能。
在“表输出”的步骤上右键选择“定义错误处理”，弹出如下对话框。
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww3.sinaimg.cn/mw600/48e24b4cjw1dq56wd5ckwj.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;相关字段说明：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;目标步骤：指定处理错误的步骤&lt;/li&gt;
&lt;li&gt;启用错误处理？：设置是否启用错误处理&lt;/li&gt;
&lt;li&gt;错误数列名：出错的记录个数&lt;/li&gt;
&lt;li&gt;错误描述列名：描述错误信息的列名称&lt;/li&gt;
&lt;li&gt;错误列的列名：出错列的名称&lt;/li&gt;
&lt;li&gt;错误编码列名：描述错误的代码的列名&lt;/li&gt;
&lt;li&gt;允许的最大错误数：允许的最大错误数，超过此数，不在处理错误&lt;/li&gt;
&lt;li&gt;允许的最大错误百分比：&lt;/li&gt;
&lt;li&gt;在计算百分百前最少要读入的行数：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;添加错误处理后的转换如下：
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dq56wdntipj.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;记录错误信息的字段列表如下，可以看出，errorNum、errorDesc、errorName、errorCode都是在定义错误处理时候填入的列名称，a、id来自于输入的记录的列。
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww2.sinaimg.cn/mw600/48e24b4cjw1dq56wdvk6uj.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;记录的错误信息如下：
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dq56we2sn2j.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分析&lt;/strong&gt;
可以看到,错误日志里只是记录了出错的行里面的信息，并没有记录当前行所在的表名称以及执行时间等等，如果能够对此进行扩展，则该错误日志表才能更有实际意义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;
1.错误日志的错误码含义（如：TOP001）含义见参考文章2.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.pentaho.com/display/EAI/.09+Transformation+Steps#.09TransformationSteps-StepErrorHandling&quot; target=&quot;_blank&quot;&gt;Step Error Handling&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.pentaho.com/display/COM/Step+error+handling+codes&quot; target=&quot;_blank&quot;&gt;Step error handling codes&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>JSF中EL表达式之this扩展</title>
   <link href="http://blog.javachen.com/java/2012/02/14/this-expression-of-jsf-el"/>
   <updated>2012-02-14T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/java/2012/02/14/this-expression-of-jsf-el</id>
   <content type="html">&lt;p&gt;本篇文章来自以前公司的一套jsf+seam+Hibernate的一套框架，其对jsf进行了一些改进，其中包括:EL表达式中添加this，通过jsf的渲染实现权限控制到按钮等等。JSF表达式中添加this，主要是为了在facelets页面使用this关键字引用（JSF自动查找）到当前页面对应的pojo类，详细说明见下午。因为，本文的文章是公司同事整理的，本文作者仅仅是将其分享出来，供大家参考思路，如果有什么不妥的话，请告知。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EL表达式this扩展&lt;/strong&gt;
在业务系统中，大量页面具有大量区域是相似或者相同的，或者可能根据某些局部特征的变化具有一定的变化，jsf中通过facelet模板功能可以达到一定程度的页面重用，从而减轻开发人员编辑和拷贝一些页面代码，达到重用的目的。然而，她们具有如下限制：
1.Java语言作为一种典型的OO语言，通过抽象、继承等功能，可以大量重用已经实现或者在父类中已经存在的属性和方法等。模板技术作为一种静态加载和内容替换，无法充分利用面向对象的继承功能
2.由于Jsf/jsp框架采用视图和动作分离的模型，多个相似功能在不同的页面实现中由于页面对应点动作类不同因而必须使用复制的方法；
3.模板中使用EL表达式与后台动作类交互，这种交互是基于绝对名称的，不同的网页对应的动作类是完全不同的，因此很难重用和利用面向对象的特征。&lt;/p&gt;

&lt;p&gt;我们需要一种新的功能，实现：
1.模板的应用特种可以参照OO的继承特种，即模板的对模板的引用可以看成一种继承，这种继承可以和java的OO是一致的
2.多个页面和多个独立java后台程序相同部分完全可以抽离出来，不依赖它们是否继承关系、只需保证他们具有相同的属性或者方法
3.动态映射功能，即在满足上述基础上可以实现页面和后台实现类的属性和方法的自动映射
4.兼容标准的EL表达式&lt;/p&gt;

&lt;p&gt;我们将上述功能处理为“this”表达式。其功能模型为：
&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/02/this-expression-of-el.jpg&quot;&gt;&lt;img src=&quot;http://blog.javachen.com/files/2012/02/this-expression-of-el-300x168.jpg&quot; alt=&quot;&quot; title=&quot;this expression of el&quot; width=&quot;300&quot; height=&quot;168&quot; class=&quot;aligncenter size-medium wp-image-2496&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;
页面A和页面B分别引用了通用功能T,内含this相关的El表达式，通过分析处理，分别映射到对应的页面动作类的属性A.name和B.name。A和B可以从相同的基类C派生而来，只需C类实现了name属性即可，A类和B类也可以毫不相关，但是它们具有相同的属性name。
&amp;lt;!--more--&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;动作类和页面的一致性保证&lt;/strong&gt;
为了有效实现this表达式，我们实现如下映射规则：
1.名称为小写方式，不管页面如何命名，对应的后台类的jsf标识符都转换为小写
2.页面和相应的后台类以相同命名方式，页面的目录转化为后台类的包名，名称通过点分隔包名，如根目录的a.xhtml对应的后台类名称为A.java，其唯一jsf标识名称为“a”，test/b.xhtml的后台类为test/B.java，其唯一jsf标识为“test.b”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“this”EL表达式算法&lt;/strong&gt;
算法流程如下图：
&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/02/this-expression-flow-of-el.jpg&quot;&gt;&lt;img src=&quot;http://blog.javachen.com/files/2012/02/this-expression-flow-of-el-300x226.jpg&quot; alt=&quot;&quot; title=&quot;this expression flow of el&quot; width=&quot;300&quot; height=&quot;226&quot; class=&quot;aligncenter size-medium wp-image-2497&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ext读取xml文件生成动态表格和表单(续)</title>
   <link href="http://blog.javachen.com/javascript/2012/01/31/ext_readxml_in_bjsasc_wuzi_continue"/>
   <updated>2012-01-31T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2012/01/31/ext_readxml_in_bjsasc_wuzi_continue</id>
   <content type="html">&lt;p&gt;很多人向我要《&lt;a href=&quot;http://blog.javachen.com/2009/10/ext_readxml_in_bjsasc_wuzi&quot; target=&quot;_blank&quot;&gt;Ext读取xml文件生成动态表格和表单&lt;/a&gt;》一文的源代码，故花了些时间将源代码整理出来，并重新编写此文，分享当时的技术思路。&lt;/p&gt;

&lt;p&gt;《Ext读取xml文件生成动态表格和表单》一文需要的文件有：
1.html文件，此处以SASC.search.MtrUse.html为例
2.Extjs相关文件,见SASC.search.MtrUse.html文件中的引用
3.工具类，DomUtils.js
4.核心js类:SASC.extjs.search.MtrUse.js
5.java代码&lt;/p&gt;

&lt;p&gt;详细html和js代码见相关文件，这里先描述思路。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;首先&lt;/strong&gt;
通过一个事件打开一个弹出窗口，该窗口的url指向SASC.search.MtrUse.html文件，并附带参数xmlFile，xmlFile的值为xml文件名称，其存于服务器的某一路径下面。如：“../SASC.search.MtrUse.html?xmlFile=PC&lt;em&gt;MTRREPLACE&lt;/em&gt;IMP.xml” .PC&lt;em&gt;MTRREPLACE&lt;/em&gt;IMP.xml文件的放置路径见DomUtils.js文件中的说明。&lt;/p&gt;

&lt;p&gt;在这里，前台会读取该xml生成ext界面，后天会从xml文件读取sql语句等信息，详细信息见java代码。
进入SASC.search.MtrUse.html页面，执行ext的初始化方法时，会先通过当前页面的url中获取xmlFile参数的值（调用getForwardXmlUrl(getQsValue(&amp;#39;xmlFile&amp;#39;))），得到xml文件的服务器路径，然后通过javascript的解析该xml文件，渲染出ext界面,这部分代码见SASC.extjs.search.MtrUse.js文件内的initStoreData(xmlObj) 方法。
需要说明的是，xml文件是按照一定规律编写的，详细的参考xml文件内容，以及解析xml文件的相关方法。你可以重新定义该xml的结构，然后修改解析xml文件的方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;然后&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;初始化完ext界面之后，会获取表格数据，这部分使用了struts，这不是本文重点，故不做介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最后&lt;/strong&gt;
相关文件打包见：
&lt;a href=&quot;http://vdisk.weibo.com/s/2enQS&quot; target=&quot;_blank&quot;&gt;http://vdisk.weibo.com/s/2enQS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;
如果还有什么不懂，欢迎email：javachen.june#gmail.com&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>使用kettle数据迁移添加主键和索引</title>
   <link href="http://blog.javachen.com/kettle/2012/01/05/add-primary-keys-and-indexes-when-migrating-datas-whith-kettle"/>
   <updated>2012-01-05T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/01/05/add-primary-keys-and-indexes-when-migrating-datas-whith-kettle</id>
   <content type="html">&lt;p&gt;Kettle是一款国外开源的etl工具，纯java编写，绿色无需安装，主要用于&lt;strong&gt;数据抽取、转换、装载&lt;/strong&gt;。kettle兼容了市面上几十种数据库，故用kettle来做数据库的迁移视乎是个不错的选择。&lt;/p&gt;

&lt;p&gt;kettle的数据抽取主要在于抽取数据，而没有考虑数据库的&lt;strong&gt;函数、存储过程、视图、表结构以及索引、约束&lt;/strong&gt;等等，而这些东西恰恰都是数据迁移需要考虑的事情。当然，如果在不考虑数据库中的函数、存储过程、视图的情况下，使用kettle进行数据的迁移还算是一个可行的方案。&lt;/p&gt;

&lt;p&gt;这篇文章主要是讲述在使用kettle进行数据库的迁移的时候如何迁移主键和索引，为什么要迁移主键和索引？异构数据库之间的迁移很难无缝的实现自定义函数、存储过程、视图、表结构、索引、约束以及数据的迁移，所以多数情况下只需要异构数据库之间类型兼容、数据一致就可以了。但是在有些情况下需要对输出表进行查询以及数据比对的时候，&lt;strong&gt;需要有主键和索引方便对比和加快查询速度&lt;/strong&gt;。
先来看看kettle中的一些组件。&lt;/p&gt;

&lt;p&gt;下图是kettle中的一个表输出组件。
&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/01/kettle-table-out.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2480 aligncenter&quot; title=&quot;kettle-table-out&quot; src=&quot;http://blog.javachen.com/files/2012/01/kettle-table-out-269x300.png&quot; alt=&quot;kettle中的表输出组件&quot; width=&quot;269&quot; height=&quot;300&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;在该组件里可以指定表名、字段等信息，并且还可以建表的sql语句。打开建表的sql语句，你可以看到该语句里只指定了字段名称和类型，没有指定主外键、约束、和索引。显然，该组件只是完成了数据的输出并没有将表的主键迁移过去。
&amp;lt;!--more--&amp;gt;
下图是kettle中纬度更新/查询的组件。
&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/01/kettle-look-up.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2481 aligncenter&quot; title=&quot;kettle-look-up&quot; src=&quot;http://blog.javachen.com/files/2012/01/kettle-look-up-292x300.png&quot; alt=&quot;kettle中纬度更新/查询的组件&quot; width=&quot;292&quot; height=&quot;300&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;
该组件可以指定输出表名、映射字段、纬度字段、并且指定主键（图中翻译为关键字段），该组件比表输出组件多了一个功能，即指定主键。
从上面两个组件中可以看出，kettle实际上预留了设置主键的接口，具体的接口说明需要查看api或者源代码，只是kettle没有智能的查处输入表的主键字段，而是需要用户在kettle ui界面指定一个主键名称。&lt;/p&gt;

&lt;p&gt;如果现在想使用kettle实现&lt;strong&gt;异构数据库的数据以及主键和索引的迁移&lt;/strong&gt;，有没有一个完整方便的解决方案呢？我能想到的解决方案如下：
&lt;strong&gt;1.&lt;/strong&gt;使用kettle向导中的多表复制菜单进行数据库的迁移，这只能实现数据的迁移还需要额外的方法添加主键和索引，你可以手动执行一些脚步添加约束。
&lt;strong&gt;2.&lt;/strong&gt;针对源数据库中的每一张表创建一个转换，转换中使用纬度更新/查询组件，在该主键中指定主键。创建完所有的转换之后，创建一个作业将这些转换串联起来即可。
&lt;strong&gt;3.&lt;/strong&gt;扩展kettle向导中的多表复制菜单里的功能，在该功能创建的作业中添加一些节点用于添加输出表的主键和索引。这些节点可以是执行sql语句的主键，故只需要通过jdbc代码获取添加主键和索引的sql语句。&lt;/p&gt;

&lt;p&gt;方案1需要单独执行脚步实现添加主键和索引，创建或生成这些脚步需要些时间；方案2需要针对每个表认为的指定主键，工作量大，而且无法实现添加索引；方案3最容易实现和扩展。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;下面是方案3的具体的实现。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先需要在每一个表的建表语句节点和复制数据节点之后添加一个执行sql语句的节点，该节点用于添加主键和索引。
多表复制向导的核心代码在src-db/org.pentaho.di.ui.spoon.delegates.SpoonJobDelegate.java的public void ripDBWizard()方法中。该方法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public void ripDBWizard(final int no) {
    final List databases = spoon.getActiveDatabases();
    if (databases.size() == 0)
        return;&amp;lt;/pre&amp;gt;

    final RipDatabaseWizardPage1 page1 = new RipDatabaseWizardPage1(&amp;quot;1&amp;quot;,
            databases);
    final RipDatabaseWizardPage2 page2 = new RipDatabaseWizardPage2(&amp;quot;2&amp;quot;);
    final RipDatabaseWizardPage3 page3 = new RipDatabaseWizardPage3(&amp;quot;3&amp;quot;,
            spoon.getRepository());
    Wizard wizard = new Wizard() {
        public boolean performFinish() {
            try {
                JobMeta jobMeta = ripDBByNo(no, databases,
                    page3.getJobname(), page3.getRepositoryDirectory(),
                    page3.getDirectory(), page1.getSourceDatabase(),
                    page1.getTargetDatabase(), page2.getSelection());

                if (jobMeta == null)
                    return false;

                if (page3.getRepositoryDirectory() != null) {
                    spoon.saveToRepository(jobMeta, false);
                } else {
                    spoon.saveToFile(jobMeta);
                }

                addJobGraph(jobMeta);
                return true;
            } catch (Exception e) {
                new ErrorDialog(spoon.getShell(), &amp;quot;Error&amp;quot;,
                        &amp;quot;An unexpected error occurred!&amp;quot;, e);
                return false;
            }
        }

        public boolean canFinish() {
            return page3.canFinish();
        }
    };

    wizard.addPage(page1);
    wizard.addPage(page2);
    wizard.addPage(page3);

    WizardDialog wd = new WizardDialog(spoon.getShell(), wizard);
    WizardDialog.setDefaultImage(GUIResource.getInstance().getImageWizard());
    wd.setMinimumPageSize(700, 400);
    wd.updateSize();
    wd.open();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;该方法主要是创建一个向导，该向导中包括三个向导页，第一个向导页用于&lt;strong&gt;选择数据库连接&lt;/strong&gt;：源数据库和目标数据库连接；第二个向导页用于&lt;strong&gt;选表&lt;/strong&gt;；第三个向导页用于&lt;strong&gt;指定作业保存路径&lt;/strong&gt;。在向导完成的时候，即performFinish()方法里，会根据选择的数据源和表生成一个作业，即JobMeta对象。
创建Jobmeta的方法为：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public JobMeta ripDB(final List databases,final String jobname, final
    RepositoryDirectoryInterface repdir,final String directory, final DatabaseMeta
    sourceDbInfo,final DatabaseMeta targetDbInfo, final String[] tables){
 //此处省略若干代码
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;该方法主要逻辑在下面代码内：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;IRunnableWithProgress op = new IRunnableWithProgress() {
    public void run(IProgressMonitor monitor)
     throws InvocationTargetException, InterruptedException {
       //此处省略若干代码
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面代码中有以下代码用于遍历所选择的表生成作业中的一些节点：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;for (int i = 0; i &amp;amp;lt; tables.length &amp;amp;amp;&amp;amp;amp; !monitor.isCanceled(); i++) {
    //此处省略若干代码
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;针对每一张表先会创建一个JobEntrySQL节点，然后创建一个转换JobEntryTrans，可以在创建转换之后再创建一个JobEntrySQL节点，该节点用于添加主键和索引。
这部分的代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;String pksql = JdbcDataMetaUtil.exportPkAndIndex(
        sourceDbInfo, sourceCon, tables[i],
        targetDbInfo, targetCon, tables[i]);
if (!Const.isEmpty(pksql)) {
    location.x += 300;
    JobEntrySQL jesql = new JobEntrySQL(
        BaseMessages.getString(PKG,&amp;quot;Spoon.RipDB.AddPkAndIndex&amp;quot;)
            + tables[i] + &amp;quot;]&amp;quot;);
    jesql.setDatabase(targetDbInfo);
    jesql.setSQL(pksql);
    jesql.setDescription(BaseMessages.getString(PKG,
            &amp;quot;Spoon.RipDB.AddPkAndIndex&amp;quot;)
            + tables[i]
            + &amp;quot;]&amp;quot;);
    JobEntryCopy jecsql = new JobEntryCopy();
    jecsql.setEntry(jesql);
    jecsql.setLocation(new Point(location.x, location.y));
    jecsql.setDrawn();
    jobMeta.addJobEntry(jecsql);
    // Add the hop too...
    JobHopMeta jhi = new JobHopMeta(previous, jecsql);
    jobMeta.addJobHop(jhi);
    previous = jecsql;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;获取添加主键和索引的sql语句，主要是采用jdbc的方式读取两个数据库，判断源数据库的表中是否存在主键和索引，如果有则返回添加主键或索引的sql语句。这部分代码封装在JdbcDataMetaUtil类中。
该代码见：&lt;a href=&quot;https://gist.github.com/1564353.js&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/1564353.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最后的效果图如下：
&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/01/kettle-add-primary-key-and-indexes.png&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-2483&quot; title=&quot;kettle-add-primary-key-and-indexes&quot; src=&quot;http://blog.javachen.com/files/2012/01/kettle-add-primary-key-and-indexes-300x79.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;79&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;div class=&quot;infor&quot;&gt;说明：
1.以上代码使用的是jdbc的方法获取主键或索引，不同的数据库的jdbc驱动实现可能不同而且不同数据库的语法可能不同，故上面代码可能有待完善。
2.如果一个数据库中存在多库并且这多个库中有相同的表，使用上面的代码针对一个表名会查出多个主键或索引。这一点也是可以改善的&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>kettle进行数据迁移遇到的问题</title>
   <link href="http://blog.javachen.com/kettle/2012/01/04/some-problems-about-migrating-database-datas-with-kettle"/>
   <updated>2012-01-04T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/01/04/some-problems-about-migrating-database-datas-with-kettle</id>
   <content type="html">&lt;p&gt;使用kettle进行oracle或db2数据导入到mysql或postgres数据库过程中遇到以下问题，以下只是一个简单描述，详细的说明以及所做的代码修改没有提及。下面所提到的最新的pdi程序是我修改kettle源码并编译之后的版本。&lt;/p&gt;

&lt;h4&gt;同时运行两个pdi程序，例如：一个为oracle到mysql，另一个为oracle到postgres，其中一个停止运行&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：从oracle迁移到mysql创建的作业和转换文件和oracle到postgres的作业和转换保存到一个路径，导致同名称的转换相互之间被覆盖，故在运行时候会出现混乱。&lt;/li&gt;
&lt;li&gt;解决办法：将新建的作业和转换分别保存在两个不同的路径，最好是新建两个不同路径的仓库，关于如何新建仓库，请参考《kettle使用说明》文档。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;关键字的问题。&lt;/h4&gt;

&lt;p&gt;Oracle初始化到mysql，关键字前面会加上前缀“MY_”。如果在建表的时候出现错误，则需要检查表的字段中是否有关键字。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解决办法：出差的表单独进行处理，新建一个转换，实现关键字段该名称然后初始化出错的表。具体操作参见文档。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;oracle中的字段名从中可以有#号，但是到mysql会报错&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;解决办法：字段改名称，去掉#号&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Db2初始化到mysql或是postgres出错&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：1）db2数据库连接用户没有权限访问出错的表；2）出错的表名存在小写字母&lt;/li&gt;
&lt;li&gt;解决办法：使用更新后的pdi程序，更新后的程序会将db2的表名使用双引号括起来。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Oracle到mysql和pg时日期类型数据值有偏差&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：从oracle中读取日期类型的数据时候，读取结果与oracle数据库中的数据已经存在偏差。少数记录使用oracle10g的驱动读取数据少一个小时，用oracle11g的驱动会多一个小时，该问题尚待oracle工程师给出解决方案。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;主键从ORACLE导入不到MYSQL和POSTGRES&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：pdi程序中没有对主键进行处理&lt;/li&gt;
&lt;li&gt;解决办法：使用更新的pdi程序，执行Tools####Wizzard####Copy Tables Extension...功能添加主键；执行Tools####Wizzard####Copy Tables Data Only...功能可以只复制数据&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Oracle中存在ascii字符导入到postgres时候报错：ERROR: invalid byte sequence for encoding &amp;quot;UTF8&amp;quot;: 0x00&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：PostgreSQL内部采用C语言风格的字符串（以0x00）表示结尾，因而不允许字符串中包括0x00，建议在转换时先对字符串类型的数据进行清洗，也就是增加一个节点用于删除字符串数据中的特殊字符0x00。&lt;/li&gt;
&lt;li&gt;解决办法:使用新的pdi程序。在kettle的DataBase类中修改PreparedStatement.setString(int index,String value)方法传入的参数，将value的值trim之后在setString&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;异构数据库之间的类型兼容问题。日期类型和时间类型的数据初始化到mysql或postgres中都为时间类型的数据，导致数据对比时候数据不一致。&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：Pdi程序中的类型转换采用的是向上兼容的方式，故日期和时间类型都转换为时间类型数据。&lt;/li&gt;
&lt;li&gt;解决办法：针对与db2数据初始化到mysql和postgres，该问题在最新的pdi程序中已经处理。因为oracle中的日期类型字段既可以存日期又可以存时间，故没针对oracle数据做出处理。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Db2中没有主键的数据初始化到mysql和postgres需要添加索引&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;解决办法：使用最新的pdi程序，最新的pdi程序会添加主键和索引。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Db2中decimal（n,m）类型的数据初始化到postgres数据库被四舍五入。&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：Db2中decimal（n,m）类型的数据初始化到postgres中的类型不对。&lt;/li&gt;
&lt;li&gt;解决办法：使用最新的pdi程序。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;导数据中途时没有报错，直接软件退出&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：1）jvm内存溢出，需要修改jvm参数；2）pdi程序报swt错误&lt;/li&gt;
&lt;li&gt;解决办法：修改jvm参数&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;初次使用kettle做db2的初始化会报错&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：kettle中的db2的jdbc驱动与使用的db2版本不对应。&lt;/li&gt;
&lt;li&gt;解决办法：从db2的安装目录下拷贝jdbc驱动到kettle目录（libext/JDBC）下&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Mondrian and OLAP</title>
   <link href="http://blog.javachen.com/pentaho/2011/12/07/mondrian-and-olap"/>
   <updated>2011-12-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/pentaho/2011/12/07/mondrian-and-olap</id>
   <content type="html">&lt;p&gt;Mondrian是一个用Java编写的OLAP引擎。他执行用MDX语言编写的查询，从关系数据库（RDBMS）中读取数据并且通过Java API以多维度的格式展示查询结果。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #00ff00;&quot;&gt;Online Analytical Processing&lt;/span&gt;&lt;/strong&gt;
联机分析处理（OLAP）指在线实时的分析大量数据。与联机事务处理系统（On-&lt;wbr&gt;Line Transaction Processing，简称OLTP）不同，OLTP中典型的操作如读和修改单个的少量的记录，而OLAP批量处理数据并且所有操作都是只读的。“online”意味着即使是处理大量的数据----百万条数据记录，占有几个GB内存----系统必须足够快的反回查询结果以允许数据的交互式响应。正如我们将看到，数据展示面临相当大的技术挑战。&lt;/wbr&gt;&lt;/p&gt;

&lt;p&gt;OLAP引入了一种多维度查询的技术。鉴于一个关系数据库以行和列的形式存储所有数据，一个多维数据集包括轴和列。考虑下面的数据集：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/file/2011/12/olap_examples20111217.jpg&quot;&gt;&lt;img class=&quot;size-medium wp-image-2469 aligncenter&quot; title=&quot;olap_examples20111217&quot; src=&quot;/file/2011/12/olap_examples20111217-300x129.jpg&quot; alt=&quot;olap多维视图&quot; width=&quot;300&quot; height=&quot;129&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;行轴包括&quot;All products&quot;, &quot;Books&quot;,&quot;Fiction&quot;等等，并且列轴包括生产年份&quot;2000&quot;”和&quot;2001&quot;、&quot;Growth&quot;的计算值以及&quot;Unit sales&quot;和&quot;Dollar sales&quot;的测量值。每个单元代表在某一年的一个产品类别的销售额，例如2001年Magazines的$销售额是2426美元。&lt;/p&gt;

&lt;p&gt;这是一个比关系型数据库展现出来的更加丰富的视图。多维数据集的只不是永远都来自于一个关系数据库的列。 'Total', 'Books' and 'Fiction' 是一个具有层次结构连续的成员，每一个成员都包括其下一层的成员。即使是在&quot;2000&quot;和&quot;2001&quot;一行，&quot;Growth&quot;是一个计算出来的值，它引入一个公式从其他列计算当前列的值。&lt;/p&gt;

&lt;p&gt;该例中使用的维度有：产品、生产线和测量值，仅仅是这个数据集可以分类和过滤的许多维度中的三个。维度，层次结构和测量值的集合被称为一个立方体。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #00ff00;&quot;&gt;结论&lt;/span&gt;&lt;/strong&gt;
我希望我已经证明垛位是一个首选的数据显示方式。虽然一些多维数据库以多维度的格式存储数据库，我仍然认为这比以关系的格式存储数据要简单。&lt;br /&gt;
现在，你可以看看OLAP系统的架构。查看Mondrian architecture。http://mondrian.pentaho.com/documentation/architecture.php&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #00ff00;&quot;&gt;说明&lt;/span&gt;&lt;/strong&gt;
&lt;div class=&quot;note&quot;&gt;
这是一篇翻译，原文来自http://mondrian.pentaho.com/documentation/olap.php。翻译水平有限，难免翻译不当，请见谅。&lt;/div&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>XUL 用户界面语言介绍</title>
   <link href="http://blog.javachen.com/javascript/2011/11/25/xml-user-interface-language-introuction"/>
   <updated>2011-11-25T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/11/25/xml-user-interface-language-introuction</id>
   <content type="html">&lt;p&gt;XUL[1]是英文“&lt;span style=&quot;color: #339966;&quot;&gt;XML User Interface Language&lt;/span&gt;”的首字母缩写。它是为了支持Mozilla系列的应用程序（如Mozilla Firefox和Mozilla Thunderbird）而开发的用户界面标示语言。顾名思义，它是一种应用XML来描述用户界面的标示语言。&lt;br /&gt;
XUL是开放标准，重用了许多现有的标准和技术[2]，包括CSS、JavaScript、DTD和RDF等。所以对于有网络编程和设计经验的人士来说，学习XUL比学习其他用户界面标示语言相对简单。&lt;br /&gt;
使用XUL的主要好处在于它提供了一套简易和跨平台的widget定义。这节省了编程人员在开发软件时所付出的努力。&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;XUL元素&lt;/strong&gt;&lt;/span&gt;
XUL定义了一套丰富的元素。它们大致上可分为以下几种：&lt;br /&gt;
基层元素：例如视窗、page、对话框、向导&lt;br /&gt;
Widget:例如标签、按钮、文字方块、条列式菜单、组合方块、选择钮、复选框、树、菜单、工具栏、分组框、标签页、色彩选择器、spacer、splitter&lt;br /&gt;
排版:例如方框、网格、堆栈、叠&lt;br /&gt;
事件和脚本:例如脚本、命令、key、broadcaster、observer&lt;br /&gt;
数据源:例如template、rule&lt;br /&gt;
其他:例如overlay（类似SSI，但在客户端运作，而且更为强大）、iframe、浏览器、编辑器&lt;br /&gt;
一个XUL文件中也可以包含其他XML命名空间的元素，例如XHTML、SVG和MathML。&lt;br /&gt;
现时的XUL还未在提供一些普遍的widget，例如spinbox、slider和canvas。XUL 2.0[3]计划中将会包括这些缺乏的控件。&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;XUL是如何处理的&lt;/strong&gt;&lt;/span&gt;[4]&lt;br /&gt;
Mozilla浏览器内部使用跟HTML的处理非常相似的方法来处理XUL：当你在浏览器的地址栏里面输入HTML页面的URL以后，浏览器就定位这个网址并下载页面内容，然后Mozilla将页面内容转换成树的数据结构，最后再将树转换成对象集合，集合中的对象最终被展现在屏幕上就成了我们所见的网页。CSS, 图片以及其他技术被用来控制页面的展现。XUL的处理过程与此非常类似。&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;XUL应用&lt;/strong&gt;&lt;/span&gt;
虽然XUL的设计原意是为了创作Mozilla程序及其扩展，但事实上人们也能利用它来编写基于HTTP的网络应用程序和基于swt/swing/gwt的客户端程序。一些开源的架构使用了XUL，例如Pentaho XUL Framework[5]。Pentaho XUL使用XUl跨多种技术（Swing, SWT, GWT）渲染用户界面，来实现业务逻辑的可重用性。shandor-xul[6]项目也是基于XUl开发的,项目地址见参考资料[6]。&lt;br /&gt;
Firefox里内置的一些XUL 地址见：&lt;a href=&quot;http://www.cnblogs.com/jxsoft/archive/2011/04/07/2008202.html&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/jxsoft/archive/2011/04/07/2008202.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;运行XUL应用程序&lt;/strong&gt;&lt;/span&gt;
可以选择 3 种方式来运行 XUL 应用程序：&lt;br /&gt;
1.使用基于 Mozilla 的浏览器进行简单测试&lt;br /&gt;
2.使用XULRunner&lt;br /&gt;
3.使用Firefox 3.0作为XUL运行时，它的功能和 XULRunner很相似&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #339966;&quot;&gt;总结&lt;/span&gt;&lt;/strong&gt;
XUL用户界面语言是一种可用于开发Mozilla独立应用程序和浏览器扩展的通用语言，还可以用来实现跨多种UI技术的用户接口，提高业务逻辑代码的重用性，第二点视乎是更值得推荐使用的。关于XUl的教程见参考资料。&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;参考资料&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;li&gt;
1.XUL Wiki :&lt;a href=&quot;http://zh.wikipedia.org/wiki/XUL&quot; target=&quot;_blank&quot;&gt;http://zh.wikipedia.org/wiki/XUL&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;2.XML 用户界面语言（XUL）开发简介：&lt;a href=&quot;http://www.ibm.com/developerworks/cn/education/xml/x-xulintro/section2.html&quot; target=&quot;_blank&quot;&gt;http://www.ibm.com/developerworks/cn/education/xml/x-xulintro/section2.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;3.XUL 2.0: &lt;a href=&quot;https://wiki.mozilla.org/XUL:Home_Page&quot; target=&quot;_blank&quot;&gt;https://wiki.mozilla.org/XUL:Home&lt;em&gt;Page&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;4.XUL结构: &amp;lt;a href=&amp;quot;https://developer.mozilla.org/cn/XUL&lt;/em&gt;%E6%95%99%E7%A8%8B/1-2&lt;em&gt;XUL%E7%9A%84%E7%BB%93%E6%9E%84&amp;quot; target=&amp;quot;&lt;/em&gt;blank&amp;quot;&amp;gt;https://developer.mozilla.org/cn/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;5.Pentaho XUL ramework: &lt;a href=&quot;http://wiki.pentaho.com/display/ServerDoc2x/The+Pentaho+XUL+Framework+Developer's+Guide&quot; target=&quot;_blank&quot;&gt;http://wiki.pentaho.com/display/ServerDoc2x/The+Pentaho+XUL+Framework+Developer&amp;#39;s+Guide&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;6.shandor-xul:&lt;a href=&quot;http://code.google.com/p/shandor-xul/&quot; target=&quot;_blank&quot;&gt;http://code.google.com/p/shandor-xul/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;7.Mozilla XUL教程: &lt;a href=&quot;https://developer.mozilla.org/index.php?title=cn/XUL_%E6%95%99%E7%A8%8B&quot; target=&quot;_blank&quot;&gt;https://developer.mozilla.org/index.php&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ext读取xml文件生成动态表格和表单</title>
   <link href="http://blog.javachen.com/javascript/2011/10/22/ext_readxml_in_bjsasc_wuzi"/>
   <updated>2011-10-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/10/22/ext_readxml_in_bjsasc_wuzi</id>
   <content type="html">&lt;p&gt;最近开发项目，需要动态读取xml文件，生成Ext界面，xml文件通过前台页面的按钮事件传进来，可以在网上查找【javascript 弹出子窗口】的相关文章&lt;/a&gt;
获取弹出窗口url后的参数方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;// 获取url后的参数值
function getQueryStringValue(name) {
    var url = window.location.search;
    if (url.indexOf(&amp;#39;?&amp;#39;) &amp;lt; 0) {
        return null
    }
    var index = url.indexOf(name + &amp;quot;=&amp;quot;);
    if (index &amp;lt; 0) {
        return null
    }
    var args = url.indexOf(&amp;#39;&amp;amp;&amp;#39;, index);
    var value;
    if (args &amp;gt; 0) {
        value = url.substring(index + name.length + 1, args);
    } else {
        value = url.substring(index + name.length + 1, url.length);
    }
    return value;
}
// 获取xml的服务器路径
function getXmlUrl(xmlFile) {
    return &amp;#39;../bjsasc_dictionary/&amp;#39; + getQueryStringValue(&amp;#39;xmlFile&amp;#39;);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;用到的一些辅助方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;// 去掉Dom节点中的空白字符
function cleanWhitespaces(elem) {
    var elem = elem || document;
    var childElem = elem.childNodes;
    var childElemArray = new Array;
    for (var i = 0; i &amp;lt; childElem.length; i++) {
        if (childElem[i].nodeType == 1) {
            childElemArray.push(childElem[i]);
        }
    }
    return childElemArray;
}
// 取得父窗口表单中键值对
function getParentFormValues() {
    var formObj = window.opener.document.forms[&amp;quot;frmMain&amp;quot;].elements;
    var formValues = &amp;quot;&amp;quot;;
    for (var i = 0; i &amp;lt; formObj.elements.length; i++) {
        if (formObj.elements[i].value != null
                &amp;amp;&amp;amp; formObj.elements[i].value != &amp;quot;&amp;quot;
                &amp;amp;&amp;amp; formObj.elements[i].value.length != 0) {
            formValues += &amp;#39;_&amp;#39; + formObj.elements[i].name.toUpperCase() + &amp;#39;{&amp;#39;
                    + formObj.elements[i].value.toUpperCase() + &amp;#39;}&amp;#39;
                    + formObj.elements[i].name.toUpperCase() + &amp;#39;_ &amp;#39;;
        }
    }
    formValues += opener.getBindValue(formObj.elements);
    return formValues;
}
// 取得过滤条件表单的键值对
function getCondictionValues() {
    var condictionString = &amp;quot;&amp;quot;;
    var formObj = form.getForm().getEl().dom;
    for (var i = 0; i &amp;lt; formObj.elements.length; i++) {
        if (formObj.elements[i].value != null
                &amp;amp;&amp;amp; formObj.elements[i].value != &amp;quot;&amp;quot;
                &amp;amp;&amp;amp; formObj.elements[i].value.length != 0) {
            condictionString += &amp;#39;_&amp;#39; + formObj.elements[i].name + &amp;#39;{&amp;#39;
                    + formObj.elements[i].value + &amp;#39;}&amp;#39;
                    + formObj.elements[i].name + &amp;#39;_ &amp;#39;;
        }
    }
    // alert(&amp;quot;condictionString&amp;quot;+condictionString);
    return condictionString;
}
// 判读Ext表单是否有输入
function isFormInputed(ExtForm) {
    var flag = false;
    var formObj = ExtForm.getEl().dom;
    for (var i = 0; i &amp;lt; formObj.elements.length; i++) {
        if (formObj.elements[i].value != null
                &amp;amp;&amp;amp; formObj.elements[i].value != &amp;quot;&amp;quot;
                &amp;amp;&amp;amp; formObj.elements[i].value.length != 0) {
            flag = true;
            break;
        }
    }
    return flag;
}
// 将计算得到的结果四舍五入
/* * ForDight(Dight,How):数值格式化函数，Dight要 * 格式化的 数字，How要保留的小数位数。 */
function ForDight(Dight, How) {
    var Dight = Math.round(Dight * Math.pow(10, How)) / Math.pow(10, How);
    return Dight;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;xml文件格式：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt; ?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;gb2312&amp;quot;?&amp;gt;
&amp;lt; dictionary&amp;gt;
    &amp;lt;title&amp;gt;领用出库-物资选择&amp;lt;/title&amp;gt;
    &amp;lt;sql&amp;gt;
    select V_stores_list.* 
    from V_stores_list where WHID=&amp;#39;+$getform(WHID)+&amp;#39; AND PROJECTNO=&amp;#39;+$getform(PROJECTNO)+&amp;#39;
        AND CANUSEQTY&amp;gt;0 AND ??? and isblock=0
    &amp;lt;/sql&amp;gt;
    &amp;lt;fromtable&amp;gt;V_stores_list&amp;lt;/fromtable&amp;gt;
    &amp;lt;targettable&amp;gt;BO_IC_EXPORT_S&amp;lt;/targettable&amp;gt;
    &amp;lt;line&amp;gt;20&amp;lt;/line&amp;gt;
    &amp;lt;!-- 条件区开始--&amp;gt;
    &amp;lt;condition&amp;gt;
        &amp;lt;fieldname&amp;gt;MTRNAME&amp;lt;/fieldname&amp;gt;
        &amp;lt;fieldtitle&amp;gt;物资名称&amp;lt;/fieldtitle&amp;gt;
        &amp;lt;fieldtype&amp;gt;文本&amp;lt;/fieldtype&amp;gt;
        &amp;lt;comparetype&amp;gt;&amp;lt; ![CDATA[like
        MTRNAME
        单行
        &amp;lt; ![CDATA[]]&amp;gt;       
        &amp;lt;/comparetype&amp;gt;
    &amp;lt;/ condition&amp;gt;
&amp;lt;/ dictionary&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后，弹出窗口页面Ext入口代码：
    // 全局变量
    var result = {};
    var grid;
    var form;
    var viewport;
    var store;
    var sm = new Ext.grid.CheckboxSelectionModel();
    var autoStore;
    var tempItems1 = [];
    var tempItems2 = [];
    var tempItems3 = [];
    var flag = 1;
    // 程序入口
    Ext.onReady(function() {
        Ext.QuickTips.init();// 初始化
        Ext.form.Field.prototype.msgTarget = &amp;#39;qtip&amp;#39;;// 统一指定错误信息提示方式
        Ext.util.CSS    .swapStyleSheet(&amp;#39;theme&amp;#39;, &amp;#39;../aws&lt;em&gt;js/extjs2/css/xtheme-gray.css&amp;#39;);// 更换皮肤
        Ext.BLANK&lt;/em&gt;IMAGE&lt;em&gt;URL = &amp;#39;../aws&lt;/em&gt;js/extjs2/images/default/s.gif&amp;#39;;
        Ext.Ajax.request({
            url : getXmlUrl(getQueryStringValue(&amp;#39;xmlFile&amp;#39;)), // 访问数据字典
            method : &amp;#39;post&amp;#39;,
            success : function(res, opt) {
                var xmlObj = res.responseXML;
                initStoreData(xmlObj); // 访问成功后执行后续工作
            }
        })
    });
    function initStoreData(xmlObj) {
        getInitData(xmlObj);
        document.title = result.winTitle;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;    var dataRecorder = Ext.data.Record.create(result.gridRecords);// 指定记录集格式
    // 获取表格数据部分
    store = new Ext.data.Store({
        idProperty : &amp;#39;ID&amp;#39;,
        proxy : new Ext.data.HttpProxy({
            url : &amp;#39;../search.do?method=findAll&amp;#39;,
            failure : function() {
                // Ext.Msg.alert(&amp;quot;Notice&amp;quot;, &amp;quot;网路问题&amp;quot;);
            },
            success : function(response) {
                // Ext.Msg.alert(&amp;quot;Notice&amp;quot;, response.responseText);
            }
        }),

        // baseParams : {
        // parentFormValues : getParentFormValues(),// 请求发送的参数：父表单值和xml文件名
        // xmlFile : getQueryStringValue(&amp;#39;xmlFile&amp;#39;)
        // // cmd:&amp;#39;search&amp;#39;
        // },
        reader : new Ext.data.JsonReader({
            totalProperty : &amp;#39;totalCount&amp;#39;,
            root : &amp;#39;data&amp;#39;
        }, dataRecorder)
    });
    // 要分页，第一次加载数据必须传start和limit两参数
    // store.load({
    // params : {
    // start : 0,
    // limit : result.limit
    // }
    // });
    initViewport();
}
// 获得界面初始化的一些数据
function getInitData(xmlObj) {
    // result.formItems = {};
    result.columnHeaders = [];
    result.gridRecords = [];
    result.dbFilterRecords = [];
    result.winTitle = xmlObj.getElementsByTagName(&amp;quot;title&amp;quot;)[0].firstChild.nodeValue; // 窗口title名称
    result.limit = xmlObj.getElementsByTagName(&amp;quot;line&amp;quot;)[0].firstChild.nodeValue;// 分页数据
    result.fromTable = xmlObj.getElementsByTagName(&amp;quot;fromTable&amp;quot;)[0].firstChild.nodeValue;// 来自哪个表
    // 获取过滤条件表单的界面数据
    var conections = xmlObj.getElementsByTagName(&amp;quot;condition&amp;quot;);
    var row = ForDight(conections.length / 3, 0);
    for (var i = 0; i &amp;lt; conections.length; i++) {
        var item = {};
        var condition = cleanWhitespaces(conections[i]);
        item.id = condition[0].firstChild.nodeValue;
        item.fieldLabel = condition[1].firstChild.nodeValue;
        item.name = condition[4].firstChild.nodeValue;
        item.anchor = &amp;#39;95%&amp;#39;;
        if (condition[6].firstChild.nodeValue == &amp;#39;单行&amp;#39;) {
            item.xtype = &amp;#39;textfield&amp;#39;;
        } else if (condition[6].firstChild.nodeValue == &amp;#39;日期&amp;#39;) {
            item.xtype = &amp;#39;datefield&amp;#39;;
            item.format = &amp;#39;Y-m-d&amp;#39;;
        } else if (condition[6].firstChild.nodeValue == &amp;#39;数值&amp;#39;) {
            item.xtype = &amp;#39;numberfield&amp;#39;;
            item.minValue = 0;
            item.minText = &amp;#39;请输入有效的数字&amp;#39;;
            item.decimalPrecision = 6;
        } else if (condition[6].firstChild.nodeValue == &amp;#39;自动填充&amp;#39;) {
            var autoStore = new Ext.data.SimpleStore({
                proxy : new Ext.data.HttpProxy({// 读取远程数据的代理
                    url : &amp;#39;../ajax/autoComplete.do?method=autoComplete&amp;#39;,
                    failure : function() {
                        Ext.Msg.alert(&amp;quot;Notice&amp;quot;, &amp;quot;no records&amp;quot;);
                    }
                }),
                fields : [&amp;#39;property&amp;#39;],
                baseParams : {
                    &amp;#39;sqlString&amp;#39; : condition[4].firstChild.nodeValue + &amp;#39; | &amp;#39;
                            + result.fromTable
                }
            });
            item.xtype = &amp;#39;combo&amp;#39;;
            item.store = autoStore;
            item.displayField = &amp;#39;property&amp;#39;;
            item.typeAhead = true;
            item.allQuery = &amp;#39;all&amp;#39;;// 查询信息的查询字符串
            item.queryParam = &amp;#39;keyword&amp;#39;;// 查询的名字
            item.mode = &amp;#39;remote&amp;#39;;
            item.minChars = 3;// 默认最少输入4
            item.forceSelection = true;
            item.queryDelay = 0;// 查询延迟时间
            item.triggerAction = &amp;#39;all&amp;#39;;
            item.emptyText = &amp;#39;&amp;#39;;
            item.resizable = true;
            item.selectOnFocus = true;
        }
        if (i / row &amp;lt; 1) {
            tempItems1.push(item);
        }
        if (i / row &amp;lt; 2 &amp;amp;&amp;amp; i / row &amp;gt;= 1) {
            tempItems2.push(item);
        } else if (i / row &amp;gt;= 2) {
            tempItems3.push(item);
        }
    }
    // alert(Ext.util.JSON.encode(result));

    // 获取表格表头的界面数据和rcord记录的数据格式
    var fields = xmlObj.getElementsByTagName(&amp;quot;field&amp;quot;);
    result.columnHeaders.push(sm);// 插入多选框
    result.columnHeaders.push(new Ext.grid.RowNumberer({
        width : 20
    }));// 插入行号
    for (var i = 0; i &amp;lt; fields.length; i++) {
        var item = {};
        var record = {};
        var array = [];
        var field = cleanWhitespaces(fields[i]);
        var renderDate = function(value) {
            return value ? value.dateFormat(&amp;#39;Y-m-d&amp;#39;) : &amp;#39;&amp;#39;;
        }
        // 生成grid表格中store数据记录
        record.name = field[0].firstChild.nodeValue;
        record.mapping = field[0].firstChild.nodeValue;
        if (field[1].firstChild.nodeValue == &amp;#39;日期&amp;#39;) {
            record.type = &amp;#39;date&amp;#39;;
            record.dateFormat = &amp;#39;Y-m-d&amp;#39;;
            item.renderer = Ext.util.Format.dateRenderer(&amp;#39;Y-m-d&amp;#39;)
        } else if (field[1].firstChild.nodeValue == &amp;#39;数值&amp;#39;) {
            record.type = &amp;#39;auto&amp;#39;;
        } else {
            record.type = &amp;#39;string&amp;#39;;
        }
        result.gridRecords.push(record);

        // 生成grid表格表头数据记录
        item.dataIndex = field[0].firstChild.nodeValue;
        item.header = field[2].firstChild.nodeValue;
        // item.width=field[3].firstChild.nodeValue;
        item.sortable = true;
        if (field.length == 7
                &amp;amp;&amp;amp; field[5].firstChild.nodeValue.toUpperCase() == &amp;#39;TRUE&amp;#39;) {
            item.hidden = true;
            // item.hideable=false;
        }
        if (field.length == 6) {
            item.hidden = false;
        }
        result.columnHeaders.push(item);

        // 生成模糊过滤store的记录
        if (field[4].firstChild.nodeValue.toUpperCase() == &amp;#39;TRUE&amp;#39;) {
            array.push(field[2].firstChild.nodeValue);// fieldName
            array.push(field[0].firstChild.nodeValue);// fieldValue
        }
        result.dbFilterRecords.push(array);
    }
    return result;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;渲染Ext界面代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;function initViewport() {
    if (!form) {
        form = getInsertForm();
    }

    if (!grid) {
        grid = getInsertGrid();
    }

    if (!viewport) {
        var formPanel = new Ext.Panel({
            title : &amp;#39;查询条件&amp;#39;,
            region : &amp;#39;north&amp;#39;,
            split : true,
            frame : true,
            border : true,
            layout : &amp;#39;fit&amp;#39;,
            height : 280,
            collapsible : true,
            items : [form]

        });
        viewport = new Ext.Viewport({
            layout : &amp;#39;border&amp;#39;,
            modal : true,// 是否为模式窗口
            border : false,
            items : [formPanel, grid]
        });
    }
}

function searchByFilter() {
    var dbfilter = Ext.get(&amp;quot;dbFilter&amp;quot;).getValue();
    var fieldMame = Ext.get(&amp;quot;search-type&amp;quot;).getValue();
    if (dbfilter == null || dbfilter == &amp;quot;&amp;quot;) {
        alert(&amp;quot;请输入一个关键字&amp;quot;);
        Ext.get(&amp;quot;dbFilter&amp;quot;).focus();
    } else if (fieldMame == &amp;quot;==选择过滤字段==&amp;quot;) {
        alert(&amp;quot;请选择一个过滤字段&amp;quot;);
        Ext.get(&amp;quot;search-type&amp;quot;).focus();
    } else {
        form.getForm().reset();
        if (flag == 1) {
            store.baseParams = {
                dbfilter : dbfilter,
                parentFormValues : getParentFormValues(),
                fieldMame : Ext.get(&amp;quot;hiddenValue&amp;quot;).dom.value,
                xmlFile : getQueryStringValue(&amp;#39;xmlFile&amp;#39;),
                cmd : &amp;#39;filter&amp;#39;
            };
            store.load({
                params : {
                    start : 0,
                    limit : result.limit
                }
            });
            form.getForm().reset();
            flag = 0;
        } else {
            store.baseParams = {
                dbfilter : dbfilter,
                parentFormValues : getParentFormValues(),
                fieldMame : Ext.get(&amp;quot;hiddenValue&amp;quot;).dom.value,
                xmlFile : getQueryStringValue(&amp;#39;xmlFile&amp;#39;),
                cmd : &amp;#39;filter&amp;#39;
            };
            store.reload();

        }
        Ext.get(&amp;quot;dbFilter&amp;quot;).dom.value = &amp;quot;&amp;quot;;
    }
}
// 获取过滤条件部分的表单控件
function getInsertForm() {
    form = new Ext.form.FormPanel({
        name : &amp;#39;frmMain&amp;#39;,
        height : 260,
        labelAlign : &amp;#39;left&amp;#39;,
        labelWidth : 110,
        layout : &amp;#39;fit&amp;#39;,
        waitMsgTarget : true,
        items : [{
            xtype : &amp;#39;fieldset&amp;#39;,
            frame : true,
            title : &amp;#39;高级查询&amp;#39;,
            autoHeight : true,
            layout : &amp;#39;column&amp;#39;,
            items : [{
                columnWidth : .333,
                layout : &amp;#39;form&amp;#39;,
                items : tempItems1
            }, {
                columnWidth : .333,
                layout : &amp;#39;form&amp;#39;,
                items : tempItems2
            }, {
                columnWidth : .333,
                layout : &amp;#39;form&amp;#39;,
                items : tempItems3
            }]
        }],
        tbar : [&amp;#39;请输入模糊值: &amp;#39;, &amp;#39; &amp;#39;, {
            xtype : &amp;#39;textfield&amp;#39;,
            width : 200,
            id : &amp;#39;dbFilter&amp;#39;,
            listeners : {
                specialkey : function(field, e) {
                    if (e.getKey() == Ext.EventObject.ENTER) {
                        searchByFilter();
                    }
                }
            }
        }, &amp;#39;-&amp;#39;, {
            xtype : &amp;#39;combo&amp;#39;,
            id : &amp;#39;search-type&amp;#39;,
            anchor : &amp;#39;60%&amp;#39;,
            hiddenName : &amp;#39;hiddenValue&amp;#39;,
            width : 120,
            triggerAction : &amp;#39;all&amp;#39;,// 单击触发按钮显示全部数据
            store : new Ext.data.SimpleStore({// 定义组合框中显示的数据源
                fields : [&amp;#39;fieldName&amp;#39;, &amp;#39;fieldValue&amp;#39;],
                data : result.dbFilterRecords
            }),// 设置数据源
            displayField : &amp;#39;fieldName&amp;#39;,// 定义要显示的字段
            valueField : &amp;#39;fieldValue&amp;#39;,// 定义值字段
            mode : &amp;#39;local&amp;#39;,// 本地模式
            forceSelection : true,// 要求输入值必须在列表中存在
            typeAhead : true,// 允许自动选择匹配的剩余部分文本
            // value : &amp;#39;==选择过滤字段==&amp;#39;,
            value : &amp;#39;==选择过滤字段==&amp;#39;,
            handleHeight : 10
                // 下拉列表中拖动手柄的高度
                }, &amp;#39;-&amp;#39;, {
                    xtype : &amp;#39;button&amp;#39;,
                    text : &amp;#39;筛选&amp;#39;,
                    tooltip : &amp;#39;先选择查询条件，再输入模糊值&amp;#39;,
                    iconCls : &amp;#39;find&amp;#39;,
                    handler : searchByFilter
                }, &amp;#39;-&amp;gt;&amp;#39;, {
                    pressed : true,
                    xtype : &amp;#39;button&amp;#39;,
                    text : &amp;#39;确认插入&amp;#39;,
                    enableToggle : true,
                    tooltip : &amp;#39;请选中一行或多行记录，再选择确认插入&amp;#39;,
                    handler : function() {
                        if (sm.hasSelection()) {
                            var records = sm.getSelections();
                            var jsonObj = &amp;quot;{data:[&amp;quot;;
                            for (var i = 0; i &amp;lt; records.length; i++) {
                                jsonObj += Ext.encode(records[i].data);
                                if (i != records.length - 1) {
                                    jsonObj += &amp;quot;,&amp;quot;;
                                }
                            }
                            jsonObj += &amp;quot;]}&amp;quot;
                            Ext.Ajax.request({
                                url : &amp;#39;../search.do?method=insertChoices&amp;#39;,
                                method : &amp;#39;post&amp;#39;,
                                params : {
                                    xmlFile : getQueryStringValue(&amp;#39;xmlFile&amp;#39;)
                                            .toString(),
                                    jsonObj : jsonObj,
                                    parentFormValues : getParentFormValues()
                                },
                                callback : function(options, success, response) {
                                    if (response.responseText == &amp;quot;success&amp;quot;) {

                                        Ext.Msg.alert(&amp;quot;提示&amp;quot;, &amp;quot;插入成功&amp;quot;, function() {
                                            window.close();
                                            // opener.location.reload();
                                        opener.saveForm();
                                        });
                                    } else {
                                        Ext.Msg.alert(&amp;quot;提示&amp;quot;, &amp;quot;插入失败&amp;quot;);
                                    }
                                }
                            })

                        } else {
                            alert(&amp;quot;请选择一行或多行数据&amp;quot;);
                        }
                    },
                    scope : this
                }, &amp;#39;-&amp;#39;, {
                    pressed : true,
                    xtype : &amp;#39;button&amp;#39;,
                    text : &amp;#39;取消&amp;#39;,
                    tooltip : &amp;#39;取消选择，直接退出&amp;#39;,
                    handler : function() {
                        Ext.Msg.confirm(&amp;#39;Notice&amp;#39;, &amp;#39;确认退出？&amp;#39;, function(id) {
                            if (id == &amp;quot;yes&amp;quot;)
                                window.close();
                        });
                    },
                    scope : this
                }],
        buttons : [{
            text : &amp;#39;执行查询条件&amp;#39;,
            handler : function() {
                var connections = getCondictionValues();
                if (!form.getForm().isValid()) {
                    return;
                };
                if (isFormInputed(form.getForm()) == false) {
                    alert(&amp;quot;请输入查询条件&amp;quot;);
                    form.getForm().focus();
                    return;
                } else {
                    Ext.get(&amp;quot;dbFilter&amp;quot;).dom.value = &amp;quot;&amp;quot;;
                    if (flag == 1) {
                        store.baseParams = {
                            xmlFile : getQueryStringValue(&amp;#39;xmlFile&amp;#39;),
                            condictions : connections,
                            parentFormValues : getParentFormValues(),
                            cmd : &amp;#39;search&amp;#39;
                        };
                        store.load({
                            params : {
                                start : 0,
                                limit : result.limit
                            }
                        });
                        form.getForm().reset();
                        flag = 0;
                    } else {
                        store.baseParams = {
                            xmlFile : getQueryStringValue(&amp;#39;xmlFile&amp;#39;),
                            condictions : connections,
                            parentFormValues : getParentFormValues(),
                            cmd : &amp;#39;search&amp;#39;
                        };
                        store.reload();
                    }

                    form.getForm().reset();
                }
            }
        }, {
            text : &amp;#39;重置&amp;#39;,
            handler : function() {
                form.getForm().reset();
            }
        }]
    });
    return form;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>在eclipse中构建Pentaho BI Server工程</title>
   <link href="http://blog.javachen.com/pentaho/2011/09/28/build-pentaho-bi-server-source-code-in-eclipse"/>
   <updated>2011-09-28T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/pentaho/2011/09/28/build-pentaho-bi-server-source-code-in-eclipse</id>
   <content type="html">&lt;p&gt;首先需要说明的是，Pentaho BI Server源代码在&lt;em&gt;svn://source.pentaho.org/svnroot/bi-platform-v2/trunk/&lt;/em&gt;，并且用ivy构建。ivy没有用过也不熟悉，故不打算从这里使用ivy构建源码。&lt;/p&gt;

&lt;p&gt;当然，您可以参考&lt;a href=&quot;http://wiki.pentaho.com/display/ServerDoc2x/Building+and+Debugging+Pentaho+with+Eclipse&quot; target=&quot;_blank&quot;&gt;官方文档&lt;/a&gt;构建源码。&lt;/p&gt;

&lt;p&gt;Pentaho BI Server打包后的文件存于&lt;a href=&quot;http://sourceforge.net/projects/pentaho/files/Business%20Intelligence%20Server/&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;，其中包括（本文使用的是3.9.0版本）：biserver-ce-3.9.0-stable.zip，bi-platform-3.9.0-stable-sources.zip，biserver-ce-3.9.0-stable-javadoc.zip。&lt;/p&gt;

&lt;p&gt;将biserver-ce-3.9.0-stable.zip解压之后执行&lt;em&gt;biserver-ce/start-pentaho.bat&lt;/em&gt;（或是再linux环境下：&lt;em&gt;biserver-ce/start-pentaho.sh&lt;/em&gt;），即可成功启动biserver。现在我想将这个工程导入到eclipse然后调式跟踪代码，怎么做呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;以下操作是在eclipse3.7+tomcat 6.20的环境中进行的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在eclipse中创建一个web项目，名称为pentaho，然后将&lt;em&gt;biserver-ce/tomcat/webapps&lt;/em&gt;下的&lt;code&gt;pentaho-style&lt;/code&gt;和&lt;code&gt;sw-style&lt;/code&gt;拷贝到你的tomcat 6服务器的webapps目录下，将pentaho文件下的所有文件拷贝到工程下的WebContent目录下。由于biserver需要访问pentaho-solutions下的文件，故还需要修改&lt;code&gt;WEB-INF/web.xml&lt;/code&gt;文件你的以下配置，用于指定pentaho-solutions的路径：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt; context-param &amp;gt;
    &amp;lt; param-name &amp;gt;solution-path&amp;lt; /param-name&amp;gt;
    &amp;lt; param-value &amp;gt;/home/june.chan/opt/biserver-ce/pentaho-solutions&amp;lt; /param-value&amp;gt;
&amp;lt; /context-param &amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;现在即可部署项目，运行&lt;code&gt;biserver-ce/data/start_hypersonic.bat&lt;/code&gt;（用于启动数据库），然后启动tomcat，就可以通过&lt;em&gt;http://localhost:8080/pentaho&lt;/em&gt;访问biserver。如果启动报错，需要将hsqldb-1.8.0.7.jar包，拷贝到应用路径下（&lt;em&gt;\tomcat-pci-test\biserver-ce\tomcat\webapps\pentaho\WEB-INF\lib&lt;/em&gt;）。&lt;br /&gt;
现在可以看到biserver的登录页面，但是还是没有看到biserver的源代码。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;接下来，构建源代码。&lt;/strong&gt;
在biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib下面有很多名称为pentaho-bi-platform-########-3.9.0-stable.jar的jar文件，这些即是biserver源码编译之后的class文件。在bi-platform-3.9.0-stable-sources.zip压缩文件你即可以看到这些class文件的源代码。将这些src包解压然后拷贝到之前新建的pentaho工程的src目录下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;font color=&quot;red&quot;&gt;需要注意的是：&lt;/font&gt;&lt;/strong&gt;
1.这些src jar包你只报告java文件，不包括配置文件：log4j配置文件，hibernate配置和实体映射文件，ehcache配置文件&lt;br /&gt;
2.上面的配置文件需要到biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib目录下的pentaho-bi-platform-########-3.9.0-stable.jar文件中寻找。&lt;br /&gt;
3.
* biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-engine-security-3.9.0-stable.jar文件中有ldap的配置文件，
* biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-engine-services-3.9.0-stable.jar文件中有ehcache的配置文件，
* biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-plugin-actions-3.9.0-stable.jar文件中有log4j的配置文件，
* biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-repository-3.9.0-stable.jar文件中有hibernate配置文件，
* biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-security-userroledao-3.9.0-stable.jar文件中有hibernated的实体映射文件。&lt;/p&gt;

&lt;p&gt;4.biserver-ce-3.9.0-stable.zip的lib（&lt;code&gt;biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib&lt;/code&gt;）目录下的servlete jar包的版本为2.3，版本过低需要替换为更高版本知道源码中不在有servlete编译错误&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pentaho现场支持遇到问题及解决办法</title>
   <link href="http://blog.javachen.com/pentaho/2011/09/26/resolved-pentaho-problems-9-16"/>
   <updated>2011-09-26T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/pentaho/2011/09/26/resolved-pentaho-problems-9-16</id>
   <content type="html">&lt;p&gt;很久没写文章了，最近在关注Pentaho。&lt;br /&gt;
 以下是9月16日现场提出的问题解决办法：&lt;br /&gt;
      1、PDF预览中文没显示，txt预览中文乱码：&lt;br /&gt;
           1）、设置File-&gt;Configuration -&gt;output-pageable-pdf的encoding 为Identity-H&lt;br /&gt;
           2）、将需要输出中文的报表项目的字体设置为中文字体，例如宋体&lt;br /&gt;
           3）、如要发布到服务器，需要修改如下的配置：&lt;br /&gt;
             pentaho/server/biserver-ee/tomcat/webapps/pentaho/WEB-INF/classes/classic-engine.properties：&lt;br /&gt;
             org.pentaho.reporting.engine.classic.core.modules.output.pageable.pdf.Encoding=Identity-H&lt;br /&gt;
     2、实现文件拷贝方式发布报表&lt;br /&gt;
           可以通过文件方式发布，只要将报表的prpt文件拷贝到Solution的目录（Pentaho安装路径的server\biserver-ee\pentaho-solutions）下就可以了&lt;br /&gt;
     3、报表链接参数传递问题&lt;br /&gt;
          由于参数带中文造成的，可以对参数的值URLENCODE(&quot;value&quot;; &quot;utf-8&quot;)来解决&lt;br /&gt;
     4、查询参数缺省值问题&lt;br /&gt;
          关于日期的默认值。可以使用报表系统提供的日期变量设置，如TODAY，DATE，YEAR。。。&lt;br /&gt;
     5、实现在pie chart上显示文字&lt;br /&gt;
          以把label默认显示的百分比改为文字：label-formate = {0}， 但是label显示百分比，同时在pie图的划分区域显示文字是不能的。&lt;br /&gt;
     6、报表集成时候垂直滚动条是否可以去掉&lt;br /&gt;
          改变报表的高度：报表设计器 file-page setup&lt;br /&gt;
     7、报表中的chart不能导出到Excel2007&lt;br /&gt;
          目前为系统bug，excel2003能够正常导出&lt;br /&gt;
     8、实现隔行换色&lt;br /&gt;
          选中Details中的field再attribute面板上设置name的名称（如“row-band”），然后通过Format--&gt;Row-Banding，可以设置Visible Color 、Inisible Color，再Element中输入&quot;row-band&quot;&lt;br /&gt;
     9、显示top N  ：托一个message field，在里面输入表达式，如，$（topn）,topn为传入的参数&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>在Fedora 15 上搭建Eucalyptus</title>
   <link href="http://blog.javachen.com/cloud/2011/08/20/install-eucalyptus-on-fedora-15"/>
   <updated>2011-08-20T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/08/20/install-eucalyptus-on-fedora-15</id>
   <content type="html">&lt;p&gt;&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://open.eucalyptus.com/themes/eucalyptus/img/eucalyptus_logo_awh.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
在Fedora 15 上搭建Eucalyptus平台，在Fedora 15 上搭建Eucalyptus与在Centos上搭建Eucalyptus有什么区别呢？参照这篇文章&lt;a href=&quot;http://open.eucalyptus.com/wiki/EucalyptusInstallationFedora_v2.0&quot; target=&quot;_blank&quot;&gt;Installing Eucalyptus (2.0) on Fedora 12&lt;/a&gt;，然后注意一些细节，视乎就能安装成功。不管你信不信，我是在虚拟机中安装fedora15，然后安装Eucalyptus失败了，失败的原因是xen的网络没有配置好，查看资源的时候free / max都为0000.&lt;/p&gt;

&lt;p&gt;毕竟是第一次接触云计算，第一次接触XEN，第一次接触Eucalyptus，Eucalyptus改装的都装了，就是XEN的网络没有配置好，当时很是迷糊。在接触了OpenNebula 和OpenStack之后，横向对比，视乎明白了很多千丝万缕的关联与奥秘。在安装OpenNebula，最主要是安装OpenStack成功之后，想到了之前Eucalyptus安装失败的原因。限于现在精力不在云计算上，暂且不去重新安装Eucalyptus，等之后再去尝试。下次尝试，定是醍醐灌顶，行云流水，很是期待。&lt;/p&gt;

&lt;p&gt;如果你也在Fedora上安装Eucalyptus平台，咱们可以交流交流，等到时机成熟，会将在Fedora 15 上搭建Eucalyptus的过程及遇到的问题发表在博客上；如果你想研究Eucalyptus平台java部分的代码，咱们也可以彼此分享各自的心得。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Export DhtmlxGrid to PDF in Java</title>
   <link href="http://blog.javachen.com/javascript/2011/08/11/export-dhtmlxgrid-to-pdf-in-java"/>
   <updated>2011-08-11T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/08/11/export-dhtmlxgrid-to-pdf-in-java</id>
   <content type="html">&lt;p&gt;将DhtmlxGrid数据导出到pdf这是很常见的需求，dhtmlx官网提供了php和java版本的例子，你可以去官网查看这篇文章《&lt;a href=&quot;http://www.dhtmlx.com/blog/?p=855&quot;&gt;Grid-to-Excel, Grid-to-PDF Available for Java&lt;/a&gt;》，你可以从以下地址下载导出程序源码：
&lt;a href=&quot;http://www.dhtmlx.com/x/download/regular/export/XML2Excel.war&quot;&gt;Export to Excel&lt;/a&gt;
&lt;a href=&quot;http://www.dhtmlx.com/x/download/regular/export/XML2PDF.war&quot;&gt;Export to PDF&lt;/a&gt;
当然，还有一个示例工程：&lt;a href=&quot;http://www.dhtmlx.com/x/download/regular/export/javaexport_sample.zip&quot;&gt; .zip archive with an example&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;XML2PDF和XML2Excel工程内代码很相似，XML2PDF内部使用了PDFjet.jar导出PDF，而XML2Excel使用JXL导出Excel。
需要说明的是，还需要引入dhtmlxgrid_export.js文件，该文件是导出grid的js源码，主要用于将表格数据，包括表头、样式等，序列化为xml字符串，然后模拟一个Form表单提交数据。&lt;/p&gt;

&lt;p&gt;将上面三个工程导入到一个工程然后打开sample.html页面，效果如下：
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;/files/2011/08/export-dhtmlxgrid-to-pdf.png&quot; alt=&quot;&quot; title=&quot;export dhtmlxgrid to pdf&quot; width=&quot;300&quot; height=&quot;166&quot; class=&quot;aligncenter size-medium wp-image-2385&quot; /&gt;
&lt;/div&gt;
点击Get as PDF按钮，你会发现会打开一个新的窗口，然后页面什么都没有，而eclipse控制台报空指针异常。异常的主要原因在于下段代码：。
&lt;pre lang=&quot;java&quot;&gt;
DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance ();
DocumentBuilder db = dbf.newDocumentBuilder();
Document dom = null;
try {
     dom = db.parse(new InputSource(new StringReader(xml)));
}catch(SAXException se) {
     se.printStackTrace();
}catch(IOException ioe) { 
     ioe.printStackTrace();
}
root = dom.getDocumentElement();
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;上面的代码，DocumentBuilder解析xml字符串后dom对象内并没有数据。
为了能够看到DhtmlxGrid导出pdf的效果，决定将上面的代码用dom4j改写，于是有了下面的代码：
&lt;pre lang=&quot;java&quot;&gt;
public class PDFXMLParser {
    Element root;
    PDFColumn[][] columns;
    PDFRow[] rows;
    double[] widths;
    private Boolean header = false;
    private Boolean footer = false;
    private String profile = &amp;quot;gray&amp;quot;;
    private double[] orientation = null;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public void setXML(String xml) {
    SAXReader saxReader = new SAXReader();

    Document document = null;
    try {
        document = saxReader.read(new ByteArrayInputStream(xml.getBytes()));
    } catch (DocumentException e) {
        e.printStackTrace();
    }
    root = document.getRootElement();

    if ((root.attributeValue(&amp;quot;header&amp;quot;) != null)
            &amp;amp;amp;&amp;amp;amp; (root.attributeValue(&amp;quot;header&amp;quot;).equalsIgnoreCase(&amp;quot;true&amp;quot;) == true)) {
        header = true;
    }
    String footer_string = root.attributeValue(&amp;quot;footer&amp;quot;);
    if ((footer_string != null)
            &amp;amp;amp;&amp;amp;amp; (footer_string.equalsIgnoreCase(&amp;quot;true&amp;quot;) == true)) {
        footer = true;
    }
    String profile_string = root.attributeValue(&amp;quot;profile&amp;quot;);
    if (profile_string != null) {
        profile = profile_string;
    }

    String orientation_string = root.attributeValue(&amp;quot;orientation&amp;quot;);
    if (orientation_string != null) {
        if (orientation_string.equalsIgnoreCase(&amp;quot;landscape&amp;quot;)) {
            orientation = A4.LANDSCAPE;
        } else {
            orientation = A4.PORTRAIT;
        }
    } else {
        orientation = Letter.PORTRAIT;
    }
}

public PDFColumn[][] getColumnsInfo() {
    PDFColumn[] colLine = null;
    List n1 = root.element(&amp;quot;head&amp;quot;).elements(&amp;quot;columns&amp;quot;);
    if ((n1 != null) &amp;amp;amp;&amp;amp;amp; (n1.size() &amp;amp;gt; 0)) {
        columns = new PDFColumn[n1.size()][];
        for (int i = 0; i &amp;amp;lt; n1.size(); i++) {
            Element cols = (Element) n1.get(i);
            List n2 = cols.elements(&amp;quot;column&amp;quot;);
            if ((n2 != null) &amp;amp;amp;&amp;amp;amp; (n2.size() &amp;amp;gt; 0)) {
                colLine = new PDFColumn[n2.size()];
                for (int j = 0; j &amp;amp;lt; n2.size(); j++) {
                    Element col_xml = (Element) n2.get(j);
                    PDFColumn col = new PDFColumn();
                    col.parse(col_xml);
                    colLine[j] = col;
                }
            }
            columns[i] = colLine;
        }
    }
    createWidthsArray();
    optimizeColumns();
    return columns;
}
    public PDFRow[] getGridContent() {
    List nodes = root.elements(&amp;quot;row&amp;quot;);
    if ((nodes != null) &amp;amp;amp;&amp;amp;amp; (nodes.size() &amp;amp;gt; 0)) {
        rows = new PDFRow[nodes.size()];
        for (int i = 0; i &amp;amp;lt; nodes.size(); i++) {
            rows[i] = new PDFRow();
            rows[i].parse((Element) nodes.get(i));
        }
    }
    return rows;

}

   *****
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;}
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;还需要修改PDFRow类的parse方法和PDFColumn的parse方法。
&lt;pre lang=&quot;java&quot;&gt;
public class PDFRow {&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;private String[] cells;

public void parse(Element parent) {
    List nodes = ((Element) parent).elements(&amp;quot;cell&amp;quot;);
    if ((nodes != null) &amp;amp;amp;&amp;amp;amp; (nodes.size() &amp;amp;gt; 0)) {
        cells = new String[nodes.size()];
        for (int i = 0; i &amp;amp;lt; nodes.size(); i++) {
            cells[i] = ((Element) nodes.get(i)).getTextTrim();
        }
    }
}

public String[] getCells() {
    return cells;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;public class PDFColumn {&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;public void parse(Element parent) {
    colName = parent.getText();
    String width_string = parent.attributeValue(&amp;quot;width&amp;quot;);
    if (width_string!=null&amp;amp;&amp;amp;width_string.length() &amp;gt; 0) {
        width = Integer.parseInt(width_string);
    }
    type = parent.attributeValue(&amp;quot;type&amp;quot;);
    align = parent.attributeValue(&amp;quot;align&amp;quot;);
    String colspan_string = parent.attributeValue(&amp;quot;colspan&amp;quot;);
    if (colspan_string!=null&amp;amp;&amp;amp;colspan_string.length() &amp;gt; 0) {
        colspan = Integer.parseInt(colspan_string);
    }
    String rowspan_string = parent.attributeValue(&amp;quot;rowspan&amp;quot;);
    if (rowspan_string!=null&amp;amp;&amp;amp;rowspan_string.length() &amp;gt; 0) {
        rowspan= Integer.parseInt(rowspan_string);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;}
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;这样xml字符串就能正常解析了，然后使用pdfjet.jar包就可以导出pdf了，最后的效果如下：
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;/files/2011/08/export-dhtmlx-to-pdf-pdf.png&quot; alt=&quot;&quot; title=&quot;export dhtmlx to pdf -pdf&quot; width=&quot;300&quot; height=&quot;134&quot; class=&quot;aligncenter size-medium wp-image-2386&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;h2&gt;结论：&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;1.导出pdf和导出Excel代码差不多，这里不做说明。&lt;/li&gt;
&lt;li&gt;2.使用上面的工具，可以将dhtmlxgrid的数据导出到pdf，并且导出的pdf还保持了grid表格的样式（包括颜色、多表头、表头合并、复选框等等），这点很不错。&lt;/li&gt;
&lt;li&gt;3.导出的pdf为多页显示，每页有表头&lt;/li&gt;
&lt;li&gt;4.导出后的pdf页面可以直接打印，当然如果在代码上做点处理，可以直接将pdf保存为一个文件，让用户下载。&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>自定义dhtmlxGrid表头菜单</title>
   <link href="http://blog.javachen.com/javascript/2011/07/31/custom-dhtmlxgrid-header-menu"/>
   <updated>2011-07-31T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/07/31/custom-dhtmlxgrid-header-menu</id>
   <content type="html">&lt;p&gt;dhtmlxGrid可以定义表头菜单以及表格右键菜单，表格右键菜单可以自定义，但是表头菜单只能使用其提供的菜单。dhtmlxGrid默认的表头菜单可以决定表格中每一列是否在表格中显示，并没有提供更多的扩展，如果我想自定义表头菜单，该怎么做呢？本文就是基于自定义表格菜单，说说我的实现方式。
以下是dhtmlxGrid的表头菜单效果：
&lt;div class=&quot;pic&quot;&gt;
&lt;img class=&quot;aligncenter size-medium wp-image-2287&quot; title=&quot;dhtmlxgrid-head-menu&quot; src=&quot;/files/2011/07/dhtmlxgrid-head-menu.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;174&quot; /&gt;&lt;/div&gt;
其功能过于单一，以下是表格右键菜单效果：
&lt;div class=&quot;pic&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-2288&quot; title=&quot;dhtmlxgrid-context-menu&quot; src=&quot;/files/2011/07/dhtmlxgrid-context-menu.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;126&quot; /&gt;&lt;/div&gt;
如果能够像表格菜单一样自定义表头菜单，那会是一件非常有意义的事情，因为dhtmlxGrid菜单都是一些针对行和单元格的操作，没有提过针对列的操作，比如我可能需要在某一列上实现该列的显示与隐藏、排序、改变列属性以及在该列右边添加一新的列，等等。
如何实现表头菜单的自定义呢？可不可将表格右键菜单移到表头上去呢？&amp;lt;!--more--&amp;gt;
首先，来看看context menu的实现方式，下面代码来自dhtmlxGrid Samples中的Context menu例子源码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;function onButtonClick(menuitemId, type) {
    var data = mygrid.contextID.split(&amp;quot;_&amp;quot;);
    //rowId_colInd;
    mygrid.setRowTextStyle(data[0], &amp;quot;color:&amp;quot; + menuitemId.split(&amp;quot;_&amp;quot;)[1]);
    return true;
}
menu = new dhtmlXMenuObject();
menu.setIconsPath(&amp;quot;../common/images/&amp;quot;);
menu.renderAsContextMenu();
menu.attachEvent(&amp;quot;onClick&amp;quot;, onButtonClick);
menu.loadXML(&amp;quot;../common/_context.xml&amp;quot;);
mygrid = new dhtmlXGridObject(&amp;#39;gridbox&amp;#39;);
mygrid.setImagePath(&amp;quot;../../codebase/imgs/&amp;quot;);
mygrid.setHeader(&amp;quot;Author,Title&amp;quot;);
mygrid.setInitWidths(&amp;quot;250,250&amp;quot;);
mygrid.enableAutoWidth(true);
mygrid.setColAlign(&amp;quot;left,left&amp;quot;);
mygrid.setColTypes(&amp;quot;ro,link&amp;quot;);
mygrid.setColSorting(&amp;quot;str,str&amp;quot;);
mygrid.enableContextMenu(menu);
mygrid.init();
mygrid.setSkin(&amp;quot;dhx_skyblue&amp;quot;);
mygrid.loadXML(&amp;quot;../common/grid_links.xml&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面代码创建了一个menu并将其作为context menu附件到grid上面去，下面为最关键的两行行代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;menu.renderAsContextMenu();
mygrid.enableContextMenu(menu);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面对于context menu提供的方法太少，这时候可以看看dhtmlxMenu api，看看有没有设置context menu生效位置的方法（指定context menu在哪片区域有效）。在dhtmlxMenu API Methods里没有找到需要的方法，这时候在官网论坛搜搜，也许可以找到点什么。
在论坛里可以找到一个例子，大致代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;function onButtonClick(menuitemId, type) {
    var data = mygrid.contextID.split(&amp;quot;_&amp;quot;);
    //rowId_colInd;
    mygrid.setRowTextStyle(data[0], &amp;quot;color:&amp;quot; + menuitemId.split(&amp;quot;_&amp;quot;)[1]);
    return true;
}
menu = new dhtmlXMenuObject();
menu.setIconsPath(&amp;quot;../common/images/&amp;quot;);
menu.attachEvent(&amp;quot;onClick&amp;quot;, onButtonClick);
menu.loadXML(&amp;quot;../common/_context.xml&amp;quot;);

mygrid = new dhtmlXGridObject(&amp;#39;gridbox&amp;#39;);
mygrid.setImagePath(&amp;quot;../../codebase/imgs/&amp;quot;);
mygrid.setHeader(&amp;quot;Author,Title&amp;quot;);
mygrid.setInitWidths(&amp;quot;250,250&amp;quot;);
mygrid.enableAutoWidth(true);
mygrid.setColAlign(&amp;quot;left,left&amp;quot;);
mygrid.setColTypes(&amp;quot;ro,link&amp;quot;);
mygrid.setColSorting(&amp;quot;str,str&amp;quot;);
//mygrid.enableContextMenu(menu); //使其失效
mygrid.init();
mygrid.setSkin(&amp;quot;dhx_skyblue&amp;quot;);
mygrid.loadXML(&amp;quot;../common/grid_links.xml&amp;quot;);

mygrid.hdr.id = &amp;quot;header_id&amp;quot;;
var header_row = mygrid.hdr.rows[1];
for ( var i = 0; i &amp;amp;lt; header_row.cells.length; i++) {
   header_row.cells[i].id = &amp;quot;context_zone_&amp;quot; + i;
}
menu.addContextZone(&amp;quot;header_id&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面最关键的代码在最后几行，给dhtmlxGrid表头设置了一个id，然后调用menu的addContextZone()方法指定centext的有效区域。视乎这就是我们所需要的，但是你执行以上代码你会发现onButtonClick方法里mygrid.contextID会报错，原因是mygrid没有contextID属性（在context menu中通过该属性可以获知鼠标焦点在哪一行，但是现在在表头上强加了该menu，所以并不存在该属性了）。
剩下的问题是需要解决，菜单单击事件了。我们可以在表头的contextmenu事件处罚的时候获取鼠标焦点，并将自定义的菜单在该位置显示，该方法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;dhtmlxEvent(mygrid.hdr, &amp;quot;contextmenu&amp;quot;, function(ev) {
    ev = ev || event;
    var el = ev.target || ev.srcElement;
    var zel = el;
    while (zel.tagName != &amp;quot;TABLE&amp;quot;)
        zel = zel.parentNode;
    var grid = zel.grid;
    if (!grid)
        return;
    grid.setActive();

    el = grid.getFirstParentOfType(el, &amp;quot;TD&amp;quot;)

    if ((grid) &amp;amp;amp;&amp;amp;amp; (!grid._colInMove)) {
        grid.resized = null;
        if ((!grid._mCols) || (grid._mCols[el._cellIndex] == &amp;quot;true&amp;quot;))
            colId = el._cellIndex + 1;//获得表头右键菜单焦点所在列索引
    }

    function mouseCoords(ev) {
        if (ev.pageX || ev.pageY) {
            return {
                x : ev.pageX,
                y : ev.pageY
            };
        }
        var d = _isIE &amp;amp;amp;&amp;amp;amp; document.compatMode != &amp;quot;BackCompat&amp;quot; ? 
                document.documentElement: document.body;
        return {
            x : ev.clientX + d.scrollLeft - d.clientLeft,
            y : ev.clientY + d.scrollTop - d.clientTop
        };
    }

    var coords = mouseCoords(ev);
    menu.addContextZone(&amp;quot;header_id&amp;quot;);
    menu.showContextMenu(coords.x, coords.y);//强制显示
    return true;
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在上面的代码里，我们获得表头右键菜单焦点所在列索引，将其值赋给colId，然后在菜单单击事件的时候添加一新的列并将colId重置：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;function onButtonClick(menuitemId, type, e) {
    mygrid.insertColumn(colId, &amp;quot;12&amp;quot;, &amp;quot;ed&amp;quot;, 80);
    colId = 0;
    return true;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后，需要禁止掉表格数据区域的菜单显示：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mygrid.attachEvent(&amp;quot;onBeforeContextMenu&amp;quot;, function(rid, cid, e) {
    return false;//禁止数据区域菜单
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最后的最后，最后的代码如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;var mygrid, colId;

function onButtonClick(menuitemId, type, e) {
    mygrid.insertColumn(colId, &amp;quot;12&amp;quot;, &amp;quot;ed&amp;quot;, 80);
    colId = 0;
    return true;
}

menu = new dhtmlXMenuObject();
menu.setIconsPath(&amp;quot;../common/images/&amp;quot;);
menu.renderAsContextMenu();
menu.attachEvent(&amp;quot;onClick&amp;quot;, onButtonClick);
menu.loadXML(&amp;quot;../common/_context.xml&amp;quot;);
menu.attachEvent(&amp;quot;onBeforeContextMenu&amp;quot;, function(zoneId, e) {
    var hdr = document.getElementById(zoneId)
    return true;
});

mygrid = new dhtmlXGridObject(&amp;#39;gridbox&amp;#39;);
mygrid.setImagePath(&amp;quot;../codebase/imgs/&amp;quot;);
mygrid.setHeader(&amp;quot;Sales,Book Title,Author,Price,In Store,Shipping,Bestseller,
          Date of Publication&amp;quot;);
mygrid.setInitWidths(&amp;quot;50,150,100,80,80,80,80,200&amp;quot;);
mygrid.setColAlign(&amp;quot;right,left,left,right,center,left,center,center&amp;quot;);
mygrid.setColTypes(&amp;quot;dyn,edtxt,ed,price,ch,co,ra,ro&amp;quot;);

mygrid.init();
mygrid.setSkin(&amp;quot;dhx_skyblue&amp;quot;);
//mygrid.enableHeaderMenu();
mygrid.enableColumnMove(true);
mygrid.enableContextMenu(menu);
dhtmlxEvent(mygrid.hdr, &amp;quot;contextmenu&amp;quot;, function(ev) {
    ev = ev || event;
    var el = ev.target || ev.srcElement;
    var zel = el;
    while (zel.tagName != &amp;quot;TABLE&amp;quot;)
        zel = zel.parentNode;
    var grid = zel.grid;
    if (!grid)
        return;
    grid.setActive();

    el = grid.getFirstParentOfType(el, &amp;quot;TD&amp;quot;)

    if ((grid) &amp;amp;#038;&amp;amp; (!grid._colInMove)) {
        grid.resized = null;
        if ((!grid._mCols) || (grid._mCols[el._cellIndex] == &amp;quot;true&amp;quot;))
                            //获得表头右键菜单焦点所在列索引
            colId = el._cellIndex + 1;
    }

    function mouseCoords(ev) {
        if (ev.pageX || ev.pageY) {
            return {
                x : ev.pageX,
                y : ev.pageY
            };
        }
        var d = _isIE &amp;amp;#038;&amp;amp; document.compatMode != &amp;quot;BackCompat&amp;quot; ? 
                         document.documentElement: document.body;
        return {
            x : ev.clientX + d.scrollLeft - d.clientLeft,
            y : ev.clientY + d.scrollTop - d.clientTop
        };
    }

    var coords = mouseCoords(ev);
    menu.addContextZone(&amp;quot;header_id&amp;quot;);
    menu.showContextMenu(coords.x, coords.y);//强制显示
    return true;
});

mygrid.attachEvent(&amp;quot;onBeforeContextMenu&amp;quot;, function(rid, cid, e) {
    return false;//禁止数据区域菜单
});

mygrid.loadXML(&amp;quot;../common/grid_ml_16_rows_columns_manipulations.xml&amp;quot;);

mygrid.hdr.id = &amp;quot;header_id&amp;quot;;
var header_row = mygrid.hdr.rows[1];
for ( var i = 0; i &amp;lt; header_row.cells.length; i++) {
    header_row.cells[i].id = &amp;quot;context_zone_&amp;quot; + i;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;效果图如下;
&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;/files/2011/07/dhtmlxgrid-custom-head-menu.jpg&quot; alt=&quot;&quot; title=&quot;dhtmlxgrid-custom-head-menu&quot; width=&quot;300&quot; height=&quot;154&quot; class=&quot;aligncenter size-medium wp-image-2291&quot; /&gt;&lt;/div&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Drag an item to dhtmlxGrid and add a column</title>
   <link href="http://blog.javachen.com/javascript/2011/07/24/drag-an-item-to-dhtmlxgrid-and-add-a-column"/>
   <updated>2011-07-24T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/07/24/drag-an-item-to-dhtmlxgrid-and-add-a-column</id>
   <content type="html">&lt;p&gt;dhtmlxGrid支持tree和grid、grid之间、grid内部进行拖拽，如在grid内部进行拖拽，可以增加一行；在grid之间拖拽，第一个grid的记录删除，第二个grid增加一行记录。如果我想在拖拽之后不是添加一行而是一列，该怎么做呢？
现在有个需求，就是左边有个tree，右边有个grid，将左边tree的一个节点拖到右边grid的表头并动态增加一列。这个怎么做呢？
如果你想快点看到最后的实现方法，你可以直接跳到本文的最后参看源码。
首先看看dhtmlxTree 关于&lt;a href=&quot;http://www.dhtmlx.com/docs/products/dhtmlxGrid/samples/05_drag_n_drop/&quot;&gt;Drag-n-Drop&lt;/a&gt;的例子，其中有这样一个例子&lt;a href=&quot;http://www.dhtmlx.com/docs/products/dhtmlxTree/samples/05_drag_n_drop/08_pro_drag_out.html&quot;&gt;Custom Drag Out&lt;/a&gt;。
上面的例子，右边定义了一个输入框，其id为“sInput”，代码如下：
&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;function maf() {
    return false;
}
tree = new dhtmlXTreeObject(&amp;quot;treeboxbox_tree&amp;quot;, &amp;quot;100%&amp;quot;, &amp;quot;100%&amp;quot;, 0);&lt;/p&gt;

&lt;p&gt;tree.setSkin(&amp;#39;dhx&lt;em&gt;skyblue&amp;#39;);
tree.setImagePath(&amp;quot;../../codebase/imgs/csh&lt;/em&gt;yellowbooks/&amp;quot;);
tree.enableDragAndDrop(true);
tree.setDragHandler(maf);
tree.enableSmartXMLParsing(true);
tree.loadXML(&amp;quot;../common/tree&lt;em&gt;05&lt;/em&gt;drag&lt;em&gt;n&lt;/em&gt;drop.xml&amp;quot;);&lt;/p&gt;

&lt;p&gt;function s&lt;em&gt;control() {
    this.&lt;/em&gt;drag = function(sourceHtmlObject, dhtmlObject, targetHtmlObject) {
        targetHtmlObject.style.backgroundColor = &amp;quot;&amp;quot;;
        targetHtmlObject.value = sourceHtmlObject.parentObject.label;
    }
    this.&lt;em&gt;dragIn = function(htmlObject, shtmlObject) {
        htmlObject.style.backgroundColor = &amp;quot;#fffacd&amp;quot;;
        return htmlObject;
    }
    this.&lt;/em&gt;dragOut = function(htmlObject) {
        htmlObject.style.backgroundColor = &amp;quot;&amp;quot;;
        return this;
    }
}
var sinput = document.getElementById(&amp;#39;sInput&amp;#39;);
tree.dragger.addDragLanding(sinput, new s_control);
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;为了使tree支持拖拽功能，必须添加以下代码：
&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;tree.enableDragAndDrop(true);&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;为了实现自定义拖拽的输出，添加了以下代码：
&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;tree.dragger.addDragLanding(sinput, new s_control);&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;从上面的字母意思可以看出，是在tree的拖拽对象dragger对象上添加一个拖拽着地对象，第一个常数是指拖拽到哪一个区域，第二个常数定义拖拽的三个方法：
&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;    this.&lt;em&gt;drag = function(sourceHtmlObject, dhtmlObject, targetHtmlObject) {
        targetHtmlObject.style.backgroundColor = &amp;quot;&amp;quot;;
        targetHtmlObject.value = sourceHtmlObject.parentObject.label;
    }
    this.&lt;/em&gt;dragIn = function(htmlObject, shtmlObject) {
        htmlObject.style.backgroundColor = &amp;quot;#fffacd&amp;quot;;
        return htmlObject;
    }
    this._dragOut = function(htmlObject) {
        htmlObject.style.backgroundColor = &amp;quot;&amp;quot;;
        return this;
    }
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;参照上面的思路，我们可以在grid的表头上面定义一个id，然后通过该id获得表头的dom对象，更好的一个方法是通过mygrid.hdr（看看源码就知道列）能过获得grid的表头对象，然后调用下面的方法，定义tree拖拽到grid的表头：
&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;tree.dragger.addDragLanding(mygrid.hdr, new s_control);&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;但是这个时候，你将tree的一个节点拖到grid的表头，grid不会有任何反应，故需要改写s_control对象的方法，这里主要是改写一个方法：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
    var insertId;
    this._drag = function(sourceHtmlObject, dhtmlObject,
        targetHtmlObject, e) {
    var zel = e;
    while (zel.tagName != &quot;TABLE&quot;)
        zel = zel.parentNode;
    var grid = zel.grid;
    if (!grid)
        return;
    grid.setActive();
    if (!grid._mCol || e.button == 2)
        return;
    e = grid.getFirstParentOfType(e, &quot;TD&quot;)

    if ((grid) &amp;amp;&amp;amp; (!grid._colInMove)) {
        grid.resized = null;
        if ((!grid._mCols) || (grid._mCols[e._cellIndex] == &quot;true&quot;))
            insertId = e._cellIndex + 1;
    }

    mygrid.insertColumn(insertId, &quot;12&quot;, &quot;ed&quot;, 80);
}
&lt;/pre&gt;

&lt;p&gt;该方法主要做的事情是计算拖拽落脚时候鼠标焦点所在的列，然后在其右边添加一新的列。
&lt;div class=&quot;pic&quot;&gt;
&lt;img class=&quot;aligncenter&quot; title=&quot;QQ20110724211631&quot; src=&quot;/files/2011/07/QQ20110724211631.png&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;本例最后的代码：
&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
    var mygrid;
    function maf() {
        return false;
    }&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;tree = new dhtmlXTreeObject(&amp;quot;treeboxbox_tree&amp;quot;, &amp;quot;100%&amp;quot;, &amp;quot;100%&amp;quot;, 0);
tree.setSkin(&amp;#39;dhx_skyblue&amp;#39;);
tree.setImagePath(&amp;quot;../../dhtmlxTree/codebase/imgs/csh_yellowbooks/&amp;quot;);
tree.enableDragAndDrop(true);
//tree.setDragHandler(maf);
tree.enableSmartXMLParsing(true);
tree.loadXML(&amp;quot;../../dhtmlxTree/samples/common/tree_05_drag_n_drop.xml&amp;quot;)
tree.openAllItems(0);

function s_control() {
    var insertId;
    this._drag = function(sourceHtmlObject, dhtmlObject,
            targetHtmlObject, e) {
        var zel = e;
        while (zel.tagName != &amp;quot;TABLE&amp;quot;)
            zel = zel.parentNode;
        var grid = zel.grid;
        if (!grid)
            return;
        grid.setActive();
        if (!grid._mCol || e.button == 2)
            return;
        e = grid.getFirstParentOfType(e, &amp;quot;TD&amp;quot;)

        if ((grid) &amp;amp;&amp;amp; (!grid._colInMove)) {
            grid.resized = null;
            if ((!grid._mCols) || (grid._mCols[e._cellIndex] == &amp;quot;true&amp;quot;))
                insertId = e._cellIndex + 1;
        }

        mygrid.insertColumn(insertId, &amp;quot;12&amp;quot;, &amp;quot;ed&amp;quot;, 80);
    }
}
mygrid = new dhtmlXGridObject(&amp;#39;gridbox&amp;#39;);
mygrid.setImagePath(&amp;quot;../codebase/imgs/&amp;quot;);
mygrid.setHeader(&amp;quot;Sales,Book Title,Author,Price,In Store,Shipping,Bestseller,
          Date of Publication&amp;quot;);
mygrid.setInitWidths(&amp;quot;50,150,100,80,80,80,80,200&amp;quot;);
mygrid.setColAlign(&amp;quot;right,left,left,right,center,left,center,center&amp;quot;);
mygrid.setColTypes(&amp;quot;dyn,edtxt,ed,price,ch,co,ra,ro&amp;quot;);
mygrid.enableDragAndDrop(&amp;quot;temporary_disabled&amp;quot;, true);
mygrid.init();
mygrid.setSkin(&amp;quot;dhx_skyblue&amp;quot;);
mygrid.enableHeaderMenu();
mygrid.enableColumnMove(true);
mygrid.setColumnHidden(2, true);
mygrid.attachEvent(&amp;quot;onHeaderClick&amp;quot;, function(ind, obj) {
});
mygrid.loadXML(&amp;quot;../common/grid_ml_16_rows_columns_manipulations.xml&amp;quot;);
tree.dragger.addDragLanding(mygrid.hdr, new s_control);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;/pre&gt;
本文实现的是将tree拖拽到grid，其实其他的一些支持拖拽的组件也可以做，并不局限于tree组件，甚至还见过有人实现jquery的dtree拖拽到dhtmlxGrid增加一行记录。&lt;/p&gt;

&lt;h2&gt;参考文章&lt;/h2&gt;

&lt;p&gt;&lt;li&gt;
Custom Drag Out：&lt;a href=&quot;http://www.dhtmlx.com/docs/products/dhtmlxTree/samples/05_drag_n_drop/08_pro_drag_out.html&quot; target=&quot;_blank&quot;&gt;http://www.dhtmlx.com/docs/products/dhtmlxTree/samples/05&lt;em&gt;drag&lt;/em&gt;n&lt;em&gt;drop/08&lt;/em&gt;pro&lt;em&gt;drag&lt;/em&gt;out.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;dhtmlxGrid doc：&lt;a href=&quot;http://docs.dhtmlx.com/doku.php?id=dhtmlxgrid:toc&quot; target=&quot;_blank&quot;&gt;http://docs.dhtmlx.com/doku.php?id=dhtmlxgrid:toc&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;dhtmlxTree doc：&lt;a href=&quot;http://docs.dhtmlx.com/doku.php?id=dhtmlxtree:toc&quot; target=&quot;_blank&quot;&gt;http://docs.dhtmlx.com/doku.php?id=dhtmlxtree:toc&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DhtmlxGrid Quick Start Guide</title>
   <link href="http://blog.javachen.com/javascript/2011/07/19/dhtmlxgrid-quick-start-guide"/>
   <updated>2011-07-19T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/07/19/dhtmlxgrid-quick-start-guide</id>
   <content type="html">&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;说明:&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;本文来源于&lt;a href=&quot;http://dhtmlx.com/docs/products/dhtmlxGrid/&quot;&gt;http://dhtmlx.com/docs/products/dhtmlxGrid/&lt;/a&gt;，本人对其进行翻译整理成下文，贴出此文，紧供分享。&lt;/p&gt;

&lt;p&gt;dhtmlxGrid是一个拥有强大的数据绑定、优秀的大数据展示性能并支持ajax的JavaScript表格控件。该组件易于使用并通过富客户端的API提供了很大的扩展性。dhtmlxGrid支持不同的数据源（XML, JSON, CSV, JavaScript 数组和HTML表格），如果需要的话，还可以从自定义的xml中加载数据。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;跨浏览器
使用JavaScript API进行控制
Ajax支持
简单的JavaScript 或者XML 配置
与HTML集成
内建过滤、排序、查询、分组功能
表格 footer/header自动计算
行内编辑
准备使用大数据集解决方案：分页，动态加载，智能渲染
序列化为XML或CSV
从 XML或CSV加载
列锁定
剪贴板支持
简单的客户端到服务器端配置 (使用 dhtmlxConnector, 可用于 PHP, Java, .NET, ColdFusion)
支持子表格
列拖拽和移动
行或列拖拽
dhtmlxTree PRO Edition支持拖拽
可以创建一个编辑器或是列格式化 (使用 eXcell – 继承自 cell 对象)
组合框，日历以及更多的预定义eXcells
Cell支持数学方程式
不同的键盘映射
简单的CSS风格或是预定义的皮肤
对于rows/entire grid不可见的数据块 (用户数据)
客户端排序(string, integer, date, custom)
服务器端排序
广泛的事件处理
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 1 – 引入文件&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt; link rel =&amp;quot;STYLESHEET&amp;quot; type=&amp;quot;text/css&amp;quot; href=&amp;quot;codebase/dhtmlxgrid.css&amp;quot; /&amp;gt;
&amp;lt; script src=&amp;quot;codebase/dhtmlxcommon.js&amp;quot;&amp;gt;&amp;lt; /script&amp;gt;
&amp;lt; script src=&amp;quot;codebase/dhtmlxgrid.js&amp;quot;&amp;gt;&amp;lt; /script&amp;gt;
&amp;lt; script src=&amp;quot;codebase/dhtmlxgridcell.js&amp;quot;&amp;gt;&amp;lt; /script&amp;gt;
&amp;lt; script&amp;gt;
    //we&amp;#39;ll write script commands here
&amp;lt; /script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 2 – 放置gird&lt;/h2&gt;

&lt;p&gt;有两种方式在一个页面放置grid，这里减少最常用的方法：创建一个div并给id熟悉设置一个惟一值。例如：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt; div id=&amp;quot;mygrid_container&amp;quot; style=&amp;quot;width:600px;height:150px;&amp;quot;&amp;gt;&amp;lt; /div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面初始化参数，首先定一个mygrid变量，然后定一个doInitGrid方法，方法内部进行mygrid初始化工作：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt; var mygrid;
 function doInitGrid(){
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;doInitGrid方法会包括以下代码：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用dhtmlXGridObject构造方法创建一个基于我们之前创建的DIV的grid对象；&lt;/li&gt;
&lt;li&gt;设置grid图片路径。这个路径包括grid外观需要的所有图片。在大多数情况下该路径为“codebase/imgs/”. 该路径最后面的一个“/”很重要。 随便说一下，这个路径和你处理表格数据所使用的图片没有关系；&lt;/li&gt;
&lt;li&gt;使用setHeader 方法定义表头；&lt;/li&gt;
&lt;li&gt;使用setInitWidths (单位为像素) 或setInitWidthsP (单位为百分比)定义列宽。 使用&lt;code&gt;*&lt;/code&gt;代表让列自动使用所有表格宽度；&lt;/li&gt;
&lt;li&gt;定义一个列的水平对其方式。 Numeric values is better to align right;&lt;/li&gt;
&lt;li&gt;使用setSkin方法设置皮肤；&lt;/li&gt;
&lt;li&gt;最好使用这些设置通过init方法初始化grid。更多的参数之后再讨论。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前，doInitGrid方法如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mygrid = new dhtmlXGridObject(&amp;#39;mygrid_container&amp;#39;);
mygrid.setImagePath(&amp;quot;codebase/imgs/&amp;quot;); //指定图片路径
mygrid.setHeader(&amp;quot;Model,Qty,Price&amp;quot;); //设置表头显示
grid.setInitWidths(&amp;quot;*,150,150&amp;quot;); //设置列的初始宽度
grid.setColAlign(&amp;quot;left,right,right&amp;quot;); //设置列的水平对其方式
mygrid.setSkin(&amp;quot;light&amp;quot;); //设置皮肤
grid.init(); //显示调用初始化方法，必须的
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;现在需要做的是运行该方法，可以将该方法加入body的onload方法里或是使用jquery的方法。下面使用body的onload方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt; body onload=&amp;quot;doInitGrid();&amp;quot;&amp;gt;&amp;lt; /body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样在该页面初始化之后会显示如下：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?cache=&amp;amp;media=dhtmlxgrid:step_2_last.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;

&lt;p&gt;说明：除了调用set方法之外，还可以如下风格定义：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mygrid = new dhtmlXGridObject({
        parent:&amp;quot;a_grid&amp;quot;,
        image_path:&amp;quot;codebase/imgs&amp;quot;,
        columns:[
            { label: &amp;quot;Sales&amp;quot;,           width:50,   type:&amp;quot;ed&amp;quot; },
            { label:[&amp;quot;Book title&amp;quot;,
                 &amp;quot;#text_filter&amp;quot;],   width:150,  type:&amp;quot;ed&amp;quot; },
            { label:[&amp;quot;Author&amp;quot;,
                 &amp;quot;#select_filter&amp;quot;], width:150,  type:&amp;quot;ed&amp;quot; },
            { label: &amp;quot;Price&amp;quot;,       width:50,   type:&amp;quot;ed&amp;quot; },
            { label:&amp;quot;In store&amp;quot; ,    width:80,   type:&amp;quot;ch&amp;quot; },
            { label:&amp;quot;Shipping&amp;quot; ,    width:50,   type:&amp;quot;ed&amp;quot; },
            { label:&amp;quot;Bestseller&amp;quot; ,  width:50,   type:&amp;quot;ed&amp;quot; },
            { label:&amp;quot;Date&amp;quot; ,    width:50,   type:&amp;quot;ed&amp;quot; }
        ],
        xml:&amp;quot;data.xml&amp;quot;
    });
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 3 – 填充数据&lt;/h2&gt;

&lt;p&gt;你已经知道了dhtmlxGrid可以加载xml或cvs或json数据，这里主要演示dhtmlxGrid加载json数据。&lt;/p&gt;

&lt;p&gt;在上面的例子中每行有三列，故我们的json数据如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;{
rows:[
    {
        id: &amp;quot;a&amp;quot;,
        data: [Model 1, 100, 399]
    },
    {
    id: &amp;quot;b&amp;quot;,
        data: [Model 2, 50, 649]
    },
    {
        id: &amp;quot;c&amp;quot;,
           data: [ Model 3, 70, 499]
    }
]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将上面存于data.json文件，然后在doInitGrid方法里调用以下方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mygrid.load (&amp;quot;data.json&amp;quot;，,&amp;quot;json&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这时候页面展示如下：
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?cache=&amp;amp;media=dhtmlxgrid:step_3.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;&lt;/p&gt;

&lt;h2&gt;Step 4 – 客户端排序&lt;/h2&gt;

&lt;p&gt;为了能够实习表格的客户端排序，必须调用grid的setColSorting（sortTypesStr）方法。sortTypesStr是一个类型列表，以逗号分隔。&lt;/p&gt;

&lt;p&gt;该类型值有以下四种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;str – 作为字符串排序&lt;/li&gt;
&lt;li&gt;int - 以Integer值排序 (通常可以是任何数字);&lt;/li&gt;
&lt;li&gt;date – 以日期排序&lt;/li&gt;
&lt;li&gt;custom sorting –自定义的更加复杂的排序方式(for example to sort days of week).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接下来我们对上面的例子进行排序。上例中每行有三列，第一列为字符串，后两列为数字，故可以调用以下方法进行排序。注意，该方法应该在init方法之前执行。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mygrid.setColSorting(&amp;quot;str,int,int&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这时候单击最后一列表头，结果如下：
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?media=dhtmlxgrid:step_4.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;&lt;/p&gt;

&lt;h2&gt;Step 5 – 单元格格式化和编辑&lt;/h2&gt;

&lt;p&gt;Grid中使用单元格的编辑器（或是eXcells – 继承自 Cells, Cell 或 Columns types）来定义值的格式和编辑方式。你可以根据你的需要创建eXcells。&lt;/p&gt;

&lt;p&gt;设定单元格的类型非常容易，其可以用一行代码定义。这里有一些常见的编辑器，如简单的编辑器代码为“ed”，多行编辑“txt”，只读单元格“ro”，复选框“ch”，价格的格式化“price”。
默认情况下所有的列是“ro”，也可以使用以下方法类设置编辑类型：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;mygrid.setColTypes(&amp;quot;ed,ed,price&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Excells格式化有以下几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;link：超链接&lt;/li&gt;
&lt;li&gt;img：图片&lt;/li&gt;
&lt;li&gt;price：价格&lt;/li&gt;
&lt;li&gt;dyn：动态行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Excell 复杂编辑器有以下几种：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;cp：colorpicker&lt;/li&gt;
&lt;li&gt;calck：允许调用grid.setNumberFormat的计算器&lt;/li&gt;
&lt;li&gt;dhxCalendar：日历，日期格式可以通过grid.setDateFormat设置&lt;/li&gt;
&lt;li&gt;dhxCalendarA：日历，日期格式可以通过grid.setDateFormat设置，单元格可以编辑&lt;/li&gt;
&lt;li&gt;calendar：YUI Calendar&lt;/li&gt;
&lt;li&gt;clist：多选组件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用其他组件作为单元格编辑器:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;grid：使用dhtmlxgrid&lt;/li&gt;
&lt;li&gt;stree ：使用dhtmlxtree&lt;/li&gt;
&lt;li&gt;context：使用dhtmlxmenu&lt;/li&gt;
&lt;li&gt;combo：使用dhtmlxCombo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Excells特别用途
sub_row：允许单元格作为一个可展开的子单元格，就想查看明细一样。&lt;/p&gt;

&lt;p&gt;两个扩展:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sub&lt;em&gt;row&lt;/em&gt;ajax – 单元格数据被认为是ajax请求的url&lt;/li&gt;
&lt;li&gt;sub&lt;em&gt;row&lt;/em&gt;grid – 允许创建一个子表作为一个子行的内容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;现在你可以双击或是F2进入编辑模式，你可以用tab键在单元格之间导航。
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?media=dhtmlxgrid:step_5.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;&lt;/p&gt;

&lt;h2&gt;Step 6 – 行操作方法&lt;/h2&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;function addRow(){
var newId = (new Date()).valueOf()
mygrid.addRow(newId,&amp;quot;&amp;quot;,mygrid.getRowsNum())
mygrid.selectRow(mygrid.getRowIndex(newId),false,false,true);
}
function removeRow(){
var selId = mygrid.getSelectedId()
mygrid.deleteRow(selId);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;代码中addRow() 方法的一些说明：
* 创建一个惟一值 (number of millisecond since 1970) 来作为row的标识；
* 在最后一行后面添加一新行，该行有新的id，值为空；
* 选中最近创建的行 (by index), 不掉用 On-Select事件，不掉用选中行之前事件并且聚焦到选中行(如果垂直滚动条存在，则滚动对应位置)。&lt;/p&gt;

&lt;p&gt;代码中removeRow() 的一些说明（一行行的）:
* 得到选中行id；
* 删除指定行id的行&lt;/p&gt;

&lt;h2&gt;Step 7 – 事件&lt;/h2&gt;

&lt;p&gt;添加事件调用attachEvent 方法，如下行选中事件：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;function doOnRowSelected(rowID,celInd){
alert(&amp;quot;Selected row ID is &amp;quot;+rowID+&amp;quot;\nUser clicked cell with index &amp;quot;+celInd);
}
mygrid.attachEvent(&amp;quot;onRowSelect&amp;quot;,doOnRowSelected);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 8 – Code&lt;/h2&gt;

&lt;p&gt;最后的代码：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt; title&amp;gt;dhtmlxGrid Sample Page&amp;lt; /title&amp;gt;
&amp;lt; link rel=&amp;quot;STYLESHEET&amp;quot; type=&amp;quot;text/css&amp;quot; href=&amp;quot;codebase/dhtmlxgrid.css&amp;quot; /&amp;gt;
&amp;lt; script src=&amp;quot;codebase/dhtmlxcommon.js&amp;quot;&amp;gt;&amp;lt; /script&amp;gt;
&amp;lt; script src=&amp;quot;codebase/dhtmlxgrid.js&amp;quot;&amp;gt;&amp;lt; /script&amp;gt;
&amp;lt; script src=&amp;quot;codebase/dhtmlxgridcell.js&amp;quot;&amp;gt;&amp;lt; /script&amp;gt;
&amp;lt; script&amp;gt;
var mygrid;
function doInitGrid(){
mygrid = new dhtmlXGridObject(&amp;#39;mygrid_container&amp;#39;);
mygrid.setImagePath(&amp;quot;codebase/imgs/&amp;quot;);
mygrid.setHeader(&amp;quot;Model,Qty,Price&amp;quot;);
mygrid.setInitWidths(&amp;quot;*,150,150&amp;quot;);
mygrid.setColAlign(&amp;quot;left,right,right&amp;quot;)
mygrid.setSkin(&amp;quot;light&amp;quot;);
mygrid.setColSorting(&amp;quot;str,int,int&amp;quot;);
mygrid.setColTypes(&amp;quot;ed,ed,price&amp;quot;);
mygrid.attachEvent(&amp;quot;onRowSelect&amp;quot;,doOnRowSelected);
mygrid.init();
mygrid.load (&amp;quot;data.json&amp;quot;,&amp;quot;json&amp;quot;);
}
function addRow(){
var newId = (new Date()).valueOf()
mygrid.addRow(newId,&amp;quot;&amp;quot;,mygrid.getRowsNum())
mygrid.selectRow(mygrid.getRowIndex(newId),false,false,true);
}
function removeRow(){
var selId = mygrid.getSelectedId()
mygrid.deleteRow(selId);
}
function doOnRowSelected(rowID,celInd){
alert(&amp;quot;Selected row ID is &amp;quot;+rowID+&amp;quot;\nUser clicked cell with index &amp;quot;+celInd);
}
&amp;lt; /script&amp;gt;
&amp;lt; body onload=&amp;quot;doInitGrid()&amp;quot;&amp;gt;
&amp;lt; div id=&amp;quot;mygrid_container&amp;quot; style=&amp;quot;width:600px;height:150px;&amp;quot;&amp;gt;&amp;lt; /div&amp;gt;
&amp;lt; /body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>网上收集的关于OpenStack的一些资源</title>
   <link href="http://blog.javachen.com/cloud/2011/07/07/some-resources-about-openstack"/>
   <updated>2011-07-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/07/07/some-resources-about-openstack</id>
   <content type="html">&lt;p&gt;&lt;li&gt;
&lt;span class=&quot;Apple-style-span&quot; style=&quot;font-size: 13px; font-weight: normal;&quot;&gt;OpenStack Nova code：&lt;a href=&quot;https://bugs.launchpad.net/nova&quot; target=&quot;_blank&quot;&gt;https://bugs.launchpad.net/nova&lt;/a&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;
OpenStack Blog：&lt;a href=&quot;http://planet.openstack.org/&quot; target=&quot;_blank&quot;&gt;http://planet.openstack.org/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack 官方文档：&lt;a href=&quot;http://docs.openstack.org/cactus/openstack-compute/admin/content/ch_getting-started-with-openstack.html&quot; target=&quot;_blank&quot;&gt;http://docs.openstack.org/cactus/openstack-compute/admin/content/ch&lt;em&gt;getting-started-with-openstack.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack 中国门户：&amp;lt;a href=&amp;quot;http://blu001068.chinaw3.com/bbs/portal.php&amp;quot; target=&amp;quot;&lt;/em&gt;blank&amp;quot;&amp;gt;http://blu001068.chinaw3.com/bbs/portal.php&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;在 Ubuntu 上安装和配置 OpenStack Nova：&lt;a href=&quot;http://www.vpsee.com/2011/05/install-openstack-nova-on-ubuntu/&quot; target=&quot;_blank&quot;&gt;http://www.vpsee.com/2011/05/install-openstack-nova-on-ubuntu/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Centos安装过程：&lt;a href=&quot;http://wiki.openstack.org/NovaInstall/CentOSNotes&quot; target=&quot;_blank&quot;&gt;http://wiki.openstack.org/NovaInstall/CentOSNotes&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Running OpenStack Compute (Nova)：&lt;a href=&quot;http://wiki.openstack.org/RunningNova&quot; target=&quot;_blank&quot;&gt;http://wiki.openstack.org/RunningNova&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;开源黄页 -  OpenStack：&lt;a href=&quot;http://yp.oss.org.cn/appcenter/software/show_software.php?sw_id=1733&quot; target=&quot;_blank&quot;&gt;http://yp.oss.org.cn/appcenter/software/show&lt;em&gt;software.php?sw&lt;/em&gt;id=1733&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Installation on Debian, Fedora orCentOS：&lt;a href=&quot;http://nova.openstack.org/adminguide/distros/others.html&quot; target=&quot;_blank&quot;&gt;http://nova.openstack.org/adminguide/distros/others.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Installing Nova on a Single Host：&lt;a href=&quot;http://nova.openstack.org/adminguide/single.node.install.html&quot; target=&quot;_blank&quot;&gt;http://nova.openstack.org/adminguide/single.node.install.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack swift 典型架构和openstack swift 简要说明：&lt;a href=&quot;http://blog.sina.com.cn/s/blog_6b98772b0100pk7p.html&quot; target=&quot;_blank&quot;&gt;http://blog.sina.com.cn/s/blog&lt;em&gt;6b98772b0100pk7p.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Swift 技术验证简单报告 :&amp;lt;a href=&amp;quot;http://www.douban.com/group/topic/17621229/&amp;quot; target=&amp;quot;&lt;/em&gt;blank&amp;quot;&amp;gt;http://www.douban.com/group/topic/17621229/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;新浪上openstack&lt;em&gt;object&lt;/em&gt;storage的一些文章：&lt;a href=&quot;http://blog.sina.com.cn/s/blog_6b98772b0100pk7p.html&quot; target=&quot;_blank&quot;&gt;http://blog.sina.com.cn/s/articlelist&lt;em&gt;1805154091&lt;/em&gt;2&lt;em&gt;1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;豆瓣上OpenStack收集资源：&amp;lt;a href=&amp;quot;http://www.douban.com/group/openstack/&amp;quot; target=&amp;quot;&lt;/em&gt;blank&amp;quot;&amp;gt;http://www.douban.com/group/openstack/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack服务部署： &lt;a href=&quot;http://hi.baidu.com/juacm/blog/item/bd05d154e7581e451138c277.html&quot; target=&quot;_blank&quot;&gt;http://hi.baidu.com/juacm/blog/item/bd05d154e7581e451138c277.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;陈沙克日志：&lt;a href=&quot;http://hi.baidu.com/chenshake/home&quot; target=&quot;_blank&quot;&gt;http://hi.baidu.com/chenshake/home&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Openstack-nova-architecture：&lt;a href=&quot;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&quot; target=&quot;_blank&quot;&gt;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack 架构：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6543880&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6543880&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
安装OpenStack：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6566370&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6566370&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
安装OpenStack-dashboard：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6572868&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6572868&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
Centos-nova-install.sh： &lt;a href=&quot;https://gist.github.com/837797&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/837797&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
RabbitMQ and Nova：&lt;a href=&quot;http://blog.163.com/clevertanglei900@126/blog/static/11135225920101110393888/&quot; target=&quot;_blank&quot;&gt;http://blog.163.com/clevertanglei900@126/blog/static/11135225920101110393888/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack(diablo-2)のNovaをインストール@CentOS6　メモ(1/n)：&lt;a href=&quot;http://blog.livedoor.jp/techpub/archives/3797358.html&quot; target=&quot;_blank&quot;&gt;OpenStack(diablo-2)のNovaをインストール@CentOS6　メモ(1/n)&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-内容列表（0）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563033-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563033-1-1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-基础部分（1）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563017-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563017-1-1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-增强部分（2）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563046-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563046-1-1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-增强部分（3）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563049-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563049-1-1.html&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>OpenStack架构预览</title>
   <link href="http://blog.javachen.com/cloud/2011/07/07/openstack-architecture-overview"/>
   <updated>2011-07-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/07/07/openstack-architecture-overview</id>
   <content type="html">&lt;p&gt;&lt;h2&gt;What is OpenStack?&lt;/h2&gt;
OpenStack提供开放源码软件，建立公共和私有云。 OpenStack是一个社区和一个项目，以及开放源码软件，以帮助企业运行的虚拟计算或者存储云。 OpenStackd开源项目由社区维护，包括OpenStack计算（代号为Nova），OpenStack对象存储（代号为SWIFT），并OpenStack镜像服务（代号Glance）的集合。 OpenStack提供了一个操作平台，或工具包，用于编排云。
&lt;h2&gt;Components of OpenStack&lt;/h2&gt;
OpenStack当前主要有三个组件：计算，存储，镜像。&lt;br /&gt;
OpenStack计算是一个云控制器，用来启动一个用户或一个组的虚拟实例，它也用于配置每个实例或项目中包含多个实例为某个特定项目的联网。&lt;br /&gt;
OpenStack对象存储是一个在具有内置冗余和容错的大容量系统中存储对象的系统。对象存储有各种应用，如备份或存档数据，存储图形或视频（流媒体数据传输到用户的浏览器），储存二级或三级静态数据，发展与数据存储集成新的应用程序，当预测存储容量困难时存储数据，创造弹性和灵活的云存储Web应用程序。&lt;br /&gt;
OpenStack镜像服务是一个查找和虚拟机图像检索系统。它可以配置三种方式：使用OpenStack对象存储来存储图像;使用亚马逊S3直接存储，或使用S3对象存储作为S3访问中间存储。
&lt;h2&gt;OpenStack Project Architecture&lt;/h2&gt;
OpenStack当前包括三个子项目，三个项目相会独立，可以单独安装。&lt;br /&gt;
• Swift 提供对象存储。这是大致类似于Rackspace云文件（从它派生）或亚马逊S3。&lt;br /&gt;
• Glance 提供OpenStack Nova虚拟机镜像的发现，存储和检索。&lt;br /&gt;
• Nova 根据要求提供虚拟服务。这与Rackspace云服务器或亚马逊EC2类似。&lt;br /&gt;
将来会出现web 接口的子项目以及队列服务的子项目。
&lt;h2&gt;Cloud Provider Conceptual Architecture&lt;/h2&gt;
构建自己的Iaas云环境并将其提供给用户，需要提供以下几个特性：&lt;br /&gt;
1. 允许应用用户注册云服务、查看使用情况以及账单。&lt;br /&gt;
2. 允许开发商和开发人员创建和存储自定义的镜像。&lt;br /&gt;
3. 允许开发商和开发人员启动、监控、停止虚拟机实例。&lt;br /&gt;
4. 允许操作人员配置和操作云基础设施。&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;上面只列出了基本的4个特性，当然还有其他一些特性，将这些特性列在一起，展示如下：
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Cloud-Provider-Conceptual-Architecture.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2123 aligncenter&quot; title=&quot;Cloud Provider Conceptual Architecture&quot; src=&quot;http://blog.javachen.com/files/2011/07/Cloud-Provider-Conceptual-Architecture-300x219.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;219&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在上面的模型中，假定了与云交互的四种人员（开发商、开发人员、操作员、用户），还定义了三层架构（表现、逻辑、资源）和两个正交领域（集成和管理）。&lt;br /&gt;
表现层，组件与用户交互，接受并显示用户的信息。在这一层，为非开发人员提供了一个web 图形界面，为开发人员提供了API。在这一层，还存在负载均衡、控制台代理、安全、命名服务。&lt;br /&gt;
逻辑层，为我们的云和控制功能提供情报。这层内包括部业务流程（工作流程复杂的任务），调度（确定作业对资源的映射），政策（配额等），镜像注册表（例如镜像的元数据），日志（事件和计量）。&lt;br /&gt;
集成功能，大多数服务提供商已经有一个客户的身份和计费系统。任何云架构将需要与这些系统集成。&lt;br /&gt;
管理层，提供一个API来管理云并提供监控功能。&lt;br /&gt;
资源层，因为这是一个计算云，我们需要实际的计算，网络和存储资源，以提供给客户。这一层提供这些服务，他们可能是服务器，网络交换机，网络附加存储或其他资源。
&lt;h2&gt;OpenStack Compute Logical Architecture&lt;/h2&gt;
OpenStack 中有两个守护进程：&lt;br /&gt;
接收和调解API调用的WSGI应用程序 （nova-api，glance-api等等）。&lt;br /&gt;
进行编排任务的工人守护进程（nova-compute， nova-network,，nova-schedule）。&lt;br /&gt;
OpenStack中还包含两个组件：消息队列服务和数据库。这两个组件方便异步编排复杂的任务通过消息传递和信息共享。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/OpenStack-Compute-Logical-Architecture.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2124 aligncenter&quot; title=&quot;OpenStack Compute Logical Architecture&quot; src=&quot;http://blog.javachen.com/files/2011/07/OpenStack-Compute-Logical-Architecture-300x220.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;220&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
这个复杂的，但不是太翔实的图表可以概括为三句话：&lt;br /&gt;
 终端用户通过nova-api 接口与Openstack 计算交互。&lt;br /&gt;
 OpenStack计算守护进程通过队列的交换信息（行动）和数据库（信息）进行API请求。&lt;br /&gt;
 OpenStack Glance是一个完全独立的基础上设施。
&lt;strong&gt;各个组件的介绍：&lt;/strong&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-api&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;：&lt;/code&gt;是对外的接口。OpenStack 云计算的核心控制器（CloudController定义在trunk/nova/api/ec2/cloud.py）。它提供了一个为所有的API查询（OpenStack API或EC2 API）的端点，引发多数业务流程的活动（如运行一个实例），并实施一些政策（主要是配额检查）。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-schedule&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;根据当前资源使用情况，决定计算节点分布到哪台计算节点上。目前实现很薄，目前已支持插件方式扩展，方便后面可能有采用更复杂算法。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-compute&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;接收队列中的动作，然后执行一系列的系统命令（如启动KVM实例），同时更新数据库中的状态。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-volume&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;给虚拟机分配额外持久化的存储，管理持久卷到计算实例的创建，连接和分离。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-network&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;网络管理，给虚拟机分配网络和管理，使外部 PC 可以可直接访问。它接受队列中的网络任务，然后执行任务操纵网络（如设立桥接接口或更改iptables规则）。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;queue&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;提供了一个守护进程之间传递消息的中央枢纽。当前由 &lt;a href=&quot;http://www.rabbitmq.com/&quot; target=&quot;_top&quot;&gt;RabbitMQ&lt;/a&gt;实现，理论上可以是Python的ampqlib支持的任何AMPQ消息队列。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;SQL database&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;存储云基础设施的编译时和运行时的状态。这包括可用的实例类型，在使用中的实例，可用的网络和项目。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;&lt;strong&gt;OpenStack Glance：&lt;/strong&gt;&lt;/code&gt;OpenStack 单独的一个项目。
&lt;h2&gt;Nova Conceptual Mapping&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenStack的架构示意图和目前已实现情况，蓝色是要 openstack概念上的架构图，红色是目前已实现的。&lt;/p&gt;

&lt;p&gt;上面的功能模块对应上面模型的映射：
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Nova-Conceptual-Mapping.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2125 alignnone&quot; title=&quot;Nova Conceptual Mapping&quot; src=&quot;http://blog.javachen.com/files/2011/07/Nova-Conceptual-Mapping-300x209.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;209&quot; /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;Service Architecture&lt;/h2&gt;
管理和使用是走两个通道的。管理必须要经由 nova-api转发过去。而运行时，直接连接计算节点上的虚拟机即可。&lt;strong&gt;&lt;/strong&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2126 aligncenter&quot; title=&quot;Service Architecture&quot; src=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture-300x295.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;295&quot; /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;部署&lt;/h2&gt;
部署时，除了Dashboard 必须部署在 nova-api server 上以外，所有的其它进程都可以部署在不同的机器上。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2127 aligncenter&quot; title=&quot;Service Architecture2&quot; src=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture2-300x140.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;140&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;OpenStack提供了基于 Puppet 的自动部署工具。经过简单配置，就可以把各个组件部署到不同机器上。
&lt;h2&gt;镜像管理&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenStack的镜像创建并没有纳入其职责列表。&lt;br /&gt;
你可以使用Ubuntu的已有image (https://help.ubuntu.com/community/UEC/)，或者直接重新自己通过KVM安装  ：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;http://cssoss.wordpress.com/2011/04/27/openstack-beginners-guide-for-ubuntu-11-04-image-management/&quot;&gt;http://cssoss.wordpress.com/2011/04/27/openstack-beginners-guide-for-ubuntu-11-04-image-management/&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;网络模型&lt;/h2&gt;
Flat Network Manager, Flat DHCP Network Manager, VLAN Network Manager.&lt;br /&gt;
VLAN Network Manager 这种方式适合于共有云。&lt;br /&gt;
在私有云方面， IP充足，而且为了方便的互联互通，简单的Flat结构网络比较适合。&lt;br /&gt;
OpenStack支持 Floating IPs ,该特性可以方便的通过更改IP来Failover(容错转移）或者迁移。
&lt;div class=&quot;note&quot;&gt;
&lt;h2&gt;参考文章&lt;/h2&gt;
OpenStack 架构：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6543880&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6543880&lt;/a&gt;
nova code:&lt;a href=&quot;https://bugs.launchpad.net/nova&quot; target=&quot;_blank&quot;&gt;https://bugs.launchpad.net/nova&lt;/a&gt;
openstack-nova-architecture：&lt;a href=&quot;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&quot; target=&quot;_blank&quot;&gt;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>OpenNebula的架构</title>
   <link href="http://blog.javachen.com/cloud/2011/07/06/opennebula-architecture"/>
   <updated>2011-07-06T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/07/06/opennebula-architecture</id>
   <content type="html">&lt;p&gt;&lt;p align=&quot;left&quot;&gt;OpenNebula是一款为云计算而打造的开源工具箱。它允许你与Xen，KVM或VMware ESX一起建立和管理私有云，同时还提供Deltacloud适配器与Amazon EC2相配合来管理混合云。除了像Amazon一样的商业云服务提供商，在不同OpenNebula实例上运行私有云的Amazon合作伙伴也同样可以作为远程云服务供应商。&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt;目前版本，可支持XEN、KVM和VMware，以及实时存取EC2和 ElasticHosts，它也支持印象档的传输、复制和虚拟网络管理网络。&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/one-cloud.png&quot;&gt;&lt;img class=&quot;size-full wp-image-2106 alignnone&quot; title=&quot;one cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/one-cloud.png&quot; alt=&quot;&quot; width=&quot;332&quot; height=&quot;166&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;图1  OpenNebula总体架构图&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt;OpenNebula可以构建私有云、混合云、公开云。&lt;!--more--&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;私有云&lt;/h2&gt;
私有云的目的是给本地的用户和管理员提供了一个灵活和敏捷的私人基础设施，以在可管理的域内运行虚拟化服务。 OpenNebula虚拟基础设施暴露虚拟化、网络、图像和物理资源的配置、管理、监督和会计的功能接口。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/private-cloud1.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2107 alignnone&quot; title=&quot;private cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/private-cloud1-300x187.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;187&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;图2 私有云&lt;/p&gt;

&lt;p&gt;一个OpenNebula私有云为平台基础设施的用户提供了一个快速交付和可扩展性的平台，以满足最终用户的动态需求。服务托管在虚拟机，然后提交，监视和被云控制，通过使用OpenNebula运营中心或OpenNebula的任何接口。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/private-cloud2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2108 aligncenter&quot; title=&quot;private cloud2&quot; src=&quot;http://blog.javachen.com/files/2011/07/private-cloud2-300x206.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;206&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图3 私有云内用户视图&lt;/p&gt;
&amp;nbsp;
&lt;h2&gt;混合云&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula提供Deltacloud适配器与Amazon EC2相配合来管理混合云。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/hyb-cloud2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2109 aligncenter&quot; title=&quot;hyb cloud2&quot; src=&quot;http://blog.javachen.com/files/2011/07/hyb-cloud2-300x203.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;203&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图4 混合云&lt;/p&gt;
&amp;nbsp;
&lt;h2&gt;公开云&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula公有云是私有云的一个扩展，是在私有云的基础上对外暴露REST接口。如果你要让合作伙伴或外部用户能够访问您的基础设施，或出售你的服务，云接口可以被添加到您的私有或混合云。显然，一个本地的云解决方案是任何公共云自然后端。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/public-cloud.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2110 aligncenter&quot; title=&quot;public cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/public-cloud-300x175.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;175&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图5 公开云&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula的构架包括三个部分：驱动层、核心层、工具层。驱动层直接与操作系统打交道，负责虚拟机的创建、启动和关闭，为虚拟机分配存储，监控物理机和虚拟机的运行状况。核心层负责对虚拟机、存储设备、虚拟网络等进行管理。工具层通过命令行界面/浏览器界面方式提供用户交互接口，通过API方式提供程序调用接口。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/3-cloud.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2111 aligncenter&quot; title=&quot;3 cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/3-cloud-300x178.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;178&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图6 三层架构图&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/3-cloud2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2112 aligncenter&quot; title=&quot;3 cloud2&quot; src=&quot;http://blog.javachen.com/files/2011/07/3-cloud2-300x181.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;181&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula使用共享存储设备（例如NFS）来提供虚拟机映像服务，使得每一个计算节点都能够访问到相同的虚拟机映像资源。当用户需要启动或者是关闭某个虚拟机时，OpenNebula通过SSH登陆到计算节点，在计算节点上直接运行相对应的虚拟化管理命令。这种模式也称为无代理模式，由于不需要在计算节点上安装额外的软件（或者服务），系统的复杂度也相对降低了。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/one-services.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2113 aligncenter&quot; title=&quot;one services&quot; src=&quot;http://blog.javachen.com/files/2011/07/one-services-300x189.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;189&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图7 前端节点和集群节点之间交互&lt;/p&gt;
&amp;nbsp;
&lt;h2&gt;网络架构&lt;/h2&gt;
OpenNebula使用桥连接来构建虚拟网络，每个节点的IP和MAC地址在一定范围内生成。一个网络会连接到一个特定的桥。每一个网络有他自己的拥有者并且可以对外公开或私有。每一个虚拟网络之间是相互隔离的。&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;虚拟网络里使用Ebtables来过滤数据链路层数据包。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;
&lt;div class=&quot;infor&quot;&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;
* 1.虚拟化管理软件比较 －－ 构架篇：&lt;a href=&quot;http://www.qyjohn.net/?p=1263&quot;&gt;http://www.qyjohn.net/?p=1263&lt;/a&gt;
* 2.opennebula.org：&lt;a href=&quot;http://opennebula.org/&quot;&gt;http://opennebula.org/&lt;/a&gt;
* 3.OpenNebula Workshop：&lt;a href=&quot;http://hpc.uamr.de/wissen/opennebula-workshop/&quot;&gt;http://hpc.uamr.de/wissen/opennebula-workshop/&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Centos上安装 OpenNebula Management Console</title>
   <link href="http://blog.javachen.com/cloud/2011/06/29/install-opennebula-management-console-in-centos5-6"/>
   <updated>2011-06-29T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/29/install-opennebula-management-console-in-centos5-6</id>
   <content type="html">&lt;p&gt;我们可以通过onehost/onevm/onevnet等等 这些命令行工具来管理 OpenNebula 云计算平台，也可以通过OpenNebula项目组开发的web控制台来访问OpenNebula。OpenNebula项目组提供了两个web程序来管理OpenNebula，一个即本文提到的&lt;a href=&quot;http://dev.opennebula.org/projects/management-console&quot; target=&quot;_blank&quot;&gt;OpenNebula Management Console&lt;/a&gt;，一个是&lt;a href=&quot;http://opennebula.org/documentation:rel2.2:sunstone&quot; target=&quot;_blank&quot;&gt;The Cloud Operations Center&lt;/a&gt;，前者需要额外&lt;a href=&quot;http://dev.opennebula.org/attachments/download/128/onemc-1.0.0.tar.gz&quot; target=&quot;_blank&quot;&gt;下载&lt;/a&gt;，后者内嵌与OpenNebula安装包内。&lt;/p&gt;

&lt;p&gt;OpenNebula 2.2提供的文档相对较少并且零散，在网上可以找到一篇关于OpenNebula Management Console安装的文章：&lt;br /&gt;
《&lt;a href=&quot;http://www.vpsee.com/2011/03/install-opennebula-management-console-on-centos/&quot; target=&quot;_blank&quot;&gt;安装 OpenNebula 基于 Web 的管理控制台》&lt;/a&gt;，我的这篇文章参考了这篇文章并加以完善，这篇文章对我完成OpenNebula Management Console的安装起到很大帮助，感谢原文作者。&lt;/p&gt;

&lt;p&gt;我的安装环境：centos5.6 ，OpenNebula2.2，在安装OpenNebula2.2之前，我执行了yum update，即更新系统的软件。&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;!--more--&gt;以下来自&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki&quot;&gt;官方文档&lt;/a&gt;：&lt;/span&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;要求:&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Apache or whatever webserver.&lt;/li&gt;
    &lt;li&gt;php5 (May work with php4 but not tested)&lt;/li&gt;
    &lt;li&gt;php-adodb&lt;br /&gt;
And you need a db driver for adodb: php-mysql or php-pgsql.&lt;/li&gt;
    &lt;li&gt;Mysql or postgresql database&lt;/li&gt;
    &lt;li&gt;php-curl&lt;/li&gt;
    &lt;li&gt;php-xmlrpc&lt;/li&gt;
    &lt;li&gt;php-pear: pecl install uploadprogress (Only if you want a nice upload progress bar)&lt;/li&gt;
&lt;/ul&gt;
如果你想查看更多资料，您可以去官网：&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki&quot;&gt;OpenNebula Management Console Wiki&lt;/a&gt;；如果你想在ubutun上安装OpenNebula Management Console，参照这篇文章：&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki/onemc_install_ubuntu&quot;&gt;Install onemc on ubuntu&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;以下为安装过程：&lt;/span&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;必要软件&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# yum -y install php mysql-server httpd mysql-connector-odbc mysql-devel libdbi-dbd-mysql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #ff0000; font-size: 15px;&quot;&gt;安装php-adodb&lt;/span&gt;&lt;/h3&gt;
从&lt;a href=&quot;http://sourceforge.net/projects/adodb/files/adodb-php5-only&quot;&gt;http://sourceforge.net/projects/adodb/files/adodb-php5-only&lt;/a&gt;下载
&lt;strong&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;注意：&lt;/span&gt;&lt;/strong&gt;将adobd包解压拷贝到/var/www/html/onemc/include/，将文件名改为adobd
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;安装php的扩展&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# yum -y install php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-curl php-mysql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;安装apache扩展&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# yum -y install httpd-manual mod_ssl mod_perl mod_auth_mysql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;修改配置文件权限&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# chmod 644 /var/www/html/onemc/include/config.php&lt;/pre&gt;
我下载的是OpenNebula 2.2其中/config.php的权限很特别，如果你从浏览器访问onemc时候页面都是空白的，你可以看看日志（我使用的是httpd，日志在httpd.log），可以看到日志中提示没有权限访问/var/www/html/onemc/include/config.php
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;下载 onemc&lt;/span&gt;&lt;/h3&gt;
下载和解压 onemc-1.0.0.tar.gz 后直接放在 apache 的默认目录里：
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# cd /var/www/html
# wget http://dev.opennebula.org/attachments/download/128/onemc-1.0.0.tar.gz
# tar zxvf onemc-1.0.0.tar.gz
# cd onemc&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;配置数据库&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# mysql -uroot -p
Enter password:
mysql&amp;gt; create database onemc;
mysql&amp;gt; create user 'oneadmin'@'localhost' identified by 'oneadmin';
mysql&amp;gt; grant all privileges on onemc.* to 'oneadmin'@'localhost';
mysql&amp;gt; \q&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;初始化数据库&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# mysql -u oneadmin -p onemc &amp;lt; /var/www/html/onemc/include/mysql.sql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;配置 onemc&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# vi /var/www/html/onemc/include/config.php
...
// vmm: kvm or xen
$vmm = &quot;xen&quot;;
...
// ADODB settings
$adodb_type = &quot;mysql&quot;;
$adodb_server = &quot;localhost&quot;;
$adodb_user = &quot;oneadmin&quot;;
$adodb_pass = &quot;oneadmin&quot;;
$adodb_name = &quot;onemc&quot;;&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;登录&lt;/span&gt;&lt;/h3&gt;
如果系统设置了 http_proxy 环境变量的话一定要先关闭，然后重启 one 和 httpd：
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# unset http_proxy
# one stop; one start
# /etc/init.d/httpd restar
&lt;/pre&gt;
访问地址为http://localhost/onemc/index.php，用户名和密码在one_auth 中。
&lt;h3&gt;&lt;span style=&quot;font-size: 15px;&quot;&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;总结&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
以上步骤最重要的是配置好centos的yum源，一次将php和mysql及相关组件安装成功，然后需要注意的是上面红色部分标出的部分。其实，除了红色那部分之外，其余和开头提到的那篇文章内容没什么差别。
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;参考文章&lt;/span&gt;&lt;/h3&gt;
&lt;li&gt;
&lt;a href=&quot;http://www.javachen.com/?page_id=2073#date=2011-06-29 12:00:00,mode=month&quot; target=&quot;_blank&quot;&gt;Centos上安装 OpenNebula Management Console&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki&quot;&gt;OpenNebula Management Console Wiki&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki/onemc_install_ubuntu&quot;&gt;Install onemc on ubuntu&lt;/a&gt;
&lt;/li&gt;
&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>OpenNebula 2.2的特性</title>
   <link href="http://blog.javachen.com/cloud/2011/06/26/opennebula-2-2-features"/>
   <updated>2011-06-26T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/26/opennebula-2-2-features</id>
   <content type="html">&lt;p&gt;以下这篇文章由&lt;a title=&quot;OpenNebula 2.2 Features&quot; href=&quot;http://opennebula.org/documentation:features&quot;&gt;OpenNebula 2.2 Features&lt;/a&gt;翻译而来。&lt;/p&gt;

&lt;p&gt;OpenNebula是一款为云计算而打造的开源工具箱。它允许你与Xen，KVM或VMware ESX一起建立和管理私有云，同时还提供Deltacloud适配器与Amazon EC2相配合来管理混合云。除了像Amazon一样的商业云服务提供商，在不同OpenNebula实例上运行私有云的Amazon合作伙伴也同样可以作为远程云服务供应商。&lt;/p&gt;

&lt;p&gt;目前版本，可支持XEN、KVM和VMware，以及实时存取EC2和 ElasticHosts，它也支持印象档的传输、复制和虚拟网络管理网络。
&lt;h2&gt;主要特点和优势&lt;/h2&gt;
&lt;strong&gt;私有云计算&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为私有数据中心或集群（管理功能&lt;strong&gt;私有云计算&lt;/strong&gt;）上运行&lt;strong&gt;的&lt;/strong&gt;&lt;strong&gt;Xen&lt;/strong&gt;，&lt;strong&gt;KVM&lt;/strong&gt;和&lt;strong&gt;VMware&lt;/strong&gt;&lt;strong&gt;的&lt;/strong&gt;。
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;用户管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;用户管理，认证框架，多个云用户和管理员角色，会计，配额管理，安全的多租户。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;VM&lt;/strong&gt;&lt;strong&gt;图像管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;带目录的镜像仓库和镜像管理，访问控制，以及从正在运行的虚拟机创建镜像。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;虚拟网络管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;对互联的虚拟机;一定范围或固定的网络;虚拟网络共享;相关的第2层虚拟网络和网络隔离的通用属性定义提供虚拟网络管理。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;虚拟机管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;虚拟机管理功能，支持在同一物理结构中的多个hypervisors，分布式环境的多个hypervisor管理，虚拟机自动配置，以及脚本在虚拟机的状态变化时的触发管理。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;服务管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;部署由多层次的相互联系的虚拟机组成的群体服务;在启动时自动配置，以及对微软Windows和Linux镜像的支持。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;基础设施管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;管理物理主机;创建本地集群，占地面积小，占用空间不到700KB。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;存储管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;虚拟机映像管理，支持多种硬件平台（FibreChannel, iSCSI, NAS shared storage…）和存储后端传输镜像。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;信息管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;虚拟机和物理基础设施的监控，并与数据监测工具集成，如&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;调度&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;强大和灵活的竞价/排名调度、工作量和资源分配政策，如包装，分割，负载感知.....&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;用户界面&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;Unix类似的云基础设施管理命令行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;运营中心&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;图形化管理的云基础设施。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;混合云计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;本地基础设施与远程云资源的扩展（&lt;strong&gt;混合云计算&lt;/strong&gt;）
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;449&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;&lt;strong&gt;Cloudbursting&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;449&quot;&gt;本地的基础设施，可以辅从外部云计算能力，以满足高峰需求，更好地服务用户的访问请求，或者为了实现高可用性策略。支持亚马逊EC2，并同时访问多个云。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;&lt;strong&gt;Federation&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;449&quot;&gt;不同的云实例以构建一个独立的虚拟化集群层次;更高水平的可扩展性。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;公共云计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;暴露云接口给私有的基础设施功能（&lt;strong&gt;公共云计算&lt;/strong&gt;）
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;云接口&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;通过提供给用户的REST接口;实现OGF OCCI和亚马逊EC2接口，使本地的基础架构转变为一个公开云;支持同时公开多种云API，客户端工具，以及安全访问。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;主要特点和集成优势&lt;/h2&gt;
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;基础设施抽象&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;无缝与任何操作平台的验证/授权，虚拟化，网络和存储平台融合，采用模块化结构，以适应任何数据中心。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;适应性和定制&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;启用任何云架构的部署：公共，私有，混合和联合;定制插件来访问虚拟化、存储、信息、认证/授权和远程云服务，新的插件可以很容易地在任何语言编写，配置和改变参数调整云管理实例的行为以满足环境和用例要求;钩机制，当虚拟机的状态改变使触发管理脚本的执行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;互操作性和标准&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;开放标准为基础的架构，以避免厂商锁定，提高互操作性​​，以及开放的实施标准。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;开放&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;开源Apache许可下发布协议。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;编程接口&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;提供Ruby和Java XMLRPC的原生云API创建新的云接口和访问核心功能。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;主要特点和生产效益&lt;/h2&gt;
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;安全&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;验证框架的密码，或基于SSH的RSA密钥对LDAP，外部和内部通信通过SSL，安全的多​​租户;隔离的网络。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;健壮性&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;持久数据库后端存储主机、网络、虚拟机信息。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;容错&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;配置主机、虚拟机或OpenNebula实例故障事件。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;测试在大规模的核心和成千上万的基础设施;高度可扩展的后端，并为MySQL和SQLite支持。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;性能&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;非常高效的内核开发C++语言。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;可靠性&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;自动化的功能、可扩展性、性能、可靠性和稳定性测试过程。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;利用充满活力的云生态系统&lt;/h2&gt;
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;OpenNebula Ecosystem&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;充分利用&lt;a title=&quot;http://www.opennebula.org/software:ecosystem&quot; href=&quot;http://www.opennebula.org/software:ecosystem&quot;&gt;OpenNebula开放云生态系统&lt;/a&gt;与新元件加强了OpenNebula云工具包提供的功能并能够与其他产品的集成：vCloud的API、OpenNebula块、Haizea调度、 Libcloud、Deltacloud、Web管理控制台，Deltacloud的混合云适配器...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;Other Cloud Ecosystems&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;围绕Amazon AWS, OGC OCCI and VMware vCloud构建的生态系统。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Eucalyptus使用的技术</title>
   <link href="http://blog.javachen.com/cloud/2011/06/22/the-technology-used-in-eucalyptus"/>
   <updated>2011-06-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/22/the-technology-used-in-eucalyptus</id>
   <content type="html">&lt;p&gt;&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://libvirt.org/&quot;&gt;libvirt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Libvirt 库是一种实现 Linux 虚拟化功能的 Linux® API，它支持各种虚拟机监控程序，包括 Xen 和 KVM，以及 QEMU 和用于其他操作系统的一些虚拟产品。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.jboss.org/netty/&quot;&gt;Netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Netty 提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://ws.apache.org/axis2/&quot;&gt;Axis2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Axis2是下一代 Apache Axis。Axis2 虽然由 Axis 1.x 处理程序模型提供支持，但它具有更强的灵活性并可扩展到新的体系结构。Axis2 基于新的体系结构进行了全新编写，而且没有采用 Axis 1.x 的常用代码。支持开发 Axis2 的动力是探寻模块化更强、灵活性更高和更有效的体系结构，这种体系结构可以很容易地插入到其他相关 Web 服务标准和协议（如 WS-Security、WS-ReliableMessaging 等）的实现中。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://ws.apache.org/axis2/c/&quot;&gt;Axis2c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Apache Axis2/C is a Web services engine implemented in the C programming language. It is based on the extensible and flexible &lt;a title=&quot;External Link&quot; href=&quot;http://ws.apache.org/axis2/1_2/Axis2ArchitectureGuide.html&quot;&gt;Axis2 architecture&lt;/a&gt;.
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://ws.apache.org/rampart/c/&quot;&gt;Rampart/C&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a title=&quot;External Link&quot; href=&quot;http://ws.apache.org/axis2/c/&quot;&gt;Apache Axis2/C&lt;/a&gt;的安全模块
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://jibx.sourceforge.net/&quot;&gt;JiBX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
JiBX是一款非常优秀的XML（Extensible Markup Language）数据绑定框架。它提供灵活的绑定映射文件实现数据对象与XML文件之间的转换；并不需要你修改既有的Java类。另外，另外，它的转换效率是目前很多开源项目都无法比拟的。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.bouncycastle.org/java.html&quot;&gt;Bouncy Castle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Bouncy Castle 是一种用于 Java 平台的开放源码的轻量级密码术包。它支持大量的密码术算法，并提供 JCE 1.2.1 的实现。因为 Bouncy Castle 被设计成轻量级的，所以从 J2SE 1.4 到 J2ME（包括 MIDP）平台，它都可以运行。它是在 MIDP 上运行的唯一完整的密码术包。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://mule.mulesource.org/display/MULE/Home&quot;&gt;Mule&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
它是一个轻量级的消息框架和整合平台，基于EIP（Enterprise Integeration Patterns,由Hohpe和Woolf编写的一本书）而实现的。Mule的核心组件是UMO(Universal Message Objects，从Mule2.0开始UMO这一概念已经被组件Componse所代替)，UMO实现整合逻辑。UMO可以是POJO,JavaBean等等。它支持20多种传输协议(file,FTP,UDP,SMTP,POP,HTTP,SOAP,JMS等)，并整合了许多流行的开源项目，比如Spring,ActiveMQ,CXF,Axis,Drools等。虽然Mule没有基于JBI来构建其架构，但是它为JBI容器提供了JBI适配器，应此可以很好地与JBI容器整合在一起。而 Mule更关注其灵活性，高效性以及易开发性。从2005年发表1.0版本以来，Mule吸引了越来越多的关注者，成为开源ESB中的一支独秀。目前许多公司都使用了Mule，比如Walmart,HP,Sony,Deutsche Bank 以及 CitiBank等公司。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.hibernate.org/&quot;&gt;Hibernate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Hibernate是一个开放源代码的&lt;a href=&quot;http://baike.baidu.com/view/2387.htm&quot; target=&quot;_blank&quot;&gt;对象&lt;/a&gt;关系映射框架，它对JDBC进行了非常轻量级的对象封装，使得Java程序员可以随心所欲的使用对象编程思维来操纵&lt;a href=&quot;http://baike.baidu.com/view/1088.htm&quot; target=&quot;_blank&quot;&gt;数据库&lt;/a&gt;。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.hsqldb.org/&quot;&gt;HSQLDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Hsqldb是一个开放源代码的JAVA数据库，其具有标准的SQL语法和JAVA接口，它可以自由使用和分发，非常简洁和快速的。在其官网可以获得最新的程序源代码及jar包文件
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://xen.org/&quot;&gt;Xen&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Xen 是一个开放源代码&lt;a href=&quot;http://baike.baidu.com/view/1132.htm&quot; target=&quot;_blank&quot;&gt;虚拟机&lt;/a&gt;监视器，由&lt;a href=&quot;http://baike.baidu.com/view/13714.htm&quot; target=&quot;_blank&quot;&gt;剑桥大学&lt;/a&gt;开发。它打算在单个计算机上运行多达100个满特征的&lt;a href=&quot;http://baike.baidu.com/view/880.htm&quot; target=&quot;_blank&quot;&gt;操作系统&lt;/a&gt;。操作系统必须进行显式地修改（“移植”）以在Xen上运行（但是提供对用户应用的兼容性）。这使得Xen无需特殊硬件支持，就能达到高性能的虚拟化。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.linux-kvm.org/page/Main_Page&quot;&gt;KVM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
基于内核的虚拟机(或简称为KVM)是一个由Qumrannet开发和赞助的开源项目.
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://code.google.com/webtoolkit/&quot;&gt;Google Web Toolkit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;em&gt; Google Web Toolkit&lt;/em&gt; (GWT) 允许开发人员使用Java 编程语言快速构建和维护复杂而又高性能的JavaScript 前端应用程序，从而降低了开发难度
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://sourceware.org/lvm2/&quot;&gt;LVM2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
LVM是 Logical Volume Manager(逻辑卷管理)的简写，它是Linux环境下对磁盘分区进行管理的一种机制，它由Heinz Mauelshagen在Linux 2.4内核上实现，目前最新版本为：稳定版1.0.5，开发版 1.1.0-rc2，以及LVM2开发版。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://jetty.codehaus.org/jetty/&quot; target=&quot;_blank&quot;&gt;Jetty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Jetty 是一个开源的servlet容器，它为基于Java的web内容，例如JSP和servlet提供运行环境。Jetty是使用&lt;a href=&quot;http://baike.baidu.com/view/229611.htm&quot; target=&quot;_blank&quot;&gt;Java语言&lt;/a&gt;编写的，它的API以一组JAR包的形式发布。开发人员可以将Jetty容器实例化成一个对象，可以迅速为一些独立运行（stand-alone）的Java应用提供网络和web连接。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Eucalyptus EE的介绍及功能说明</title>
   <link href="http://blog.javachen.com/cloud/2011/06/22/the-introduction-of-eucalyptus-ee-features-and-functions"/>
   <updated>2011-06-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/22/the-introduction-of-eucalyptus-ee-features-and-functions</id>
   <content type="html">&lt;p&gt;Eucalyptus企业版2.0是一个基于Linux的软件架构，在企业现有的IT架构上实现一个可扩展的、提高效率的私有和混合云。Eucalyptus作为基础设施提供IaaS服务。这意味着用户可以通过Eucalyptus自助服务界面提供自己的资源（硬件、存储和网络）。一个Eucalyptus云是部署在企业的内部数据中心，由企业内部用户访问。因此，敏感数据可以在防火墙的保护下防止外部入侵。&lt;/p&gt;

&lt;p&gt;Eucalyptus的设计目的是从根本上易于安装和尽可能没有侵扰。该软件高度模块化，具有行业标准，和语言无关。它提供了可以与EC2兼容的云计算平台和与S3兼容的云存储平台。&lt;!--more--&gt;
&lt;h1&gt;功能亮点&lt;/h1&gt;
&lt;ul&gt;
    &lt;li&gt;无缝管理多个管理程序环境（Xen的，vSphere的，KVM，ESX，ESXi的）下一个管理控制台&lt;/li&gt;
    &lt;li&gt;启用跨平台的客户机操作系统包括微软Windows和Linux&lt;/li&gt;
    &lt;li&gt;高级存储集成器（iSCSI，SAN，NAS），您可以轻松地连接和管理Eucalyptus云内现有的存储系统&lt;/li&gt;
    &lt;li&gt;完善的用户和组管理，允许私有云资源的精确控制&lt;/li&gt;
    &lt;li&gt;测试，开发和部署能够顺利过渡到公共云或反之亦然，没有任何修改&lt;/li&gt;
    &lt;li&gt;快速，轻松地建立与基于VMware的虚拟化环境和其他公共云混合云&lt;/li&gt;
    &lt;li&gt;启用先进设备，最先进的企业，如可扩展的存储整合，监控，审计，报表&lt;/li&gt;
    &lt;li&gt;利用充满活力的生态系统围绕亚马逊AWS构建，提供解决方案，无缝地与Eucalyptus兼容&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;优点&lt;/h1&gt;
&lt;ul&gt;
    &lt;li&gt;建立一个私有云，让你接入到亚马逊AWS&lt;/li&gt;
    &lt;li&gt;允许云在原有的所有硬件和软件类型很容易的部署&lt;/li&gt;
    &lt;li&gt;客户可以利用其全球用户社区&lt;/li&gt;
    &lt;li&gt;Eucalyptus是与Linux和多个管理程序兼容&lt;/li&gt;
    &lt;li&gt;Eucalyptus还支持商业Linux发行版本：红帽企业Linux（RHEL）和SUSE Linux企业服务器（SLES）&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;对于IT管理员的好处&lt;/h1&gt;
&lt;ul&gt;
    &lt;li&gt;提供自助服务的IT基础设施供应到最终用户需要的IT资源迅速&lt;/li&gt;
    &lt;li&gt;没有额外的资金保持现有的基础设施费用，降低运营成本&lt;/li&gt;
    &lt;li&gt;保持防火墙后面的关键数据&lt;/li&gt;
    &lt;li&gt;技术是对现有的硬件和软件基础设施覆盖，而不是替代&lt;/li&gt;
    &lt;li&gt;避免锁定在第三方公共云供应商&lt;/li&gt;
    &lt;li&gt;可轻松转换之间来回私人和公共云&lt;/li&gt;
&lt;/ul&gt;
&amp;nbsp;
&lt;h1&gt;Eucalyptus EE新特性&lt;/h1&gt;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;对windows VM的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
1.  运行windows 虚拟机在Eucalyptus 云环境上运行，目前支持Windows 2003 Server,Windows 2008 Server和Windows 7。&lt;br /&gt;
2.  试用Euca2ools管理和控制windows虚拟机。&lt;br /&gt;
3.  试用EC2兼容的命令从正在运行的windows虚拟机创建新的虚拟机&lt;br /&gt;
4.  在Eucalyptus中通过标准的RDP客户端工具，使用AWS “get-password”访问虚拟机实例&lt;br /&gt;
5.  在多个hypervisors环境中部署windows虚拟机，包括Xen、Kvm、VMware（ESX/ESXi）&lt;br /&gt;
6.  基于windows 操作系统安装文件（ISO镜像、CD/DVD）创建新的windows虚拟机
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;对VMware的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
1.支持VMware vCenter 4.0,ESX/ESXi 4.0!&lt;br /&gt;
2.与VMware vSphere 客户端兼容&lt;br /&gt;
3.能够合并VMware(ESX/ESXi)和开源的hypervisors（Xen、Kvm）到一个单独的云环境&lt;br /&gt;
4.通过Eucalyptus的软件扩展一些云的基本特性（例如IPs，安全组，S3）到一个VMware基础架构&lt;/p&gt;

&lt;p&gt;&amp;nbsp;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;引入SAN的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
Eucalyptus EE引入对SAN的支持，使你能够整合enterprise-grade SAN(Storage Area Network) 硬件设备到Eucalyptus云环境。SAN扩展SC并在Eucalyptus中运行的虚拟机和SAN设备之间提供高性能的数据通道。Eucalyptus EE的SAN支持为Eucalyptus云环境提供了一个企业级的EBS解决方案。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;
&lt;h1&gt;Eucalyptus的功能&lt;/h1&gt;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;基本组成部分及功能&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; width=&quot;614&quot; align=&quot;left&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;模块&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;功能&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;说明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;云控制器（CLC）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.对外提供EC2和Web接口，管理各类组件中的可用虚拟资源（服务、网络、存储）。&lt;br /&gt;
2.资源抽象，决定哪个簇将提供给实例，分发请求给CC。&lt;br /&gt;
3.管理运行的实例。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;CLC是整个云结构的前端。CLC为客户工具提供与EC2/S3兼容的网络接口，与Eucalyptus的组件通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;存储控制器（SC）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.提供与EBS类似的存储功能，能够与大量的文件存储系统交互。&lt;br /&gt;
2.使用AoE或者iSCSI协议为实例提供块存储。&lt;br /&gt;
3.允许在存储系统中（如Walrus）建立快照。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;SC提供实例使用的块存储。&lt;br /&gt;
与EBS类似。&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;

&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;Walrus控制器（WS3）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.允许用户存储持久化的数据。&lt;br /&gt;
2.提供REST接口操作数据，设置数据访问策略。&lt;br /&gt;
3.使用S3 API存储和获取虚拟镜像和数据。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;WS3使用与S3 API兼容的REST和SOAP   API提供简单的存储服务&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;控制簇（CC）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.接收CLC的请求，然后部署实例。&lt;br /&gt;
2.收集虚拟机的信息并决定在哪个节点控制上执行虚拟机。&lt;br /&gt;
3.为实例提供有效的虚拟网络。&lt;br /&gt;
4.收集NCs提交的信息，并报告给CLC。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;CC管理NC，部署和管理在节点上的实例，在Eucalyptus联网模型的类型下管理在控制节点上运行的实例的联网。&lt;br /&gt;
CC连接着云控制器CLC和控制节点NC。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;节点控制器（NC）&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.托管虚拟机实例&lt;br /&gt;
2.收集节点上相关的数据资源的可用性和利用率，并报告给控制簇CC。&lt;br /&gt;
3.管理虚拟机的生命周期，能够获取和清除镜像的本地拷贝。&lt;br /&gt;
4.维护虚拟网络&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;UEC的节点使用虚拟化技术使KVM能作为管理程序在服务器上运行。当用户安装UEC节点时，UEC将自动安装KVM。UEC的实例就是在管理程序下运行的虚拟机。Eucalyptus支持其他管理程序，如Xen。&lt;br /&gt;
节点控制器在每一个节点上运行，控制着节点上实例的生命周期。&lt;/td&gt;

&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;VMware   Broker&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;允许 Eucalyptus直接地或通过 VMware&lt;strong&gt; &lt;/strong&gt;Vcenter在   VMware设备部署虚拟机，在CC和 VMware  hypervisors(ESX/ESXi)起一个连接作用&lt;strong&gt; &lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;Eucalyptus   EE额外的一个组件，用于对VMware的支持&lt;/td&gt;
&lt;/tr&gt;


&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;font-size: 20px; font-weight: bold; color: #0000ff;&quot;&gt;管理员拥有的功能&lt;/span&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; width=&quot;614&quot; align=&quot;left&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;模块&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;功能&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;说明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;用户管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  添加用户（邮件通知，设置管理员）&lt;br /&gt;
2.  查看用户，设置账户是否激活&lt;br /&gt;
3.  删除用户&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;组管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  添加用户组&lt;br /&gt;
2.  查看用户组&lt;br /&gt;
3.  删除用户组&lt;br /&gt;
4.  添加/删除组员&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;权限管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.给组设置权限&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;Web接口&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  查看、下载证书&lt;br /&gt;
2.  查看上传的镜像，并能修改镜像状态&lt;br /&gt;
3.  配置管理。可以设置云主机IP、DNS、Walrus、Cluster和SAN&lt;br /&gt;
4.  审计报表。查看用户状态、资源使用率、系统日志、已注册的组件&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;这部分是web 管理界面提供的功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;组件管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  可以注册Cloud、Walrus、Storage、Node，并可以查看、删除&lt;br /&gt;
2.  启动、停止云服务&lt;br /&gt;
3.  允许转换卷的实现方式&lt;br /&gt;
4.  可以查看、修改配置文件&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;对外以SOAP和REST提供接口&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;使用者拥有的功能&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; width=&quot;614&quot; align=&quot;left&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;模块&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;功能&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;说明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;Web接口&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  用户可以注册帐号，修改信息及密码&lt;br /&gt;
2.  查看、下载证书&lt;br /&gt;
3.  查看上传的镜像&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;这部分是web 管理界面提供的功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;组件管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  启动、停止节点&lt;br /&gt;
2.  可以绑定、上传、注册、查看镜像，也可以删除、取消绑定镜像&lt;br /&gt;
3.  查看本地可用的资源&lt;br /&gt;
4.  可以查看、启动、停止、重启虚拟机&lt;br /&gt;
5.  可以登入到一个windows虚拟机实例&lt;br /&gt;
6.  创建、附件、脱离、删除快照和卷&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;通过Euca2ools工具完成这些功能&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;nbsp;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>接触云服务环境Eucalyptus</title>
   <link href="http://blog.javachen.com/cloud/2011/06/16/touch-cloud-environment-which-it-is-eucalyptus"/>
   <updated>2011-06-16T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/16/touch-cloud-environment-which-it-is-eucalyptus</id>
   <content type="html">&lt;p&gt;最近在接触云计算平台，熟悉了&lt;a href=&quot;http://www.eucalyptus.com/&quot;&gt;Eucalyptus&lt;/a&gt;，并用其搭建云环境。通过网上的一些例子，逐渐的摸索出用&lt;a href=&quot;http://www.eucalyptus.com/&quot;&gt;Eucalyptus&lt;/a&gt;搭建云计算平台的方法。我所用的Eucalyptus是免费版，缺少很多企业版的功能。
&lt;h2&gt;Eucalyptus&lt;/h2&gt;
Elastic Utility Computing Architecture for Linking Your Programs To Useful Systems （Eucalyptus） 是一种开源的软件基础结构，用来通过&lt;span style=&quot;color: #ff0000;&quot;&gt;计算集群或工作站群实现弹性的、实用的云计算&lt;/span&gt;。它最初是美国加利福尼亚大学 Santa Barbara 计算机科学学院的一个研究项目，现在已经商业化，发展成为了 Eucalyptus Systems Inc。不过，Eucalyptus 仍然按开源项目那样维护和开发。Eucalyptus Systems 还在基于开源的 Eucalyptus 构建额外的产品；它还提供支持服务。
&lt;!--more--&gt; 它提供了如下这些高级特性：
&lt;blockquote&gt;与 EC2 和 S3 的接口兼容性（&lt;span style=&quot;color: #ff0000;&quot;&gt;SOAP 接口和 REST 接口&lt;/span&gt;）。使用这些接口的几乎所有现有工具都将可以与基于 Eucalyptus 的云协作。&lt;br /&gt;
支持运行在&lt;span style=&quot;color: #ff0000;&quot;&gt; Xen hypervisor&lt;/span&gt; 或 &lt;span style=&quot;color: #ff0000;&quot;&gt;KVM&lt;/span&gt; 之上的 VM 的运行。未来版本还有望支持其他类型的 VM，比如 VMware。&lt;br /&gt;
用来进行&lt;span style=&quot;color: #ff0000;&quot;&gt;系统管理和用户结算&lt;/span&gt;的云管理工具。&lt;br /&gt;
能够将多个分别具有各自私有的内部网络地址的&lt;span style=&quot;color: #ff0000;&quot;&gt;集群&lt;/span&gt;配置到一个云内。&lt;/blockquote&gt;
&lt;h2&gt;架构&lt;/h2&gt;
Eucalyptus 包含五个主要组件，它们能相互协作共同提供所需的云服务。这些组件使用具有 WS-Security 的 SOAP 消息传递安全地相互通信。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cloud Controller (CLC)&lt;/strong&gt;
在 Eucalyptus 云内，这是主要的控制器组件，负责管理整个系统。它是所有用户和管理员进入 Eucalyptus 云的主要入口。所有客户机通过基于 SOAP 或 REST 的 API 只与 CLC 通信。由 CLC 负责将请求传递给正确的组件、收集它们并将来自这些组件的响应发送回至该客户机。这是 Eucalyptus 云的对外 “窗口”。
&lt;strong&gt;Cluster Controller (CC)&lt;/strong&gt;
Eucalyptus 内的这个控制器组件负责管理整个虚拟实例网络。请求通过基于 SOAP 或 REST 的接口被送至 CC。CC 维护有关运行在系统内的 Node Controller 的全部信息，并负责控制这些实例的生命周期。它将开启虚拟实例的请求路由到具有可用资源的 Node Controller。
&lt;strong&gt;Node Controller (NC)&lt;/strong&gt;
它控制主机操作系统及相应的 hypervisor（Xen 或最近的 KVM，很快就会支持 VMWare）。必须在托管了实际的虚拟实例（根据来自 CC 的请求实例化）的每个机器上运行 NC 的一个实例。
&lt;strong&gt;Walrus (W)&lt;/strong&gt;
这个控制器组件管理对 Eucalyptus 内的存储服务的访问。请求通过基于 SOAP 或 REST 的接口传递至 Walrus。
&lt;strong&gt;Storage Controller (SC)&lt;/strong&gt;
Eucalyptus 内的这个存储服务实现 Amazon 的 S3 接口。SC 与 Walrus 联合工作，用于存储和访问虚拟机映像、内核映像、RAM 磁盘映像和用户数据。其中，VM 映像可以是公共的，也可以是私有的，并最初以压缩和加密的格式存储。这些映像只有在某个节点需要启动一个新的实例并请求访问此映像时才会被解密。&lt;br /&gt;
一个 Eucalyptus 云安装可以聚合和管理来自一个或多个集群的资源。一个集群 是连接到相同 LAN 的一组机器。在一个集群中，可以有一个或多个 NC 实例，每个实例管理虚拟实例的实例化和终止。
&lt;div class=&quot;info&quot;&gt;
&lt;h2&gt;参考文章&lt;/h2&gt;
在安装的过程中，参考了一些网上的文章：&lt;br /&gt;
&lt;li&gt;Eucalyptus 开启云端：
&lt;a href=&quot;http://blog.163.com/firstsko@126/blog/static/132168891201022935737810/&quot;&gt;http://blog.163.com/firstsko@126/blog/static/132168891201022935737810/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
Installing Eucalyptus (2.0) on Fedora 12
&lt;a href=&quot;http://open.eucalyptus.com/wiki/EucalyptusInstallationFedora_v2.0&quot;&gt;http://open.eucalyptus.com/wiki/EucalyptusInstallationFedora_v2.0&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
 在Fedora 13 上搭建Eucalyptus
&lt;a href=&quot;http://blog.csdn.net/hispania/archive/2010/09/24/5902926.aspx&quot;&gt;http://blog.csdn.net/hispania/archive/2010/09/24/5902926.aspx&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;ubuntu 9.04 (server)下 eucalyptus 安装（推荐）：
&lt;a href=&quot;http://bbs.chinacloud.cn/archiver/showtopic-230.aspx&quot;&gt;http://bbs.chinacloud.cn/archiver/showtopic-230.aspx&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;/li&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;
&lt;h2&gt;Eucalyptus java源代码&lt;/h2&gt;
在安装过程中，我把Eucalyptus的java源代码（eucalyptus-2.0.3-src-offline.tar.gz）下下来了，并按照&lt;a href=&quot;http://open.eucalyptus.com/participate/sourcecode&quot;&gt;http://open.eucalyptus.com/participate/sourcecode&lt;/a&gt;的说明好不容易把java代码通过ant编译然后手动复制粘贴导入eclipse了，现在这些代码能够通过编译了，并能够清楚的看到Eucalyptus的java代码部分的实现方式。&lt;br /&gt;&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
