<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>JavaChen Blog</title>
 <link href="http://blog.javachen.com/atom.xml" rel="self"/>
 <link href="http://blog.javachen.com"/>
 <updated>2013-07-07T14:17:55+08:00</updated>
 <id>http://blog.javachen.com</id>
 <author>
   <name>JavaChen</name>
   <email>june.chan@foxmail.com</email>
 </author>

 
 <entry>
   <title>通过Cloudera Manager安装CDH</title>
   <link href="http://blog.javachen.com/hadoop/2013/06/24/install-cdh-by-cloudera-manager"/>
   <updated>2013-06-24T15:10:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/06/24/install-cdh-by-cloudera-manager</id>
   <content type="html">&lt;p&gt;你可以从&lt;a href=&quot;https://ccp.cloudera.com/display/SUPPORT/Downloads&quot;&gt;https://ccp.cloudera.com/display/SUPPORT/Downloads&lt;/a&gt;下载cloudera-manager-installer.bin，然后修改执行权限并执行该脚本。
该脚本中配置的rhel6的yum源为：&lt;a href=&quot;http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/4/&quot;&gt;http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/4/&lt;/a&gt;，下载的过程必须连网并且rpm的过程会非常慢，这种方法对虚拟机或者是无法连网的内网机器来说根本无法使用。&lt;/p&gt;

&lt;p&gt;因为知道所有的rpm都在上面网址可以下载到，故你可以手动下载这些rpm然后手动安装，详细过程请参考：&lt;a href=&quot;http://dreamyue.com/post/41090075449/cloudera-manager-hadoop&quot;&gt;通过cloudera-manager来安装hadoop&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;这里还有一种方法，就是手动下载&lt;code&gt;Cloudera Manager&lt;/code&gt;的yum tar包，在虚拟机中搭建一个本地yum源，然后修改hosts文件，使&lt;code&gt;archive.cloudera.com&lt;/code&gt;域名映射到本地ip。&lt;/p&gt;

&lt;p&gt;出于好奇，想破解&lt;code&gt;cloudera-manager-installer.bin&lt;/code&gt;，然后看看其中做了哪些操作。通过以下脚本即可解压该文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[june@june-fedora cdh]$ mv cloudera-manager-installer.bin cloudera-manager-installer.zip
[june@june-fedora cdh]$ unzip cloudera-manager-installer.zip 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解压之后的目录如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[june@june-fedora cloudera-manager-installer]$ ll
总用量 512
-rwxrwxr-x. 1 june june 501698 5月  25 09:53 cloudera-manager-installer.zip
drwxr-xr-x. 2 june june   4096 5月  23 03:05 data
drwxr-xr-x. 2 june june   4096 5月  22 21:48 guis
drwxr-xr-x. 2 june june   4096 5月  22 21:48 meta
drwxr-xr-x. 2 june june   4096 5月  22 21:48 scripts
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看解压之后的文件可以看到安装脚本是用lua编写并用MojoSetup编译的，从scripts/config.lua脚本中大概可以看出安装脚本的执行过程。&lt;/p&gt;

&lt;p&gt;整理下该脚本逻辑，主要是做了以下操作：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install -y jdk.x86_64 
yum install -y cloudera-manager-server 
yum install -y cloudera-manager-server-db
/etc/init.d/cloudera-scm-server start
/etc/init.d/cloudera-scm-server-db start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;知道了上面这点之后，就可以在本地的cloudera-manager yum中，执行以上操作完成cloudera-manager的安装，安装成功之后即可以访问web界面。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>kettle访问IDH2.3中的HBase</title>
   <link href="http://blog.javachen.com/hadoop/2013/04/17/access-idh-2.3-hbase-in-kettle"/>
   <updated>2013-04-17T21:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/04/17/access-idh-2.3-hbase-in-kettle</id>
   <content type="html">&lt;p&gt;Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，绿色无需安装，数据抽取高效稳定。&lt;a href=&quot;https://github.com/pentaho/big-data-plugin&quot;&gt;big-data-plugin&lt;/a&gt;是kettle中用于访问bigdata，包括hadoop、cassandra、mongodb等nosql数据库的一个插件。&lt;/p&gt;

&lt;p&gt;截至目前，kettle的版本为4.4.1，&lt;code&gt;big-data-plugin&lt;/code&gt;插件支持&lt;code&gt;cloudera CDH3u4、CDH4.1&lt;/code&gt;，暂不支持Intel的hadoop发行版本IDH。&lt;/p&gt;

&lt;p&gt;本文主要介绍如何让kettle支持IDH的hadoop版本。&lt;/p&gt;

&lt;p&gt;假设你已经安装好IDH-2.3的集群，并已经拷贝出&lt;code&gt;/usr/lib/&lt;/code&gt;下的hadoop、hbase、zookeeper目录。&lt;/p&gt;

&lt;p&gt;首先，下载一个kettle版本，如社区版data-integration，然后进入&lt;code&gt;data-integration/plugins/pentaho-big-data-plugin&lt;/code&gt;目录，修改plugin.properties文件中的&lt;code&gt;active.hadoop.configuration&lt;/code&gt;属性，将其值改为cdh4&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;active.hadoop.configuration=cdh4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改kettle的log4j日志等级，并启动kettle，检查启动过程中是否报错，如有错误，请修正错误。&lt;/p&gt;

&lt;p&gt;进入hadoop-configurations目录，copy and paste cdh3u4并命名为idh2.3。&lt;/p&gt;

&lt;p&gt;因为IDH和CDH的hadoop版本不一致，故需要替换hadoop和hbase、zookeeper为IDH的版本，涉及到需要替换、增加的jar有，这些jar文件从IDH安装后的目录中拷贝即可：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/hbase-0.94.1-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/protobuf-java-2.4.0a.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/zookeeper-3.4.5-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-ant-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-core-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-examples-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-test-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-tools-1.0.3-Intel.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libthrift-0.8.0.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其他依赖包可以尝试添加，并删除多版本的jar文件。&lt;/p&gt;

&lt;p&gt;需要删除CDH的jar有：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/hbase-0.90.6-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/pmr/zookeeper-3.3.5-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-client-0.20.2-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/client/hadoop-core-0.20.2-cdh3u4.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libfb303-0.5.0-cdh.jar
data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/idh2.3/lib/libthrift-0.5.0-cdh.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改plugin.properties文件中的active.hadoop.configuration属性，将其值改为idh2.3。重起kettle，观察启动过程中是否报错。&lt;/p&gt;

&lt;h3&gt;验证是否可以访问IDH2.3中的hbase。&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;打开hbase output组件，配置zookeeper的host和port&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/files/2013/hbase-output-setup-for-idh-2.3.png&quot; alt=&quot;hbase-output-setup-for-idh-2.3&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在&lt;code&gt;Create/Edit mappings&lt;/code&gt; tab页点击&lt;code&gt;Get table names&lt;/code&gt;，发现该组件卡住，kettle控制台提示异常则需要检查客户端jar版本和服务端是否一致：&lt;/p&gt;

&lt;p&gt; 13/04/17 10:22:13 INFO client.HConnectionManager$HConnectionImplementation: getMaster attempt 0 of 10 failed;
 retrying after sleep of 1000
 java.io.IOException: Call to OS-GZP2308-04/192.168.40.84:60000 failed on local exception: java.io.EOFException
     at org.apache.hadoop.hbase.ipc.HBaseClient.wrapException(HBaseClient.java:1110)
     at org.apache.hadoop.hbase.ipc.HBaseClient.call(HBaseClient.java:1079)
     at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:150)
     at $Proxy5.getProtocolVersion(Unknown Source)
     at org.apache.hadoop.hbase.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:183)
     at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:335)
     at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:312)
     at org.apache.hadoop.hbase.ipc.HBaseRPC.getProxy(HBaseRPC.java:364)
     at org.apache.hadoop.hbase.client.HConnectionManager$HConnectionImplementation.getMaster(HConnectionManager.java:710)
     at org.apache.hadoop.hbase.client.HBaseAdmin.&amp;lt; init&gt;(HBaseAdmin.java:141)
     at com.intel.hbase.test.createtable.TableBuilder.main(TableBuilder.java:48)
 Caused by: java.io.EOFException
     at java.io.DataInputStream.readInt(DataInputStream.java:375)
     at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.receiveResponse(HBaseClient.java:605)
     at org.apache.hadoop.hbase.ipc.HBaseClient$Connection.run(HBaseClient.java:538)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>kettle中添加一个参数字段到输出</title>
   <link href="http://blog.javachen.com/kettle/2013/04/07/add-a-field-from-paramter-to-output"/>
   <updated>2013-04-07T21:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2013/04/07/add-a-field-from-paramter-to-output</id>
   <content type="html">&lt;p&gt;kettle可以将输入流中的字段输出到输出流中，输入输出流可以为数据库、文件或其他，通常情况下输入流中字段为已知确定的，如果我想在输出流中添加一个来自转换的命令行参数的一个字段，该如何操作？&lt;/p&gt;

&lt;p&gt;上述问题可以拆分为两个问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从命令行接受一个参数作为一个字段&lt;/li&gt;
&lt;li&gt;合并输入流和这个字段&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;问题1&lt;/h3&gt;

&lt;p&gt;第一个问题可以使用kettle中&lt;code&gt;获取系统信息&lt;/code&gt;组件，定义一个变量，该值来自命令行参数，见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/get-a-field-from-paramter.png&quot; alt=&quot;get-a-field-from-paramter&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;问题2&lt;/h3&gt;

&lt;p&gt;第二个问题可以使用kettle中&lt;code&gt;记录关联 (笛卡尔输出)&lt;/code&gt;组件将两个组件关联起来，输出一个笛卡尔结果集，关联条件设定恒为true，在运行前设置第一个参数的值，然后运行即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/files/2013/run-kettle-for-join-two-inputs.png&quot; alt=&quot;run-kettle-for-join-two-inputs&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;下载脚本&lt;/h3&gt;

&lt;p&gt;最后，kettle转换文件下载地址：&lt;a href=&quot;/files/2013/join-a-paramter-to-input-in-kettle.zip&quot;&gt;在这里&lt;/a&gt;。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>从yum安装Cloudera CDH4.2</title>
   <link href="http://blog.javachen.com/hadoop/2013/04/06/install-cloudera-cdh4.2-by-yum"/>
   <updated>2013-04-06T17:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/04/06/install-cloudera-cdh4.2-by-yum</id>
   <content type="html">&lt;p&gt;记录使用yum通过rpm方式安装Cloudera CDH4.2中的hadoop、yarn、HBase，需要注意初始化namenode之前需要手动创建一些目录并设置权限。&lt;/p&gt;

&lt;h2&gt;目录&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;安装jdk&lt;/li&gt;
&lt;li&gt;设置yum源&lt;/li&gt;
&lt;li&gt;安装HDFS&lt;/li&gt;
&lt;li&gt;配置hadoop&lt;/li&gt;
&lt;li&gt;安装YARN&lt;/li&gt;
&lt;li&gt;安装zookeeper&lt;/li&gt;
&lt;li&gt;安装HBase&lt;/li&gt;
&lt;li&gt;安装Hive&lt;/li&gt;
&lt;li&gt;参考文章&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;1. 安装jdk&lt;/h2&gt;

&lt;p&gt;安装jdk并设置环境变量&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export JAVA_HOME=&amp;lt; jdk-install-dir&amp;gt;
export PATH=$JAVA_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检查环境变量中是否有设置JAVA_HOME&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo env | grep JAVA_HOME
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果env中没有JAVA_HOME变量，则修改/etc/sudoers文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vi /etc/sudoers
Defaults env_keep+=JAVA_HOME
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;2. 设置yum源&lt;/h2&gt;

&lt;p&gt;从http://archive.cloudera.com/cdh4/repo-as-tarball/4.2.0/cdh4.2.0-centos6.tar.gz 下载压缩包解压并设置本地或ftp yum源，可以参考&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_30.html&quot;&gt;Creating a Local Yum Repository&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;3. 安装HDFS&lt;/h2&gt;

&lt;h3&gt;在NameNode节点yum安装&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;yum list hadoop
yum install hadoop-hdfs-namenode
yum install hadoop-hdfs-secondarynamenode
yum install hadoop-yarn-resourcemanager
yum install hadoop-mapreduce-historyserver
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;在DataNode节点yum安装&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;yum list hadoop
yum install hadoop-hdfs-datanode
yum install hadoop-yarn-nodemanager
yum install hadoop-mapreduce
yum install zookeeper-server
yum install hadoop-httpfs
yum install hadoop-debuginfo
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;4. 配置hadoop&lt;/h2&gt;

&lt;h3&gt;修改配置文件&lt;/h3&gt;

&lt;p&gt;hadoop的默认配置文件在/etc/hadoop/conf&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;core-site.xml:&lt;/p&gt;

&lt;p&gt; &lt;property&gt;
     &lt;name&gt;fs.defaultFS&lt;/name&gt;
     &lt;value&gt;hdfs://node1&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;fs.trash.interval&lt;/name&gt;
     &lt;value&gt;10080&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;
     &lt;value&gt;10080&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;io.bytes.per.checksum&lt;/name&gt;
   &lt;value&gt;4096&lt;/value&gt;
 &lt;/property&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;hdfs-site.xml:&lt;/p&gt;

&lt;p&gt; &lt;property&gt;
   &lt;name&gt;dfs.replication&lt;/name&gt;
   &lt;value&gt;3&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
   &lt;value&gt;/opt/data/hadoop&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;dfs.block.size&lt;/name&gt;
     &lt;value&gt;268435456&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;dfs.permissions.superusergroup&lt;/name&gt;
   &lt;value&gt;hadoop&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;
   &lt;value&gt;100&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;dfs.datanode.handler.count&lt;/name&gt;
   &lt;value&gt;100&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;dfs.datanode.balance.bandwidthPerSec&lt;/name&gt;
   &lt;value&gt;1048576&lt;/value&gt;
   &lt;description&gt;
     Specifies the maximum amount of bandwidth that each datanode
     can utilize for the balancing purpose in term of
     the number of bytes per second.
   &lt;/description&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
     &lt;value&gt;node1:50070&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
     &lt;value&gt;node1:50090&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;修改master和slaves文件&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;NameNode HA&lt;/h3&gt;

&lt;p&gt;https://ccp.cloudera.com/display/CDH4DOC/Introduction+to+HDFS+High+Availability&lt;/p&gt;

&lt;h3&gt;Secondary NameNode Parameters&lt;/h3&gt;

&lt;p&gt;在hdfs-site.xml中可以配置以下参数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dfs.namenode.checkpoint.check.period
dfs.namenode.checkpoint.txns
dfs.namenode.checkpoint.dir
dfs.namenode.checkpoint.edits.dir
dfs.namenode.num.checkpoints.retained
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;multi-host-secondarynamenode-configuration&lt;/h4&gt;

&lt;p&gt;http://blog.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/.&lt;/p&gt;

&lt;h3&gt;Config list&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Directory                       Owner       Permissions Default Path
hadoop.tmp.dir                  hdfs:hdfs   drwx------  /var/hadoop
dfs.namenode.name.dir               hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir               hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir         hdfs:hdfs   drwx------  file://${hadoop.tmp.dir}/dfs/namesecondary
yarn.nodemanager.local-dirs         yarn:yarn   drwxr-xr-x  ${hadoop.tmp.dir}/nm-local-dir
yarn.nodemanager.log-dirs           yarn:yarn   drwxr-xr-x  ${yarn.log.dir}/userlogs
yarn.nodemanager.remote-app-log-dir                     /tmp/logs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;my set:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hadoop.tmp.dir                  /opt/data/hadoop
dfs.namenode.name.dir               ${hadoop.tmp.dir}/dfs/name
dfs.datanode.data.dir               ${hadoop.tmp.dir}/dfs/data
dfs.namenode.checkpoint.dir         ${hadoop.tmp.dir}/dfs/namesecondary
yarn.nodemanager.local-dirs         /opt/data/yarn/local
yarn.nodemanager.log-dirs           /var/log/hadoop-yarn/logs
yarn.nodemanager.remote-app-log-dir         /var/log/hadoop-yarn/app
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Create the data Directory in the Cluster&lt;/h3&gt;

&lt;p&gt;在namenode节点创建name目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /opt/data/hadoop/dfs/name
chown -R hdfs:hdfs /opt/data/hadoop/dfs/name
chmod 700 /opt/data/hadoop/dfs/name
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在所有datanode节点创建data目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /opt/data/hadoop/dfs/data
chown -R hdfs:hdfs /opt/data/hadoop/dfs/data
chmod 700 /opt/data/hadoop/dfs/data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在secondarynode节点创建namesecondary目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /opt/data/hadoop/dfs/namesecondary
chown -R hdfs:hdfs /opt/data/hadoop/dfs/namesecondary
chmod 700 /opt/data/hadoop/dfs/namesecondary
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在所有datanode节点创建yarn的local目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /opt/data/hadoop/yarn/local
chown -R yarn:yarn /opt/data/hadoop/yarn/local
chmod 700 /opt/data/hadoop/yarn/local
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;同步配置文件到整个集群&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo scp -r /etc/hadoop/conf root@nodeX:/etc/hadoop/conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;格式化NameNode&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo -u hdfs hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;在每个节点启动hdfs&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;for x in `cd /etc/init.d ; ls hadoop-hdfs-*` ; do sudo service $x restart ; done
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;5. 安装YARN&lt;/h2&gt;

&lt;p&gt;先在一台机器上配置好，然后在做同步。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;mapred-site.xml:&lt;/p&gt;

&lt;p&gt; &lt;property&gt;
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
     &lt;value&gt;yarn&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
     &lt;value&gt;node1:10020&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
     &lt;value&gt;node1:19888&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;mapreduce.task.io.sort.factor&lt;/name&gt;
   &lt;value&gt;100&lt;/value&gt;
   &lt;description&gt;The number of streams to merge at once while sorting
   files.  This determines the number of open file handles.&lt;/description&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;mapreduce.task.io.sort.mb&lt;/name&gt;
   &lt;value&gt;200&lt;/value&gt;
   &lt;description&gt;The total amount of buffer memory to use while sorting
   files, in megabytes.  By default, gives each merge stream 1MB, which
   should minimize seeks.&lt;/description&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;mapreduce.reduce.shuffle.parallelcopies&lt;/name&gt;
   &lt;value&gt;16&lt;/value&gt;
    &lt;!-- 一般介于节点数开方和节点数一半之间，小于20节点，则为节点数--&gt;
   &lt;description&gt;The default number of parallel transfers run by reduce
   during the copy(shuffle) phase.
   &lt;/description&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;mapreduce.task.timeout&lt;/name&gt;
   &lt;value&gt;1800000&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;mapreduce.tasktracker.map.tasks.maximum&lt;/name&gt;
   &lt;value&gt;4&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
   &lt;name&gt;mapreduce.tasktracker.reduce.tasks.maximum&lt;/name&gt;
   &lt;value&gt;2&lt;/value&gt;
 &lt;/property&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;yarn-site.xml:&lt;/p&gt;

&lt;p&gt; &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
     &lt;value&gt;node1:8031&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
     &lt;value&gt;node1:8032&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
     &lt;value&gt;node1:8030&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
     &lt;value&gt;node1:8033&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
     &lt;value&gt;node1:8088&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
     &lt;value&gt;mapreduce.shuffle&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
     &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;description&gt;Classpath for typical applications.&lt;/description&gt;
     &lt;name&gt;yarn.application.classpath&lt;/name&gt;
     &lt;value&gt;
     $HADOOP_CONF_DIR,
     $HADOOP_COMMON_HOME/&lt;em&gt;,$HADOOP_COMMON_HOME/lib/&lt;/em&gt;,
     $HADOOP_HDFS_HOME/&lt;em&gt;,$HADOOP_HDFS_HOME/lib/&lt;/em&gt;,
     $HADOOP_MAPRED_HOME/&lt;em&gt;,$HADOOP_MAPRED_HOME/lib/&lt;/em&gt;,
     $YARN_HOME/&lt;em&gt;,$YARN_HOME/lib/&lt;/em&gt;
     &lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;
     &lt;value&gt;/opt/hadoop/yarn/local&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
     &lt;value&gt;/var/log/hadoop-yarn/logs&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
     &lt;value&gt;/var/log/hadoop-yarn/apps&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;
     &lt;value&gt;/user&lt;/value&gt;
 &lt;/property&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;HDFS创建临时目录&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo -u hdfs hadoop fs -mkdir /tmp
sudo -u hdfs hadoop fs -chmod -R 1777 /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;创建日志目录&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo -u hdfs hadoop fs -mkdir /user/history
sudo -u hdfs hadoop fs -chmod -R 1777 /user/history
sudo -u hdfs hadoop fs -chown yarn /user/history
sudo -u hdfs hadoop fs -mkdir /var/log/hadoop-yarn
sudo -u hdfs hadoop fs -chown yarn:mapred /var/log/hadoop-yarn
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;验证hdfs结构是否正确&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;[root@node1 data]# sudo -u hdfs hadoop fs -ls -R /
drwxrwxrwt   - hdfs supergroup          0 2012-04-19 14:31 /tmp
drwxr-xr-x   - hdfs supergroup          0 2012-05-31 10:26 /user
drwxrwxrwt   - yarn supergroup          0 2012-04-19 14:31 /user/history
drwxr-xr-x   - hdfs   supergroup        0 2012-05-31 15:31 /var
drwxr-xr-x   - hdfs   supergroup        0 2012-05-31 15:31 /var/log
drwxr-xr-x   - yarn   mapred            0 2012-05-31 15:31 /var/log/hadoop-yarn
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;启动mapred-historyserver&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;/etc/init.d/hadoop-mapreduce-historyserver start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;在每个节点启动YARN&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;for x in `cd /etc/init.d ; ls hadoop-yarn-*` ; do sudo service $x start ; done
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;为每个MapReduce用户创建主目录&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo -u hdfs hadoop fs -mkdir /user/$USER
sudo -u hdfs hadoop fs -chown $USER /user/$USER
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Set HADOOP_MAPRED_HOME&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Configure the Hadoop Daemons to Start at Boot Time&lt;/h3&gt;

&lt;p&gt;https://ccp.cloudera.com/display/CDH4DOC/Maintenance+Tasks+and+Notes#MaintenanceTasksandNotes-ConfiguringinittoStartCoreHadoopSystemServices&lt;/p&gt;

&lt;h2&gt;6. 安装Zookeeper&lt;/h2&gt;

&lt;p&gt;安装zookeeper&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;yum install zookeeper*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;设置crontab&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;crontab -e
15 * * * * java -cp $classpath:/usr/lib/zookeeper/lib/log4j-1.2.15.jar:\
/usr/lib/zookeeper/lib/jline-0.9.94.jar:\   
/usr/lib/zookeeper/zookeeper.jar:/usr/lib/zookeeper/conf\
org.apache.zookeeper.server.PurgeTxnLog /var/zookeeper/ -n 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在每个需要安装zookeeper的节点上创建zookeeper的目录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /opt/data/zookeeper
chown -R zookeeper:zookeeper /opt/data/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;设置zookeeper配置：/etc/zookeeper/conf/zoo.cfg，并同步到其他机器&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
dataDir=/opt/data/zookeeper
clientPort=2181
server.1=node1:2888:3888
server.2=node2:2888:3888
server.3=node3:2888:3888
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在每个节点上初始化并启动zookeeper，注意修改n值&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service zookeeper-server init --myid=n
service zookeeper-server restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;7. 安装HBase&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;yum install hbase*
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;在hdfs中创建/hbase&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo -u hdfs hadoop fs -mkdir /hbase
sudo -u hdfs hadoop fs -chown hbase:hbase /hbase
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;设置crontab：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;crontab -e
* 10 * * * cd /var/log/hbase/; rm -rf\
`ls /var/log/hbase/|grep -P 'hbase\-hbase\-.+\.log\.[0-9]'\`&amp;gt;&amp;gt; /dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;修改配置文件并同步到其他机器：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://node1:8020/hbase&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/hbase&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;node1,node2,node3&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hregion.max.filesize&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;536870912&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;
    Maximum HStoreFile size. If any one of a column families' HStoreFiles has
    grown to exceed this value, the hosting HRegion is split in two.
    Default: 10G.
    &amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hregion.memstore.flush.size&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;67108864&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;
    Memstore will be flushed to disk if size of the memstore
    exceeds this number of bytes.  Value is checked by a thread that runs
    every hbase.server.thread.wakefrequency.
    &amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regionserver.lease.period&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;600000&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;HRegion server lease period in milliseconds. Default is
    60 seconds. Clients must report in within this period else they are
    considered dead.&amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.client.retries.number&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt; 
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regionserver.handler.count&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;100&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.property.maxClientCnxns&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;2000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hfile.block.cache.size&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;0.1&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;
    Percentage of maximum heap (-Xmx setting) to allocate to block cache
    used by HFile/StoreFile. Default of 0.25 means allocate 25%.
    Set to 0 to disable but it's not recommended.
    &amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.regions.slop&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;0&amp;lt;/value&amp;gt;
    &amp;lt;description&amp;gt;Rebalance if any regionserver has average + (average * slop) regions.
    Default is 20% slop.
    &amp;lt;/description&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hstore.compactionThreshold&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;10&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.hstore.blockingStoreFiles&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;30&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;修改regionserver文件&lt;/h3&gt;

&lt;h3&gt;启动HBase&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;service hbase-master start
service hbase-regionserver start
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;8. 安装hive&lt;/h2&gt;

&lt;h3&gt;在一个节点上安装hive&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo yum install hive*
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;安装metastore&lt;/h3&gt;

&lt;h3&gt;修改配置文件&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://node1:8020&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;jdbc:postgresql://node1/metastore&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;JDBC connect string for a JDBC metastore&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;org.postgresql.Driver&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;Driver class name for a JDBC metastore&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;hiveuser&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;username to use against metastore database&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;redhat&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;password to use against metastore database&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapred.job.tracker&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;node1:8031&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;datanucleus.autoCreateSchema&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;datanucleus.fixedDatastore&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/user/hive/warehouse&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;thrift://node1:9083&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.local&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.support.concurrency&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Enable Hive's Table Lock Manager Service&amp;lt;/description&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.zookeeper.quorum&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Zookeeper quorum used by Hive's Table Lock Manager&amp;lt;/description&amp;gt;
  &amp;lt;value&amp;gt;node2,node3,node1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.host&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;node1&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the host address the Hive Web Interface will listen on&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.port&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;9999&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the port the Hive Web Interface will listen on&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.war.file&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;lib/hive-hwi-0.10.0-cdh4.2.0.war&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the WAR file with the jsp content for Hive Web Interface&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.merge.mapredfiles&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;Merge small files at the end of a map-reduce job&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;在hdfs中创建hive数据仓库目录&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;hive的数据仓库在hdfs中默认为&lt;code&gt;/user/hive/warehouse&lt;/code&gt;,建议修改其访问权限为1777，以便其他所有用户都可以创建、访问表，但不能删除不属于他的表。&lt;/li&gt;
&lt;li&gt;每一个查询hive的用户都必须有一个hdfs的home目录(/user目录下，如root用户的为&lt;code&gt;/user/root&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;p&gt;hive所在节点的 /tmp必须是world-writable权限的。&lt;/p&gt;

&lt;p&gt;  sudo -u hdfs hadoop fs -mkdir /user/hive/warehouse
  sudo -u hdfs hadoop fs -chown hive /user/hive/warehouse&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;启动hive&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;service hive-metastore start
service hive-server start
service hive-server2 start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;访问beeline&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ /usr/lib/hive/bin/beeline
beeline&amp;gt; !connect jdbc:hive2://localhost:10000 username password org.apache.hive.jdbc.HiveDriver
0: jdbc:hive2://localhost:10000&amp;gt; SHOW TABLES;
show tables;
+-----------+
| tab_name  |
+-----------+
+-----------+
No rows selected (0.238 seconds)
0: jdbc:hive2://localhost:10000&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其 sql语法参考&lt;a href=&quot;http://sqlline.sourceforge.net/&quot;&gt;SQLLine CLI&lt;/a&gt;，在这里，你不能使用HiveServer的sql语句&lt;/p&gt;

&lt;h3&gt;与hbase集成&lt;/h3&gt;

&lt;p&gt;需要在hive里添加以下jar包：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ADD JAR /usr/lib/hive/lib/zookeeper.jar;
ADD JAR /usr/lib/hive/lib/hbase.jar;
ADD JAR /usr/lib/hive/lib/hive-hbase-handler-0.10.0-cdh4.2.0.jar
ADD JAR /usr/lib/hive/lib/guava-11.0.2.jar;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;9. 参考文章&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_30.html&quot;&gt;Creating a Local Yum Repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_29.html&quot;&gt;Java Development Kit Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_11_2.html&quot;&gt;Deploying HDFS on a Cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_20.html&quot;&gt;HBase Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_21.html&quot;&gt;ZooKeeper Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://roserouge.iteye.com/blog/1558498&quot;&gt;hadoop cdh 安装笔记&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>安装impala过程</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/29/install-impala"/>
   <updated>2013-03-29T10:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/29/install-impala</id>
   <content type="html">&lt;p&gt;与Hive类似，Impala也可以直接与HDFS和HBase库直接交互。只不过Hive和其它建立在MapReduce上的框架适合需要长时间运行的批处理任务。例如那些批量提取，转化，加载（ETL）类型的Job。而Impala主要用于实时查询。&lt;/p&gt;

&lt;h3&gt;install&lt;/h3&gt;

&lt;p&gt;下载 impala，目前最新版本为0.6-1，&lt;a href=&quot;http://beta.cloudera.com/impala/redhat/6/x86_64/impala/0/RPMS/x86_64/&quot;&gt;下载地址&lt;/a&gt;。&lt;/p&gt;

&lt;h3&gt;安装过程&lt;/h3&gt;

&lt;p&gt;安装前提：先安装好hadoop集群以及hive，可以参考我的文章：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.javachen.com/Hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH4.2.html&quot;&gt;手动安装Cloudera Hadoop CDH4.2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/Hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2.html&quot;&gt;手动安装Cloudera Hive CDH4.2&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DataNode节点&lt;/p&gt;

&lt;p&gt; yum install -y impala-0.6-1.p0.548.el6.x86_64.rpm   impala-server-0.6-1.p0.548.el6.x86_64.rpm impala-state-store-0.6-1.p0.548.el6.x86_64.rpm    impala-shell-0.6-1.p0.548.el6.x86_64.rpm libevent-1.4.13-4.el6.x86_64.rpm bigtop-utils-0.4+300-1.cdh4.0.1.p0.1.el6.noarch.rpm --skip-broken&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在hive节点上&lt;/p&gt;

&lt;p&gt; yum install -y impala-0.6-1.p0.548.el6.x86_64.rpm   impala-server-0.6-1.p0.548.el6.x86_64.rpm \
 impala-state-store-0.6-1.p0.548.el6.x86_64.rpm  impala-shell-0.6-1.p0.548.el6.x86_64.rpm \
 libevent-1.4.13-4.el6.x86_64.rpm    bigtop-utils-0.4+300-1.cdh4.0.1.p0.1.el6.noarch.rpm&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;配置Impala&lt;/h3&gt;

&lt;h4&gt;查看安装路径&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 conf]# find / -name impala
/var/run/impala
/var/lib/alternatives/impala
/var/log/impala
/usr/lib/impala
/etc/alternatives/impala
/etc/default/impala
/etc/impala
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;添加配置文件&lt;/h4&gt;

&lt;p&gt;impalad的配置文件路径由环境变量&lt;code&gt;IMPALA_CONF_DIR&lt;/code&gt;指定，默认为&lt;code&gt;/usr/lib/impala/conf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在节点desktop1上 拷贝&lt;code&gt;hive-site.xml&lt;/code&gt;、&lt;code&gt;core-site.xml&lt;/code&gt;、&lt;code&gt;hdfs-site.xml&lt;/code&gt;至&lt;code&gt;/usr/lib/impala/conf&lt;/code&gt;目录下:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 conf]# mkdir /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/log4j.properties /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/core-site.xml /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop/hdfs-site.xml /usr/lib/impala/conf/
[root@desktop1 conf]# cp /opt/hive-0.10.0-cdh4.2.0/conf/hive-site.xml /usr/lib/impala/conf/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;并作下面修改在&lt;code&gt;hdfs-site.xml&lt;/code&gt;文件中添加如下内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.client.read.shortcircuit&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.domain.socket.path&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/var/run/hadoop-hdfs/dn._PORT&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.datanode.hdfs-blocks-metadata.enabled&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.datanode.hdfs-blocks-metadata.enabled&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同步以上文件到其他节点&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop3:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop4:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop6:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop7:/usr/lib/impala/
[root@desktop1 ~]# scp -r /usr/lib/impala/conf desktop8:/usr/lib/impala/
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;hadoop中添加native包&lt;/h4&gt;

&lt;p&gt;拷贝hadoop native包到hadoop安装路径下，并同步hadoop文件到其他节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# cp /usr/lib/impala/lib/*.so* /opt/hadoop-2.0.0-cdh4.2.0/lib/native/
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;创建socket path&lt;/h4&gt;

&lt;p&gt;在每个节点上创建/var/run/hadoop-hdfs:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop3 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop4 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop6 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop7 ~]# mkdir -p /var/run/hadoop-hdfs
[root@desktop8 ~]# mkdir -p /var/run/hadoop-hdfs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;拷贝postgres jdbc jar：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /opt/hive-0.10.0-cdh4.2.0/lib/postgresql-9.1-903.jdbc* /usr/lib/impala/lib/
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;启动服务&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在hive所在节点启动statestored（默认端口为24000）:&lt;/p&gt;

&lt;p&gt; GLOG_v=1 nohup statestored -state_store_port=24000 &amp;amp;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;如果statestore正常启动，可以在/tmp/statestored.INFO查看。如果出现异常，可以查看/tmp/statestored.ERROR定位错误信息。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在所有impalad节点上：&lt;/p&gt;

&lt;p&gt; HADOOP_CONF_DIR=&quot;/usr/lib/impala/conf&quot; nohup impalad -state_store_host=desktop1 -nn=desktop1 \
     -nn_port=8020 -hostname=desktop3 -ipaddress=192.168.0.3 &amp;amp;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;注意： 其中的&lt;code&gt;-hostname&lt;/code&gt;和&lt;code&gt;-ipaddress&lt;/code&gt;表示当前启动impalad实例所在机器的主机名和ip地址。&lt;/p&gt;

&lt;p&gt;如果impalad正常启动，可以在&lt;code&gt;/tmp/ impalad.INFO&lt;/code&gt;查看。如果出现异常，可以查看&lt;code&gt;/tmp/impalad.ERROR&lt;/code&gt;定位错误信息。&lt;/p&gt;

&lt;h3&gt;使用shell&lt;/h3&gt;

&lt;p&gt;使用&lt;code&gt;impala-shell&lt;/code&gt;启动Impala Shell，分别连接各Impalad主机(desktop3、desktop4、desktop6、desktop7、desktop8)，刷新元数据，之后就可以执行shell命令。相关的命令如下(可以在任意节点执行)：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;impala-shell
[Not connected] &amp;gt;connect desktop3:21000
[desktop3:21000] &amp;gt;refresh
[desktop3:21000] &amp;gt;connect desktop4:21000
[desktop4:21000] &amp;gt;refresh
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;注意：&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;如果hive使用mysql或postgres数据库作为metastore的存储，则需要拷贝相应的jdbc jar到&lt;code&gt;/usr/lib/impala/lib&lt;/code&gt;目录下&lt;/li&gt;
&lt;li&gt;E0325 11:04:19.937718  7239 statestored-main.cc:52] Could not start webserver on port: 25010&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;可能是已经启动了statestored进程&lt;/p&gt;

&lt;h3&gt;参考文章&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://yuntai.1kapp.com/?p=904&quot;&gt;Impala安装文档完整版&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://tech.uc.cn/?p=817&quot;&gt;Impala入门笔记&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ccp.cloudera.com/display/IMPALA10BETADOC/Installing+and+Using+Cloudera+Impala&quot;&gt;Installing and Using Cloudera Impala&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>手动安装Cloudera Hadoop CDH4.2</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH4.2"/>
   <updated>2013-03-24T15:10:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-Hadoop-CDH4.2</id>
   <content type="html">&lt;h2&gt;安装版本&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;hadoop-2.0.0-cdh4.2.0
hbase-0.94.2-cdh4.2.0
hive-0.10.0-cdh4.2.0
jdk1.6.0_38
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;安装前说明&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;安装目录为/opt&lt;/li&gt;
&lt;li&gt;检查hosts文件&lt;/li&gt;
&lt;li&gt;关闭防火墙&lt;/li&gt;
&lt;li&gt;设置时钟同步&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;使用说明&lt;/h2&gt;

&lt;p&gt;安装hadoop、hbase、hive成功之后启动方式为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动dfs和mapreduce
desktop1上执行start-dfs.sh和start-yarn.sh&lt;/li&gt;
&lt;li&gt;启动hbase
desktop3上执行start-hbase.xml&lt;/li&gt;
&lt;li&gt;启动hive
desktop1上执行hive&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;规划&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;    192.168.0.1             NameNode、Hive、ResourceManager
    192.168.0.2             SSNameNode
    192.168.0.3             DataNode、HBase、NodeManager
    192.168.0.4             DataNode、HBase、NodeManager
    192.168.0.6             DataNode、HBase、NodeManager
    192.168.0.7             DataNode、HBase、NodeManager
    192.168.0.8             DataNode、HBase、NodeManager
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;部署过程&lt;/h2&gt;

&lt;h3&gt;系统和网络配置&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;修改每台机器的名称&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;
    [root@desktop1 ~]# cat /etc/sysconfig/network
    NETWORKING=yes
    HOSTNAME=desktop1
&lt;/pre&gt;


&lt;ol&gt;
&lt;li&gt;在各个节点上修改/etc/hosts增加以下内容:&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;
    [root@desktop1 ~]# cat /etc/hosts
    127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
    192.168.0.1     desktop1
    192.168.0.2     desktop2
    192.168.0.3     desktop3
    192.168.0.4     desktop4
    192.168.0.6     desktop6
    192.168.0.7     desktop7
    192.168.0.8     desktop8
&lt;/pre&gt;


&lt;ol&gt;
&lt;li&gt;配置ssh无密码登陆
以下是设置desktop1上可以无密码登陆到其他机器上。&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;
    [root@desktop1 ~]# ssh-keygen
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop2
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop3
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop4
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop6
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop7
    [root@desktop1 ~]# ssh-copy-id -i .ssh/id_rsa.pub desktop8
&lt;/pre&gt;


&lt;ol&gt;
&lt;li&gt;每台机器上关闭防火墙：&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;    [root@desktop1 ~]# service iptables stop
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;安装Hadoop&lt;/h3&gt;

&lt;h4&gt;配置Hadoop&lt;/h4&gt;

&lt;p&gt;将jdk1.6.0_38.zip上传到/opt，并解压缩。
将hadoop-2.0.0-cdh4.2.0.zip上传到/opt，并解压缩。&lt;/p&gt;

&lt;p&gt;在NameNode上配置以下文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;core-site.xml fs.defaultFS指定NameNode文件系统，开启回收站功能。
hdfs-site.xml 
    dfs.namenode.name.dir指定NameNode存储meta和editlog的目录，
    dfs.datanode.data.dir指定DataNode存储blocks的目录，
    dfs.namenode.secondary.http-address指定Secondary NameNode地址。
    开启WebHDFS。
slaves 添加DataNode节点主机
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;core-site.xml
该文件指定fs.defaultFS连接desktop1，即NameNode节点。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;```
[root@desktop1 hadoop]# pwd
/opt/hadoop-2.0.0-cdh4.2.0/etc/hadoop
[root@desktop1 hadoop]# cat core-site.xml
&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;&lt;/p&gt;

&lt;!--fs.default.name for MRV1 ,fs.defaultFS for MRV2(yarn) --&gt;


&lt;p&gt;&lt;property&gt;
     &lt;name&gt;fs.defaultFS&lt;/name&gt;
         &lt;!--这个地方的值要和hdfs-site.xml文件中的dfs.federation.nameservices一致--&gt;
     &lt;value&gt;hdfs://desktop1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;fs.trash.interval&lt;/name&gt;
&lt;value&gt;10080&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;fs.trash.checkpoint.interval&lt;/name&gt;
&lt;value&gt;10080&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
```&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;hdfs-site.xml
该文件主要设置数据副本保存份数，以及namenode、datanode数据保存路径以及http-address。&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]# cat hdfs-site.xml 
&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/hadoop-${user.name}&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.namenode.http-address&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;desktop1:50070&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;desktop2:50090&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.webhdfs.enabled&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;masters
设置namenode和secondary namenode节点。&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]# cat masters 
desktop1
desktop2
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;slaves
设置哪些机器上安装datanode节点。&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]# cat slaves 
desktop3
desktop4
desktop6
desktop7
desktop8
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;配置MapReduce&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;mapred-site.xml
配置使用yarn计算框架，以及jobhistory的地址。&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]# cat mapred-site.xml
&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;desktop1:10020&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;desktop1:19888&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;yarn-site.xml
主要配置resourcemanager地址以及&lt;code&gt;yarn.application.classpath&lt;/code&gt;（这个路径很重要，要不然集成hive时候会提示找不到class）&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]# cat yarn-site.xml 
&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.resource-tracker.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8031&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8032&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8030&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.admin.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8033&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;desktop1:8088&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;description&amp;gt;Classpath for typical applications.&amp;lt;/description&amp;gt;
    &amp;lt;name&amp;gt;yarn.application.classpath&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,
    $HADOOP_COMMON_HOME/share/hadoop/common/lib/*,
    $HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,
    $YARN_HOME/share/hadoop/yarn/*,$YARN_HOME/share/hadoop/yarn/lib/*,
    $YARN_HOME/share/hadoop/mapreduce/*,$YARN_HOME/share/hadoop/mapreduce/lib/*&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;mapreduce.shuffle&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;

  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.local-dirs&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/yarn/local&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.log-dirs&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/yarn/logs&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;description&amp;gt;Where to aggregate logs&amp;lt;/description&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.remote-app-log-dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/opt/data/yarn/logs&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;

  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.app.mapreduce.am.staging-dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/user&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;同步配置文件&lt;/h4&gt;

&lt;p&gt;修改.bashrc环境变量，并将其同步到其他几台机器，并且source .bashrc&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# cat .bashrc 
# .bashrc
alias rm='rm -i'
alias cp='cp -i'
alias mv='mv -i'

# Source global definitions
if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi
# User specific environment and startup programs
export LANG=zh_CN.utf8

export JAVA_HOME=/opt/jdk1.6.0_38
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=./:$JAVA_HOME/lib:$JRE_HOME/lib:$JRE_HOME/lib/tools.jar

export HADOOP_HOME=/opt/hadoop-2.0.0-cdh4.2.0
export HIVE_HOME=/opt/hive-0.10.0-cdh4.2.0
export HBASE_HOME=/opt/hbase-0.94.2-cdh4.2.0

export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export HADOOP_YARN_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_HOME}/etc/hadoop

export PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/bin:$HIVE_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改配置文件之后，使其生效。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# source .bashrc 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将desktop1上的/opt/hadoop-2.0.0-cdh4.2.0拷贝到其他机器上&lt;/p&gt;

&lt;h4&gt;启动脚本&lt;/h4&gt;

&lt;p&gt;第一次启动hadoop需要先格式化NameNode，该操作只做一次。当修改了配置文件时，需要重新格式化&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]hadoop namenode -format
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在desktop1上启动hdfs：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]#start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在desktop1上启动mapreduce：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]#start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在desktop1上启动historyserver：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 hadoop]#mr-jobhistory-daemon.sh start historyserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看MapReduce：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://desktop1:8088/cluster
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://desktop2:8042/
http://desktop2:8042/node
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;检查集群进程&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# jps
5389 NameNode
5980 Jps
5710 ResourceManager
7032 JobHistoryServer

[root@desktop2 ~]# jps
3187 Jps
3124 SecondaryNameNode

[root@desktop3 ~]# jps
3187 Jps
3124 DataNode
5711 NodeManager
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>手动安装Cloudera HBase CDH4.2</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH4.2"/>
   <updated>2013-03-24T15:05:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hbase-CDH4.2</id>
   <content type="html">&lt;p&gt;本文主要记录手动安装cloudera HBase cdh4.2.0集群过程，环境设置及Hadoop安装过程见上篇文章。&lt;/p&gt;

&lt;h3&gt;安装HBase&lt;/h3&gt;

&lt;p&gt;HBase安装在desktop3、desktop4、desktop6、desktop7、desktop8机器上。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;上传文件
上传hbase-0.94.2-cdh4.2.0.zip到desktop3上，先在desktop3上修改好配置文件，在同步到其他机器上。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;hbase-site.xml&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop3 conf]# pwd
/opt/hbase-0.94.2-cdh4.2.0/conf
[root@desktop3 conf]# cat hbase-site.xml 
&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;hdfs://desktop1/hbase-${user.name}&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hbase.tmp.dir&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;/opt/data/hbase-${user.name}&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;desktop3,desktop4,desktop6,desktop7,desktop8&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;regionservers&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop3 conf]# cat regionservers 
desktop3
desktop4
desktop6
desktop7
desktop8
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;环境变量
参考hadoop中环境变量的设置&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;同步文件
同步文件到其他4台机器上&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;启动脚本
可以在desktop3上配置无密码登陆到其他机器，然后在desktop3上启动hbase，这样其他节点上hbase都可以启动，否则，需要每台机器上单独启动hbase&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop3 ~]# start-hbase.sh 
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;HBase&lt;/li&gt;
&lt;/ol&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop3 ~]# hbase 
HBase ; enter 'help&amp;lt;RETURN&amp;gt;' for list of supported commands.
Type &quot;exit&amp;lt;RETURN&amp;gt;&quot; to leave the HBase 
Version 0.94.2-cdh4.2.0, r, Fri Feb 15 11:37:00 PST 2013

hbase(main):001:0&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>手动安装Cloudera Hive CDH4.2</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2"/>
   <updated>2013-03-24T15:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/24/manual-install-Cloudera-hive-CDH4.2</id>
   <content type="html">&lt;p&gt;本文主要记录手动安装cloudera Hive cdh4.2.0集群过程，环境设置及Hadoop、HBase安装过程见上篇文章。&lt;/p&gt;

&lt;h3&gt;安装hive&lt;/h3&gt;

&lt;p&gt;hive安装在desktop1上，注意hive默认是使用derby数据库保存元数据，这里替换为postgresql，下面会提到postgresql的安装说明，并且需要拷贝postgres的jdbc jar文件导hive的lib目录下。&lt;/p&gt;

&lt;h4&gt;上传文件&lt;/h4&gt;

&lt;p&gt;上传&lt;code&gt;hive-0.10.0-cdh4.2.0.tar&lt;/code&gt;到desktop1的&lt;code&gt;/opt&lt;/code&gt;，并解压缩&lt;/p&gt;

&lt;h4&gt;安装postgres&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;创建数据库&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;这里创建数据库metastore并创建hiveuser用户，其密码为redhat。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;psql -U postgres

CREATE DATABASE metastore;
 \c metastore;
CREATE USER hiveuser WITH PASSWORD 'redhat';
GRANT ALL ON DATABASE metastore TO hiveuser;
\q
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;初始化数据库&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code&gt;psql  -U hiveuser -d metastore
 \i /opt/hive-0.10.0-cdh4.2.0/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;编辑postgresql配置文件，修改访问权限&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# vi /opt/PostgreSQL/9.1/data/pg_hba.conf

# IPv4 local connections:
host    all             all             0.0.0.0/0            md5

[root@desktop1 ~]# vi postgresql.conf

standard_conforming_strings = off
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;重起postgres&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code&gt;su -c '/opt/PostgreSQL/9.1/bin/pg_ctl -D /opt/PostgreSQL/9.1/data restart' postgres
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;拷贝postgres 的jdbc驱动到&lt;code&gt;/opt/hive-0.10.0-cdh4.2.0/lib&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;修改配置文件&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;hive-site.xml
注意修改下面配置文件中postgres数据库的密码，注意配置&lt;code&gt;hive.aux.jars.path&lt;/code&gt;，在hive集成hbase时候需要从该路径家在hbase的一些jar文件。&lt;/li&gt;
&lt;/ul&gt;


&lt;pre&gt;&lt;code&gt;[root@desktop1 ~]# cd /opt/hive-0.10.0-cdh4.2.0/conf/
[root@desktop1 conf]# cat hive-site.xml 
&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;
&amp;lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;jdbc:postgresql://127.0.0.1/metastore&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;JDBC connect string for a JDBC metastore&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;org.postgresql.Driver&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;Driver class name for a JDBC metastore&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;hiveuser&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;username to use against metastore database&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;redhat&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;password to use against metastore database&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapred.job.tracker&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;desktop1:8031&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.aux.jars.path&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;file:///opt/hive-0.10.0-cdh4.2.0/lib/zookeeper-3.4.5-cdh4.2.0.jar,
    file:///opt/hive-0.10.0-cdh4.2.0/lib/hive-hbase-handler-0.10.0-cdh4.2.0.jar,
    file:///opt/hive-0.10.0-cdh4.2.0/lib/hbase-0.94.2-cdh4.2.0.jar,
    file:///opt/hive-0.10.0-cdh4.2.0/lib/guava-11.0.2.jar&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/warehouse-${user.name}&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;location of default database for the warehouse&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.exec.scratchdir&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/hive-${user.name}&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;Scratch space for Hive jobs&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.querylog.location&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;/opt/data/querylog-${user.name}&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;
    Location of Hive run time structured log file
  &amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.support.concurrency&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Enable Hive's Table Lock Manager Service&amp;lt;/description&amp;gt;
  &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.zookeeper.quorum&amp;lt;/name&amp;gt;
  &amp;lt;description&amp;gt;Zookeeper quorum used by Hive's Table Lock Manager&amp;lt;/description&amp;gt;
  &amp;lt;value&amp;gt;desktop3,desktop4,desktop6,desktop7,desktop8&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.host&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;desktop1&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the host address the Hive Web Interface will listen on&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.listen.port&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;9999&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the port the Hive Web Interface will listen on&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.hwi.war.file&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;lib/hive-hwi-0.10.0-cdh4.2.0.war&amp;lt;/value&amp;gt;
  &amp;lt;description&amp;gt;This is the WAR file with the jsp content for Hive Web Interface&amp;lt;/description&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;环境变量&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;参考hadoop中环境变量的设置&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;启动脚本&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;在启动完之后，执行一些sql语句可能会提示错误，如何解决错误可以参考&lt;a href=&quot;http://kicklinux.com/hive-deploy/&quot;&gt;Hive安装与配置&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@desktop1 ~] hive
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;hive与hbase集成
在&lt;code&gt;hive-site.xml&lt;/code&gt;中配置&lt;code&gt;hive.aux.jars.path&lt;/code&gt;,在环境变量中配置hadoop、mapreduce的环境变量&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;异常说明&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;FAILED: Error in metadata: MetaException(message:org.apache.hadoop.hbase.ZooKeeperConnectionException: An error is preventing HBase from connecting to ZooKeeper&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;原因：hadoop配置文件没有zk&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;FAILED: Error in metadata: MetaException(message:Got exception: org.apache.hadoop.hive.metastore.api.MetaException javax.jdo.JDODataStoreException: Error executing JDOQL query &quot;SELECT &quot;THIS&quot;.&quot;TBL_NAME&quot; AS NUCORDER0 FROM &quot;TBLS&quot; &quot;THIS&quot; LEFT OUTER JOIN &quot;DBS&quot; &quot;THIS_DATABASE_NAME&quot; ON &quot;THIS&quot;.&quot;DB_ID&quot; = &quot;THIS_DATABASE_NAME&quot;.&quot;DB_ID&quot; WHERE &quot;THIS_DATABASE_NAME&quot;.&quot;NAME&quot; = ? AND (LOWER(&quot;THIS&quot;.&quot;TBL_NAME&quot;) LIKE ? ESCAPE '\' ) ORDER BY NUCORDER0 &quot; : ERROR: invalid escape string 建议：Escape string must be empty or one character..&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;参考：https://issues.apache.org/jira/browse/HIVE-3994&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;hive&gt; select count(*) from hive_userinfo; 没反应&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(966)) - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (无法定位登录配置)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;原因：hive中没有设置zk&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;hbase 中提示：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;原因：cloudera hadoop lib中没有hadoop的native jar&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/apache/hadoop/mapreduce/v2/app/MRAppMaster&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;原因：classpath没有配置正确，检查环境变量以及yarn的classpath&lt;/p&gt;

&lt;h3&gt;参考文章&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://kicklinux.com/hive-deploy/&quot;&gt;Hive安装与配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ccp.cloudera.com/display/CDH4DOC/Hive+Installation&quot;&gt;Hive Installation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>【笔记】Hadoop安装部署</title>
   <link href="http://blog.javachen.com/hadoop/2013/03/08/note-about-installing-hadoop-cluster"/>
   <updated>2013-03-08T21:00:00+08:00</updated>
   <id>http://blog.javachen.com/hadoop/2013/03/08/note-about-installing-hadoop-cluster</id>
   <content type="html">&lt;h3&gt;安装虚拟机&lt;/h3&gt;

&lt;p&gt;   VirtualBox安装rhel6.3，存储为30G，内存为1G，并复制2份&lt;/p&gt;

&lt;h3&gt;配置网络&lt;/h3&gt;

&lt;ol type=&quot;a&quot;&gt;
&lt;li&gt;&lt;p&gt;VirtualBox全局设定-网络中添加一个新的连接：vboxnet0vi&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;设置每一个虚拟机的网络为Host-Only&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;c.分别修改每个虚拟机的ip，DHCP或手动设置
        vim etc/sysconfig/network-scripts/ifcfg-eth0
        vim /etc/udev/rules.d/70-persistent-net.rules  #删掉第一个，修改第二个名字为eth0
        start_udev&lt;/p&gt;

&lt;p&gt;d.修改主机名
        vim /etc/sysconfig/network&lt;/p&gt;

&lt;p&gt;e.每个虚拟机中修改hosts：
        192.168.56.100 rhel-june
        192.168.56.101 rhel-june-1
        192.168.56.102 rhel-june-2&lt;/p&gt;

&lt;p&gt;最后机器列表为：
        rhel-june:   192.168.56.100
        rhel-june-1: 192.168.56.101
        rhel-june-2: 192.168.56.102&lt;/p&gt;

&lt;h3&gt;机群规划&lt;/h3&gt;

&lt;p&gt;版本：
        hadoop:1.1.1
        JDK:1.6.0_38&lt;/p&gt;

&lt;p&gt;集群各节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    NameNode:192.168.56.100
    NameSecondary:192.168.56.100
    DataNode:192.168.56.101
    DataNode:192.168.56.102
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;安装过程&lt;/h3&gt;

&lt;p&gt;   a.解压缩到/opt&lt;/p&gt;

&lt;p&gt;   b.设置配置文件：
        core-site.xml
        hdfs-site.sml  &lt;br/&gt;
        mapred-site.xml&lt;/p&gt;

&lt;p&gt;   c.设置master、slaves&lt;/p&gt;

&lt;p&gt;   d.设置环境变量&lt;/p&gt;

&lt;p&gt;   方便执行java命令及hadoop命令. 使用root登录，vi ~/.bash_profile 追加下列信息
        export JAVA_HOME=/opt/jdk1.6.0_38
        export HADOOP_INSTALL=/opt/hadoop-1.1.1
        export PATH=$PATH:$HADOOP_INSTALL/bin:$JAVA_HOME/bin&lt;/p&gt;

&lt;p&gt;   e.修改hadoop脚本中JAVA_HOME：/opt/hadoop-1.1.1/conf/hadoop-env.sh&lt;/p&gt;

&lt;p&gt;   f.格式化namenode
        hadoop namenode -format&lt;/p&gt;

&lt;p&gt;   g.启动hdfs集群
        sh /opt/hadoop-1.1.1/bin/start-all.sh&lt;/p&gt;

&lt;p&gt;   h.查看节点进程
        jps&lt;/p&gt;

&lt;h3&gt;查看状态&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;    http://rhel-june:50030/
    http://rhel-june:50070/
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>2012年度总结</title>
   <link href="http://blog.javachen.com/work/2013/02/20/summary-of-the-work-in-2012"/>
   <updated>2013-02-20T14:00:00+08:00</updated>
   <id>http://blog.javachen.com/work/2013/02/20/summary-of-the-work-in-2012</id>
   <content type="html">&lt;p&gt;2012年是在公司工作的第二年，在总结2012年的得与失的时候，有必要和《2011的度年终总结》相比较，在比较中审视自己在2012年是否有改进2011年存在的不足、是否有实现2011年定下的2012年工作计划。
以下是2012年相对于2011年的一些变化。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2011年，在调研云计算产品过程中，深刻的意识到自身在linux方面存在的不足；2012年，熟悉了基本的linux命令，能够读懂并编写简单shell脚本；&lt;/li&gt;
&lt;li&gt;2011年，工作环境是win7+fedora；2012年，一直使用fedora操作系统工作、编码；&lt;/li&gt;
&lt;li&gt;2011年，较多的时间花在编写代码、完成开发任务上；2012年，更多的时间花在学习架构的设计、系统的运维、项目的管理上，视野不再局限于开发、精力不再局限于编码。&lt;/li&gt;
&lt;li&gt;2011年，在工作中没有及时提交项目周报，没有及时的跟踪、检查分配下去的任务完成情况，对新人的指导不够；2012年，没有写过项目周报，做到了及是跟踪、检查分配下去的任务完成情况；&lt;/li&gt;
&lt;li&gt;2011年，博客文章篇数较少，平时的总结与分享不够积极；2012年，很少有时间写技术方面的博客；&lt;/li&gt;
&lt;li&gt;2011年，在与客户的交流中底气不足、表达能力不够；2012年，还是发现自己与客户交流中胆怯、没有底气；&lt;/li&gt;
&lt;li&gt;2011年，希望能够将Pentaho的咨询服务工作更多交给其他人完成；2012年，发现大部分的工作还是落在自己身上一个人去完成，没有发挥其他人员的作用；&lt;/li&gt;
&lt;li&gt;2011年，希望2012年能够深入理解Spring、Jboss、Pentaho、缓存、云计算、架构等技术；2012年，了解gemfire、infinispan、jboss cache、cassandra等分布式缓存的实现及原理，但每一个方面都没有时间去深入研究和学习；&lt;/li&gt;
&lt;li&gt;2011年，公司在代码复查方面做的不够；2012年，这方面还是做的不够；&lt;/li&gt;
&lt;li&gt;2011年，项目开发方面没有形成一套成型的开发框架；2012年，还是没有看到一个成熟、易用、简单的开发框架以及相配套开发文档；&lt;/li&gt;
&lt;li&gt;2011年，项目于项目之间在一些同时使用的相关技术上面的沟通于交流做的不够；2012年，团队在项目上还是缺少沟通交流，尤其体现在XXXX项目网站开发上。&lt;/li&gt;
&lt;li&gt;2011年，花了一些时间在Pentaho上，并希望2012年能够创建一个Pentaho社区、一个QQ分享群；2012年，Pentaho方面基本上没有投入；&lt;/li&gt;
&lt;li&gt;2011年，编写文档时候，没有可参考的模版，导致文档编写不规范；2012年，每次写文档时都要去找文档模版；&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;2012年参与了XXXXX项目、cassandra项目，。。。。。。此处省略314.15926个字。&lt;/p&gt;

&lt;p&gt;2012年，公司也存在一些不足：上级对下级、项目经理对团队人员了解不足，不知道其工作上、生活上的内心想法以及遇到何种困难；多数情况下，团队自我要求低，积极性不高，没有生机与活力；对新人能力审核不够，对新人培养不够重视，对新人的存在感不够关注；在各个项目的人员安排及使用上、任务分配和工作计划上不合理，导致经常被动加班、熬夜等等。&lt;/p&gt;

&lt;h3&gt;2013年工作计划：&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;通过CE考试，熟练掌握shell编程；&lt;/li&gt;
&lt;li&gt;做好项目管理者的角色，培养新人，提高团队人员编码、处理问题的能力；&lt;/li&gt;
&lt;li&gt;深入理解、学习cassandra源码、原理以及cassandra的运维；&lt;/li&gt;
&lt;li&gt;学习hadoop的安装、部署、原理、开发及运维，掌握kettle和nosql的集成，希望积累几个hadoop项目经验；&lt;/li&gt;
&lt;li&gt;学习分布式缓存理论知识，阅读源代码，完善缓存系统的监控及运维&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;在经历了2011年和2012年之后，2013年希望自己能够专注细节，深入理解，在技术、管理、交际方面有所成长；希望公司能够重视对团队的培养，能够规范各种规章制度，能够更上一层楼！&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>使用Octopress将博客从wordpress迁移到GitHub上</title>
   <link href="http://blog.javachen.com/github/2012/06/03/migrate-blog-form-wordpress-to-github-with-octopress"/>
   <updated>2012-06-03T14:00:00+08:00</updated>
   <id>http://blog.javachen.com/github/2012/06/03/migrate-blog-form-wordpress-to-github-with-octopress</id>
   <content type="html">&lt;h2&gt;Step1 - 在本机安装Octopress&lt;/h2&gt;

&lt;p&gt;首先，必须先在本机安装配置&lt;a href=&quot;http://git-scm.com/&quot;&gt;Git&lt;/a&gt;和&lt;a href=&quot;https://rvm.beginrescueend.com/rvm/install/&quot;&gt;Ruby&lt;/a&gt;,Octopress需要Ruby版本至少为1.9.2。你可以使用&lt;a href=&quot;http://rvm.beginrescueend.com/&quot;&gt;RVM&lt;/a&gt;或&lt;a href=&quot;https://github.com/sstephenson/rbenv&quot;&gt;rbenv&lt;/a&gt;安装ruby，安装方法见Octopress官方文档：&lt;a href=&quot;http://octopress.org/docs/setup/&quot;&gt;http://octopress.org/docs/setup/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我使用rvm安装：
    rvm install 1.9.2 &amp;amp;&amp;amp; rvm use 1.9.2
安装完之后可以查看ruby版本：
    ruby --version
结果为：
    ruby 1.9.2p320 (2012-04-20 revision 35421) [x86_64-linux]&lt;/p&gt;

&lt;p&gt;然后需要从github下载Octopress：
    git clone git://github.com/imathis/octopress.git octopress&lt;/p&gt;

&lt;p&gt;因为我fork了Octopress，并在配置文件上做了一些修改，故我从我的仓库地址下载Octopress，命令如下：
    git clone git@github.com:javachen/octopress.git
运行上面的代码后，你会看到：
    Cloning into 'octopress'...
    remote: Counting objects: 6579, done.
    remote: Compressing objects: 100% (2361/2361), done.
    remote: Total 6579 (delta 3773), reused 6193 (delta 3610)
    Receiving objects: 100% (6579/6579), 1.34 MiB | 35 KiB/s, done.
    Resolving deltas: 100% (3773/3773), done.&lt;/p&gt;

&lt;p&gt;接下来进入octopress：
    cd octopress&lt;/p&gt;

&lt;p&gt;接下来安装依赖：
    gem install bundler
    rbenv rehash    # If you use rbenv, rehash to be able to run the bundle command
    bundle install&lt;/p&gt;

&lt;p&gt;安装Octopress默认的主题：
    rake install&lt;/p&gt;

&lt;p&gt;你也可以安装自定义的主题，blog为主题名称：
    rake install['blog']&lt;/p&gt;

&lt;p&gt;至此，Octopress所需的环境已经搭建成功。&lt;/p&gt;

&lt;h2&gt;Step2 - 连接GitHub Pages&lt;/h2&gt;

&lt;p&gt;首先，你得有一个GitHub的帐号，并且已经创建了一个新的Repository。如果你准备用自己的域名的话，Repository的名称可以随便取，不过正常人在正常情况下，一般都是以域名取名的。如果你没有自己的域名，GitHub是提供二级域名使用的，但是你得把Repository取名为&lt;code&gt;你的帐号.github.com&lt;/code&gt;，并且，部署的时候会占用你的master分支。&lt;/p&gt;

&lt;p&gt;*Tips：*
如果用自己的一级域名，记得把source/CNAME文件内的域名改成你的一级域名，还有在dns管理中把域名的A Record指向IP：207.97.227.245；
如果用自己的二级域名，记得把source/CNAME文件内的域名改成你的二级域名，还有在dns管理中把域名的CNAME Record指向网址：charlie.github.com；
    echo 'your-domain.com' &gt;&gt; source/CNAME
如果用GitHub提供的二级域名，记得把source/CNAME删掉。&lt;/p&gt;

&lt;p&gt;完成上述准备工作后，运行：
    rake setup_github_pages
它会提示你输入有读写权限的Repository Url，这个在GitHub上可以找到。Url形如：https://github.com/javachen/javachen.github.com.git，javachen.github.com是我的Repository的名称。&lt;/p&gt;

&lt;h2&gt;Step3 - 配置你的博客&lt;/h2&gt;

&lt;p&gt;需要配置博客url、名称、作者、rss等信息。
    url: http://javachen.github.com
    title: JavaChen on Java
    subtitle: Just some random thoughts about technology,Java and life.
    author: javachen
    simple_search: http://google.com/search
    description:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;date_format: &quot;%Y年%m月%d日&quot;

subscribe_rss: /atom.xml
subscribe_email:
email:

# 如果你使用的是一个子目录，如http://site.com/project，则设置为'root: /project'
root: /
# 文章标题格式
permalink: /:year/:month/:day/:title/
source: source
destination: public
plugins: plugins
code_dir: downloads/code
# 分类存放路径
category_dir: categories
markdown: rdiscount
pygments: false # default python pygments have been replaced by pygments.rb
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Step4 - 部署&lt;/h2&gt;

&lt;p&gt;先把整个项目静态化，然后再部署到GitHub：
    rake generate
    rake deploy
当你看到“Github Pages deploy complete”后，就表示你大功已成。Enjoy!&lt;/p&gt;

&lt;p&gt;*Tips：*
Octopress提供的所有rake方法，可以运行&lt;code&gt;rake -T&lt;/code&gt;查看。
如果在执行上述命令中ruby报错，则需要一一修复错误，这一步是没有接触过ruby的人比较苦恼的。&lt;/p&gt;

&lt;h2&gt;Step5 - 从Wordpress迁移到Octopress&lt;/h2&gt;

&lt;h3&gt;备份&lt;/h3&gt;

&lt;h4&gt;备份评论内容&lt;/h4&gt;

&lt;p&gt;Octopress由于是纯静态，所以没有办法存储用户评论了，我们可以使用DISQUS提供的“云评论”服务。首先安装DISQUS的WordPress插件，在插件设置中我们可以将现有的评论内容导入到DISQUS中。DISQUS处理导入数据的时间比较长，往往需要24小时甚至以上的时间。&lt;/p&gt;

&lt;h4&gt;备份文章内容&lt;/h4&gt;

&lt;p&gt;在WordPress后台我们可以将整站数据备份成一个.xml文件下载下来。同时，我原先文章中的图片都是直接在Wordpress后台上传的，所以要把服务器上&lt;code&gt;wp-content/uploads&lt;/code&gt;下的所有文件备份下来。&lt;/p&gt;

&lt;h3&gt;迁移&lt;/h3&gt;

&lt;h4&gt;迁移文章&lt;/h4&gt;

&lt;p&gt;jekyll本身提供了一个从WordPress迁移文章的工具，不过对中文实在是不太友好。这里我使用了YORKXIN的修改版本。将上面备份的wordpress.xml放到Octopress根目录，把脚本放到新建的utils目录中，然后运行：
    ruby -r &quot;./utils/wordpressdotcom.rb&quot; -e &quot;Jekyll::WordpressDotCom.process&quot;
于是转换好的文章都放进source目录了。&lt;/p&gt;

&lt;h4&gt;迁移URL&lt;/h4&gt;

&lt;p&gt;迁移URL，便是要保证以前的文章链接能够自动重定向到新的链接上。这样既能保证搜索引擎的索引不受影响，也是一项对读者负责任的行为是吧。不过这是一项挺麻烦的事情。&lt;/p&gt;

&lt;p&gt;幸好我当初建立WordPress的时候就留下了后路。原先网站的链接是这样的：
    http://XXXXXXXXX.com/[year]/[month]/[the-long-long-title].html
    http://XXXXXXXXX.com/page/xx/
    http://XXXXXXXXX.com/category/[category-name]/
这样的格式是比较容易迁移的。如果原先的文章URL是带有数字ID的话，只能说声抱歉了。到_config.yml里面设置一下新站点的文章链接格式，跟原先的格式保持一致：
    permalink: /:year/:month/:title/
    category_dir: category
    pagination_dir:  # 留空&lt;/p&gt;

&lt;h4&gt;迁移评论&lt;/h4&gt;

&lt;p&gt;既然做好了301，那么迁移评论就显得非常简单了。登录DISQUS后台，进入站点管理后台的“Migrate Threads”栏目，那里有一个“Redirect Crawler”的功能，便是自动跟随301重定向，将评论指向新的网址。点一下那个按钮就大功告成。&lt;/p&gt;

&lt;h4&gt;迁移图片&lt;/h4&gt;

&lt;p&gt;可以参考&lt;a href=&quot;http://log4d.com/2012/05/image-host/&quot;&gt;使用独立图床子域名&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Step6 - 再次部署&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;rake generate
rake deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Octopress Setup： http://octopress.org/docs/setup/&lt;/li&gt;
&lt;li&gt;Octopress Deploying：http://octopress.org/docs/deploying/&lt;/li&gt;
&lt;li&gt;Blog = GitHub + Octopress：http://mrzhang.me/blog/blog-equals-github-plus-octopress.html&lt;/li&gt;
&lt;li&gt;从Wordpress迁移到Octopress：http://blog.dayanjia.com/2012/04/migration-to-octopress-from-wordpress/&lt;/li&gt;
&lt;li&gt;使用独立图床子域名：http://log4d.com/2012/05/image-host/ http://log4d.com/2012/05/image-host/&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Kettle dependency management</title>
   <link href="http://blog.javachen.com/kettle/2012/04/13/kettle-dependency-management"/>
   <updated>2012-04-13T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/04/13/kettle-dependency-management</id>
   <content type="html">&lt;p&gt;pentaho的项目使用了ant和ivy解决项目依赖,所以必须编译源码需要ivy工具.直接使用ivy编译pentaho的bi server项目,一直没有编译成功.&lt;br /&gt;
使用ivy编译kettle的源代码却是非常容易的事情.&lt;/p&gt;




&lt;p&gt;该篇文章翻译并参考了Will Gorman在pentaho的wiki上添加的&lt;a href=&quot;http://wiki.pentaho.com/display/EAI/Kettle+dependency+management&quot; target=&quot;_blank&quot;&gt;Kettle dependency management&lt;/a&gt;,文章标题没作修改.&lt;br /&gt;
编写此文,是为了记录编译kettle源码的方法和过程.&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;以下是对原文的一个简单翻译.&lt;/strong&gt;
将kettle作为一个产品发行是一个很有趣的事情.有很多来自于pentaho其他项目(其中有一些有依赖于kettle)的jar包被导入到kettle.这些jar包必须在发行的时候构建并且加入到kettle中.如果一个核心的库被更新了,我们必须将其导入到kettle中(如果有必要).bi服务器,pentaho报表以及pentaho元数据编辑器都将kettle作为一个服务/引擎资源而被构建的.自从我们已经将这些jar导入到我们的源码仓库,这些项目必须使用ivy明确列出kettle以及他的依赖.当kettle的依赖变化的时候,我们必须审查libext文件是否需要更新.&lt;/p&gt;




&lt;p&gt;pentaho创建了一系列的脚本来自动化的安装ivy,解决jar(或者是artifacts),构建并发行artifacts.kettle已经升级使用subfloor(简单的意味着build.xml继承自subfloor的构建脚本).subfloor使用ivy从pentaho仓库()或者ibiblio maven2仓库来获取跟新jar.ibiblio仓库用于大多数第三方的jar文件(如apache-commons).pentaho仓库用于在线的pentaho项目或者一些比在ibiblio的三方库.为了解决kettle的依赖,我们不得不在ivy.xml里创建一个清单.这个文件明确地列出每一个没有传递依赖的jar文件.这意味着libext文件的映射在ivy.xml中是一对一的.
&lt;!--more--&gt;
&lt;strong&gt;关于Ivy&lt;/strong&gt;
&lt;a href=&quot;http://ant.apache.org/ivy/&quot; target=&quot;_blank&quot;&gt;Apache Ivy™&lt;/a&gt;是一个流行的致力于灵活性和简单性的依赖管理工具.更多的参考:&lt;a href=&quot;http://ant.apache.org/ivy/features.html&quot; target=&quot;_blank&quot;&gt;enterprise features&lt;/a&gt;, &lt;a href=&quot;http://ant.apache.org/ivy/testimonials.html&quot; target=&quot;_blank&quot;&gt;what people say about it&lt;/a&gt;, 以及 &lt;a href=&quot;http://ant.apache.org/ivy/history/latest-milestone/index.html&quot; target=&quot;_blank&quot;&gt;how it can improve your build system&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;在kettle中使用ivyIDE&lt;/strong&gt;
首先,从svn上下载kettle的源代码:
&lt;pre&gt;
svn://source.pentaho.org/svnkettleroot/Kettle/trunk
&lt;/pre&gt;
如果你想在Eclipse上使用&lt;a href=&quot;http://ant.apache.org/ivy/ivyde/download.cgi&quot; target=&quot;_blank&quot;&gt;ivyde plugin&lt;/a&gt;.&lt;br /&gt;
请参考相关文章安装该插件.&lt;/p&gt;




&lt;p&gt;如果你不想使用ivyde,你可以简单快速并且容易的开始并编译代码.&lt;br /&gt;
1.执行&lt;code&gt;ant resolve&lt;/code&gt;,这个命令将会创建一个叫做resolved-libs的文件夹.&lt;br /&gt;
2.使用下面命令更新classpath &lt;br /&gt;
  a.手动的添加这些jar文件到你的ide的classpath&lt;br /&gt;
  b.执行ant create-dot-classpath,将会修改你的.classpath文件(注意刷新项目以使改变生效)&lt;br /&gt;
注意:kettle项目中的构建脚本会自动安装ivy插件.&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;构建Kettle&lt;/strong&gt;
你可以下载kettle源代码然后立即执行&lt;code&gt;ant distrib&lt;/code&gt;命令&lt;br /&gt;
或者你可以在ide中导入下载的kettle工程,然后按照你的操作系统(默认的是Windows 32-bit)版本修改依赖的swt.jar文件.&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;ivy中未完成的&lt;/strong&gt;
&lt;strong&gt;pentaho-database-&lt;/strong&gt;这是一个依赖kettle-db的常用项目,但又被kettle-ui使用.这样会导致循环依赖,将来可能会将其引入到kettle项目或是从该项目中去掉对kettle的依赖.
&lt;strong&gt;swt-&lt;/strong&gt;swt文件目前没有包括在ivy.xml文件中
&lt;strong&gt;library configurations-&lt;/strong&gt;每一个kettle库(kettle-db,kettle-core等等)应该在ivy.xml中有他自己的依赖.这些库应该继承一些特定的依赖,而取代继承整个kettle依赖.
&lt;strong&gt;checked-in plugins-&lt;/strong&gt;当前引入的插件如;DummyJob, DummyPlugin, S3CsvInput, ShapeFileReader3,versioncheck应该都移到ivy的plugin配置中.&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;
&lt;a href=&quot;http://wiki.pentaho.com/display/EAI/Kettle+dependency+management&quot; target=&quot;_blank&quot;&gt;Kettle dependency management&lt;/a&gt;
&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Getting Started Using the Cassandra CLI</title>
   <link href="http://blog.javachen.com/cassandra/2012/04/09/getting-started-using-the-cassandra-cli"/>
   <updated>2012-04-09T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cassandra/2012/04/09/getting-started-using-the-cassandra-cli</id>
   <content type="html">&lt;p&gt;这仅仅是一个Cassandra CLI使用方法的清单。&lt;br /&gt;
Cassandra CLI 客户端用于处理集群中基本的数据定义（DDL）和数据维护（DML）。其处于&lt;code&gt;/usr/bin/cassandra-cli&lt;/code&gt;，如果是试用包安装，或者是&lt;code&gt;$CASSANDRA_HOME/bin/cassandra-cli&lt;/code&gt;，如果使用二进制文件安装。&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Starting the CLI&lt;/h1&gt;
使用&lt;code&gt;cassandra-cli&lt;/code&gt; &lt;code&gt;-host&lt;/code&gt; &lt;code&gt;-port&lt;/code&gt; 命令启动 Cassandra CLI，他将会连接&lt;code&gt;cassandra.yaml&lt;/code&gt;文件中定义的集群名称，默认为“&lt;em&gt;Test Cluster&lt;/em&gt;”。&lt;br /&gt;
如果你有一个但节点的集群，则使用以下命令：
&lt;pre&gt; 
$ cassandra-cli -host localhost -port 9160
&lt;/pre&gt;
如果想连接多节点集群中的一个节点，可以使用以下命令:
&lt;pre&gt;
$ cassandra-cli -host 110.123.4.5 -port 9160
&lt;/pre&gt;
或者，可以直接执行以下命令：
&lt;pre&gt;
$ cassandra-cli
&lt;/pre&gt;
登录成功之后，可以看到：
&lt;pre&gt;
Welcome to cassandra CLI.
Type 'help;' or '?' for help. Type 'quit;' or 'exit;' to quit.
&lt;/pre&gt;
你必须指定连接一个节点：
&lt;pre&gt;
[default@unknown]connect localhost/9160;
&lt;/pre&gt;
&lt;!--more--&gt;
&lt;h1&gt;Creating a Keyspace&lt;/h1&gt;
&lt;pre&gt;
[default@unknown] CREATE KEYSPACE demo;
&lt;/pre&gt;
下面的一个例子，创建一个叫demo的Keyspace,并且复制因子为1，使用&lt;code&gt;SimpleStrategy&lt;/code&gt;复制替换策略。
&lt;pre&gt;
[default@unknown] CREATE KEYSPACE demo with 
        placement_strategy ='org.apache.cassandra.locator.SimpleStrategy' 
        and strategy_options = [{replication_factor:1}];
&lt;/pre&gt;
你可以使用&lt;code&gt;SHOW KEYSPACES&lt;/code&gt;来查看所有系统的和你创建的Keyspace&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Use a keyspace&lt;/h1&gt;
&lt;pre&gt;
[default@unknown] USE demo;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Creating a Column Family&lt;/h1&gt;
&lt;pre&gt;
[default@demo] CREATE COLUMN FAMILY users
WITH comparator = UTF8Type
AND key_validation_class=UTF8Type
AND column_metadata = [
{column_name: full_name, validation_class: UTF8Type}
{column_name: email, validation_class: UTF8Type}
{column_name: state, validation_class: UTF8Type}
{column_name: gender, validation_class: UTF8Type}
{column_name: birth_year, validation_class: LongType}
];
&lt;/pre&gt;
我们使用demo keyspace创建了一个column family，其名称为users，并包括5个静态列：full_name，email,state,gender,birth_year.comparator, key_validation_class和validation_class，用于设置；列名称，行key的值，列值的编码。comparator还定义了列名称的排序方式。&lt;br /&gt;
下面命令创建一个名称为 blog_entry的动态column family，我们不需要定义列，而由应用程序稍后定义。
&lt;pre&gt;
[default@demo] CREATE COLUMN FAMILY blog_entry WITH comparator = TimeUUIDType AND key_validation_class=UTF8Type AND default_validation_class = UTF8Type;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Creating a Counter Column Family&lt;/h1&gt;
&lt;pre&gt;
[default@demo] CREATE COLUMN FAMILY page_view_counts WITH 
          default_validation_class=CounterColumnType 
          AND key_validation_class=UTF8Type AND comparator=UTF8Type;
&lt;/pre&gt;
插入一行和计数列：
&lt;pre&gt;
[default@demo] INCR page_view_counts['www.datastax.com'][home] BY 0;
&lt;/pre&gt;
增加计数：
&lt;pre&gt;
[default@demo] INCR page_view_counts['www.datastax.com'][home] BY 1;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Inserting Rows and Columns&lt;/h1&gt;
以下命令以一个特点的行key值插入列到users中
&lt;pre&gt;
[default@demo] SET users['bobbyjo']['full_name']='Robert Jones';
[default@demo] SET users['bobbyjo']['email']='bobjones@gmail.com';
[default@demo] SET users['bobbyjo']['state']='TX';
[default@demo] SET users['bobbyjo']['gender']='M';
[default@demo] SET users['bobbyjo']['birth_year']='1975';
&lt;/pre&gt;
更新数据： set users['bobbyjo']['full_name'] = 'Jack';&lt;br /&gt;
获取数据： get users['bobbyjo'];&lt;br /&gt;
get命令用法参考：&lt;a href=&quot;http://wiki.apache.org/cassandra/API#get_slice&quot; target=&quot;_blank&quot;&gt;API#get_slice&lt;/a&gt;
查询数据： get users where gender= 'M';&lt;br /&gt;
下面命令在 blog_entry中创建了一行，其行key为“yomama”，并指定了一列：timeuuid()的值为 'I love my new shoes!'
&lt;pre&gt;
[default@demo] SET blog_entry['yomama'][timeuuid()] = 'I love my new shoes!';
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Reading Rows and Columns&lt;/h1&gt;
使用List命令查询记录，默认查询100条记录
&lt;pre&gt;
[default@demo] LIST users;
&lt;/pre&gt;
Cassandra 默认以16进制数组的格式存储数据 为了返回可读的数据格式，可以指定编码：
&lt;li&gt;ascii&lt;/li&gt;
&lt;li&gt;bytes&lt;/li&gt;
&lt;li&gt;integer (a generic variable-length integer type)&lt;/li&gt;
&lt;li&gt;lexicalUUID&lt;/li&gt;
&lt;li&gt;long&lt;/li&gt;
&lt;li&gt;utf8&lt;/li&gt;
例如：
&lt;pre&gt;
[default@demo] GET users[utf8('bobby')][utf8('full_name')];
&lt;/pre&gt;
你也可以使用&lt;code&gt;ASSUME&lt;/code&gt;命令指定编码，例如，指定行key，行名称，行值显示ascii码格式：
&lt;pre&gt;
[default@demo] ASSUME users KEYS AS ascii;
[default@demo] ASSUME users COMPARATOR AS ascii;
[default@demo] ASSUME users VALIDATOR AS ascii;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Setting an Expiring Column&lt;/h1&gt;
例如，假设我们正在跟踪我们的用户，到期后10天的优惠券代码。我们可以定义coupon_code的列和设置该列的过期日期。例如：
&lt;pre&gt;
[default@demo] SET users['bobbyjo'] [utf8('coupon_code')] = utf8('SAVE20') WITH ttl=864000;
&lt;/pre&gt;
自该列被设置值之后，经过10天或864,000秒后，其值将被标记为删除，不再由读操作返回。然而，请注意，直到Cassandra的处理过程完成，该值才会从硬盘中删除。&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Indexing a Column&lt;/h1&gt;
给birth_year添加一个二级索引：
&lt;pre&gt;
[default@demo] UPDATE COLUMN FAMILY users 
            WITH comparator = UTF8Type AND column_metadata = 
            [{column_name: birth_year, validation_class: LongType, index_type: KEYS}];
&lt;/pre&gt;
由于该列被索引了，所以可以直接通过该列查询：
&lt;pre&gt;
[default@demo] GET users WHERE birth_date = 1969;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Deleting Rows and Columns&lt;/h1&gt;
删除yomama索引的coupon_code列：
&lt;pre&gt;
[default@demo] DEL users ['yomama']['coupon_code'];
[default@demo] GET users ['yomama'];
&lt;/pre&gt;
或者删除整行：
&lt;pre&gt;
[default@demo] DEL users ['yomama'];
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;Dropping Column Families and Keyspaces&lt;/h1&gt;
&lt;pre&gt;
[default@demo] DROP COLUMN FAMILY users;
[default@demo] DROP KEYSPACE demo;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;For help&lt;/h1&gt;
&lt;pre&gt;
[default@unknown]help;
&lt;/pre&gt;
查看某一个命令的详细说明：
&lt;pre&gt;
[default@unknown] help SET;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;To Quit&lt;/h1&gt;
&lt;pre&gt;
[default@unknown]quit;
&lt;/pre&gt;&lt;/p&gt;




&lt;p&gt;&lt;h1&gt;To Execute Script&lt;/h1&gt;
&lt;pre&gt;
bin/cassandra-cli -host localhost -port 9160 -f script.txt
&lt;/pre&gt;&lt;/p&gt;




&lt;h1&gt;参考文章&lt;/h1&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.datastax.com/docs/0.8/dml/using_cli&quot; target=&quot;_blank&quot;&gt;Getting Started Using the Cassandra CLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.apache.org/cassandra/CassandraCli&quot; target=&quot;_blank&quot;&gt;CassandraCli&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>使用DataStax Community Edition安装Cassandra单节点</title>
   <link href="http://blog.javachen.com/cassandra/2012/04/06/install_singlenode-with-datastax-community-editio"/>
   <updated>2012-04-06T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cassandra/2012/04/06/install_singlenode-with-datastax-community-editio</id>
   <content type="html">&lt;p&gt;本文主要记录使用DataStax Community Edition安装Cassandra单节点的过程.配置单节点的Cassandra,是为了方便快速的了解学习Cassandra.&lt;/p&gt;

&lt;h1&gt;检查java环境&lt;/h1&gt;


&lt;p&gt;Cassandra由java编写,需要运行中jvm虚拟机之上.如果用于生产环境,则需要jre 1.6.0-19或更高版本.&lt;/p&gt;

&lt;h3&gt;1.检查是否安装java:&lt;/h3&gt;


&lt;pre&gt;
# java -version
&lt;/pre&gt;


&lt;p&gt;如果你没有安装java,可以参考网上相关文章.这里主要记录在RHEL系统上安装jdk的方法.&lt;/p&gt;

&lt;h3&gt;2.安装jdk&lt;/h3&gt;


&lt;p&gt;下载&lt;a href=&quot;http://www.oracle.com/technetwork/java/javase/downloads/index.html&quot; target=&quot;_blank&quot;&gt;Oracle JRE&lt;/a&gt;
1）修改执行权限:&lt;/p&gt;

&lt;pre&gt;
$ cd /tmp
$ chmod a+x jre-6u25-linux-x64-rpm.bin
&lt;/pre&gt;


&lt;!--more--&gt;


&lt;p&gt;2）解压执行RPM文件,例如:&lt;/p&gt;

&lt;pre&gt;
$ sudo ./jre-6u25-linux-x64-rpm.bin
&lt;/pre&gt;


&lt;p&gt;这样JRE会安装在/usr/java/
3）配置Oracle JRE取代OpenJDK JRE
可以使用alternatives命令添加一个链接到Oracle JRE.&lt;/p&gt;

&lt;pre&gt;
$ sudo alternatives --install /usr/bin/java java /usr/java/jre1.6.0_25/bin/java 20000
&lt;/pre&gt;


&lt;p&gt;4）确认是否安装JRE&lt;/p&gt;

&lt;pre&gt;
$ java -version
  java version &quot;1.6.0_25&quot;
  Java(TM) SE Runtime Environment (build 1.6.0_25-b06)
  Java HotSpot(TM) 64-Bit Server VM (build 20.0-b11, mixed mode)
&lt;/pre&gt;


&lt;p&gt;如果OpenJDK JRE仍然被使用,可以使用alternatives命令切换到Oracle JRE.例如:&lt;/p&gt;

&lt;pre&gt;
$ sudo alternatives --config java
There are 2 programs which provide 'java'.

Selection      Command
-----------------------------------------------
   1           /usr/lib/jvm/jre-1.6.0-openjdk.x86_64/bin/java
*+ 2           /usr/java/jre1.6.0_25/bin/java
&lt;/pre&gt;




&lt;h1&gt;在Linux系统上安装DataStax Community二进制文件&lt;/h1&gt;


&lt;h3&gt;1.在用户目录创建一个目录,如datas&lt;/h3&gt;


&lt;pre&gt;
$ cd $HOME
$ mkdir datas
$ cd datas
&lt;/pre&gt;


&lt;h3&gt;2.下载cassandra(必须的)和OpsCenter包(可选的)&lt;/h3&gt;


&lt;pre&gt;
$ wget http://downloads.datastax.com/community/dsc.tar.gz
$ wget http://downloads.datastax.com/community/opscenter.tar.gz
$ wget http://downloads.datastax.com/community/dsc-1.0.1-demo-bin.tar.gz
&lt;/pre&gt;


&lt;h3&gt;3.解压&lt;/h3&gt;


&lt;pre&gt;
$ tar -xzvf dsc.tar.gz
$ tar -xzvf opscenter.tar.gz
$ tar -xzvf dsc-1.0.1-demo-bin.tar.gz
$ rm *.tar.gz
&lt;/pre&gt;


&lt;h3&gt;4.设置环境变量&lt;/h3&gt;


&lt;p&gt;1)编辑 .bashrc&lt;/p&gt;

&lt;pre&gt;
 vi $HOME/.bashrc
&lt;/pre&gt;


&lt;p&gt;2)添加以下代码&lt;/p&gt;

&lt;pre&gt;
export CASSANDRA_HOME=$HOME/datas/dsc_package_name
export DSCDEMO_HOME=$HOME/datas/dsc-1.0.1/demos/portfolio_manager
export OPSC_HOME=$HOME/datas/opscenter_package_name
export PATH=&quot;$PATH:$CASSANDRA_HOME/bin:$DSCDEMO_HOME/bin:$OPSC_HOME/bin&quot;
&lt;/pre&gt;


&lt;p&gt;注意替换&lt;font color=&quot;red&quot;&gt;dsc_package_name&lt;/font&gt;和&lt;font color=&quot;red&quot;&gt;opscenter_package_name&lt;/font&gt;
3)保存退出
4)使该文件生效&lt;/p&gt;

&lt;pre&gt;
source $HOME/.bashrc
&lt;/pre&gt;


&lt;h3&gt;5.创建保存Cassandra数据的文件和日志目录&lt;/h3&gt;


&lt;pre&gt;
$ mkdir $HOME/datas/cassandra-data
&lt;/pre&gt;




&lt;h1&gt;配置并启动单节点&lt;/h1&gt;


&lt;h3&gt;1.编辑配置环境&lt;/h3&gt;


&lt;p&gt;修改$CASSANDRA_HOME/conf/cassandra.yaml&lt;/p&gt;

&lt;pre&gt;
$ sed -i -e &quot;s,initial_token:,initial_token: 0,&quot; \
  $CASSANDRA_HOME/conf/cassandra.yaml

$ sed -i -e &quot;s,- /var/lib/cassandra/data,- $HOME/datastax/cassandra-data,&quot; \
  $CASSANDRA_HOME/conf/cassandra.yaml

$ sed -i -e &quot;s,saved_caches_directory: /var/lib/cassandra/saved_caches, \
  saved_caches_directory: $HOME/datastax/cassandra-data/saved_caches,&quot; \
  $CASSANDRA_HOME/conf/cassandra.yaml

$ sed -i -e &quot;s,commitlog_directory: /var/lib/cassandra/commitlog,commitlog_directory: \
  $HOME/datastax/cassandra-data/commitlog,&quot; $CASSANDRA_HOME/conf/cassandra.yaml
&lt;/pre&gt;




&lt;h3&gt;2.设置日志文件位置&lt;/h3&gt;


&lt;p&gt;
修改：$CASSANDRA_HOME/conf/log4j-server.properties&lt;/p&gt;

&lt;pre&gt;
$ sed -i -e &quot;s,log4j.appender.R.File=/var/log/cassandra/system.log, \
  log4j.appender.R.File=$HOME/datastax/cassandra-data/system.log,&quot; \
  $CASSANDRA_HOME/conf/log4j-server.properties
&lt;/pre&gt;


&lt;h3&gt;3.配置DataStax示例程序指向Cassandra的安装位置&lt;/h3&gt;


&lt;pre&gt;
$ sed -i -e &quot;s,/usr/share/cassandra,$HOME/datastax/&lt;dsc_package_name&gt;,&quot; \
  $DSCDEMO_HOME/bin/pricer
&lt;/dsc_package_name&gt;
&lt;/pre&gt;




&lt;h3&gt;4.后台启动Cassandra&lt;/h3&gt;


&lt;pre&gt;
$ cassandra
&lt;/pre&gt;


&lt;h3&gt;5.检查cassandra环是否在运行&lt;/h3&gt;


&lt;pre&gt;
$ nodetool ring -h localhost
&lt;/pre&gt;


&lt;h3&gt;6.运行Portfolio Demo示例程序&lt;/h3&gt;


&lt;p&gt;1)进入Portfolio目录&lt;/p&gt;

&lt;pre&gt;
$ cd $DSCDEMO_HOME
&lt;/pre&gt;


&lt;p&gt;2)运行 ./bin/pricer工具生成数据&lt;/p&gt;

&lt;pre&gt;
./bin/pricer --help
&lt;/pre&gt;


&lt;p&gt;下面代码生成100天的历史数据&lt;/p&gt;

&lt;pre&gt;
./bin/pricer -o INSERT_PRICES
./bin/pricer -o UPDATE_PORTFOLIOS
./bin/pricer -o INSERT_HISTORICAL_PRICES -n 100
&lt;/pre&gt;


&lt;p&gt;3)启动服务(必须在$DSCDEMO_HOME/website目录下启动)&lt;/p&gt;

&lt;pre&gt;
$ cd $DSCDEMO_HOME/website
$ java -jar start.jar &amp;
&lt;/pre&gt;


&lt;p&gt;4)浏览程序 http://localhost:8983/portfolio&lt;/p&gt;

&lt;h1&gt;参考文章&lt;/h1&gt;


&lt;ul&gt;
&lt;li&gt;1.&lt;a href=&quot;http://www.datastax.com/docs/1.0/getting_started/install_singlenode&quot; target=&quot;_blank&quot;&gt;Installing a Single-Node Instance of Cassandra&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>哈希表</title>
   <link href="http://blog.javachen.com/java/2012/03/26/hash-and-hash-functions"/>
   <updated>2012-03-26T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/java/2012/03/26/hash-and-hash-functions</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;定义 &lt;/strong&gt;
一般的线性表、树，数据在结构中的相对位置是&lt;code&gt;随机&lt;/code&gt;的，即和记录的关键字之间不存在确定的关系，因此，在结构中查找记录时需进行一系列和关键字的比较。这一类查找方法建立在“比较“的基础上，查找的效率依赖于查找过程中所进行的比较次数。 若想能直接找到需要的记录，必须在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使每个关键字和结构中一个唯一的存储位置相对应，这就是哈希表。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;哈希表&lt;/code&gt;又称散列表。
&lt;em&gt;哈希表存储的基本思想是&lt;/em&gt;：以数据表中的每个记录的关键字 k为自变量，通过一种函数H(k)计算出函数值。把这个值解释为一块连续存储空间（即&lt;code&gt;数组空间&lt;/code&gt;）的单元地址（即&lt;code&gt;下标&lt;/code&gt;），将该记录存储到这个单元中。在此称该函数H为哈希函数或散列函数。按这种方法建立的表称为&lt;code&gt;哈希表&lt;/code&gt;或&lt;code&gt;散列表&lt;/code&gt;。&lt;br /&gt;
哈希表是一种数据结构，它可以提供快速的插入操作和查找操作。&lt;br /&gt;
哈希表是基于&lt;code&gt;数组结构&lt;/code&gt;实现的，所以它也存在一些&lt;em&gt;缺点&lt;/em&gt;： 数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重。 这个问题是哈希表不可避免的，即&lt;code&gt;冲突现象&lt;/code&gt;：对不同的关键字可能得到同一哈希地址。 所以在以下情况下可以优先考虑使用哈希表： &lt;em&gt;不需要有序遍历数据，并且可以提前预测数据量的大小&lt;/em&gt;。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;冲突&lt;/strong&gt;
理想情况下，哈希函数在关键字和地址之间建立了一个一一对应关系，从而使得查找只需一次计算即可完成。由于关键字值的某种随机性，使得这种一一对应关系难以发现或构造。因而可能会出现不同的关键字对应一个存储地址。即k1≠k2，但H(k1)=H(k2)，这种现象称为冲突。&lt;br /&gt;
把这种具有不同关键字值而具有相同哈希地址的对象称&lt;code&gt;同义词&lt;/code&gt;。 在大多数情况下，冲突是不能完全避免的。这是因为所有可能的关键字的集合可能比较大，而对应的地址数则可能比较少。&lt;br /&gt;
对于哈希技术，主要研究两个问题：&lt;br /&gt;
（1）如何设计哈希函数以使冲突尽可能少地发生。&lt;br /&gt;
（2）发生冲突后如何解决。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;哈希函数的构造方法&lt;/strong&gt;
构造好的哈希函数的方法，应能使冲突尽可能地少，因而应具有较好的随机性。这样可使一组关键字的散列地址均匀地分布在整个地址空间。根据关键字的结构和分布的不同，可构造出许多不同的哈希函数。
&lt;strong&gt;1．直接定址法&lt;/strong&gt;
&lt;code&gt;直接定址法&lt;/code&gt;是以关键字k本身或关键字加上某个数值常量c作为哈希地址的方法。&lt;br /&gt;
该哈希函数H(k)为：&lt;br /&gt;
H(k)=k+c (c≥0)&lt;br /&gt;
这种哈希函数计算简单，并且不可能有冲突发生。当关键字的分布基本连续时，可使用直接定址法的哈希函数。否则，若关键字分布不连续将造成内存单元的大量浪费&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;2．除留余数法&lt;/strong&gt;&lt;/p&gt;




&lt;p&gt;取关键字k除以哈希表长度m所得余数作为哈希函数地址的方法。即：&lt;br /&gt;
H(k)=k％m&lt;br /&gt;
这是一种较简单、也是较常见的构造方法。&lt;br /&gt;
这种方法的关键是选择好哈希表的长度m。使得数据集合中的每一个关键字通过该函数转化后映射到哈希表的任意地址上的概率相等。&lt;br /&gt;
理论研究表明，在m取值为素数（质数）时，冲突可能性相对较少。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;3．平方取中法&lt;/strong&gt;
取关键字平方后的中间几位作为哈希函数地址（若超出范围时，可再取模）。&lt;br /&gt;
设有一组关键字ABC，BCD,CDE，DEF，……其对应的机内码如表所示。假定地址空间的大小为1000，编号为0-999。现按平方取中法构造哈希函数，则可取关键字机内码平方后的中间三位作为存储位置。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;4．折叠法&lt;/strong&gt;
这种方法适合在关键字的位数较多，而地址区间较小的情况。&lt;br /&gt;
将关键字分隔成位数相同的几部分。然后将这几部分的叠加和作为哈希地址（若超出范围，可再取模）。&lt;br /&gt;
例如，假设关键字为某人身份证号码430104681015355，则可以用4位为一组进行叠加。即有5355+8101+1046+430=14932，舍去高位。 则有H(430104681015355)=4932 为该身份证关键字的哈希函数地址。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;5．数值分析法&lt;/strong&gt;
若事先知道所有可能的关键字的取值时，可通过对这些关键字进行分析，发现其变化规律，构造出相应的哈希函数。&lt;br /&gt;
例：对如下一组关键字通过分析可知：每个关键字从左到右的第l，2，3位和第6位取值较集中，不宜作哈希地址。 剩余的第4，5，7和8位取值较分散，可根据实际需要取其中的若干位作为哈希地址。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;6. 随机数法&lt;/strong&gt;
选择一个随机函数，取关键字的随机函数值为它的哈希地址，即H(key)＝random(key)，其中random为随机函数。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;7. 斐波那契（Fibonacci）散列法&lt;/strong&gt;
平方散列法的缺点是显而易见的，所以我们能不能找出一个理想的乘数，而不是拿value本身当作乘数呢？答案是肯定的。&lt;br /&gt;
1，对于16位整数而言，这个乘数是40503&lt;br /&gt;
2，对于32位整数而言，这个乘数是2654435769&lt;br /&gt;
3，对于64位整数而言，这个乘数是11400714819323198485&lt;br /&gt;
这几个“理想乘数”是如何得出来的呢？这跟一个法则有关，叫黄金分割法则，而描述黄金分割法则的最经典表达式无疑就是著名的斐波那契数列，如果你还有兴趣，就到网上查找一下“斐波那契数列”等关键字，我数学水平有限，不知道怎么描述清楚为什么，另外斐波那契数列的值居然和太阳系八大行星的轨道半径的比例出奇吻合，很神奇，对么？&lt;br /&gt;
对我们常见的32位整数而言，公式：&lt;br /&gt;
index = (value * 2654435769) &amp;gt;&amp;gt; 28&lt;br /&gt;
如果用这种斐波那契散列法的话，那我上面的图就变成这样了：&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;冲突的解决方法&lt;/strong&gt;
假设哈希表的地址范围为0～m-l，当对给定的关键字k，由哈希函数H(k)算出的哈希地址为i（0≤i≤m-1）的位置上已存有记录，这种情况就是&lt;code&gt;冲突现象&lt;/code&gt;。 处理冲突就是为该关键字的记录找到另一个“空”的哈希地址。即通过一个新的哈希函数得到一个新的哈希地址。如果仍然发生冲突，则再求下一个，依次类推。直至新的哈希地址不再发生冲突为止。&lt;br /&gt;
常用的处理冲突的方法有开放地址法、链地址法两大类
&lt;strong&gt;1．开放定址法&lt;/strong&gt;
用开放定址法处理冲突就是当冲突发生时，形成一个地址序列。沿着这个序列逐个探测，直到找出一个“空”的开放地址。将发生冲突的关键字值存放到该地址中去。&lt;br /&gt;
如 Hi=(H(k)+d（i）) % m, i=1，2，…k (k 其中H(k)为哈希函数，m为哈希表长，d为增量函数，d(i)=dl，d2…dn-l。&lt;br /&gt;
增量序列的取法不同，可得到不同的开放地址处理冲突探测方法。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;1）线性探测法&lt;/strong&gt;
线性探测法是从发生冲突的地址（设为d）开始，依次探查d+l，d+2，…m-1（当达到表尾m-1时，又从0开始探查）等地址，直到找到一个空闲位置来存放冲突处的关键字。&lt;br /&gt;
若整个地址都找遍仍无空地址，则产生溢出。&lt;br /&gt;
线性探查法的数学递推描述公式为：&lt;br /&gt;
d0=H(k)&lt;br /&gt;
di=(di-1+1)% m (1≤i≤m-1)&lt;/p&gt;




&lt;p&gt;【例】已知哈希表地址区间为0～10，给定关键字序列（20，30，70，15，8，12，18，63，19）。哈希函数为H(k)=k％ll，采用线性探测法处理冲突，则将以上关键字依次存储到哈希表中。试构造出该哈希表，并求出等概率情况下的平均查找长度。&lt;br /&gt;
假设数组为A, 本题中各元素的存放过程如下：&lt;br /&gt;
H(20)=9，可直接存放到A[9]中去。&lt;br /&gt;
H(30)=8，可直接存放到A[8]中去。&lt;br /&gt;
H(70)=4，可直接存放到A[4]中去。&lt;br /&gt;
H(15)=4，冲突；&lt;br /&gt;
d0=4&lt;br /&gt;
d1=(4+1)%11=5，将15放入到A[5]中。&lt;br /&gt;
H(8)=8，冲突；&lt;br /&gt;
d0=8&lt;br /&gt;
d1=(8+1)%11=9，仍冲突；&lt;br /&gt;
d2=(8+2)%11=10，将8放入到A[10]中。&lt;/p&gt;




&lt;p&gt;在等概率情况下成功的平均查找长度为：&lt;br /&gt;
（1*5+2+3+4+6）/9 =20/9&lt;br /&gt;
利用线性探查法处理冲突容易造成关键字的&lt;code&gt;堆积&lt;/code&gt;问题。这是因为当连续n个单元被占用后，再散列到这些单元上的关键字和直接散列到后面一个空闲单元上的关键字都要占用这个空闲单元，致使该空闲单元很容易被占用，从而发生非同义冲突。造成平均查找长度的增加。&lt;br /&gt;
为了克服堆积现象的发生，可以用下面的方法替代线性探查法。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;（2）平方探查法&lt;/strong&gt;
设发生冲突的地址为d，则平方探查法的探查序列为：d+12，d+22，…直到找到一个空闲位置为止。&lt;br /&gt;
平方探查法的数学描述公式为：&lt;br /&gt;
d0=H(k)&lt;br /&gt;
di=(d0+i2) % m (1≤i≤m-1)&lt;br /&gt;
在等概率情况下成功的平均查找长度为：&lt;br /&gt;
（1*4+2*2+3+4+6）/9 =21/9&lt;br /&gt;
平方探查法是一种较好的处理冲突的方法，可以避免出现堆积问题。它的缺点是不能探查到哈希表上的所有单元，但至少能探查到一半单元。&lt;br /&gt;
例如，若表长m=13，假设在第3个位置发生冲突，则后面探查的位置依次为4、7、12、6、2、0，即可以探查到一半单元。&lt;br /&gt;
若解决冲突时，探查到一半单元仍找不到一个空闲单元。则表明此哈希表太满，需重新建立哈希表。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;2．链地址法&lt;/strong&gt;
用链地址法解决冲突的方法是：把所有关键字为同义词的记录存储在一个线性链表中，这个链表称为同义词链表。并将这些链表的表头指针放在数组中（下标从0到m-1）。这类似于图中的邻接表和树中孩子链表的结构。&lt;br /&gt;
由于在各链表中的第一个元素的查找长度为l，第二个元素的查找长度为2，依此类推。因此，在等概率情况下成功的平均查找长度为：&lt;br /&gt;
(1*5+2*2+3*l+4*1)／9=16／9&lt;/p&gt;




&lt;p&gt;虽然链地址法要多费一些存储空间，但是彻底解决了“堆积”问题，大大提高了查找效率。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;3. 再哈希法&lt;/strong&gt;：&lt;br /&gt;
Hi=R Hi(key)，&lt;br /&gt;
R Hi均是不同的哈希函数，即在同义词产生地址冲突时计算另一个哈希函数地址，直到冲突不再发生。这种方法不易产生&lt;code&gt;聚集&lt;/code&gt;，但增加了计算的时间。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;4.建立一个公共溢出区&lt;/strong&gt;
这也是处理冲突的一种方法。&lt;br /&gt;
假设哈希函数的值域为[0，m-1]，则设向量HashTable[0…m-1]为基本表，每个分量存放一个记录，另设立向量OverTable[0．．v]为溢出表。所有关键字和基本表中关键字为同义词的记录，不管它们由哈希函数得到的哈希地址是什么，一旦发生冲突，都填入溢出表。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;哈希表的查找及性能分析&lt;/strong&gt;
&lt;code&gt;哈希法&lt;/code&gt;是利用关键字进行计算后直接求出存储地址的。当哈希函数能得到均匀的地址分布时，不需要进行任何比较就可以直接找到所要查的记录。但实际上不可能完全避免冲突，因此查找时还需要进行探测比较。&lt;br /&gt;
在哈希表中，虽然冲突很难避免，但发生冲突的可能性却有大有小。这主要与三个因素有关。
&lt;strong&gt;第一:与装填因子有关&lt;/strong&gt;
所谓装填因子是指哈希表中己存入的元素个数n与哈希表的大小m的比值，即f=n/m。&lt;br /&gt;
当f越小时，发生冲突的可能性越小，越大（最大为1）时，发生冲突的可能性就越大。
&lt;strong&gt;第二:与所构造的哈希函数有关&lt;/strong&gt;
若哈希函数选择得当，就可使哈希地址尽可能均匀地分布在哈希地址空间上，从而减少冲突的发生。否则，若哈希函数选择不当，就可能使哈希地址集中于某些区域，从而加大冲突的发生。
&lt;strong&gt;第三:与解决冲突的哈希冲突函数有关&lt;/strong&gt;
哈希冲突函数选择的好坏也将减少或增加发生冲突的可能性。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;思考&lt;/strong&gt;
&lt;em&gt;哈希算法的基本思想是什么？&lt;/em&gt;
&lt;em&gt;哈希算法的存储效率主要取决于什么？&lt;/em&gt;
&lt;em&gt;哈希算法解决冲突的方式有哪些？&lt;/em&gt;&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;java 哈希表实现&lt;/strong&gt;
java中哈希表的实现有多个，比如hashtable，hashmap，currenthashmap，也有其他公司实现的，如apache的FashHashmap,google的mapmarker,high-lib的NonBlockingHashMap,其中差别是：&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;hastable&lt;/strong&gt;:线程同步，比较慢
&lt;strong&gt;hashmap&lt;/strong&gt;：线程不同步，不同步时候读写最快（但是不能保证读到最新数据），加同步修饰的时候， 读写比较慢
&lt;strong&gt;currenthashmap&lt;/strong&gt;:线程同步，默认分成16块，写入的时候只锁要写入的快，读取一般不锁块，只有读到空的时候，才锁块，性能比较高，处于hashmap同步和不同步之间。
&lt;strong&gt;fashhashmap&lt;/strong&gt;:apache collection 将HashMap封装，读取的时候copy一个新的，写入比较慢（尤其是存入比较多对象每写一次都要复制一个对象，超级慢），读取快
&lt;strong&gt;NoBlockingHashMap&lt;/strong&gt;： high_scale_lib实现写入慢，读取较快
&lt;strong&gt;MiltigetHashMap&lt;/strong&gt;，MapMaker google collection，和CurrentHashMap性能相当，功能比较全，可以设置超时，重复的可以保存成list&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;
&lt;a href=&quot;http://course.onlinesjtu.com/mod/page/view.php?id=423&quot; target=&quot;_blank&quot;&gt; http://course.onlinesjtu.com/mod/page/view.php?id=423&lt;/a&gt;
&lt;a href=&quot;http://www.cnblogs.com/bigshuai/articles/2398116.html&quot; target=&quot;_blank&quot;&gt; http://www.cnblogs.com/bigshuai/articles/2398116.html&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;扩展阅读&lt;/strong&gt;
Hash碰撞的拒绝式服务攻击 &lt;a href=&quot;http://blog.jobbole.com/11454/&quot; target=&quot;_blank&quot;&gt;http://blog.jobbole.com/11454/&lt;/a&gt;
Berkeley DB Hash、Btree、Queue、Recno选择&lt;a href=&quot; http://www.webzone8.com/article/560.html&quot; target=&quot;_blank&quot;&gt; http://www.webzone8.com/article/560.html&lt;/a&gt;
Java Hashtable &lt;a href=&quot;http://javapapers.com/core-java/java-hashtable/#&amp;amp;slider1=1&quot; target=&quot;_blank&quot;&gt;http://javapapers.com/core-java/java-hashtable/#&amp;amp;slider1=1&lt;/a&gt;
Java Hashtable分析 &lt;a href=&quot;http://kantery.iteye.com/blog/441755&quot; target=&quot;_blank&quot;&gt;http://kantery.iteye.com/blog/441755&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>如何在kettle4.2上面实现cassandra的输入与输出</title>
   <link href="http://blog.javachen.com/kettle/2012/03/23/how-to-implement-cassandra-input-and-output-in-kettle4-2"/>
   <updated>2012-03-23T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/03/23/how-to-implement-cassandra-input-and-output-in-kettle4-2</id>
   <content type="html">&lt;p&gt;这是在QQ群里有人问到的一个问题.&lt;br /&gt;
如何在pdi-ce-4.2.X-stable上面实现cassandra的输入与输出,或是实现hadoop,hbase,mapreduce,mongondb的输入输出?&lt;/p&gt;

&lt;p&gt;在kettle中实现cassandra的输入与输出有以下两种方式:&lt;br /&gt;
第一种方式:自己编写cassandra输入输出组件&lt;br /&gt;
第二种方式:使用别人编写好的插件,将其集成进来&lt;/p&gt;

&lt;p&gt;当然还有第三种方法,直接使用4.3版本的pdi.&lt;br /&gt;
第一种方法需要对cassandra很熟悉编写插件才可以做到,第二种方法可以通过拷贝pdi-ce-big-data-4.3.0-preview中的文件来完成.&lt;/p&gt;

&lt;p&gt;在pdi-ce-big-data-4.3.0-preview&lt;a href=&quot;http://ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/&quot; target=&quot;_blank&quot;&gt;(下载页面&lt;/a&gt;)版本中可以看到kettle开始支持cassandra的输入和输出.&lt;br /&gt;
故我们可以将4.3版本中的cassandra相关文件拷贝到4.2.1中.我使用的是pdi-ce-4.2.1-stable.&lt;br /&gt;
在pdi-ce-big-data-4.3.0-preview/plugins目录下有以下目录或文件:&lt;/p&gt;

&lt;pre&gt;
.
|-- databases
|-- hour-partitioner.jar
|-- jobentries
|-- kettle-gpload-plugin
|-- kettle-hl7-plugin
|-- kettle-palo-plugin
|-- pentaho-big-data-plugin
|-- repositories
|-- spoon
|-- steps
`-- versioncheck
&lt;/pre&gt;


&lt;p&gt;pentaho-big-data-plugin目录是kettle对大数据的集成与支持,我们只需要将该目录拷贝到pdi-ce-4.2.1-stable/plugins目录下即可.最后的结构如下&lt;/p&gt;

&lt;pre&gt;
.
|-- databases
|-- hour-partitioner.jar
|-- jobentries
|   `-- DummyJob
|       |-- DPL.png
|       |-- dummyjob.jar
|       `-- plugin.xml
|-- pentaho-big-data-plugin
|   |-- lib
|   |   |-- apache-cassandra-1.0.0.jar
|   |   |-- apache-cassandra-thrift-1.0.0.jar
|   |   |-- aws-java-sdk-1.0.008.jar
|   |   |-- commons-cli-1.2.jar
|   |   |-- guava-r08.jar
|   |   |-- hbase-comparators-TRUNK-SNAPSHOT.jar
|   |   |-- jline-0.9.94.jar
|   |   |-- libthrift-0.6.jar
|   |   |-- mongo-java-driver-2.7.2.jar
|   |   |-- pig-0.8.1.jar
|   |   |-- xpp3_min-1.1.4c.jar
|   |   `-- xstream-1.3.1.jar
|   `-- pentaho-big-data-plugin-TRUNK-SNAPSHOT.jar
|-- repositories
|-- spoon
|-- steps
|   |-- DummyPlugin
|   |   |-- DPL.png
|   |   |-- dummy.jar
|   |   `-- plugin.xml
|   |-- S3CsvInput
|   |   |-- jets3t-0.7.0.jar
|   |   |-- plugin.xml
|   |   |-- S3CIN.png
|   |   `-- s3csvinput.jar
|   `-- ShapeFileReader3
|       |-- plugin.xml
|       |-- SFR.png
|       `-- shapefilereader3.jar
`-- versioncheck
    |-- kettle-version-checker-0.2.0.jar
    `-- lib
        `-- pentaho-versionchecker.jar

13 directories, 29 files
&lt;/pre&gt;


&lt;p&gt;启动pdi-ce-4.2.1-stable之后,打开一个转换,在核心对象窗口就可以看到Big Data步骤目录了.&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dr9zaa66nbj.jpg&quot; target=&quot;_blank&quot;&gt;
&lt;img alt=&quot;&quot; src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dr9zaa66nbj.jpg&quot; title=&quot;pdi big data plugin in kette 4.2&quot; class=&quot;aligncenter&quot; width=&quot;600&quot; height=&quot;375&quot; /&gt;
&lt;/a&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;获取pentaho-big-data-plugin源码&lt;/strong&gt;
如果想在eclipse中查看或修改pentaho-big-data-plugin源码,该怎么做呢?&lt;br /&gt;
你可以从&lt;a href=&quot;http://ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/pentaho-big-data-plugin-TRUNK-SNAPSHOT-sources.zip&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;下载到源码,然后将src下的文件拷贝到你的pdi-ce-4.2.1-stable源码工程中.&lt;/p&gt;

&lt;p&gt;然后,需要在kettle-steps.xml中注册步骤节点&lt;br /&gt;
例如,下面是MongoDbInput步骤的注册方法,请针对不同插件的不同类路径加以修改.&lt;/p&gt;

&lt;pre&gt;
&lt;step id=&quot;MongoDbInput&quot;&gt;
&lt;description&gt;i18n:org.pentaho.di.trans.step:BaseStep.TypeLongDesc.MongoDbInput
&lt;classname&gt;org.pentaho.di.trans.steps.mongodbinput.MongoDbInputMeta
&lt;category&gt;i18n:org.pentaho.di.trans.step:BaseStep.Category.Input
&lt;tooltip&gt;i18n:org.pentaho.di.trans.step:BaseStep.TypeTooltipDesc.MongoDbInput
&lt;iconfile&gt;ui/images/mongodb-input.png
&lt;/iconfile&gt;&lt;/tooltip&gt;&lt;/category&gt;&lt;/classname&gt;&lt;/description&gt;&lt;/step&gt;
&lt;/pre&gt;




&lt;div class=&quot;note&quot;&gt;
&lt;h&gt;注意:&lt;br /&gt;
由于pdi-ce-4.2.1-stable中存在hive组件,故添加pentaho-big-data-plugin插件之后有可能会出现找不到类的情况,这是由于jar重复版本不一致导致的,按照异常信息,找到重复的jar并按情况删除一个jar包即可.
&lt;/h&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;扩展阅读:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Pentaho Big Data Plugin &lt;a href=&quot;http://wiki.pentaho.com/display/BAD/Getting+Started+for+Java+Developers&quot; target=&quot;_blank&quot;&gt;http://wiki.pentaho.com/display/BAD/Getting+Started+for+Java+Developers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;pentaho-big-data-plugin ci
&lt;a href=&quot;http://ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/&quot; target=&quot;_blank&quot;&gt;http://- - ci.pentaho.com/job/pentaho-big-data-plugin/lastSuccessfulBuild/artifact/pentaho-big-data-plugin/dist/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pentaho Community Edition (CE) downloads &lt;a href=&quot;http://wiki.pentaho.com/display/BAD/Downloads&quot; target=&quot;_blank&quot;&gt;http://wiki.pentaho.com/display/BAD/Downloads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Seam的启动过程</title>
   <link href="http://blog.javachen.com/seam/2012/02/23/the-process-of-seam-initiation"/>
   <updated>2012-02-23T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/seam/2012/02/23/the-process-of-seam-initiation</id>
   <content type="html">&lt;p&gt;了解seam2的人知道，seam是通过在web.xml中配置监听器启动的。注意，本文中的seam是指的seam2，不是seam3.&lt;/p&gt;

&lt;pre lang=&quot;xml&quot;&gt;
&lt; listener&gt;
    &lt; listener-class&gt;org.jboss.seam.servlet.SeamListener&lt; /listener-class&gt;
&lt; /listener&gt;
&lt;/pre&gt;


&lt;p&gt;该监听器会做哪些事情呢？看看Gavin King对SeamListener类的描述。&lt;/p&gt;

&lt;blockquote&gt;Drives certain Seam functionality such as initialization and cleanup of application and session contexts from the web application lifecycle.&lt;/blockquote&gt;


&lt;p&gt;从描述中可以知道
SeamListener主要完成应用以及web应用生命周期中的session上下文的初始化和清理工作。&lt;/p&gt;

&lt;p&gt;该类实现了ServletContextListener接口，在contextInitialized(ServletContextEvent event)方法内主要初始化生命周期并完成应用的初始化，在contextDestroyed(ServletContextEvent event)方法内结束应用的生命周期。
该类实现了HttpSessionListener接口，主要是用于在生命周期中开始和结束session。
&lt;strong&gt;第一步&lt;/strong&gt;，构造方法里从ServletContext获取一些路径信息：warRoot、warClassesDirectory、warLibDirectory、hotDeployDirectory。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二步&lt;/strong&gt;，扫描配置文件完成seam组件的初始化（Initialization的create方法）。
其中包括：添加命名空间、初始化组件、初始化Properties、初始化jndi信息。这一步，其实主要是读取一些配置文件,加载seam组件。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.添加命名空间&lt;/li&gt;
&lt;li&gt;2.从“/WEB-INF/components.xml”加载组件&lt;/li&gt;
&lt;li&gt;3.从“/WEB-INF/events.xml”加载组件&lt;/li&gt;
&lt;li&gt;4.从“META-INF/components.xml”加载组件&lt;/li&gt;
&lt;li&gt;5.从ServletContext初始化Properties&lt;/li&gt;
&lt;li&gt;6.从“/seam.properties”初始化Properties&lt;/li&gt;
&lt;li&gt;7.初始化jndi Properties&lt;/li&gt;
&lt;li&gt;8.从system加载Properties&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;strong&gt;第三步&lt;/strong&gt;，seam初始化过程（Initialization的init方法）。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.ServletLifecycle开始初始化&lt;/li&gt;
&lt;li&gt;2.设置Application上下文&lt;/li&gt;
&lt;li&gt;3.添加Init组件&lt;/li&gt;
&lt;li&gt;4.通过standardDeploymentStrategy的注解和xml组件扫描组件&lt;/li&gt;
&lt;li&gt;5.判断jbpm是否安装&lt;/li&gt;
&lt;li&gt;6.检查默认拦截器&lt;/li&gt;
&lt;li&gt;7.添加特别组件&lt;/li&gt;
&lt;li&gt;8.添加war root部署、热部署&lt;/li&gt;
&lt;li&gt;9.安装组件&lt;/li&gt;
&lt;li&gt;10.导入命名空间&lt;/li&gt;
&lt;li&gt;11.ServletLifecycle结束初始化。启动生命周期为APPLICATION的组件。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;如果组件标注为startup，则会构造其实例进行初始化。例如seam于Hibernate的集成，就可以通过此方法初始化Hibernate，对应的组件类为org.jboss.seam.persistence.HibernateSessionFactory。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kettle运行作业之前的初始化过程</title>
   <link href="http://blog.javachen.com/kettle/2012/02/22/the-init-process-before-job-execution"/>
   <updated>2012-02-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/02/22/the-init-process-before-job-execution</id>
   <content type="html">&lt;p&gt;本文主要描述Kettle是如何通过GUI调用代码启动线程执行作业的。&lt;/p&gt;

&lt;p&gt;之前用英文写了一篇文章《&lt;a href=&quot;http://www.javachen.com/2012/02/the-execution-process-of-kettles-job/&quot; target=&quot;_blank&quot;&gt;The execution process of kettle’s job&lt;/a&gt;》 ，这篇文章只是用于英语写技术博客的一个尝试。由于很久没有使用英语写作了，故那篇文章只是简单的通过UML的序列图描述kettle运行job的一个java类调用过程。将上篇文章的序列图和这篇文章联系起来，会更加容易理解本文。&lt;/p&gt;

&lt;p&gt;在Spoon界面点击运行按钮，Spoon GUI会调用Spoon.runFile()方法，这可以从xul文件（ui/menubar.xul）中的描述看出来。关于kettle中的xul的使用，不是本文重点故不在此说明。&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;
public void runFile() {
    executeFile(true, false, false, false, false, null, false);
}

public void executeFile(boolean local, boolean remote, boolean cluster,
        boolean preview, boolean debug, Date replayDate, boolean safe) {
    TransMeta transMeta = getActiveTransformation();
    if (transMeta != null)
        executeTransformation(transMeta, local, remote, cluster, preview,
                debug, replayDate, safe);

    JobMeta jobMeta = getActiveJob();
    if (jobMeta != null)
        executeJob(jobMeta, local, remote, replayDate, safe, null, 0);
}

public void executeJob(JobMeta jobMeta, boolean local, boolean remote,
        Date replayDate, boolean safe, String startCopyName, int startCopyNr) {
    try {
        delegates.jobs.executeJob(jobMeta, local, remote, replayDate, safe,
                startCopyName, startCopyNr);
    } catch (Exception e) {
        new ErrorDialog(shell, &quot;Execute job&quot;,
                &quot;There was an error during job execution&quot;, e);
    }
}
&lt;/pre&gt;


&lt;p&gt;runFile()方法内部调用executeFile()方法，executeFile方法有以下几个参数：
- local：是否本地运行
- remote：是否远程运行
- cluster：是否集群环境运行
- preview：是否预览
- debug：是否调试
- replayDate：回放时间
- safe：是否安全模式&lt;/p&gt;

&lt;p&gt;executeFile方法会先获取当前激活的转换，如果获取结果不为空，则执行该转换；否则获取当前激活的作业，执行该作业。 本文主要讨论作业的执行过程，关于转换的执行过程，之后单独一篇文章进行讨论。&lt;/p&gt;

&lt;p&gt;executeJob委托SpoonJobDelegate执行其内部的executeJob方法，注意，其将JobMeta传递给了executeJob方法。SpoonJobDelegate还保存着对Spoon的引用。&lt;/p&gt;

&lt;p&gt;SpoonJobDelegate的executeJob方法主要完成以下操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.设置Spoon的执行配置JobExecutionConfiguration类，该类设置变量、仓库、是否执行安全模式、日志等级等等。&lt;/li&gt;
&lt;li&gt;2.获得当前Job对应的图形类JobGraph。&lt;/li&gt;
&lt;li&gt;3.将执行配置类JobExecutionConfiguration的变量、参数、命令行参数设置给jobMeta。&lt;/li&gt;
&lt;li&gt;4.如果本地执行，则调用jobGraph.startJob(executionConfiguration)，如果远程执行，则委托给SpoonSlaveDelegate执行。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;JobExecutionConfiguration类是保存job执行过程中的一些配置，该类会在Spoon、JobGraph类之间传递。&lt;/p&gt;

&lt;p&gt;本文只讨论本地执行的情况，故往下查看jobGraph.startJob(executionConfiguration)方法。该方法被synchronized关键字修饰。&lt;/p&gt;

&lt;p&gt;JobGraph类包含当前Spoon类的引用、以及对Job的引用。初始情况，Job的引用应该为null。该类会做以下操作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1.如果job为空或者没有运行或者没有激活，则先保存，然后往下执行作业。&lt;/li&gt;
&lt;li&gt;2.在仓库不为空的时候，通过仓库加载Job获得一个运行时的JobMeta对象，名称为runJobMeta；否则，通过文件名称直接new一个JobMeta对象，名称也为runJobMeta。&lt;/li&gt;
&lt;li&gt;3.通过仓库和runJobMeta对象构建一个Job对象，并将jobMeta对象（此对象通过JobGraph构造方法传入）的变量、参数共享给Job对象。&lt;/li&gt;
&lt;li&gt;4.Job对象添加JobEntry监听器、Job监听器。&lt;/li&gt;
&lt;li&gt;5.调用Job的start方法，启动线程开始执行一个job。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Job继承自Thread类，该类的run方法内部会递归执行该作业内部的作业项，限于篇幅，本文不做深究。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The execution process of kettle’s job</title>
   <link href="http://blog.javachen.com/kettle/2012/02/21/the-execution-process-of-kettles-job"/>
   <updated>2012-02-21T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/02/21/the-execution-process-of-kettles-job</id>
   <content type="html">&lt;p&gt;How to execute a kettle job in Spoon GUI or command line after we create a job in Spoon GUI? In Spoon GUI,the main class is &quot;org.pentaho.di.ui.spoon.Spoon.java&quot;.This class handles the main window of the Spoon graphical transformation editor.Many operations about a job or transformation such as run,debug,preview,zoomIn,etc,are all in this class.This post just writes about the code execution process.&lt;/p&gt;




&lt;p&gt;When we start a job or transformation,Spoon invokes the method runFile(),and then is distributed to executeTransformation() or executeJob().At now,we mainly study about executeJob() method.&lt;/p&gt;




&lt;p&gt;This is a simple sequence diagram below.It contains several classes for Starting to execute a job using execute(int nr, Result result) in Job.java.We can see the relation of these classes from it.&lt;/p&gt;




&lt;p&gt;&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://www.javachen.com/wp-content/uploads/2012/02/spoon-execute-sequence.jpg&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;http://www.javachen.com/wp-content/uploads/2012/02/spoon-execute-sequence-300x180.jpg&quot; alt=&quot;&quot; title=&quot;spoon execute sequence&quot; width=&quot;300&quot; height=&quot;180&quot; class=&quot;aligncenter size-medium wp-image-2511&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;




&lt;p&gt;What is the detail process of job execution? You should look into the Job.run() method for detail information.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>kettle中定义错误处理</title>
   <link href="http://blog.javachen.com/kettle/2012/02/17/step-error-handling-in-kettle"/>
   <updated>2012-02-17T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/02/17/step-error-handling-in-kettle</id>
   <content type="html">&lt;p&gt;在kettle执行的过程中，如果遇到错误，kettle会停止运行。在某些时候，并不希望kettle停止运行，这时候可以使用错误处理（Step Error Handling）。错误处理允许你配置一个步骤来取代出现错误时停止运行一个转换，出现错误的记录行将会传递给另一个步骤。在Step error handling settings对话框里，需要设置启用错误处理。&lt;/p&gt;

&lt;p&gt;下面例子中读取postgres数据库中的a0表数据，然后输出到a1表：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img alt=&quot;&quot; src=&quot;http://ww2.sinaimg.cn/mw600/48e24b4cjw1dq56wck3m7j.jpg&quot; class=&quot;alignnone&quot; width=&quot;600&quot; height=&quot;172&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;a1表结构如下：&lt;/p&gt;

&lt;pre lang=&quot;sql&quot;&gt;
CREATE TABLE a1
(
  a double precision,
  id integer NOT NULL,
  CONSTRAINT id_pk PRIMARY KEY (id ),
  CONSTRAINT id_unin UNIQUE (id )
)
&lt;/pre&gt;


&lt;p&gt;从表结构可以看出，a1表中id为主键、唯一。&lt;/p&gt;

&lt;p&gt;a0表数据预览：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img alt=&quot;&quot; src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dq56wcr6c2j.jpg&quot; class=&quot;alignnone&quot; width=&quot;553&quot; height=&quot;403&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;现在a1表数据为空，执行上面的转换，执行成功之后，a1表数据和a0表数据一致。
再次执行，上面的转换会报错，程序停止运行，会报主键重复的异常。&lt;/p&gt;

&lt;p&gt;现在，我想报错之后，程序继续往下执行，并记录错误的记录的相关信息，这时候可以使用“定义错误处理”的功能。
在“表输出”的步骤上右键选择“定义错误处理”，弹出如下对话框。&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww3.sinaimg.cn/mw600/48e24b4cjw1dq56wd5ckwj.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;相关字段说明：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;目标步骤：指定处理错误的步骤&lt;/li&gt;
&lt;li&gt;启用错误处理？：设置是否启用错误处理&lt;/li&gt;
&lt;li&gt;错误数列名：出错的记录个数&lt;/li&gt;
&lt;li&gt;错误描述列名：描述错误信息的列名称&lt;/li&gt;
&lt;li&gt;错误列的列名：出错列的名称&lt;/li&gt;
&lt;li&gt;错误编码列名：描述错误的代码的列名&lt;/li&gt;
&lt;li&gt;允许的最大错误数：允许的最大错误数，超过此数，不在处理错误&lt;/li&gt;
&lt;li&gt;允许的最大错误百分比：&lt;/li&gt;
&lt;li&gt;在计算百分百前最少要读入的行数：&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;添加错误处理后的转换如下：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dq56wdntipj.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;记录错误信息的字段列表如下，可以看出，errorNum、errorDesc、errorName、errorCode都是在定义错误处理时候填入的列名称，a、id来自于输入的记录的列。&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww2.sinaimg.cn/mw600/48e24b4cjw1dq56wdvk6uj.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;记录的错误信息如下：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;http://ww4.sinaimg.cn/mw600/48e24b4cjw1dq56we2sn2j.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;分析&lt;/strong&gt;
可以看到,错误日志里只是记录了出错的行里面的信息，并没有记录当前行所在的表名称以及执行时间等等，如果能够对此进行扩展，则该错误日志表才能更有实际意义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;
1.错误日志的错误码含义（如：TOP001）含义见参考文章2.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考文章&lt;/strong&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.pentaho.com/display/EAI/.09+Transformation+Steps#.09TransformationSteps-StepErrorHandling&quot; target=&quot;_blank&quot;&gt;Step Error Handling&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.pentaho.com/display/COM/Step+error+handling+codes&quot; target=&quot;_blank&quot;&gt;Step error handling codes&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>JSF中EL表达式之this扩展</title>
   <link href="http://blog.javachen.com/jsf/2012/02/14/this-expression-of-jsf-el"/>
   <updated>2012-02-14T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/jsf/2012/02/14/this-expression-of-jsf-el</id>
   <content type="html">&lt;p&gt;本篇文章来自以前公司的一套jsf+seam+Hibernate的一套框架，其对jsf进行了一些改进，其中包括:EL表达式中添加this，通过jsf的渲染实现权限控制到按钮等等。JSF表达式中添加this，主要是为了在facelets页面使用this关键字引用（JSF自动查找）到当前页面对应的pojo类，详细说明见下午。因为，本文的文章是公司同事整理的，本文作者仅仅是将其分享出来，供大家参考思路，如果有什么不妥的话，请告知。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EL表达式this扩展&lt;/strong&gt;
在业务系统中，大量页面具有大量区域是相似或者相同的，或者可能根据某些局部特征的变化具有一定的变化，jsf中通过facelet模板功能可以达到一定程度的页面重用，从而减轻开发人员编辑和拷贝一些页面代码，达到重用的目的。然而，她们具有如下限制：
1.Java语言作为一种典型的OO语言，通过抽象、继承等功能，可以大量重用已经实现或者在父类中已经存在的属性和方法等。模板技术作为一种静态加载和内容替换，无法充分利用面向对象的继承功能
2.由于Jsf/jsp框架采用视图和动作分离的模型，多个相似功能在不同的页面实现中由于页面对应点动作类不同因而必须使用复制的方法；
3.模板中使用EL表达式与后台动作类交互，这种交互是基于绝对名称的，不同的网页对应的动作类是完全不同的，因此很难重用和利用面向对象的特征。&lt;/p&gt;

&lt;p&gt;我们需要一种新的功能，实现：
1.模板的应用特种可以参照OO的继承特种，即模板的对模板的引用可以看成一种继承，这种继承可以和java的OO是一致的
2.多个页面和多个独立java后台程序相同部分完全可以抽离出来，不依赖它们是否继承关系、只需保证他们具有相同的属性或者方法
3.动态映射功能，即在满足上述基础上可以实现页面和后台实现类的属性和方法的自动映射
4.兼容标准的EL表达式&lt;/p&gt;

&lt;p&gt;我们将上述功能处理为“this”表达式。其功能模型为：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/02/this-expression-of-el.jpg&quot;&gt;&lt;img src=&quot;http://blog.javachen.com/files/2012/02/this-expression-of-el-300x168.jpg&quot; alt=&quot;&quot; title=&quot;this expression of el&quot; width=&quot;300&quot; height=&quot;168&quot; class=&quot;aligncenter size-medium wp-image-2496&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;


&lt;p&gt;页面A和页面B分别引用了通用功能T,内含this相关的El表达式，通过分析处理，分别映射到对应的页面动作类的属性A.name和B.name。A和B可以从相同的基类C派生而来，只需C类实现了name属性即可，A类和B类也可以毫不相关，但是它们具有相同的属性name。&lt;/p&gt;

&lt;!--more--&gt;


&lt;p&gt;&lt;strong&gt;动作类和页面的一致性保证&lt;/strong&gt;
为了有效实现this表达式，我们实现如下映射规则：
1.名称为小写方式，不管页面如何命名，对应的后台类的jsf标识符都转换为小写
2.页面和相应的后台类以相同命名方式，页面的目录转化为后台类的包名，名称通过点分隔包名，如根目录的a.xhtml对应的后台类名称为A.java，其唯一jsf标识名称为“a”，test/b.xhtml的后台类为test/B.java，其唯一jsf标识为“test.b”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“this”EL表达式算法&lt;/strong&gt;
算法流程如下图：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/02/this-expression-flow-of-el.jpg&quot;&gt;&lt;img src=&quot;http://blog.javachen.com/files/2012/02/this-expression-flow-of-el-300x226.jpg&quot; alt=&quot;&quot; title=&quot;this expression flow of el&quot; width=&quot;300&quot; height=&quot;226&quot; class=&quot;aligncenter size-medium wp-image-2497&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Ext读取xml文件生成动态表格和表单(续)</title>
   <link href="http://blog.javachen.com/extjs/2012/01/31/ext_readxml_in_bjsasc_wuzi_continue"/>
   <updated>2012-01-31T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/extjs/2012/01/31/ext_readxml_in_bjsasc_wuzi_continue</id>
   <content type="html">&lt;p&gt;很多人向我要《&lt;a href=&quot;http://blog.javachen.com/2009/10/ext_readxml_in_bjsasc_wuzi&quot; target=&quot;_blank&quot;&gt;Ext读取xml文件生成动态表格和表单&lt;/a&gt;》一文的源代码，故花了些时间将源代码整理出来，并重新编写此文，分享当时的技术思路。&lt;/p&gt;

&lt;p&gt;《Ext读取xml文件生成动态表格和表单》一文需要的文件有：
1.html文件，此处以SASC.search.MtrUse.html为例
2.Extjs相关文件,见SASC.search.MtrUse.html文件中的引用
3.工具类，DomUtils.js
4.核心js类:SASC.extjs.search.MtrUse.js
5.java代码&lt;/p&gt;

&lt;p&gt;详细html和js代码见相关文件，这里先描述思路。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;首先&lt;/strong&gt;
通过一个事件打开一个弹出窗口，该窗口的url指向SASC.search.MtrUse.html文件，并附带参数xmlFile，xmlFile的值为xml文件名称，其存于服务器的某一路径下面。如：“../SASC.search.MtrUse.html?xmlFile=PC_MTRREPLACE_IMP.xml” .PC_MTRREPLACE_IMP.xml文件的放置路径见DomUtils.js文件中的说明。&lt;/p&gt;

&lt;p&gt;在这里，前台会读取该xml生成ext界面，后天会从xml文件读取sql语句等信息，详细信息见java代码。
进入SASC.search.MtrUse.html页面，执行ext的初始化方法时，会先通过当前页面的url中获取xmlFile参数的值（调用getForwardXmlUrl(getQsValue('xmlFile'))），得到xml文件的服务器路径，然后通过javascript的解析该xml文件，渲染出ext界面,这部分代码见SASC.extjs.search.MtrUse.js文件内的initStoreData(xmlObj) 方法。
需要说明的是，xml文件是按照一定规律编写的，详细的参考xml文件内容，以及解析xml文件的相关方法。你可以重新定义该xml的结构，然后修改解析xml文件的方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;然后&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;初始化完ext界面之后，会获取表格数据，这部分使用了struts，这不是本文重点，故不做介绍。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最后&lt;/strong&gt;
相关文件打包见：
&lt;a href=&quot;http://vdisk.weibo.com/s/2enQS&quot; target=&quot;_blank&quot;&gt;http://vdisk.weibo.com/s/2enQS&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;说明&lt;/strong&gt;
如果还有什么不懂，欢迎email：javachen.june#gmail.com&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>使用kettle数据迁移添加主键和索引</title>
   <link href="http://blog.javachen.com/kettle/2012/01/05/add-primary-keys-and-indexes-when-migrating-datas-whith-kettle"/>
   <updated>2012-01-05T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/01/05/add-primary-keys-and-indexes-when-migrating-datas-whith-kettle</id>
   <content type="html">&lt;p&gt;Kettle是一款国外开源的etl工具，纯java编写，绿色无需安装，主要用于&lt;strong&gt;数据抽取、转换、装载&lt;/strong&gt;。kettle兼容了市面上几十种数据库，故用kettle来做数据库的迁移视乎是个不错的选择。&lt;/p&gt;

&lt;p&gt;kettle的数据抽取主要在于抽取数据，而没有考虑数据库的&lt;strong&gt;函数、存储过程、视图、表结构以及索引、约束&lt;/strong&gt;等等，而这些东西恰恰都是数据迁移需要考虑的事情。当然，如果在不考虑数据库中的函数、存储过程、视图的情况下，使用kettle进行数据的迁移还算是一个可行的方案。&lt;/p&gt;

&lt;p&gt;这篇文章主要是讲述在使用kettle进行数据库的迁移的时候如何迁移主键和索引，为什么要迁移主键和索引？异构数据库之间的迁移很难无缝的实现自定义函数、存储过程、视图、表结构、索引、约束以及数据的迁移，所以多数情况下只需要异构数据库之间类型兼容、数据一致就可以了。但是在有些情况下需要对输出表进行查询以及数据比对的时候，&lt;strong&gt;需要有主键和索引方便对比和加快查询速度&lt;/strong&gt;。
先来看看kettle中的一些组件。&lt;/p&gt;

&lt;p&gt;下图是kettle中的一个表输出组件。&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/01/kettle-table-out.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2480 aligncenter&quot; title=&quot;kettle-table-out&quot; src=&quot;http://blog.javachen.com/files/2012/01/kettle-table-out-269x300.png&quot; alt=&quot;kettle中的表输出组件&quot; width=&quot;269&quot; height=&quot;300&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;


&lt;p&gt;在该组件里可以指定表名、字段等信息，并且还可以建表的sql语句。打开建表的sql语句，你可以看到该语句里只指定了字段名称和类型，没有指定主外键、约束、和索引。显然，该组件只是完成了数据的输出并没有将表的主键迁移过去。&lt;/p&gt;

&lt;!--more--&gt;


&lt;p&gt;下图是kettle中纬度更新/查询的组件。&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/01/kettle-look-up.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2481 aligncenter&quot; title=&quot;kettle-look-up&quot; src=&quot;http://blog.javachen.com/files/2012/01/kettle-look-up-292x300.png&quot; alt=&quot;kettle中纬度更新/查询的组件&quot; width=&quot;292&quot; height=&quot;300&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;


&lt;p&gt;该组件可以指定输出表名、映射字段、纬度字段、并且指定主键（图中翻译为关键字段），该组件比表输出组件多了一个功能，即指定主键。
从上面两个组件中可以看出，kettle实际上预留了设置主键的接口，具体的接口说明需要查看api或者源代码，只是kettle没有智能的查处输入表的主键字段，而是需要用户在kettle ui界面指定一个主键名称。&lt;/p&gt;

&lt;p&gt;如果现在想使用kettle实现&lt;strong&gt;异构数据库的数据以及主键和索引的迁移&lt;/strong&gt;，有没有一个完整方便的解决方案呢？我能想到的解决方案如下：
&lt;strong&gt;1.&lt;/strong&gt;使用kettle向导中的多表复制菜单进行数据库的迁移，这只能实现数据的迁移还需要额外的方法添加主键和索引，你可以手动执行一些脚步添加约束。
&lt;strong&gt;2.&lt;/strong&gt;针对源数据库中的每一张表创建一个转换，转换中使用纬度更新/查询组件，在该主键中指定主键。创建完所有的转换之后，创建一个作业将这些转换串联起来即可。
&lt;strong&gt;3.&lt;/strong&gt;扩展kettle向导中的多表复制菜单里的功能，在该功能创建的作业中添加一些节点用于添加输出表的主键和索引。这些节点可以是执行sql语句的主键，故只需要通过jdbc代码获取添加主键和索引的sql语句。&lt;/p&gt;

&lt;p&gt;方案1需要单独执行脚步实现添加主键和索引，创建或生成这些脚步需要些时间；方案2需要针对每个表认为的指定主键，工作量大，而且无法实现添加索引；方案3最容易实现和扩展。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;下面是方案3的具体的实现。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先需要在每一个表的建表语句节点和复制数据节点之后添加一个执行sql语句的节点，该节点用于添加主键和索引。
多表复制向导的核心代码在src-db/org.pentaho.di.ui.spoon.delegates.SpoonJobDelegate.java的public void ripDBWizard()方法中。该方法如下：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;public void ripDBWizard(final int no) {
    final List databases = spoon.getActiveDatabases();
    if (databases.size() == 0)
        return;&lt;/pre&gt;


&lt;pre&gt;&lt;code&gt;final RipDatabaseWizardPage1 page1 = new RipDatabaseWizardPage1(&quot;1&quot;,
        databases);
final RipDatabaseWizardPage2 page2 = new RipDatabaseWizardPage2(&quot;2&quot;);
final RipDatabaseWizardPage3 page3 = new RipDatabaseWizardPage3(&quot;3&quot;,
        spoon.getRepository());
Wizard wizard = new Wizard() {
    public boolean performFinish() {
        try {
            JobMeta jobMeta = ripDBByNo(no, databases,
                page3.getJobname(), page3.getRepositoryDirectory(),
                page3.getDirectory(), page1.getSourceDatabase(),
                page1.getTargetDatabase(), page2.getSelection());

            if (jobMeta == null)
                return false;

            if (page3.getRepositoryDirectory() != null) {
                spoon.saveToRepository(jobMeta, false);
            } else {
                spoon.saveToFile(jobMeta);
            }

            addJobGraph(jobMeta);
            return true;
        } catch (Exception e) {
            new ErrorDialog(spoon.getShell(), &quot;Error&quot;,
                    &quot;An unexpected error occurred!&quot;, e);
            return false;
        }
    }

    public boolean canFinish() {
        return page3.canFinish();
    }
};

wizard.addPage(page1);
wizard.addPage(page2);
wizard.addPage(page3);

WizardDialog wd = new WizardDialog(spoon.getShell(), wizard);
WizardDialog.setDefaultImage(GUIResource.getInstance().getImageWizard());
wd.setMinimumPageSize(700, 400);
wd.updateSize();
wd.open();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
该方法主要是创建一个向导，该向导中包括三个向导页，第一个向导页用于&lt;strong&gt;选择数据库连接&lt;/strong&gt;：源数据库和目标数据库连接；第二个向导页用于&lt;strong&gt;选表&lt;/strong&gt;；第三个向导页用于&lt;strong&gt;指定作业保存路径&lt;/strong&gt;。在向导完成的时候，即performFinish()方法里，会根据选择的数据源和表生成一个作业，即JobMeta对象。
创建Jobmeta的方法为：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;public JobMeta ripDB(final List databases,final String jobname, final
    RepositoryDirectoryInterface repdir,final String directory, final DatabaseMeta
    sourceDbInfo,final DatabaseMeta targetDbInfo, final String[] tables){
 //此处省略若干代码
}&lt;/pre&gt;


&lt;p&gt;该方法主要逻辑在下面代码内：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;IRunnableWithProgress op = new IRunnableWithProgress() {
    public void run(IProgressMonitor monitor)
     throws InvocationTargetException, InterruptedException {
           //此处省略若干代码
        }
}&lt;/pre&gt;


&lt;p&gt;上面代码中有以下代码用于遍历所选择的表生成作业中的一些节点：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;for (int i = 0; i &amp;lt; tables.length &amp;amp;&amp;amp; !monitor.isCanceled(); i++) {
    //此处省略若干代码
}&lt;/pre&gt;


&lt;p&gt;针对每一张表先会创建一个JobEntrySQL节点，然后创建一个转换JobEntryTrans，可以在创建转换之后再创建一个JobEntrySQL节点，该节点用于添加主键和索引。
这部分的代码如下：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;String pksql = JdbcDataMetaUtil.exportPkAndIndex(
        sourceDbInfo, sourceCon, tables[i],
        targetDbInfo, targetCon, tables[i]);

if (!Const.isEmpty(pksql)) {
    location.x += 300;
    JobEntrySQL jesql = new JobEntrySQL(
        BaseMessages.getString(PKG,&quot;Spoon.RipDB.AddPkAndIndex&quot;)
            + tables[i] + &quot;]&quot;);
    jesql.setDatabase(targetDbInfo);
    jesql.setSQL(pksql);
    jesql.setDescription(BaseMessages.getString(PKG,
            &quot;Spoon.RipDB.AddPkAndIndex&quot;)
            + tables[i]
            + &quot;]&quot;);

    JobEntryCopy jecsql = new JobEntryCopy();
    jecsql.setEntry(jesql);
    jecsql.setLocation(new Point(location.x, location.y));
    jecsql.setDrawn();
    jobMeta.addJobEntry(jecsql);

    // Add the hop too...
    JobHopMeta jhi = new JobHopMeta(previous, jecsql);
    jobMeta.addJobHop(jhi);
    previous = jecsql;
}
&lt;/pre&gt;


&lt;p&gt;获取添加主键和索引的sql语句，主要是采用jdbc的方式读取两个数据库，判断源数据库的表中是否存在主键和索引，如果有则返回添加主键或索引的sql语句。这部分代码封装在JdbcDataMetaUtil类中。
该代码见：&lt;a href=&quot;https://gist.github.com/1564353.js&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/1564353.js&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最后的效果图如下：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;a href=&quot;http://blog.javachen.com/files/2012/01/kettle-add-primary-key-and-indexes.png&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-2483&quot; title=&quot;kettle-add-primary-key-and-indexes&quot; src=&quot;http://blog.javachen.com/files/2012/01/kettle-add-primary-key-and-indexes-300x79.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;79&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;




&lt;div class=&quot;infor&quot;&gt;说明：
1.以上代码使用的是jdbc的方法获取主键或索引，不同的数据库的jdbc驱动实现可能不同而且不同数据库的语法可能不同，故上面代码可能有待完善。
2.如果一个数据库中存在多库并且这多个库中有相同的表，使用上面的代码针对一个表名会查出多个主键或索引。这一点也是可以改善的&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>kettle进行数据迁移遇到的问题</title>
   <link href="http://blog.javachen.com/kettle/2012/01/04/some-problems-about-migrating-database-datas-with-kettle"/>
   <updated>2012-01-04T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/kettle/2012/01/04/some-problems-about-migrating-database-datas-with-kettle</id>
   <content type="html">&lt;p&gt;使用kettle进行oracle或db2数据导入到mysql或postgres数据库过程中遇到以下问题，以下只是一个简单描述，详细的说明以及所做的代码修改没有提及。下面所提到的最新的pdi程序是我修改kettle源码并编译之后的版本。&lt;/p&gt;

&lt;h4&gt;同时运行两个pdi程序，例如：一个为oracle到mysql，另一个为oracle到postgres，其中一个停止运行&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：从oracle迁移到mysql创建的作业和转换文件和oracle到postgres的作业和转换保存到一个路径，导致同名称的转换相互之间被覆盖，故在运行时候会出现混乱。&lt;/li&gt;
&lt;li&gt;解决办法：将新建的作业和转换分别保存在两个不同的路径，最好是新建两个不同路径的仓库，关于如何新建仓库，请参考《kettle使用说明》文档。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;关键字的问题。&lt;/h4&gt;

&lt;p&gt;Oracle初始化到mysql，关键字前面会加上前缀“MY_”。如果在建表的时候出现错误，则需要检查表的字段中是否有关键字。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;解决办法：出差的表单独进行处理，新建一个转换，实现关键字段该名称然后初始化出错的表。具体操作参见文档。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;oracle中的字段名从中可以有#号，但是到mysql会报错&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;解决办法：字段改名称，去掉#号&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Db2初始化到mysql或是postgres出错&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：1）db2数据库连接用户没有权限访问出错的表；2）出错的表名存在小写字母&lt;/li&gt;
&lt;li&gt;解决办法：使用更新后的pdi程序，更新后的程序会将db2的表名使用双引号括起来。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Oracle到mysql和pg时日期类型数据值有偏差&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：从oracle中读取日期类型的数据时候，读取结果与oracle数据库中的数据已经存在偏差。少数记录使用oracle10g的驱动读取数据少一个小时，用oracle11g的驱动会多一个小时，该问题尚待oracle工程师给出解决方案。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;主键从ORACLE导入不到MYSQL和POSTGRES&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：pdi程序中没有对主键进行处理&lt;/li&gt;
&lt;li&gt;解决办法：使用更新的pdi程序，执行Tools####Wizzard####Copy Tables Extension...功能添加主键；执行Tools####Wizzard####Copy Tables Data Only...功能可以只复制数据&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Oracle中存在ascii字符导入到postgres时候报错：ERROR: invalid byte sequence for encoding &quot;UTF8&quot;: 0x00&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：PostgreSQL内部采用C语言风格的字符串（以0x00）表示结尾，因而不允许字符串中包括0x00，建议在转换时先对字符串类型的数据进行清洗，也就是增加一个节点用于删除字符串数据中的特殊字符0x00。&lt;/li&gt;
&lt;li&gt;解决办法:使用新的pdi程序。在kettle的DataBase类中修改PreparedStatement.setString(int index,String value)方法传入的参数，将value的值trim之后在setString&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;异构数据库之间的类型兼容问题。日期类型和时间类型的数据初始化到mysql或postgres中都为时间类型的数据，导致数据对比时候数据不一致。&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：Pdi程序中的类型转换采用的是向上兼容的方式，故日期和时间类型都转换为时间类型数据。&lt;/li&gt;
&lt;li&gt;解决办法：针对与db2数据初始化到mysql和postgres，该问题在最新的pdi程序中已经处理。因为oracle中的日期类型字段既可以存日期又可以存时间，故没针对oracle数据做出处理。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Db2中没有主键的数据初始化到mysql和postgres需要添加索引&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;解决办法：使用最新的pdi程序，最新的pdi程序会添加主键和索引。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Db2中decimal（n,m）类型的数据初始化到postgres数据库被四舍五入。&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：Db2中decimal（n,m）类型的数据初始化到postgres中的类型不对。&lt;/li&gt;
&lt;li&gt;解决办法：使用最新的pdi程序。&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;导数据中途时没有报错，直接软件退出&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：1）jvm内存溢出，需要修改jvm参数；2）pdi程序报swt错误&lt;/li&gt;
&lt;li&gt;解决办法：修改jvm参数&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;初次使用kettle做db2的初始化会报错&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;原因：kettle中的db2的jdbc驱动与使用的db2版本不对应。&lt;/li&gt;
&lt;li&gt;解决办法：从db2的安装目录下拷贝jdbc驱动到kettle目录（libext/JDBC）下&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Mondrian and OLAP</title>
   <link href="http://blog.javachen.com/mondrian/2011/12/07/mondrian-and-olap"/>
   <updated>2011-12-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/mondrian/2011/12/07/mondrian-and-olap</id>
   <content type="html">&lt;p&gt;Mondrian是一个用Java编写的OLAP引擎。他执行用MDX语言编写的查询，从关系数据库（RDBMS）中读取数据并且通过Java API以多维度的格式展示查询结果。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #00ff00;&quot;&gt;Online Analytical Processing&lt;/span&gt;&lt;/strong&gt;
联机分析处理（OLAP）指在线实时的分析大量数据。与联机事务处理系统（On-&lt;wbr&gt;Line Transaction Processing，简称OLTP）不同，OLTP中典型的操作如读和修改单个的少量的记录，而OLAP批量处理数据并且所有操作都是只读的。“online”意味着即使是处理大量的数据----百万条数据记录，占有几个GB内存----系统必须足够快的反回查询结果以允许数据的交互式响应。正如我们将看到，数据展示面临相当大的技术挑战。&lt;/wbr&gt;&lt;/p&gt;




&lt;p&gt;OLAP引入了一种多维度查询的技术。鉴于一个关系数据库以行和列的形式存储所有数据，一个多维数据集包括轴和列。考虑下面的数据集：&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;/file/2011/12/olap_examples20111217.jpg&quot;&gt;&lt;img class=&quot;size-medium wp-image-2469 aligncenter&quot; title=&quot;olap_examples20111217&quot; src=&quot;/file/2011/12/olap_examples20111217-300x129.jpg&quot; alt=&quot;olap多维视图&quot; width=&quot;300&quot; height=&quot;129&quot; /&gt;&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;行轴包括&quot;All products&quot;, &quot;Books&quot;,&quot;Fiction&quot;等等，并且列轴包括生产年份&quot;2000&quot;”和&quot;2001&quot;、&quot;Growth&quot;的计算值以及&quot;Unit sales&quot;和&quot;Dollar sales&quot;的测量值。每个单元代表在某一年的一个产品类别的销售额，例如2001年Magazines的$销售额是2426美元。&lt;/p&gt;




&lt;p&gt;这是一个比关系型数据库展现出来的更加丰富的视图。多维数据集的只不是永远都来自于一个关系数据库的列。 'Total', 'Books' and 'Fiction' 是一个具有层次结构连续的成员，每一个成员都包括其下一层的成员。即使是在&quot;2000&quot;和&quot;2001&quot;一行，&quot;Growth&quot;是一个计算出来的值，它引入一个公式从其他列计算当前列的值。&lt;/p&gt;




&lt;p&gt;该例中使用的维度有：产品、生产线和测量值，仅仅是这个数据集可以分类和过滤的许多维度中的三个。维度，层次结构和测量值的集合被称为一个立方体。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #00ff00;&quot;&gt;结论&lt;/span&gt;&lt;/strong&gt;
我希望我已经证明垛位是一个首选的数据显示方式。虽然一些多维数据库以多维度的格式存储数据库，我仍然认为这比以关系的格式存储数据要简单。&lt;br /&gt;
现在，你可以看看OLAP系统的架构。查看Mondrian architecture。http://mondrian.pentaho.com/documentation/architecture.php&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #00ff00;&quot;&gt;说明&lt;/span&gt;&lt;/strong&gt;
&lt;div class=&quot;note&quot;&gt;
这是一篇翻译，原文来自http://mondrian.pentaho.com/documentation/olap.php。翻译水平有限，难免翻译不当，请见谅。&lt;/div&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>XUL 用户界面语言介绍</title>
   <link href="http://blog.javachen.com/xml/2011/11/25/xml-user-interface-language-introuction"/>
   <updated>2011-11-25T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/xml/2011/11/25/xml-user-interface-language-introuction</id>
   <content type="html">&lt;p&gt;XUL[1]是英文“&lt;span style=&quot;color: #339966;&quot;&gt;XML User Interface Language&lt;/span&gt;”的首字母缩写。它是为了支持Mozilla系列的应用程序（如Mozilla Firefox和Mozilla Thunderbird）而开发的用户界面标示语言。顾名思义，它是一种应用XML来描述用户界面的标示语言。&lt;br /&gt;
XUL是开放标准，重用了许多现有的标准和技术[2]，包括CSS、JavaScript、DTD和RDF等。所以对于有网络编程和设计经验的人士来说，学习XUL比学习其他用户界面标示语言相对简单。&lt;br /&gt;
使用XUL的主要好处在于它提供了一套简易和跨平台的widget定义。这节省了编程人员在开发软件时所付出的努力。&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;XUL元素&lt;/strong&gt;&lt;/span&gt;
XUL定义了一套丰富的元素。它们大致上可分为以下几种：&lt;br /&gt;
基层元素：例如视窗、page、对话框、向导&lt;br /&gt;
Widget:例如标签、按钮、文字方块、条列式菜单、组合方块、选择钮、复选框、树、菜单、工具栏、分组框、标签页、色彩选择器、spacer、splitter&lt;br /&gt;
排版:例如方框、网格、堆栈、叠&lt;br /&gt;
事件和脚本:例如脚本、命令、key、broadcaster、observer&lt;br /&gt;
数据源:例如template、rule&lt;br /&gt;
其他:例如overlay（类似SSI，但在客户端运作，而且更为强大）、iframe、浏览器、编辑器&lt;br /&gt;
一个XUL文件中也可以包含其他XML命名空间的元素，例如XHTML、SVG和MathML。&lt;br /&gt;
现时的XUL还未在提供一些普遍的widget，例如spinbox、slider和canvas。XUL 2.0[3]计划中将会包括这些缺乏的控件。&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;XUL是如何处理的&lt;/strong&gt;&lt;/span&gt;[4]&lt;br /&gt;
Mozilla浏览器内部使用跟HTML的处理非常相似的方法来处理XUL：当你在浏览器的地址栏里面输入HTML页面的URL以后，浏览器就定位这个网址并下载页面内容，然后Mozilla将页面内容转换成树的数据结构，最后再将树转换成对象集合，集合中的对象最终被展现在屏幕上就成了我们所见的网页。CSS, 图片以及其他技术被用来控制页面的展现。XUL的处理过程与此非常类似。&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;XUL应用&lt;/strong&gt;&lt;/span&gt;
虽然XUL的设计原意是为了创作Mozilla程序及其扩展，但事实上人们也能利用它来编写基于HTTP的网络应用程序和基于swt/swing/gwt的客户端程序。一些开源的架构使用了XUL，例如Pentaho XUL Framework[5]。Pentaho XUL使用XUl跨多种技术（Swing, SWT, GWT）渲染用户界面，来实现业务逻辑的可重用性。shandor-xul[6]项目也是基于XUl开发的,项目地址见参考资料[6]。&lt;br /&gt;
Firefox里内置的一些XUL 地址见：&lt;a href=&quot;http://www.cnblogs.com/jxsoft/archive/2011/04/07/2008202.html&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/jxsoft/archive/2011/04/07/2008202.html&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;运行XUL应用程序&lt;/strong&gt;&lt;/span&gt;
可以选择 3 种方式来运行 XUL 应用程序：&lt;br /&gt;
1.使用基于 Mozilla 的浏览器进行简单测试&lt;br /&gt;
2.使用XULRunner&lt;br /&gt;
3.使用Firefox 3.0作为XUL运行时，它的功能和 XULRunner很相似&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #339966;&quot;&gt;总结&lt;/span&gt;&lt;/strong&gt;
XUL用户界面语言是一种可用于开发Mozilla独立应用程序和浏览器扩展的通用语言，还可以用来实现跨多种UI技术的用户接口，提高业务逻辑代码的重用性，第二点视乎是更值得推荐使用的。关于XUl的教程见参考资料。&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #339966;&quot;&gt;&lt;strong&gt;参考资料&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;li&gt;
1.XUL Wiki :&lt;a href=&quot;http://zh.wikipedia.org/wiki/XUL&quot; target=&quot;_blank&quot;&gt;http://zh.wikipedia.org/wiki/XUL&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;2.XML 用户界面语言（XUL）开发简介：&lt;a href=&quot;http://www.ibm.com/developerworks/cn/education/xml/x-xulintro/section2.html&quot; target=&quot;_blank&quot;&gt;http://www.ibm.com/developerworks/cn/education/xml/x-xulintro/section2.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;3.XUL 2.0: &lt;a href=&quot;https://wiki.mozilla.org/XUL:Home_Page&quot; target=&quot;_blank&quot;&gt;https://wiki.mozilla.org/XUL:Home_Page&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;4.XUL结构: &lt;a href=&quot;https://developer.mozilla.org/cn/XUL_%E6%95%99%E7%A8%8B/1-2_XUL%E7%9A%84%E7%BB%93%E6%9E%84&quot; target=&quot;_blank&quot;&gt;https://developer.mozilla.org/cn/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;5.Pentaho XUL ramework: &lt;a href=&quot;http://wiki.pentaho.com/display/ServerDoc2x/The+Pentaho+XUL+Framework+Developer's+Guide&quot; target=&quot;_blank&quot;&gt;http://wiki.pentaho.com/display/ServerDoc2x/The+Pentaho+XUL+Framework+Developer's+Guide&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;6.shandor-xul:&lt;a href=&quot;http://code.google.com/p/shandor-xul/&quot; target=&quot;_blank&quot;&gt;http://code.google.com/p/shandor-xul/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;7.Mozilla XUL教程: &lt;a href=&quot;https://developer.mozilla.org/index.php?title=cn/XUL_%E6%95%99%E7%A8%8B&quot; target=&quot;_blank&quot;&gt;https://developer.mozilla.org/index.php&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Ext读取xml文件生成动态表格和表单</title>
   <link href="http://blog.javachen.com/extjs/2011/10/22/ext_readxml_in_bjsasc_wuzi"/>
   <updated>2011-10-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/extjs/2011/10/22/ext_readxml_in_bjsasc_wuzi</id>
   <content type="html">&lt;p&gt;最近开发项目，需要动态读取xml文件，生成Ext界面，xml文件通过前台页面的按钮事件传进来，可以在网上查找【javascript 弹出子窗口】的相关文章&lt;/a&gt;
获取弹出窗口url后的参数方法：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
// 获取url后的参数值
function getQueryStringValue(name) {
    var url = window.location.search;
    if (url.indexOf('?') &lt; 0) {
        return null
    }
    var index = url.indexOf(name + &quot;=&quot;);
    if (index &lt; 0) {
        return null
    }
    var args = url.indexOf('&amp;', index);
    var value;
    if (args &gt; 0) {
        value = url.substring(index + name.length + 1, args);
    } else {
        value = url.substring(index + name.length + 1, url.length);
    }
    return value;
}
// 获取xml的服务器路径
function getXmlUrl(xmlFile) {
    return '../bjsasc_dictionary/' + getQueryStringValue('xmlFile');
}
&lt;/pre&gt;


&lt;p&gt;用到的一些辅助方法：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
// 去掉Dom节点中的空白字符
function cleanWhitespaces(elem) {
    var elem = elem || document;
    var childElem = elem.childNodes;
    var childElemArray = new Array;
    for (var i = 0; i &lt; childElem.length; i++) {
        if (childElem[i].nodeType == 1) {
            childElemArray.push(childElem[i]);
        }
    }
    return childElemArray;
}
// 取得父窗口表单中键值对
function getParentFormValues() {
    var formObj = window.opener.document.forms[&quot;frmMain&quot;].elements;
    var formValues = &quot;&quot;;
    for (var i = 0; i &lt; formObj.elements.length; i++) {
        if (formObj.elements[i].value != null
                &amp;&amp; formObj.elements[i].value != &quot;&quot;
                &amp;&amp; formObj.elements[i].value.length != 0) {
            formValues += '_' + formObj.elements[i].name.toUpperCase() + '{'
                    + formObj.elements[i].value.toUpperCase() + '}'
                    + formObj.elements[i].name.toUpperCase() + '_ ';
        }
    }
    formValues += opener.getBindValue(formObj.elements);
    return formValues;
}
// 取得过滤条件表单的键值对
function getCondictionValues() {
    var condictionString = &quot;&quot;;
    var formObj = form.getForm().getEl().dom;
    for (var i = 0; i &lt; formObj.elements.length; i++) {
        if (formObj.elements[i].value != null
                &amp;&amp; formObj.elements[i].value != &quot;&quot;
                &amp;&amp; formObj.elements[i].value.length != 0) {
            condictionString += '_' + formObj.elements[i].name + '{'
                    + formObj.elements[i].value + '}'
                    + formObj.elements[i].name + '_ ';
        }
    }
    // alert(&quot;condictionString&quot;+condictionString);
    return condictionString;
}

// 判读Ext表单是否有输入
function isFormInputed(ExtForm) {
    var flag = false;
    var formObj = ExtForm.getEl().dom;
    for (var i = 0; i &lt; formObj.elements.length; i++) {
        if (formObj.elements[i].value != null
                &amp;&amp; formObj.elements[i].value != &quot;&quot;
                &amp;&amp; formObj.elements[i].value.length != 0) {
            flag = true;
            break;
        }
    }
    return flag;
}

// 将计算得到的结果四舍五入
/* * ForDight(Dight,How):数值格式化函数，Dight要 * 格式化的 数字，How要保留的小数位数。 */
function ForDight(Dight, How) {
    var Dight = Math.round(Dight * Math.pow(10, How)) / Math.pow(10, How);
    return Dight;
}
&lt;/pre&gt;


&lt;p&gt;xml文件格式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt; ?xml version=&quot;1.0&quot; encoding=&quot;gb2312&quot;?&amp;gt;
&amp;lt; dictionary&amp;gt;
    &amp;lt;title&amp;gt;领用出库-物资选择&amp;lt;/title&amp;gt;
    &amp;lt;sql&amp;gt;
    select V_stores_list.* 
    from V_stores_list where WHID='+$getform(WHID)+' AND PROJECTNO='+$getform(PROJECTNO)+'
        AND CANUSEQTY&amp;gt;0 AND ??? and isblock=0
    &amp;lt;/sql&amp;gt;
    &amp;lt;fromtable&amp;gt;V_stores_list&amp;lt;/fromtable&amp;gt;
    &amp;lt;targettable&amp;gt;BO_IC_EXPORT_S&amp;lt;/targettable&amp;gt;
    &amp;lt;line&amp;gt;20&amp;lt;/line&amp;gt;
    &amp;lt;!-- 条件区开始--&amp;gt;
    &amp;lt;condition&amp;gt;
        &amp;lt;fieldname&amp;gt;MTRNAME&amp;lt;/fieldname&amp;gt;
        &amp;lt;fieldtitle&amp;gt;物资名称&amp;lt;/fieldtitle&amp;gt;
        &amp;lt;fieldtype&amp;gt;文本&amp;lt;/fieldtype&amp;gt;
        &amp;lt;comparetype&amp;gt;&amp;lt; ![CDATA[like
        MTRNAME
        单行
        &amp;lt; ![CDATA[]]&amp;gt;       
        &amp;lt;/comparetype&amp;gt;
    &amp;lt;/ condition&amp;gt;
&amp;lt;/ dictionary&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后，弹出窗口页面Ext入口代码：&lt;/p&gt;

&lt;pre&gt;
// 全局变量
var result = {};
var grid;
var form;
var viewport;
var store;
var sm = new Ext.grid.CheckboxSelectionModel();
var autoStore;
var tempItems1 = [];
var tempItems2 = [];
var tempItems3 = [];
var flag = 1;
// 程序入口
Ext.onReady(function() {
    Ext.QuickTips.init();// 初始化
    Ext.form.Field.prototype.msgTarget = 'qtip';// 统一指定错误信息提示方式
    Ext.util.CSS    .swapStyleSheet('theme', '../aws_js/extjs2/css/xtheme-gray.css');// 更换皮肤
    Ext.BLANK_IMAGE_URL = '../aws_js/extjs2/images/default/s.gif';
    Ext.Ajax.request({
        url : getXmlUrl(getQueryStringValue('xmlFile')), // 访问数据字典
        method : 'post',
        success : function(res, opt) {
            var xmlObj = res.responseXML;
            initStoreData(xmlObj); // 访问成功后执行后续工作
        }
    })
});
function initStoreData(xmlObj) {
    getInitData(xmlObj);
    document.title = result.winTitle;

    var dataRecorder = Ext.data.Record.create(result.gridRecords);// 指定记录集格式
    // 获取表格数据部分
    store = new Ext.data.Store({
        idProperty : 'ID',
        proxy : new Ext.data.HttpProxy({
            url : '../search.do?method=findAll',
            failure : function() {
                // Ext.Msg.alert(&quot;Notice&quot;, &quot;网路问题&quot;);
            },
            success : function(response) {
                // Ext.Msg.alert(&quot;Notice&quot;, response.responseText);
            }
        }),

        // baseParams : {
        // parentFormValues : getParentFormValues(),// 请求发送的参数：父表单值和xml文件名
        // xmlFile : getQueryStringValue('xmlFile')
        // // cmd:'search'
        // },
        reader : new Ext.data.JsonReader({
            totalProperty : 'totalCount',
            root : 'data'
        }, dataRecorder)
    });
    // 要分页，第一次加载数据必须传start和limit两参数
    // store.load({
    // params : {
    // start : 0,
    // limit : result.limit
    // }
    // });
    initViewport();
}
// 获得界面初始化的一些数据
function getInitData(xmlObj) {
    // result.formItems = {};
    result.columnHeaders = [];
    result.gridRecords = [];
    result.dbFilterRecords = [];
    result.winTitle = xmlObj.getElementsByTagName(&quot;title&quot;)[0].firstChild.nodeValue; // 窗口title名称
    result.limit = xmlObj.getElementsByTagName(&quot;line&quot;)[0].firstChild.nodeValue;// 分页数据
    result.fromTable = xmlObj.getElementsByTagName(&quot;fromTable&quot;)[0].firstChild.nodeValue;// 来自哪个表
    // 获取过滤条件表单的界面数据
    var conections = xmlObj.getElementsByTagName(&quot;condition&quot;);
    var row = ForDight(conections.length / 3, 0);
    for (var i = 0; i &lt; conections.length; i++) {
        var item = {};
        var condition = cleanWhitespaces(conections[i]);
        item.id = condition[0].firstChild.nodeValue;
        item.fieldLabel = condition[1].firstChild.nodeValue;
        item.name = condition[4].firstChild.nodeValue;
        item.anchor = '95%';
        if (condition[6].firstChild.nodeValue == '单行') {
            item.xtype = 'textfield';
        } else if (condition[6].firstChild.nodeValue == '日期') {
            item.xtype = 'datefield';
            item.format = 'Y-m-d';
        } else if (condition[6].firstChild.nodeValue == '数值') {
            item.xtype = 'numberfield';
            item.minValue = 0;
            item.minText = '请输入有效的数字';
            item.decimalPrecision = 6;
        } else if (condition[6].firstChild.nodeValue == '自动填充') {
            var autoStore = new Ext.data.SimpleStore({
                proxy : new Ext.data.HttpProxy({// 读取远程数据的代理
                    url : '../ajax/autoComplete.do?method=autoComplete',
                    failure : function() {
                        Ext.Msg.alert(&quot;Notice&quot;, &quot;no records&quot;);
                    }
                }),
                fields : ['property'],
                baseParams : {
                    'sqlString' : condition[4].firstChild.nodeValue + ' | '
                            + result.fromTable
                }
            });
            item.xtype = 'combo';
            item.store = autoStore;
            item.displayField = 'property';
            item.typeAhead = true;
            item.allQuery = 'all';// 查询信息的查询字符串
            item.queryParam = 'keyword';// 查询的名字
            item.mode = 'remote';
            item.minChars = 3;// 默认最少输入4
            item.forceSelection = true;
            item.queryDelay = 0;// 查询延迟时间
            item.triggerAction = 'all';
            item.emptyText = '';
            item.resizable = true;
            item.selectOnFocus = true;
        }
        if (i / row &lt; 1) {
            tempItems1.push(item);
        }
        if (i / row &lt; 2 &amp;&amp; i / row &gt;= 1) {
            tempItems2.push(item);
        } else if (i / row &gt;= 2) {
            tempItems3.push(item);
        }
    }
    // alert(Ext.util.JSON.encode(result));

    // 获取表格表头的界面数据和rcord记录的数据格式
    var fields = xmlObj.getElementsByTagName(&quot;field&quot;);
    result.columnHeaders.push(sm);// 插入多选框
    result.columnHeaders.push(new Ext.grid.RowNumberer({
        width : 20
    }));// 插入行号
    for (var i = 0; i &lt; fields.length; i++) {
        var item = {};
        var record = {};
        var array = [];
        var field = cleanWhitespaces(fields[i]);
        var renderDate = function(value) {
            return value ? value.dateFormat('Y-m-d') : '';
        }
        // 生成grid表格中store数据记录
        record.name = field[0].firstChild.nodeValue;
        record.mapping = field[0].firstChild.nodeValue;
        if (field[1].firstChild.nodeValue == '日期') {
            record.type = 'date';
            record.dateFormat = 'Y-m-d';
            item.renderer = Ext.util.Format.dateRenderer('Y-m-d')
        } else if (field[1].firstChild.nodeValue == '数值') {
            record.type = 'auto';
        } else {
            record.type = 'string';
        }
        result.gridRecords.push(record);

        // 生成grid表格表头数据记录
        item.dataIndex = field[0].firstChild.nodeValue;
        item.header = field[2].firstChild.nodeValue;
        // item.width=field[3].firstChild.nodeValue;
        item.sortable = true;
        if (field.length == 7
                &amp;&amp; field[5].firstChild.nodeValue.toUpperCase() == 'TRUE') {
            item.hidden = true;
            // item.hideable=false;
        }
        if (field.length == 6) {
            item.hidden = false;
        }
        result.columnHeaders.push(item);

        // 生成模糊过滤store的记录
        if (field[4].firstChild.nodeValue.toUpperCase() == 'TRUE') {
            array.push(field[2].firstChild.nodeValue);// fieldName
            array.push(field[0].firstChild.nodeValue);// fieldValue
        }
        result.dbFilterRecords.push(array);
    }
    return result;
};
&lt;/pre&gt;


&lt;p&gt;渲染Ext界面代码：&lt;/p&gt;

&lt;pre&gt;
function initViewport() {
    if (!form) {
        form = getInsertForm();
    }

    if (!grid) {
        grid = getInsertGrid();
    }

    if (!viewport) {
        var formPanel = new Ext.Panel({
            title : '查询条件',
            region : 'north',
            split : true,
            frame : true,
            border : true,
            layout : 'fit',
            height : 280,
            collapsible : true,
            items : [form]

        });
        viewport = new Ext.Viewport({
            layout : 'border',
            modal : true,// 是否为模式窗口
            border : false,
            items : [formPanel, grid]
        });
    }
}

function searchByFilter() {
    var dbfilter = Ext.get(&quot;dbFilter&quot;).getValue();
    var fieldMame = Ext.get(&quot;search-type&quot;).getValue();
    if (dbfilter == null || dbfilter == &quot;&quot;) {
        alert(&quot;请输入一个关键字&quot;);
        Ext.get(&quot;dbFilter&quot;).focus();
    } else if (fieldMame == &quot;==选择过滤字段==&quot;) {
        alert(&quot;请选择一个过滤字段&quot;);
        Ext.get(&quot;search-type&quot;).focus();
    } else {
        form.getForm().reset();
        if (flag == 1) {
            store.baseParams = {
                dbfilter : dbfilter,
                parentFormValues : getParentFormValues(),
                fieldMame : Ext.get(&quot;hiddenValue&quot;).dom.value,
                xmlFile : getQueryStringValue('xmlFile'),
                cmd : 'filter'
            };
            store.load({
                params : {
                    start : 0,
                    limit : result.limit
                }
            });
            form.getForm().reset();
            flag = 0;
        } else {
            store.baseParams = {
                dbfilter : dbfilter,
                parentFormValues : getParentFormValues(),
                fieldMame : Ext.get(&quot;hiddenValue&quot;).dom.value,
                xmlFile : getQueryStringValue('xmlFile'),
                cmd : 'filter'
            };
            store.reload();

        }
        Ext.get(&quot;dbFilter&quot;).dom.value = &quot;&quot;;
    }
}
// 获取过滤条件部分的表单控件
function getInsertForm() {
    form = new Ext.form.FormPanel({
        name : 'frmMain',
        height : 260,
        labelAlign : 'left',
        labelWidth : 110,
        layout : 'fit',
        waitMsgTarget : true,
        items : [{
            xtype : 'fieldset',
            frame : true,
            title : '高级查询',
            autoHeight : true,
            layout : 'column',
            items : [{
                columnWidth : .333,
                layout : 'form',
                items : tempItems1
            }, {
                columnWidth : .333,
                layout : 'form',
                items : tempItems2
            }, {
                columnWidth : .333,
                layout : 'form',
                items : tempItems3
            }]
        }],
        tbar : ['请输入模糊值: ', ' ', {
            xtype : 'textfield',
            width : 200,
            id : 'dbFilter',
            listeners : {
                specialkey : function(field, e) {
                    if (e.getKey() == Ext.EventObject.ENTER) {
                        searchByFilter();
                    }
                }
            }
        }, '-', {
            xtype : 'combo',
            id : 'search-type',
            anchor : '60%',
            hiddenName : 'hiddenValue',
            width : 120,
            triggerAction : 'all',// 单击触发按钮显示全部数据
            store : new Ext.data.SimpleStore({// 定义组合框中显示的数据源
                fields : ['fieldName', 'fieldValue'],
                data : result.dbFilterRecords
            }),// 设置数据源
            displayField : 'fieldName',// 定义要显示的字段
            valueField : 'fieldValue',// 定义值字段
            mode : 'local',// 本地模式
            forceSelection : true,// 要求输入值必须在列表中存在
            typeAhead : true,// 允许自动选择匹配的剩余部分文本
            // value : '==选择过滤字段==',
            value : '==选择过滤字段==',
            handleHeight : 10
                // 下拉列表中拖动手柄的高度
                }, '-', {
                    xtype : 'button',
                    text : '筛选',
                    tooltip : '先选择查询条件，再输入模糊值',
                    iconCls : 'find',
                    handler : searchByFilter
                }, '-&gt;', {
                    pressed : true,
                    xtype : 'button',
                    text : '确认插入',
                    enableToggle : true,
                    tooltip : '请选中一行或多行记录，再选择确认插入',
                    handler : function() {
                        if (sm.hasSelection()) {
                            var records = sm.getSelections();
                            var jsonObj = &quot;{data:[&quot;;
                            for (var i = 0; i &lt; records.length; i++) {
                                jsonObj += Ext.encode(records[i].data);
                                if (i != records.length - 1) {
                                    jsonObj += &quot;,&quot;;
                                }
                            }
                            jsonObj += &quot;]}&quot;
                            Ext.Ajax.request({
                                url : '../search.do?method=insertChoices',
                                method : 'post',
                                params : {
                                    xmlFile : getQueryStringValue('xmlFile')
                                            .toString(),
                                    jsonObj : jsonObj,
                                    parentFormValues : getParentFormValues()
                                },
                                callback : function(options, success, response) {
                                    if (response.responseText == &quot;success&quot;) {

                                        Ext.Msg.alert(&quot;提示&quot;, &quot;插入成功&quot;, function() {
                                            window.close();
                                            // opener.location.reload();
                                            opener.saveForm();
                                        });
                                    } else {
                                        Ext.Msg.alert(&quot;提示&quot;, &quot;插入失败&quot;);
                                    }
                                }
                            })

                        } else {
                            alert(&quot;请选择一行或多行数据&quot;);
                        }
                    },
                    scope : this
                }, '-', {
                    pressed : true,
                    xtype : 'button',
                    text : '取消',
                    tooltip : '取消选择，直接退出',
                    handler : function() {
                        Ext.Msg.confirm('Notice', '确认退出？', function(id) {
                            if (id == &quot;yes&quot;)
                                window.close();
                        });
                    },
                    scope : this
                }],
        buttons : [{
            text : '执行查询条件',
            handler : function() {
                var connections = getCondictionValues();
                if (!form.getForm().isValid()) {
                    return;
                };
                if (isFormInputed(form.getForm()) == false) {
                    alert(&quot;请输入查询条件&quot;);
                    form.getForm().focus();
                    return;
                } else {
                    Ext.get(&quot;dbFilter&quot;).dom.value = &quot;&quot;;
                    if (flag == 1) {
                        store.baseParams = {
                            xmlFile : getQueryStringValue('xmlFile'),
                            condictions : connections,
                            parentFormValues : getParentFormValues(),
                            cmd : 'search'
                        };
                        store.load({
                            params : {
                                start : 0,
                                limit : result.limit
                            }
                        });
                        form.getForm().reset();
                        flag = 0;
                    } else {
                        store.baseParams = {
                            xmlFile : getQueryStringValue('xmlFile'),
                            condictions : connections,
                            parentFormValues : getParentFormValues(),
                            cmd : 'search'
                        };
                        store.reload();
                    }

                    form.getForm().reset();
                }
            }
        }, {
            text : '重置',
            handler : function() {
                form.getForm().reset();
            }
        }]
    });
    return form;
}
&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>在eclipse中构建Pentaho BI Server工程</title>
   <link href="http://blog.javachen.com/pentaho/2011/09/28/build-pentaho-bi-server-source-code-in-eclipse"/>
   <updated>2011-09-28T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/pentaho/2011/09/28/build-pentaho-bi-server-source-code-in-eclipse</id>
   <content type="html">&lt;p&gt;首先需要说明的是，Pentaho BI Server源代码在&lt;em&gt;svn://source.pentaho.org/svnroot/bi-platform-v2/trunk/&lt;/em&gt;，并且用ivy构建。ivy没有用过也不熟悉，故不打算从这里使用ivy构建源码。&lt;br /&gt;
当然，您可以参考&lt;a href=&quot;http://wiki.pentaho.com/display/ServerDoc2x/Building+and+Debugging+Pentaho+with+Eclipse&quot; target=&quot;_blank&quot;&gt;官方文档&lt;/a&gt;构建源码。&lt;/p&gt;




&lt;p&gt;Pentaho BI Server打包后的文件存于&lt;a href=&quot;http://sourceforge.net/projects/pentaho/files/Business%20Intelligence%20Server/&quot; target=&quot;_blank&quot;&gt;这里&lt;/a&gt;，其中包括（本文使用的是3.9.0版本）：biserver-ce-3.9.0-stable.zip，bi-platform-3.9.0-stable-sources.zip，biserver-ce-3.9.0-stable-javadoc.zip。
&lt;!--more--&gt;
将biserver-ce-3.9.0-stable.zip解压之后执行&lt;em&gt;biserver-ce/start-pentaho.bat&lt;/em&gt;（或是再linux环境下：&lt;em&gt;biserver-ce/start-pentaho.sh&lt;/em&gt;），即可成功启动biserver。现在我想将这个工程导入到eclipse然后调式跟踪代码，怎么做呢？&lt;/p&gt;




&lt;p&gt;&lt;p&gt;&lt;strong&gt;以下操作是在eclipse3.7+tomcat 6.20的环境中进行的。&lt;/strong&gt;
在eclipse中创建一个web项目，名称为pentaho，然后将&lt;em&gt;biserver-ce/tomcat/webapps&lt;/em&gt;下的&lt;code&gt;pentaho-style&lt;/code&gt;和&lt;code&gt;sw-style&lt;/code&gt;拷贝到你的tomcat 6服务器的webapps目录下，将pentaho文件下的所有文件拷贝到工程下的WebContent目录下。由于biserver需要访问pentaho-solutions下的文件，故还需要修改&lt;code&gt;WEB-INF/web.xml&lt;/code&gt;文件你的以下配置，用于指定pentaho-solutions的路径：
&lt;pre&gt;
&amp;lt; context-param &gt;
    &amp;lt; param-name &gt;solution-path&amp;lt; /param-name&gt;
    &amp;lt; param-value &gt;/home/june.chan/opt/biserver-ce/pentaho-solutions&amp;lt; /param-value&gt;
&amp;lt; /context-param &gt;
&lt;/pre&gt;
现在即可部署项目，运行&lt;code&gt;biserver-ce/data/start_hypersonic.bat&lt;/code&gt;（用于启动数据库），然后启动tomcat，就可以通过&lt;em&gt;http://localhost:8080/pentaho&lt;/em&gt;访问biserver。如果启动报错，需要将hsqldb-1.8.0.7.jar包，拷贝到应用路径下（&lt;em&gt;\tomcat-pci-test\biserver-ce\tomcat\webapps\pentaho\WEB-INF\lib&lt;/em&gt;）。&lt;br /&gt;
现在可以看到biserver的登录页面，但是还是没有看到biserver的源代码。&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;&lt;strong&gt;接下来，构建源代码。&lt;/strong&gt;
在biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib下面有很多名称为pentaho-bi-platform-########-3.9.0-stable.jar的jar文件，这些即是biserver源码编译之后的class文件。在bi-platform-3.9.0-stable-sources.zip压缩文件你即可以看到这些class文件的源代码。将这些src包解压然后拷贝到之前新建的pentaho工程的src目录下。&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;&lt;strong&gt;&lt;font color=&quot;red&quot;&gt;需要注意的是：&lt;/font&gt;&lt;/strong&gt;
1.这些src jar包你只报告java文件，不包括配置文件：log4j配置文件，hibernate配置和实体映射文件，ehcache配置文件&lt;br /&gt;
2.上面的配置文件需要到biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib目录下的pentaho-bi-platform-########-3.9.0-stable.jar文件中寻找。&lt;br /&gt;
3.
&lt;pre&gt; &lt;br/&gt;
&lt;ul&gt;
&lt;li&gt;biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-engine-security-3.9.0-stable.jar文件中有ldap的配置文件，&lt;/li&gt;
    &lt;li&gt;biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-engine-services-3.9.0-stable.jar文件中有ehcache的配置文件，&lt;/li&gt;
    &lt;li&gt;biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-plugin-actions-3.9.0-stable.jar文件中有log4j的配置文件，&lt;/li&gt;
&lt;li&gt; biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-repository-3.9.0-stable.jar文件中有hibernate配置文件，&lt;/li&gt;
&lt;li&gt;biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib/pentaho-bi-platform-security-userroledao-3.9.0-stable.jar文件中有hibernated的实体映射文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;/pre&gt;
4.biserver-ce-3.9.0-stable.zip的lib（biserver-ce/tomcat/webapps/pentaho/WEB-INF/lib）目录下的servlete jar包的版本为2.3，版本过低需要替换为更高版本知道源码中不在有servlete编译错误
&lt;/p&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Pentaho现场支持遇到问题及解决办法</title>
   <link href="http://blog.javachen.com/pentaho/2011/09/26/resolved-pentaho-problems-9-16"/>
   <updated>2011-09-26T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/pentaho/2011/09/26/resolved-pentaho-problems-9-16</id>
   <content type="html">&lt;p&gt;很久没写文章了，最近在关注Pentaho。&lt;br /&gt;
 以下是9月16日现场提出的问题解决办法：&lt;br /&gt;
      1、PDF预览中文没显示，txt预览中文乱码：&lt;br /&gt;
           1）、设置File-&gt;Configuration -&gt;output-pageable-pdf的encoding 为Identity-H&lt;br /&gt;
           2）、将需要输出中文的报表项目的字体设置为中文字体，例如宋体&lt;br /&gt;
           3）、如要发布到服务器，需要修改如下的配置：&lt;br /&gt;
             pentaho/server/biserver-ee/tomcat/webapps/pentaho/WEB-INF/classes/classic-engine.properties：&lt;br /&gt;
             org.pentaho.reporting.engine.classic.core.modules.output.pageable.pdf.Encoding=Identity-H&lt;br /&gt;
     2、实现文件拷贝方式发布报表&lt;br /&gt;
           可以通过文件方式发布，只要将报表的prpt文件拷贝到Solution的目录（Pentaho安装路径的server\biserver-ee\pentaho-solutions）下就可以了&lt;br /&gt;
     3、报表链接参数传递问题&lt;br /&gt;
          由于参数带中文造成的，可以对参数的值URLENCODE(&quot;value&quot;; &quot;utf-8&quot;)来解决&lt;br /&gt;
     4、查询参数缺省值问题&lt;br /&gt;
          关于日期的默认值。可以使用报表系统提供的日期变量设置，如TODAY，DATE，YEAR。。。&lt;br /&gt;
     5、实现在pie chart上显示文字&lt;br /&gt;
          以把label默认显示的百分比改为文字：label-formate = {0}， 但是label显示百分比，同时在pie图的划分区域显示文字是不能的。&lt;br /&gt;
     6、报表集成时候垂直滚动条是否可以去掉&lt;br /&gt;
          改变报表的高度：报表设计器 file-page setup&lt;br /&gt;
     7、报表中的chart不能导出到Excel2007&lt;br /&gt;
          目前为系统bug，excel2003能够正常导出&lt;br /&gt;
     8、实现隔行换色&lt;br /&gt;
          选中Details中的field再attribute面板上设置name的名称（如“row-band”），然后通过Format--&gt;Row-Banding，可以设置Visible Color 、Inisible Color，再Element中输入&quot;row-band&quot;&lt;br /&gt;
     9、显示top N  ：托一个message field，在里面输入表达式，如，$（topn）,topn为传入的参数&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>在Fedora 15 上搭建Eucalyptus</title>
   <link href="http://blog.javachen.com/cloud/2011/08/20/install-eucalyptus-on-fedora-15"/>
   <updated>2011-08-20T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/08/20/install-eucalyptus-on-fedora-15</id>
   <content type="html">&lt;p&gt;&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://open.eucalyptus.com/themes/eucalyptus/img/eucalyptus_logo_awh.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
在Fedora 15 上搭建Eucalyptus平台，在Fedora 15 上搭建Eucalyptus与在Centos上搭建Eucalyptus有什么区别呢？参照这篇文章&lt;a href=&quot;http://open.eucalyptus.com/wiki/EucalyptusInstallationFedora_v2.0&quot; target=&quot;_blank&quot;&gt;Installing Eucalyptus (2.0) on Fedora 12&lt;/a&gt;，然后注意一些细节，视乎就能安装成功。不管你信不信，我是在虚拟机中安装fedora15，然后安装Eucalyptus失败了，失败的原因是xen的网络没有配置好，查看资源的时候free / max都为0000.&lt;/p&gt;




&lt;p&gt;毕竟是第一次接触云计算，第一次接触XEN，第一次接触Eucalyptus，Eucalyptus改装的都装了，就是XEN的网络没有配置好，当时很是迷糊。在接触了OpenNebula 和OpenStack之后，横向对比，视乎明白了很多千丝万缕的关联与奥秘。在安装OpenNebula，最主要是安装OpenStack成功之后，想到了之前Eucalyptus安装失败的原因。限于现在精力不在云计算上，暂且不去重新安装Eucalyptus，等之后再去尝试。下次尝试，定是醍醐灌顶，行云流水，很是期待。&lt;/p&gt;




&lt;p&gt;如果你也在Fedora上安装Eucalyptus平台，咱们可以交流交流，等到时机成熟，会将在Fedora 15 上搭建Eucalyptus的过程及遇到的问题发表在博客上；如果你想研究Eucalyptus平台java部分的代码，咱们也可以彼此分享各自的心得。&lt;/p&gt;




&lt;p&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Export DhtmlxGrid to PDF in Java</title>
   <link href="http://blog.javachen.com/javascript/2011/08/11/export-dhtmlxgrid-to-pdf-in-java"/>
   <updated>2011-08-11T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/08/11/export-dhtmlxgrid-to-pdf-in-java</id>
   <content type="html">&lt;p&gt;将DhtmlxGrid数据导出到pdf这是很常见的需求，dhtmlx官网提供了php和java版本的例子，你可以去官网查看这篇文章《&lt;a href=&quot;http://www.dhtmlx.com/blog/?p=855&quot;&gt;Grid-to-Excel, Grid-to-PDF Available for Java&lt;/a&gt;》，你可以从以下地址下载导出程序源码：
&lt;a href=&quot;http://www.dhtmlx.com/x/download/regular/export/XML2Excel.war&quot;&gt;Export to Excel&lt;/a&gt;
&lt;a href=&quot;http://www.dhtmlx.com/x/download/regular/export/XML2PDF.war&quot;&gt;Export to PDF&lt;/a&gt;
当然，还有一个示例工程：&lt;a href=&quot;http://www.dhtmlx.com/x/download/regular/export/javaexport_sample.zip&quot;&gt; .zip archive with an example&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;XML2PDF和XML2Excel工程内代码很相似，XML2PDF内部使用了PDFjet.jar导出PDF，而XML2Excel使用JXL导出Excel。
需要说明的是，还需要引入dhtmlxgrid_export.js文件，该文件是导出grid的js源码，主要用于将表格数据，包括表头、样式等，序列化为xml字符串，然后模拟一个Form表单提交数据。&lt;/p&gt;

&lt;p&gt;将上面三个工程导入到一个工程然后打开sample.html页面，效果如下：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;/files/2011/08/export-dhtmlxgrid-to-pdf.png&quot; alt=&quot;&quot; title=&quot;export dhtmlxgrid to pdf&quot; width=&quot;300&quot; height=&quot;166&quot; class=&quot;aligncenter size-medium wp-image-2385&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;点击Get as PDF按钮，你会发现会打开一个新的窗口，然后页面什么都没有，而eclipse控制台报空指针异常。异常的主要原因在于下段代码：。&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;
DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance ();
DocumentBuilder db = dbf.newDocumentBuilder();
Document dom = null;
try {
     dom = db.parse(new InputSource(new StringReader(xml)));
}catch(SAXException se) {
     se.printStackTrace();
}catch(IOException ioe) { 
     ioe.printStackTrace();
}
root = dom.getDocumentElement();
&lt;/pre&gt;


&lt;p&gt;上面的代码，DocumentBuilder解析xml字符串后dom对象内并没有数据。
为了能够看到DhtmlxGrid导出pdf的效果，决定将上面的代码用dom4j改写，于是有了下面的代码：&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;
public class PDFXMLParser {
    Element root;
    PDFColumn[][] columns;
    PDFRow[] rows;
    double[] widths;
    private Boolean header = false;
    private Boolean footer = false;
    private String profile = &quot;gray&quot;;
    private double[] orientation = null;

    public void setXML(String xml) {
        SAXReader saxReader = new SAXReader();

        Document document = null;
        try {
            document = saxReader.read(new ByteArrayInputStream(xml.getBytes()));
        } catch (DocumentException e) {
            e.printStackTrace();
        }
        root = document.getRootElement();

        if ((root.attributeValue(&quot;header&quot;) != null)
                &amp;amp;&amp;amp; (root.attributeValue(&quot;header&quot;).equalsIgnoreCase(&quot;true&quot;) == true)) {
            header = true;
        }
        String footer_string = root.attributeValue(&quot;footer&quot;);
        if ((footer_string != null)
                &amp;amp;&amp;amp; (footer_string.equalsIgnoreCase(&quot;true&quot;) == true)) {
            footer = true;
        }
        String profile_string = root.attributeValue(&quot;profile&quot;);
        if (profile_string != null) {
            profile = profile_string;
        }

        String orientation_string = root.attributeValue(&quot;orientation&quot;);
        if (orientation_string != null) {
            if (orientation_string.equalsIgnoreCase(&quot;landscape&quot;)) {
                orientation = A4.LANDSCAPE;
            } else {
                orientation = A4.PORTRAIT;
            }
        } else {
            orientation = Letter.PORTRAIT;
        }
    }

    public PDFColumn[][] getColumnsInfo() {
        PDFColumn[] colLine = null;
        List n1 = root.element(&quot;head&quot;).elements(&quot;columns&quot;);
        if ((n1 != null) &amp;amp;&amp;amp; (n1.size() &amp;gt; 0)) {
            columns = new PDFColumn[n1.size()][];
            for (int i = 0; i &amp;lt; n1.size(); i++) {
                Element cols = (Element) n1.get(i);
                List n2 = cols.elements(&quot;column&quot;);
                if ((n2 != null) &amp;amp;&amp;amp; (n2.size() &amp;gt; 0)) {
                    colLine = new PDFColumn[n2.size()];
                    for (int j = 0; j &amp;lt; n2.size(); j++) {
                        Element col_xml = (Element) n2.get(j);
                        PDFColumn col = new PDFColumn();
                        col.parse(col_xml);
                        colLine[j] = col;
                    }
                }
                columns[i] = colLine;
            }
        }
        createWidthsArray();
        optimizeColumns();
        return columns;
    }
        public PDFRow[] getGridContent() {
        List nodes = root.elements(&quot;row&quot;);
        if ((nodes != null) &amp;amp;&amp;amp; (nodes.size() &amp;gt; 0)) {
            rows = new PDFRow[nodes.size()];
            for (int i = 0; i &amp;lt; nodes.size(); i++) {
                rows[i] = new PDFRow();
                rows[i].parse((Element) nodes.get(i));
            }
        }
        return rows;

    }

       *****
}
&lt;/pre&gt;


&lt;p&gt;还需要修改PDFRow类的parse方法和PDFColumn的parse方法。&lt;/p&gt;

&lt;pre lang=&quot;java&quot;&gt;
public class PDFRow {

    private String[] cells;

    public void parse(Element parent) {
        List nodes = ((Element) parent).elements(&quot;cell&quot;);
        if ((nodes != null) &amp;amp;&amp;amp; (nodes.size() &amp;gt; 0)) {
            cells = new String[nodes.size()];
            for (int i = 0; i &amp;lt; nodes.size(); i++) {
                cells[i] = ((Element) nodes.get(i)).getTextTrim();
            }
        }
    }

    public String[] getCells() {
        return cells;
    }
}

public class PDFColumn {

    public void parse(Element parent) {
        colName = parent.getText();
        String width_string = parent.attributeValue(&quot;width&quot;);
        if (width_string!=null&amp;&amp;width_string.length() &gt; 0) {
            width = Integer.parseInt(width_string);
        }
        type = parent.attributeValue(&quot;type&quot;);
        align = parent.attributeValue(&quot;align&quot;);
        String colspan_string = parent.attributeValue(&quot;colspan&quot;);
        if (colspan_string!=null&amp;&amp;colspan_string.length() &gt; 0) {
            colspan = Integer.parseInt(colspan_string);
        }
        String rowspan_string = parent.attributeValue(&quot;rowspan&quot;);
        if (rowspan_string!=null&amp;&amp;rowspan_string.length() &gt; 0) {
            rowspan= Integer.parseInt(rowspan_string);
        }
    }
}
&lt;/pre&gt;


&lt;p&gt;这样xml字符串就能正常解析了，然后使用pdfjet.jar包就可以导出pdf了，最后的效果如下：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;/files/2011/08/export-dhtmlx-to-pdf-pdf.png&quot; alt=&quot;&quot; title=&quot;export dhtmlx to pdf -pdf&quot; width=&quot;300&quot; height=&quot;134&quot; class=&quot;aligncenter size-medium wp-image-2386&quot; /&gt;
&lt;/div&gt;




&lt;h2&gt;结论：&lt;/h2&gt;


&lt;ul&gt;
&lt;li&gt;1.导出pdf和导出Excel代码差不多，这里不做说明。&lt;/li&gt;
&lt;li&gt;2.使用上面的工具，可以将dhtmlxgrid的数据导出到pdf，并且导出的pdf还保持了grid表格的样式（包括颜色、多表头、表头合并、复选框等等），这点很不错。&lt;/li&gt;
&lt;li&gt;3.导出的pdf为多页显示，每页有表头&lt;/li&gt;
&lt;li&gt;4.导出后的pdf页面可以直接打印，当然如果在代码上做点处理，可以直接将pdf保存为一个文件，让用户下载。&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>自定义dhtmlxGrid表头菜单</title>
   <link href="http://blog.javachen.com/javascript/2011/07/31/custom-dhtmlxgrid-header-menu"/>
   <updated>2011-07-31T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/07/31/custom-dhtmlxgrid-header-menu</id>
   <content type="html">&lt;p&gt;dhtmlxGrid可以定义表头菜单以及表格右键菜单，表格右键菜单可以自定义，但是表头菜单只能使用其提供的菜单。dhtmlxGrid默认的表头菜单可以决定表格中每一列是否在表格中显示，并没有提供更多的扩展，如果我想自定义表头菜单，该怎么做呢？本文就是基于自定义表格菜单，说说我的实现方式。
以下是dhtmlxGrid的表头菜单效果：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-2287&quot; title=&quot;dhtmlxgrid-head-menu&quot; src=&quot;/files/2011/07/dhtmlxgrid-head-menu.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;174&quot; /&gt;&lt;/div&gt;


&lt;p&gt;其功能过于单一，以下是表格右键菜单效果：&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;&lt;img class=&quot;aligncenter size-medium wp-image-2288&quot; title=&quot;dhtmlxgrid-context-menu&quot; src=&quot;/files/2011/07/dhtmlxgrid-context-menu.jpg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;126&quot; /&gt;&lt;/div&gt;


&lt;p&gt;如果能够像表格菜单一样自定义表头菜单，那会是一件非常有意义的事情，因为dhtmlxGrid菜单都是一些针对行和单元格的操作，没有提过针对列的操作，比如我可能需要在某一列上实现该列的显示与隐藏、排序、改变列属性以及在该列右边添加一新的列，等等。
如何实现表头菜单的自定义呢？可不可将表格右键菜单移到表头上去呢？&lt;!--more--&gt;
首先，来看看context menu的实现方式，下面代码来自dhtmlxGrid Samples中的Context menu例子源码：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot;&gt;
function onButtonClick(menuitemId, type) {
    var data = mygrid.contextID.split(&quot;_&quot;);
    //rowId_colInd;
    mygrid.setRowTextStyle(data[0], &quot;color:&quot; + menuitemId.split(&quot;_&quot;)[1]);
    return true;
}
menu = new dhtmlXMenuObject();
menu.setIconsPath(&quot;../common/images/&quot;);
menu.renderAsContextMenu();
menu.attachEvent(&quot;onClick&quot;, onButtonClick);
menu.loadXML(&quot;../common/_context.xml&quot;);
mygrid = new dhtmlXGridObject('gridbox');
mygrid.setImagePath(&quot;../../codebase/imgs/&quot;);
mygrid.setHeader(&quot;Author,Title&quot;);
mygrid.setInitWidths(&quot;250,250&quot;);
mygrid.enableAutoWidth(true);
mygrid.setColAlign(&quot;left,left&quot;);
mygrid.setColTypes(&quot;ro,link&quot;);
mygrid.setColSorting(&quot;str,str&quot;);
mygrid.enableContextMenu(menu);
mygrid.init();
mygrid.setSkin(&quot;dhx_skyblue&quot;);
mygrid.loadXML(&quot;../common/grid_links.xml&quot;);&lt;/pre&gt;


&lt;p&gt;上面代码创建了一个menu并将其作为context menu附件到grid上面去，下面为最关键的两行行代码：&lt;/p&gt;

&lt;pre lang=&quot;JavaScript&quot;&gt;menu.renderAsContextMenu();
mygrid.enableContextMenu(menu);
&lt;/pre&gt;


&lt;p&gt;上面对于context menu提供的方法太少，这时候可以看看dhtmlxMenu api，看看有没有设置context menu生效位置的方法（指定context menu在哪片区域有效）。在dhtmlxMenu API Methods里没有找到需要的方法，这时候在官网论坛搜搜，也许可以找到点什么。
在论坛里可以找到一个例子，大致代码如下：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot;&gt;function onButtonClick(menuitemId, type) {
    var data = mygrid.contextID.split(&quot;_&quot;);
    //rowId_colInd;
    mygrid.setRowTextStyle(data[0], &quot;color:&quot; + menuitemId.split(&quot;_&quot;)[1]);
    return true;
}
menu = new dhtmlXMenuObject();
menu.setIconsPath(&quot;../common/images/&quot;);
menu.attachEvent(&quot;onClick&quot;, onButtonClick);
menu.loadXML(&quot;../common/_context.xml&quot;);

mygrid = new dhtmlXGridObject('gridbox');
mygrid.setImagePath(&quot;../../codebase/imgs/&quot;);
mygrid.setHeader(&quot;Author,Title&quot;);
mygrid.setInitWidths(&quot;250,250&quot;);
mygrid.enableAutoWidth(true);
mygrid.setColAlign(&quot;left,left&quot;);
mygrid.setColTypes(&quot;ro,link&quot;);
mygrid.setColSorting(&quot;str,str&quot;);
//mygrid.enableContextMenu(menu); //使其失效
mygrid.init();
mygrid.setSkin(&quot;dhx_skyblue&quot;);
mygrid.loadXML(&quot;../common/grid_links.xml&quot;);

mygrid.hdr.id = &quot;header_id&quot;;
var header_row = mygrid.hdr.rows[1];
for ( var i = 0; i &amp;lt; header_row.cells.length; i++) {
   header_row.cells[i].id = &quot;context_zone_&quot; + i;
}
menu.addContextZone(&quot;header_id&quot;);
&lt;/pre&gt;


&lt;p&gt;上面最关键的代码在最后几行，给dhtmlxGrid表头设置了一个id，然后调用menu的addContextZone()方法指定centext的有效区域。视乎这就是我们所需要的，但是你执行以上代码你会发现onButtonClick方法里mygrid.contextID会报错，原因是mygrid没有contextID属性（在context menu中通过该属性可以获知鼠标焦点在哪一行，但是现在在表头上强加了该menu，所以并不存在该属性了）。
剩下的问题是需要解决，菜单单击事件了。我们可以在表头的contextmenu事件处罚的时候获取鼠标焦点，并将自定义的菜单在该位置显示，该方法如下：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot;&gt;dhtmlxEvent(mygrid.hdr, &quot;contextmenu&quot;, function(ev) {
    ev = ev || event;
    var el = ev.target || ev.srcElement;
    var zel = el;
    while (zel.tagName != &quot;TABLE&quot;)
        zel = zel.parentNode;
    var grid = zel.grid;
    if (!grid)
        return;
    grid.setActive();

    el = grid.getFirstParentOfType(el, &quot;TD&quot;)

    if ((grid) &amp;amp;&amp;amp; (!grid._colInMove)) {
        grid.resized = null;
        if ((!grid._mCols) || (grid._mCols[el._cellIndex] == &quot;true&quot;))
            colId = el._cellIndex + 1;//获得表头右键菜单焦点所在列索引
    }

    function mouseCoords(ev) {
        if (ev.pageX || ev.pageY) {
            return {
                x : ev.pageX,
                y : ev.pageY
            };
        }
        var d = _isIE &amp;amp;&amp;amp; document.compatMode != &quot;BackCompat&quot; ? 
                    document.documentElement: document.body;
        return {
            x : ev.clientX + d.scrollLeft - d.clientLeft,
            y : ev.clientY + d.scrollTop - d.clientTop
        };
    }

    var coords = mouseCoords(ev);
    menu.addContextZone(&quot;header_id&quot;);
    menu.showContextMenu(coords.x, coords.y);//强制显示
    return true;
});
&lt;/pre&gt;


&lt;p&gt;在上面的代码里，我们获得表头右键菜单焦点所在列索引，将其值赋给colId，然后在菜单单击事件的时候添加一新的列并将colId重置：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot;&gt;function onButtonClick(menuitemId, type, e) {
    mygrid.insertColumn(colId, &quot;12&quot;, &quot;ed&quot;, 80);
    colId = 0;
    return true;
}&lt;/pre&gt;


&lt;p&gt;然后，需要禁止掉表格数据区域的菜单显示：&lt;/p&gt;

&lt;pre lang=&quot;JavaScript&quot;&gt;mygrid.attachEvent(&quot;onBeforeContextMenu&quot;, function(rid, cid, e) {
    return false;//禁止数据区域菜单
});&lt;/pre&gt;


&lt;p&gt;最后的最后，最后的代码如下：&lt;/p&gt;

&lt;pre lang=&quot;javascript&quot;&gt;
    var mygrid, colId;

    function onButtonClick(menuitemId, type, e) {
        mygrid.insertColumn(colId, &quot;12&quot;, &quot;ed&quot;, 80);
        colId = 0;
        return true;
    }

    menu = new dhtmlXMenuObject();
    menu.setIconsPath(&quot;../common/images/&quot;);
    menu.renderAsContextMenu();
    menu.attachEvent(&quot;onClick&quot;, onButtonClick);
    menu.loadXML(&quot;../common/_context.xml&quot;);
    menu.attachEvent(&quot;onBeforeContextMenu&quot;, function(zoneId, e) {
        var hdr = document.getElementById(zoneId)
        return true;
    });

    mygrid = new dhtmlXGridObject('gridbox');
    mygrid.setImagePath(&quot;../codebase/imgs/&quot;);
    mygrid.setHeader(&quot;Sales,Book Title,Author,Price,In Store,Shipping,Bestseller,
              Date of Publication&quot;);
    mygrid.setInitWidths(&quot;50,150,100,80,80,80,80,200&quot;);
    mygrid.setColAlign(&quot;right,left,left,right,center,left,center,center&quot;);
    mygrid.setColTypes(&quot;dyn,edtxt,ed,price,ch,co,ra,ro&quot;);

    mygrid.init();
    mygrid.setSkin(&quot;dhx_skyblue&quot;);
    //mygrid.enableHeaderMenu();
    mygrid.enableColumnMove(true);
    mygrid.enableContextMenu(menu);
    dhtmlxEvent(mygrid.hdr, &quot;contextmenu&quot;, function(ev) {
        ev = ev || event;
        var el = ev.target || ev.srcElement;
        var zel = el;
        while (zel.tagName != &quot;TABLE&quot;)
            zel = zel.parentNode;
        var grid = zel.grid;
        if (!grid)
            return;
        grid.setActive();

        el = grid.getFirstParentOfType(el, &quot;TD&quot;)

        if ((grid) &amp;#038;&amp; (!grid._colInMove)) {
            grid.resized = null;
            if ((!grid._mCols) || (grid._mCols[el._cellIndex] == &quot;true&quot;))
                                //获得表头右键菜单焦点所在列索引
                colId = el._cellIndex + 1;
        }

        function mouseCoords(ev) {
            if (ev.pageX || ev.pageY) {
                return {
                    x : ev.pageX,
                    y : ev.pageY
                };
            }
            var d = _isIE &amp;#038;&amp; document.compatMode != &quot;BackCompat&quot; ? 
                             document.documentElement: document.body;
            return {
                x : ev.clientX + d.scrollLeft - d.clientLeft,
                y : ev.clientY + d.scrollTop - d.clientTop
            };
        }

        var coords = mouseCoords(ev);
        menu.addContextZone(&quot;header_id&quot;);
        menu.showContextMenu(coords.x, coords.y);//强制显示
        return true;
    });

    mygrid.attachEvent(&quot;onBeforeContextMenu&quot;, function(rid, cid, e) {
        return false;//禁止数据区域菜单
    });

    mygrid.loadXML(&quot;../common/grid_ml_16_rows_columns_manipulations.xml&quot;);

    mygrid.hdr.id = &quot;header_id&quot;;
    var header_row = mygrid.hdr.rows[1];
    for ( var i = 0; i &lt; header_row.cells.length; i++) {
        header_row.cells[i].id = &quot;context_zone_&quot; + i;
    }
&lt;/pre&gt;


&lt;p&gt;效果图如下;&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img src=&quot;/files/2011/07/dhtmlxgrid-custom-head-menu.jpg&quot; alt=&quot;&quot; title=&quot;dhtmlxgrid-custom-head-menu&quot; width=&quot;300&quot; height=&quot;154&quot; class=&quot;aligncenter size-medium wp-image-2291&quot; /&gt;&lt;/div&gt;



</content>
 </entry>
 
 <entry>
   <title>Drag an item to dhtmlxGrid and add a column</title>
   <link href="http://blog.javachen.com/javascript/2011/07/24/drag-an-item-to-dhtmlxgrid-and-add-a-column"/>
   <updated>2011-07-24T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/07/24/drag-an-item-to-dhtmlxgrid-and-add-a-column</id>
   <content type="html">&lt;p&gt;dhtmlxGrid支持tree和grid、grid之间、grid内部进行拖拽，如在grid内部进行拖拽，可以增加一行；在grid之间拖拽，第一个grid的记录删除，第二个grid增加一行记录。如果我想在拖拽之后不是添加一行而是一列，该怎么做呢？
现在有个需求，就是左边有个tree，右边有个grid，将左边tree的一个节点拖到右边grid的表头并动态增加一列。这个怎么做呢？
如果你想快点看到最后的实现方法，你可以直接跳到本文的最后参看源码。
首先看看dhtmlxTree 关于&lt;a href=&quot;http://www.dhtmlx.com/docs/products/dhtmlxGrid/samples/05_drag_n_drop/&quot;&gt;Drag-n-Drop&lt;/a&gt;的例子，其中有这样一个例子&lt;a href=&quot;http://www.dhtmlx.com/docs/products/dhtmlxTree/samples/05_drag_n_drop/08_pro_drag_out.html&quot;&gt;Custom Drag Out&lt;/a&gt;。
上面的例子，右边定义了一个输入框，其id为“sInput”，代码如下：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;function maf() {
    return false;
}
tree = new dhtmlXTreeObject(&quot;treeboxbox_tree&quot;, &quot;100%&quot;, &quot;100%&quot;, 0);

tree.setSkin('dhx_skyblue');
tree.setImagePath(&quot;../../codebase/imgs/csh_yellowbooks/&quot;);
tree.enableDragAndDrop(true);
tree.setDragHandler(maf);
tree.enableSmartXMLParsing(true);
tree.loadXML(&quot;../common/tree_05_drag_n_drop.xml&quot;);

function s_control() {
    this._drag = function(sourceHtmlObject, dhtmlObject, targetHtmlObject) {
        targetHtmlObject.style.backgroundColor = &quot;&quot;;
        targetHtmlObject.value = sourceHtmlObject.parentObject.label;
    }
    this._dragIn = function(htmlObject, shtmlObject) {
        htmlObject.style.backgroundColor = &quot;#fffacd&quot;;
        return htmlObject;
    }
    this._dragOut = function(htmlObject) {
        htmlObject.style.backgroundColor = &quot;&quot;;
        return this;
    }
}
var sinput = document.getElementById('sInput');
tree.dragger.addDragLanding(sinput, new s_control);
&lt;/pre&gt;


&lt;p&gt;为了使tree支持拖拽功能，必须添加以下代码：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;tree.enableDragAndDrop(true);&lt;/pre&gt;


&lt;p&gt;为了实现自定义拖拽的输出，添加了以下代码：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;tree.dragger.addDragLanding(sinput, new s_control);&lt;/pre&gt;


&lt;p&gt;从上面的字母意思可以看出，是在tree的拖拽对象dragger对象上添加一个拖拽着地对象，第一个常数是指拖拽到哪一个区域，第二个常数定义拖拽的三个方法：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;    this._drag = function(sourceHtmlObject, dhtmlObject, targetHtmlObject) {
        targetHtmlObject.style.backgroundColor = &quot;&quot;;
        targetHtmlObject.value = sourceHtmlObject.parentObject.label;
    }
    this._dragIn = function(htmlObject, shtmlObject) {
        htmlObject.style.backgroundColor = &quot;#fffacd&quot;;
        return htmlObject;
    }
    this._dragOut = function(htmlObject) {
        htmlObject.style.backgroundColor = &quot;&quot;;
        return this;
    }
&lt;/pre&gt;


&lt;p&gt;参照上面的思路，我们可以在grid的表头上面定义一个id，然后通过该id获得表头的dom对象，更好的一个方法是通过mygrid.hdr（看看源码就知道列）能过获得grid的表头对象，然后调用下面的方法，定义tree拖拽到grid的表头：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;tree.dragger.addDragLanding(mygrid.hdr, new s_control);&lt;/pre&gt;


&lt;p&gt;但是这个时候，你将tree的一个节点拖到grid的表头，grid不会有任何反应，故需要改写s_control对象的方法，这里主要是改写一个方法：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
    var insertId;
    this._drag = function(sourceHtmlObject, dhtmlObject,
        targetHtmlObject, e) {
    var zel = e;
    while (zel.tagName != &quot;TABLE&quot;)
        zel = zel.parentNode;
    var grid = zel.grid;
    if (!grid)
        return;
    grid.setActive();
    if (!grid._mCol || e.button == 2)
        return;
    e = grid.getFirstParentOfType(e, &quot;TD&quot;)

    if ((grid) &amp;amp;&amp;amp; (!grid._colInMove)) {
        grid.resized = null;
        if ((!grid._mCols) || (grid._mCols[e._cellIndex] == &quot;true&quot;))
            insertId = e._cellIndex + 1;
    }

    mygrid.insertColumn(insertId, &quot;12&quot;, &quot;ed&quot;, 80);
}
&lt;/pre&gt;


&lt;p&gt;该方法主要做的事情是计算拖拽落脚时候鼠标焦点所在的列，然后在其右边添加一新的列。&lt;/p&gt;

&lt;div class=&quot;pic&quot;&gt;
&lt;img class=&quot;aligncenter&quot; title=&quot;QQ20110724211631&quot; src=&quot;/files/2011/07/QQ20110724211631.png&quot; alt=&quot;&quot; /&gt;
&lt;/div&gt;


&lt;p&gt;本例最后的代码：&lt;/p&gt;

&lt;pre escaped=&quot;true&quot; lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
    var mygrid;
    function maf() {
        return false;
    }

    tree = new dhtmlXTreeObject(&quot;treeboxbox_tree&quot;, &quot;100%&quot;, &quot;100%&quot;, 0);
    tree.setSkin('dhx_skyblue');
    tree.setImagePath(&quot;../../dhtmlxTree/codebase/imgs/csh_yellowbooks/&quot;);
    tree.enableDragAndDrop(true);
    //tree.setDragHandler(maf);
    tree.enableSmartXMLParsing(true);
    tree.loadXML(&quot;../../dhtmlxTree/samples/common/tree_05_drag_n_drop.xml&quot;)
    tree.openAllItems(0);

    function s_control() {
        var insertId;
        this._drag = function(sourceHtmlObject, dhtmlObject,
                targetHtmlObject, e) {
            var zel = e;
            while (zel.tagName != &quot;TABLE&quot;)
                zel = zel.parentNode;
            var grid = zel.grid;
            if (!grid)
                return;
            grid.setActive();
            if (!grid._mCol || e.button == 2)
                return;
            e = grid.getFirstParentOfType(e, &quot;TD&quot;)

            if ((grid) &amp;&amp; (!grid._colInMove)) {
                grid.resized = null;
                if ((!grid._mCols) || (grid._mCols[e._cellIndex] == &quot;true&quot;))
                    insertId = e._cellIndex + 1;
            }

            mygrid.insertColumn(insertId, &quot;12&quot;, &quot;ed&quot;, 80);
        }
    }
    mygrid = new dhtmlXGridObject('gridbox');
    mygrid.setImagePath(&quot;../codebase/imgs/&quot;);
    mygrid.setHeader(&quot;Sales,Book Title,Author,Price,In Store,Shipping,Bestseller,
              Date of Publication&quot;);
    mygrid.setInitWidths(&quot;50,150,100,80,80,80,80,200&quot;);
    mygrid.setColAlign(&quot;right,left,left,right,center,left,center,center&quot;);
    mygrid.setColTypes(&quot;dyn,edtxt,ed,price,ch,co,ra,ro&quot;);
    mygrid.enableDragAndDrop(&quot;temporary_disabled&quot;, true);
    mygrid.init();
    mygrid.setSkin(&quot;dhx_skyblue&quot;);
    mygrid.enableHeaderMenu();
    mygrid.enableColumnMove(true);
    mygrid.setColumnHidden(2, true);
    mygrid.attachEvent(&quot;onHeaderClick&quot;, function(ind, obj) {
    });
    mygrid.loadXML(&quot;../common/grid_ml_16_rows_columns_manipulations.xml&quot;);
    tree.dragger.addDragLanding(mygrid.hdr, new s_control);
&lt;/pre&gt;


&lt;p&gt;本文实现的是将tree拖拽到grid，其实其他的一些支持拖拽的组件也可以做，并不局限于tree组件，甚至还见过有人实现jquery的dtree拖拽到dhtmlxGrid增加一行记录。&lt;/p&gt;

&lt;h2&gt;参考文章&lt;/h2&gt;


&lt;p&gt;&lt;li&gt;
Custom Drag Out：&lt;a href=&quot;http://www.dhtmlx.com/docs/products/dhtmlxTree/samples/05_drag_n_drop/08_pro_drag_out.html&quot; target=&quot;_blank&quot;&gt;http://www.dhtmlx.com/docs/products/dhtmlxTree/samples/05_drag_n_drop/08_pro_drag_out.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;dhtmlxGrid doc：&lt;a href=&quot;http://docs.dhtmlx.com/doku.php?id=dhtmlxgrid:toc&quot; target=&quot;_blank&quot;&gt;http://docs.dhtmlx.com/doku.php?id=dhtmlxgrid:toc&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;dhtmlxTree doc：&lt;a href=&quot;http://docs.dhtmlx.com/doku.php?id=dhtmlxtree:toc&quot; target=&quot;_blank&quot;&gt;http://docs.dhtmlx.com/doku.php?id=dhtmlxtree:toc&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DhtmlxGrid Quick Start Guide</title>
   <link href="http://blog.javachen.com/javascript/2011/07/19/dhtmlxgrid-quick-start-guide"/>
   <updated>2011-07-19T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/javascript/2011/07/19/dhtmlxgrid-quick-start-guide</id>
   <content type="html">&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;strong&gt;说明:&lt;/strong&gt;&lt;/span&gt;本文来源于&lt;a href=&quot;http://dhtmlx.com/docs/products/dhtmlxGrid/&quot;&gt;http://dhtmlx.com/docs/products/dhtmlxGrid/&lt;/a&gt;，本人对其进行翻译整理成下文，贴出此文，紧供分享。&lt;/p&gt;




&lt;p&gt;&lt;p&gt;dhtmlxGrid是一个拥有强大的数据绑定、优秀的大数据展示性能并支持ajax的JavaScript表格控件。该组件易于使用并通过富客户端的API提供了很大的扩展性。dhtmlxGrid支持不同的数据源（XML, JSON, CSV, JavaScript 数组和HTML表格），如果需要的话，还可以从自定义的xml中加载数据。
&lt;ul&gt;
    &lt;li&gt;跨浏览器&lt;/li&gt;
    &lt;li&gt;使用JavaScript API进行控制&lt;/li&gt;
    &lt;li&gt;Ajax支持&lt;/li&gt;
    &lt;li&gt;简单的JavaScript 或者XML 配置&lt;/li&gt;
    &lt;li&gt;与HTML集成&lt;/li&gt;
    &lt;li&gt;内建过滤、排序、查询、分组功能&lt;/li&gt;
    &lt;li&gt;表格 footer/header自动计算&lt;/li&gt;
    &lt;li&gt;行内编辑&lt;/li&gt;
    &lt;li&gt;准备使用大数据集解决方案：分页，动态加载，智能渲染&lt;/li&gt;
    &lt;li&gt;序列化为XML或CSV&lt;/li&gt;
    &lt;li&gt;从 XML或CSV加载&lt;/li&gt;
    &lt;li&gt;列锁定&lt;/li&gt;
    &lt;li&gt;剪贴板支持&lt;/li&gt;
    &lt;li&gt;简单的客户端到服务器端配置 (使用 dhtmlxConnector, 可用于 PHP, Java, .NET, ColdFusion)&lt;/li&gt;
    &lt;li&gt;支持子表格&lt;/li&gt;
    &lt;li&gt;列拖拽和移动&lt;/li&gt;
    &lt;li&gt;行或列拖拽&lt;/li&gt;
    &lt;li&gt;dhtmlxTree PRO Edition支持拖拽&lt;/li&gt;
    &lt;li&gt;可以创建一个编辑器或是列格式化 (使用 eXcell – 继承自 cell 对象)&lt;/li&gt;
    &lt;li&gt;组合框，日历以及更多的预定义eXcells&lt;/li&gt;
    &lt;li&gt;Cell支持数学方程式&lt;/li&gt;
    &lt;li&gt;不同的键盘映射&lt;/li&gt;
    &lt;li&gt;简单的CSS风格或是预定义的皮肤&lt;/li&gt;
    &lt;li&gt;对于rows/entire grid不可见的数据块 (用户数据)&lt;/li&gt;
    &lt;li&gt;客户端排序(string, integer, date, custom)&lt;/li&gt;
    &lt;li&gt;服务器端排序&lt;/li&gt;
    &lt;li&gt;广泛的事件处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;!--more--&gt;
Step 1 – 引入文件&lt;/h2&gt;
&lt;pre lang=&quot;html&quot; line=&quot;1&quot;&gt;
&amp;lt; link rel =&quot;STYLESHEET&quot; type=&quot;text/css&quot; href=&quot;codebase/dhtmlxgrid.css&quot; /&gt;
&amp;lt; script src=&quot;codebase/dhtmlxcommon.js&quot;&gt;&amp;lt; /script&gt;
&amp;lt; script src=&quot;codebase/dhtmlxgrid.js&quot;&gt;&amp;lt; /script&gt;
&amp;lt; script src=&quot;codebase/dhtmlxgridcell.js&quot;&gt;&amp;lt; /script&gt;
&amp;lt; script&gt;
    //we'll write script commands here
&amp;lt; /script&gt;
&lt;/pre&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;&lt;h2&gt;Step 2 – 放置gird&lt;/h2&gt;
有两种方式在一个页面放置grid，这里减少最常用的方法：创建一个div并给id熟悉设置一个惟一值。例如：
&lt;pre&gt;  &amp;lt; div id=&quot;mygrid_container&quot; style=&quot;width:600px;height:150px;&quot;&gt;&amp;lt; /div&gt;&lt;/pre&gt;
下面初始化参数，首先定一个mygrid变量，然后定一个doInitGrid方法，方法内部进行mygrid初始化工作：
&lt;pre&gt;
 var mygrid;
 function doInitGrid(){
 }
&lt;/pre&gt;
doInitGrid方法会包括以下代码：&lt;br /&gt;
o 使用dhtmlXGridObject构造方法创建一个基于我们之前创建的DIV的grid对象；&lt;br /&gt;
o 设置grid图片路径。这个路径包括grid外观需要的所有图片。在大多数情况下该路径为“codebase/imgs/”. 该路径最后面的一个“/”很重要。 随便说一下，这个路径和你处理表格数据所使用的图片没有关系；&lt;br /&gt;
o 使用setHeader 方法定义表头；&lt;br /&gt;
o 使用setInitWidths (单位为像素) 或setInitWidthsP (单位为百分比)定义列宽。 使用*代表让列自动使用所有表格宽度；&lt;br /&gt;
o 定义一个列的水平对其方式。 Numeric values is better to align right;&lt;br /&gt;
o 使用setSkin方法设置皮肤；&lt;br /&gt;
o 最好使用这些设置通过init方法初始化grid。更多的参数之后再讨论。目前，doInitGrid方法如下：
&lt;pre&gt;
mygrid = new dhtmlXGridObject('mygrid_container');
mygrid.setImagePath(&quot;codebase/imgs/&quot;); //指定图片路径
mygrid.setHeader(&quot;Model,Qty,Price&quot;); //设置表头显示
grid.setInitWidths(&quot;*,150,150&quot;); //设置列的初始宽度
grid.setColAlign(&quot;left,right,right&quot;); //设置列的水平对其方式
mygrid.setSkin(&quot;light&quot;); //设置皮肤
grid.init(); //显示调用初始化方法，必须的
&lt;/pre&gt;
现在需要做的是运行该方法，可以将该方法加入body的onload方法里或是使用jquery的方法。下面使用body的onload方法：
&lt;pre&gt;&amp;lt; body onload=&quot;doInitGrid();&quot;&gt;&amp;lt; /body&gt;&lt;/pre&gt;
这样在该页面初始化之后会显示如下：
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?cache=&amp;amp;media=dhtmlxgrid:step_2_last.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
说明：除了调用set方法之外，还可以如下风格定义：
&lt;pre lang=&quot;Javascript&quot;&gt;mygrid = new dhtmlXGridObject({
        parent:&quot;a_grid&quot;,
        image_path:&quot;codebase/imgs&quot;,
        columns:[
            { label: &quot;Sales&quot;,           width:50,   type:&quot;ed&quot; },
            { label:[&quot;Book title&quot;,
                 &quot;#text_filter&quot;],   width:150,  type:&quot;ed&quot; },
            { label:[&quot;Author&quot;,
                 &quot;#select_filter&quot;], width:150,  type:&quot;ed&quot; },
            { label: &quot;Price&quot;,       width:50,   type:&quot;ed&quot; },
            { label:&quot;In store&quot; ,    width:80,   type:&quot;ch&quot; },
            { label:&quot;Shipping&quot; ,    width:50,   type:&quot;ed&quot; },
            { label:&quot;Bestseller&quot; ,  width:50,   type:&quot;ed&quot; },
            { label:&quot;Date&quot; ,    width:50,   type:&quot;ed&quot; }
        ],&lt;/pre&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;     xml:&quot;data.xml&quot;&lt;br /&gt;
    });
&lt;h2&gt;Step 3 – 填充数据&lt;/h2&gt;
你已经知道了dhtmlxGrid可以加载xml或cvs或json数据，这里主要演示dhtmlxGrid加载json数据。&lt;br /&gt;
在上面的例子中每行有三列，故我们的json数据如下：
&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt;{
rows:[
{
        id: &quot;a&quot;,
        data: [Model 1, 100, 399]
},
{
id: &quot;b&quot;,
        data: [Model 2, 50, 649]
},
{
    id: &quot;c&quot;,
       data: [ Model 3, 70, 499]
}
]
}&lt;/pre&gt;
将上面存于data.json文件，然后在doInitGrid方法里调用以下方法：
&lt;pre lang=&quot;javascript&quot;&gt;mygrid.load (&quot;data.json&quot;，,&quot;json&quot;);&lt;/pre&gt;
这时候页面展示如下：
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?cache=&amp;amp;media=dhtmlxgrid:step_3.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h2&gt;Step 4 – 客户端排序&lt;/h2&gt;
为了能够实习表格的客户端排序，必须调用grid的setColSorting（sortTypesStr）方法。sortTypesStr是一个类型列表，以逗号分隔。该类型值有以下四种：&lt;br /&gt;
o str – 作为字符串排序&lt;br /&gt;
o int - 以Integer值排序 (通常可以是任何数字);&lt;br /&gt;
o date – 以日期排序&lt;br /&gt;
o custom sorting –自定义的更加复杂的排序方式(for example to sort days of week).&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;接下来我们对上面的例子进行排序。上例中每行有三列，第一列为字符串，后两列为数字，故可以调用以下方法进行排序。注意，该方法应该在init方法之前执行。
&lt;pre lang=&quot;javascript&quot;&gt;mygrid.setColSorting(&quot;str,int,int&quot;);&lt;/pre&gt;
这时候单击最后一列表头，结果如下：
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?media=dhtmlxgrid:step_4.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h2&gt;Step 5 – 单元格格式化和编辑&lt;/h2&gt;
Grid中使用单元格的编辑器（或是eXcells – 继承自 Cells, Cell 或 Columns types）来定义值的格式和编辑方式。你可以根据你的需要创建eXcells。&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;设定单元格的类型非常容易，其可以用一行代码定义。这里有一些常见的编辑器，如简单的编辑器代码为“ed”，多行编辑“txt”，只读单元格“ro”，复选框“ch”，价格的格式化“price”。&lt;br /&gt;
默认情况下所有的列是“ro”，也可以使用以下方法类设置编辑类型：
&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
mygrid.setColTypes(&quot;ed,ed,price&quot;);
&lt;/pre&gt; &lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;p&gt;Excells格式化有以下几种：
&lt;div class=&quot;note&quot;&gt; link：超链接&lt;br /&gt;
 img：图片&lt;br /&gt;
 price：价格&lt;br /&gt;
 dyn：动态行&lt;/div&gt;
Excell 复杂编辑器有以下几种：
&lt;div class=&quot;note&quot;&gt; cp：colorpicker&lt;br /&gt;
 calck：允许调用grid.setNumberFormat的计算器&lt;br /&gt;
 dhxCalendar：日历，日期格式可以通过grid.setDateFormat设置&lt;br /&gt;
 dhxCalendarA：日历，日期格式可以通过grid.setDateFormat设置，单元格可以编辑&lt;br /&gt;
 calendar：YUI Calendar&lt;br /&gt;
 clist：多选组件&lt;/div&gt;
使用其他组件作为单元格编辑器
&lt;div class=&quot;note&quot;&gt; grid：使用dhtmlxgrid&lt;br /&gt;
 stree ：使用dhtmlxtree&lt;br /&gt;
 context：使用dhtmlxmenu&lt;br /&gt;
 combo：使用dhtmlxCombo&lt;/div&gt;
Excells特别用途
&lt;div class=&quot;note&quot;&gt;sub_row：允许单元格作为一个可展开的子单元格，就想查看明细一样。&lt;br /&gt;
两个扩展&lt;br /&gt;
o sub_row_ajax – 单元格数据被认为是ajax请求的url&lt;br /&gt;
o sub_row_grid – 允许创建一个子表作为一个子行的内容&lt;/div&gt;
现在你可以双击或是F2进入编辑模式，你可以用tab键在单元格之间导航。
&lt;div class=&quot;pic&quot;&gt;&lt;img src=&quot;http://docs.dhtmlx.com/lib/exe/fetch.php?media=dhtmlxgrid:step_5.png&quot; alt=&quot;&quot; /&gt;&lt;/div&gt;
&lt;h2&gt;Step 6 – 行操作方法&lt;/h2&gt;
&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt;    function addRow(){
        var newId = (new Date()).valueOf()
        mygrid.addRow(newId,&quot;&quot;,mygrid.getRowsNum())
        mygrid.selectRow(mygrid.getRowIndex(newId),false,false,true);
    }
    function removeRow(){
        var selId = mygrid.getSelectedId()
        mygrid.deleteRow(selId);
    }&lt;/pre&gt;
代码中addRow() 方法的一些说明：
&lt;div class=&quot;note&quot;&gt;o 创建一个惟一值 (number of millisecond since 1970) 来作为row的标识；&lt;br /&gt;
o 在最后一行后面添加一新行，该行有新的id，值为空；&lt;br /&gt;
o 选中最近创建的行 (by index), 不掉用 On-Select事件，不掉用选中行之前事件并且聚焦到选中行(如果垂直滚动条存在，则滚动对应位置)。&lt;/div&gt;
代码中removeRow() 的一些说明（一行行的）:
&lt;div class=&quot;note&quot;&gt;o 得到选中行id；&lt;br /&gt;
o 删除指定行id的行&lt;/div&gt;
&lt;h2&gt;Step 7 – 事件&lt;/h2&gt;
添加事件调用attachEvent 方法，如下行选中事件：
&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt; &lt;br/&gt;
    function doOnRowSelected(rowID,celInd){
        alert(&quot;Selected row ID is &quot;+rowID+&quot;\nUser clicked cell with index &quot;+celInd);
    }
    mygrid.attachEvent(&quot;onRowSelect&quot;,doOnRowSelected);&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;&lt;h2&gt;Step 8 – Code&lt;/h2&gt;
最后的代码：
&lt;pre lang=&quot;javascript&quot; line=&quot;1&quot;&gt;
 &amp;lt; title&gt;dhtmlxGrid Sample Page&amp;lt; /title&gt;
     &amp;lt; link rel=&quot;STYLESHEET&quot; type=&quot;text/css&quot; href=&quot;codebase/dhtmlxgrid.css&quot; /&gt;
     &amp;lt; script src=&quot;codebase/dhtmlxcommon.js&quot;&gt;&amp;lt; /script&gt;
     &amp;lt; script src=&quot;codebase/dhtmlxgrid.js&quot;&gt;&amp;lt; /script&gt;
     &amp;lt; script src=&quot;codebase/dhtmlxgridcell.js&quot;&gt;&amp;lt; /script&gt;
     &amp;lt; script&gt;
      var mygrid;&lt;br /&gt;
      function doInitGrid(){&lt;br /&gt;
       mygrid = new dhtmlXGridObject('mygrid_container');&lt;br /&gt;
       mygrid.setImagePath(&quot;codebase/imgs/&quot;);&lt;br /&gt;
       mygrid.setHeader(&quot;Model,Qty,Price&quot;);&lt;br /&gt;
       mygrid.setInitWidths(&quot;*,150,150&quot;);&lt;br /&gt;
       mygrid.setColAlign(&quot;left,right,right&quot;)&lt;br /&gt;
       mygrid.setSkin(&quot;light&quot;);&lt;br /&gt;
       mygrid.setColSorting(&quot;str,int,int&quot;);&lt;br /&gt;
       mygrid.setColTypes(&quot;ed,ed,price&quot;);&lt;br /&gt;
       mygrid.attachEvent(&quot;onRowSelect&quot;,doOnRowSelected);&lt;br /&gt;
       mygrid.init();&lt;br /&gt;
       mygrid.load (&quot;data.json&quot;,&quot;json&quot;);&lt;br /&gt;
      }
     function addRow(){&lt;br /&gt;
       var newId = (new Date()).valueOf()&lt;br /&gt;
       mygrid.addRow(newId,&quot;&quot;,mygrid.getRowsNum())&lt;br /&gt;
       mygrid.selectRow(mygrid.getRowIndex(newId),false,false,true);&lt;br /&gt;
      }&lt;br /&gt;
      function removeRow(){&lt;br /&gt;
       var selId = mygrid.getSelectedId()&lt;br /&gt;
       mygrid.deleteRow(selId);&lt;br /&gt;
      }
     function doOnRowSelected(rowID,celInd){&lt;br /&gt;
       alert(&quot;Selected row ID is &quot;+rowID+&quot;\nUser clicked cell with index &quot;+celInd);&lt;br /&gt;
      }
   &amp;lt; /script&gt;
   &amp;lt; body onload=&quot;doInitGrid()&quot;&gt;
      &amp;lt; div id=&quot;mygrid_container&quot; style=&quot;width:600px;height:150px;&quot;&gt;&amp;lt; /div&gt;
   &amp;lt; /body&gt;
&lt;/pre&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>网上收集的关于OpenStack的一些资源</title>
   <link href="http://blog.javachen.com/cloud/2011/07/07/some-resources-about-openstack"/>
   <updated>2011-07-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/07/07/some-resources-about-openstack</id>
   <content type="html">&lt;p&gt;&lt;li&gt;
&lt;span class=&quot;Apple-style-span&quot; style=&quot;font-size: 13px; font-weight: normal;&quot;&gt;OpenStack Nova code：&lt;a href=&quot;https://bugs.launchpad.net/nova&quot; target=&quot;_blank&quot;&gt;https://bugs.launchpad.net/nova&lt;/a&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;
OpenStack Blog：&lt;a href=&quot;http://planet.openstack.org/&quot; target=&quot;_blank&quot;&gt;http://planet.openstack.org/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack 官方文档：&lt;a href=&quot;http://docs.openstack.org/cactus/openstack-compute/admin/content/ch_getting-started-with-openstack.html&quot; target=&quot;_blank&quot;&gt;http://docs.openstack.org/cactus/openstack-compute/admin/content/ch_getting-started-with-openstack.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack 中国门户：&lt;a href=&quot;http://blu001068.chinaw3.com/bbs/portal.php&quot; target=&quot;_blank&quot;&gt;http://blu001068.chinaw3.com/bbs/portal.php&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;在 Ubuntu 上安装和配置 OpenStack Nova：&lt;a href=&quot;http://www.vpsee.com/2011/05/install-openstack-nova-on-ubuntu/&quot; target=&quot;_blank&quot;&gt;http://www.vpsee.com/2011/05/install-openstack-nova-on-ubuntu/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Centos安装过程：&lt;a href=&quot;http://wiki.openstack.org/NovaInstall/CentOSNotes&quot; target=&quot;_blank&quot;&gt;http://wiki.openstack.org/NovaInstall/CentOSNotes&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Running OpenStack Compute (Nova)：&lt;a href=&quot;http://wiki.openstack.org/RunningNova&quot; target=&quot;_blank&quot;&gt;http://wiki.openstack.org/RunningNova&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;开源黄页 -  OpenStack：&lt;a href=&quot;http://yp.oss.org.cn/appcenter/software/show_software.php?sw_id=1733&quot; target=&quot;_blank&quot;&gt;http://yp.oss.org.cn/appcenter/software/show_software.php?sw_id=1733&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Installation on Debian, Fedora orCentOS：&lt;a href=&quot;http://nova.openstack.org/adminguide/distros/others.html&quot; target=&quot;_blank&quot;&gt;http://nova.openstack.org/adminguide/distros/others.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Installing Nova on a Single Host：&lt;a href=&quot;http://nova.openstack.org/adminguide/single.node.install.html&quot; target=&quot;_blank&quot;&gt;http://nova.openstack.org/adminguide/single.node.install.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack swift 典型架构和openstack swift 简要说明：&lt;a href=&quot;http://blog.sina.com.cn/s/blog_6b98772b0100pk7p.html&quot; target=&quot;_blank&quot;&gt;http://blog.sina.com.cn/s/blog_6b98772b0100pk7p.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Swift 技术验证简单报告 :&lt;a href=&quot;http://www.douban.com/group/topic/17621229/&quot; target=&quot;_blank&quot;&gt;http://www.douban.com/group/topic/17621229/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;新浪上openstack_object_storage的一些文章：&lt;a href=&quot;http://blog.sina.com.cn/s/blog_6b98772b0100pk7p.html&quot; target=&quot;_blank&quot;&gt;http://blog.sina.com.cn/s/articlelist_1805154091_2_1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;豆瓣上OpenStack收集资源：&lt;a href=&quot;http://www.douban.com/group/openstack/&quot; target=&quot;_blank&quot;&gt;http://www.douban.com/group/openstack/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack服务部署： &lt;a href=&quot;http://hi.baidu.com/juacm/blog/item/bd05d154e7581e451138c277.html&quot; target=&quot;_blank&quot;&gt;http://hi.baidu.com/juacm/blog/item/bd05d154e7581e451138c277.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;陈沙克日志：&lt;a href=&quot;http://hi.baidu.com/chenshake/home&quot; target=&quot;_blank&quot;&gt;http://hi.baidu.com/chenshake/home&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;Openstack-nova-architecture：&lt;a href=&quot;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&quot; target=&quot;_blank&quot;&gt;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack 架构：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6543880&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6543880&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
安装OpenStack：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6566370&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6566370&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
安装OpenStack-dashboard：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6572868&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6572868&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
Centos-nova-install.sh： &lt;a href=&quot;https://gist.github.com/837797&quot; target=&quot;_blank&quot;&gt;https://gist.github.com/837797&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
RabbitMQ and Nova：&lt;a href=&quot;http://blog.163.com/clevertanglei900@126/blog/static/11135225920101110393888/&quot; target=&quot;_blank&quot;&gt;http://blog.163.com/clevertanglei900@126/blog/static/11135225920101110393888/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;OpenStack(diablo-2)のNovaをインストール@CentOS6　メモ(1/n)：&lt;a href=&quot;http://blog.livedoor.jp/techpub/archives/3797358.html&quot; target=&quot;_blank&quot;&gt;OpenStack(diablo-2)のNovaをインストール@CentOS6　メモ(1/n)&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-内容列表（0）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563033-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563033-1-1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-基础部分（1）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563017-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563017-1-1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-增强部分（2）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563046-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563046-1-1.html&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;openstack nova部署完整实例-参考手册-增强部分（3）：&lt;a href=&quot;http://bbs.chinaunix.net/thread-3563049-1-1.html&quot; target=&quot;_blank&quot;&gt;http://bbs.chinaunix.net/thread-3563049-1-1.html&lt;/a&gt;
&lt;/li&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>OpenStack架构预览</title>
   <link href="http://blog.javachen.com/cloud/2011/07/07/openstack-architecture-overview"/>
   <updated>2011-07-07T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/07/07/openstack-architecture-overview</id>
   <content type="html">&lt;p&gt;&lt;h2&gt;What is OpenStack?&lt;/h2&gt;
OpenStack提供开放源码软件，建立公共和私有云。 OpenStack是一个社区和一个项目，以及开放源码软件，以帮助企业运行的虚拟计算或者存储云。 OpenStackd开源项目由社区维护，包括OpenStack计算（代号为Nova），OpenStack对象存储（代号为SWIFT），并OpenStack镜像服务（代号Glance）的集合。 OpenStack提供了一个操作平台，或工具包，用于编排云。
&lt;h2&gt;Components of OpenStack&lt;/h2&gt;
OpenStack当前主要有三个组件：计算，存储，镜像。&lt;br /&gt;
OpenStack计算是一个云控制器，用来启动一个用户或一个组的虚拟实例，它也用于配置每个实例或项目中包含多个实例为某个特定项目的联网。&lt;br /&gt;
OpenStack对象存储是一个在具有内置冗余和容错的大容量系统中存储对象的系统。对象存储有各种应用，如备份或存档数据，存储图形或视频（流媒体数据传输到用户的浏览器），储存二级或三级静态数据，发展与数据存储集成新的应用程序，当预测存储容量困难时存储数据，创造弹性和灵活的云存储Web应用程序。&lt;br /&gt;
OpenStack镜像服务是一个查找和虚拟机图像检索系统。它可以配置三种方式：使用OpenStack对象存储来存储图像;使用亚马逊S3直接存储，或使用S3对象存储作为S3访问中间存储。
&lt;h2&gt;OpenStack Project Architecture&lt;/h2&gt;
OpenStack当前包括三个子项目，三个项目相会独立，可以单独安装。&lt;br /&gt;
• Swift 提供对象存储。这是大致类似于Rackspace云文件（从它派生）或亚马逊S3。&lt;br /&gt;
• Glance 提供OpenStack Nova虚拟机镜像的发现，存储和检索。&lt;br /&gt;
• Nova 根据要求提供虚拟服务。这与Rackspace云服务器或亚马逊EC2类似。&lt;br /&gt;
将来会出现web 接口的子项目以及队列服务的子项目。
&lt;h2&gt;Cloud Provider Conceptual Architecture&lt;/h2&gt;
构建自己的Iaas云环境并将其提供给用户，需要提供以下几个特性：&lt;br /&gt;
1. 允许应用用户注册云服务、查看使用情况以及账单。&lt;br /&gt;
2. 允许开发商和开发人员创建和存储自定义的镜像。&lt;br /&gt;
3. 允许开发商和开发人员启动、监控、停止虚拟机实例。&lt;br /&gt;
4. 允许操作人员配置和操作云基础设施。&lt;!--more--&gt;&lt;/p&gt;




&lt;p&gt;上面只列出了基本的4个特性，当然还有其他一些特性，将这些特性列在一起，展示如下：
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Cloud-Provider-Conceptual-Architecture.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2123 aligncenter&quot; title=&quot;Cloud Provider Conceptual Architecture&quot; src=&quot;http://blog.javachen.com/files/2011/07/Cloud-Provider-Conceptual-Architecture-300x219.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;219&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
在上面的模型中，假定了与云交互的四种人员（开发商、开发人员、操作员、用户），还定义了三层架构（表现、逻辑、资源）和两个正交领域（集成和管理）。&lt;br /&gt;
表现层，组件与用户交互，接受并显示用户的信息。在这一层，为非开发人员提供了一个web 图形界面，为开发人员提供了API。在这一层，还存在负载均衡、控制台代理、安全、命名服务。&lt;br /&gt;
逻辑层，为我们的云和控制功能提供情报。这层内包括部业务流程（工作流程复杂的任务），调度（确定作业对资源的映射），政策（配额等），镜像注册表（例如镜像的元数据），日志（事件和计量）。&lt;br /&gt;
集成功能，大多数服务提供商已经有一个客户的身份和计费系统。任何云架构将需要与这些系统集成。&lt;br /&gt;
管理层，提供一个API来管理云并提供监控功能。&lt;br /&gt;
资源层，因为这是一个计算云，我们需要实际的计算，网络和存储资源，以提供给客户。这一层提供这些服务，他们可能是服务器，网络交换机，网络附加存储或其他资源。
&lt;h2&gt;OpenStack Compute Logical Architecture&lt;/h2&gt;
OpenStack 中有两个守护进程：&lt;br /&gt;
接收和调解API调用的WSGI应用程序 （nova-api，glance-api等等）。&lt;br /&gt;
进行编排任务的工人守护进程（nova-compute， nova-network,，nova-schedule）。&lt;br /&gt;
OpenStack中还包含两个组件：消息队列服务和数据库。这两个组件方便异步编排复杂的任务通过消息传递和信息共享。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/OpenStack-Compute-Logical-Architecture.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2124 aligncenter&quot; title=&quot;OpenStack Compute Logical Architecture&quot; src=&quot;http://blog.javachen.com/files/2011/07/OpenStack-Compute-Logical-Architecture-300x220.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;220&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
这个复杂的，但不是太翔实的图表可以概括为三句话：&lt;br /&gt;
 终端用户通过nova-api 接口与Openstack 计算交互。&lt;br /&gt;
 OpenStack计算守护进程通过队列的交换信息（行动）和数据库（信息）进行API请求。&lt;br /&gt;
 OpenStack Glance是一个完全独立的基础上设施。
&lt;strong&gt;各个组件的介绍：&lt;/strong&gt;&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-api&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;：&lt;/code&gt;是对外的接口。OpenStack 云计算的核心控制器（CloudController定义在trunk/nova/api/ec2/cloud.py）。它提供了一个为所有的API查询（OpenStack API或EC2 API）的端点，引发多数业务流程的活动（如运行一个实例），并实施一些政策（主要是配额检查）。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-schedule&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;根据当前资源使用情况，决定计算节点分布到哪台计算节点上。目前实现很薄，目前已支持插件方式扩展，方便后面可能有采用更复杂算法。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-compute&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;接收队列中的动作，然后执行一系列的系统命令（如启动KVM实例），同时更新数据库中的状态。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-volume&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;给虚拟机分配额外持久化的存储，管理持久卷到计算实例的创建，连接和分离。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;nova-network&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;网络管理，给虚拟机分配网络和管理，使外部 PC 可以可直接访问。它接受队列中的网络任务，然后执行任务操纵网络（如设立桥接接口或更改iptables规则）。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;queue&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;提供了一个守护进程之间传递消息的中央枢纽。当前由 &lt;a href=&quot;http://www.rabbitmq.com/&quot; target=&quot;_top&quot;&gt;RabbitMQ&lt;/a&gt;实现，理论上可以是Python的ampqlib支持的任何AMPQ消息队列。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;SQL database&lt;/strong&gt;&lt;/code&gt;&lt;code&gt;&lt;strong&gt;：&lt;/strong&gt;&lt;/code&gt;存储云基础设施的编译时和运行时的状态。这包括可用的实例类型，在使用中的实例，可用的网络和项目。&lt;/p&gt;




&lt;p&gt;&lt;code&gt;&lt;strong&gt;OpenStack Glance：&lt;/strong&gt;&lt;/code&gt;OpenStack 单独的一个项目。
&lt;h2&gt;Nova Conceptual Mapping&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenStack的架构示意图和目前已实现情况，蓝色是要 openstack概念上的架构图，红色是目前已实现的。&lt;/p&gt;
上面的功能模块对应上面模型的映射：
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Nova-Conceptual-Mapping.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2125 alignnone&quot; title=&quot;Nova Conceptual Mapping&quot; src=&quot;http://blog.javachen.com/files/2011/07/Nova-Conceptual-Mapping-300x209.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;209&quot; /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;




&lt;p&gt;&lt;h2&gt;Service Architecture&lt;/h2&gt;
管理和使用是走两个通道的。管理必须要经由 nova-api转发过去。而运行时，直接连接计算节点上的虚拟机即可。&lt;strong&gt;&lt;/strong&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2126 aligncenter&quot; title=&quot;Service Architecture&quot; src=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture-300x295.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;295&quot; /&gt;&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;




&lt;p&gt;&lt;h2&gt;部署&lt;/h2&gt;
部署时，除了Dashboard 必须部署在 nova-api server 上以外，所有的其它进程都可以部署在不同的机器上。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2127 aligncenter&quot; title=&quot;Service Architecture2&quot; src=&quot;http://blog.javachen.com/files/2011/07/Service-Architecture2-300x140.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;140&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
OpenStack提供了基于 Puppet 的自动部署工具。经过简单配置，就可以把各个组件部署到不同机器上。
&lt;h2&gt;镜像管理&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenStack的镜像创建并没有纳入其职责列表。&lt;br /&gt;
你可以使用Ubuntu的已有image (https://help.ubuntu.com/community/UEC/)，或者直接重新自己通过KVM安装  ：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;http://cssoss.wordpress.com/2011/04/27/openstack-beginners-guide-for-ubuntu-11-04-image-management/&quot;&gt;http://cssoss.wordpress.com/2011/04/27/openstack-beginners-guide-for-ubuntu-11-04-image-management/&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;




&lt;p&gt;&lt;h2&gt;网络模型&lt;/h2&gt;
Flat Network Manager, Flat DHCP Network Manager, VLAN Network Manager.&lt;br /&gt;
VLAN Network Manager 这种方式适合于共有云。&lt;br /&gt;
在私有云方面， IP充足，而且为了方便的互联互通，简单的Flat结构网络比较适合。&lt;br /&gt;
OpenStack支持 Floating IPs ,该特性可以方便的通过更改IP来Failover(容错转移）或者迁移。
&lt;div class=&quot;note&quot;&gt;
&lt;h2&gt;参考文章&lt;/h2&gt;
OpenStack 架构：&lt;a href=&quot;http://blog.csdn.net/anghlq/article/details/6543880&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/anghlq/article/details/6543880&lt;/a&gt;
nova code:&lt;a href=&quot;https://bugs.launchpad.net/nova&quot; target=&quot;_blank&quot;&gt;https://bugs.launchpad.net/nova&lt;/a&gt;
openstack-nova-architecture：&lt;a href=&quot;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&quot; target=&quot;_blank&quot;&gt;http://ken.pepple.info/openstack/2011/04/22/openstack-nova-architecture/&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>OpenNebula的架构</title>
   <link href="http://blog.javachen.com/cloud/2011/07/06/opennebula-architecture"/>
   <updated>2011-07-06T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/07/06/opennebula-architecture</id>
   <content type="html">&lt;p&gt;&lt;p align=&quot;left&quot;&gt;OpenNebula是一款为云计算而打造的开源工具箱。它允许你与Xen，KVM或VMware ESX一起建立和管理私有云，同时还提供Deltacloud适配器与Amazon EC2相配合来管理混合云。除了像Amazon一样的商业云服务提供商，在不同OpenNebula实例上运行私有云的Amazon合作伙伴也同样可以作为远程云服务供应商。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;目前版本，可支持XEN、KVM和VMware，以及实时存取EC2和 ElasticHosts，它也支持印象档的传输、复制和虚拟网络管理网络。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/one-cloud.png&quot;&gt;&lt;img class=&quot;size-full wp-image-2106 alignnone&quot; title=&quot;one cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/one-cloud.png&quot; alt=&quot;&quot; width=&quot;332&quot; height=&quot;166&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图1  OpenNebula总体架构图&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula可以构建私有云、混合云、公开云。&lt;!--more--&gt;&lt;/p&gt;&lt;/p&gt;




&lt;p&gt;&lt;h2&gt;私有云&lt;/h2&gt;
私有云的目的是给本地的用户和管理员提供了一个灵活和敏捷的私人基础设施，以在可管理的域内运行虚拟化服务。 OpenNebula虚拟基础设施暴露虚拟化、网络、图像和物理资源的配置、管理、监督和会计的功能接口。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/private-cloud1.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2107 alignnone&quot; title=&quot;private cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/private-cloud1-300x187.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;187&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图2 私有云&lt;/p&gt;
一个OpenNebula私有云为平台基础设施的用户提供了一个快速交付和可扩展性的平台，以满足最终用户的动态需求。服务托管在虚拟机，然后提交，监视和被云控制，通过使用OpenNebula运营中心或OpenNebula的任何接口。
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/private-cloud2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2108 aligncenter&quot; title=&quot;private cloud2&quot; src=&quot;http://blog.javachen.com/files/2011/07/private-cloud2-300x206.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;206&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图3 私有云内用户视图&lt;/p&gt;
&amp;nbsp;
&lt;h2&gt;混合云&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula提供Deltacloud适配器与Amazon EC2相配合来管理混合云。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/hyb-cloud2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2109 aligncenter&quot; title=&quot;hyb cloud2&quot; src=&quot;http://blog.javachen.com/files/2011/07/hyb-cloud2-300x203.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;203&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图4 混合云&lt;/p&gt;
&amp;nbsp;
&lt;h2&gt;公开云&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula公有云是私有云的一个扩展，是在私有云的基础上对外暴露REST接口。如果你要让合作伙伴或外部用户能够访问您的基础设施，或出售你的服务，云接口可以被添加到您的私有或混合云。显然，一个本地的云解决方案是任何公共云自然后端。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/public-cloud.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2110 aligncenter&quot; title=&quot;public cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/public-cloud-300x175.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;175&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图5 公开云&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula的构架包括三个部分：驱动层、核心层、工具层。驱动层直接与操作系统打交道，负责虚拟机的创建、启动和关闭，为虚拟机分配存储，监控物理机和虚拟机的运行状况。核心层负责对虚拟机、存储设备、虚拟网络等进行管理。工具层通过命令行界面/浏览器界面方式提供用户交互接口，通过API方式提供程序调用接口。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/07/3-cloud.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2111 aligncenter&quot; title=&quot;3 cloud&quot; src=&quot;http://blog.javachen.com/files/2011/07/3-cloud-300x178.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;178&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图6 三层架构图&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/3-cloud2.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2112 aligncenter&quot; title=&quot;3 cloud2&quot; src=&quot;http://blog.javachen.com/files/2011/07/3-cloud2-300x181.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;181&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;OpenNebula使用共享存储设备（例如NFS）来提供虚拟机映像服务，使得每一个计算节点都能够访问到相同的虚拟机映像资源。当用户需要启动或者是关闭某个虚拟机时，OpenNebula通过SSH登陆到计算节点，在计算节点上直接运行相对应的虚拟化管理命令。这种模式也称为无代理模式，由于不需要在计算节点上安装额外的软件（或者服务），系统的复杂度也相对降低了。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt; &lt;a href=&quot;http://blog.javachen.com/files/2011/07/one-services.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2113 aligncenter&quot; title=&quot;one services&quot; src=&quot;http://blog.javachen.com/files/2011/07/one-services-300x189.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;189&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;图7 前端节点和集群节点之间交互&lt;/p&gt;
&amp;nbsp;
&lt;h2&gt;网络架构&lt;/h2&gt;
OpenNebula使用桥连接来构建虚拟网络，每个节点的IP和MAC地址在一定范围内生成。一个网络会连接到一个特定的桥。每一个网络有他自己的拥有者并且可以对外公开或私有。每一个虚拟网络之间是相互隔离的。&lt;/p&gt;




&lt;p&gt;虚拟网络里使用Ebtables来过滤数据链路层数据包。&lt;/p&gt;




&lt;p&gt;&amp;nbsp;
&lt;div class=&quot;infor&quot;&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;
* 1.虚拟化管理软件比较 －－ 构架篇：&lt;a href=&quot;http://www.qyjohn.net/?p=1263&quot;&gt;http://www.qyjohn.net/?p=1263&lt;/a&gt;
* 2.opennebula.org：&lt;a href=&quot;http://opennebula.org/&quot;&gt;http://opennebula.org/&lt;/a&gt;
* 3.OpenNebula Workshop：&lt;a href=&quot;http://hpc.uamr.de/wissen/opennebula-workshop/&quot;&gt;http://hpc.uamr.de/wissen/opennebula-workshop/&lt;/a&gt;
&lt;/div&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Centos上安装 OpenNebula Management Console</title>
   <link href="http://blog.javachen.com/cloud/2011/06/29/install-opennebula-management-console-in-centos5-6"/>
   <updated>2011-06-29T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/29/install-opennebula-management-console-in-centos5-6</id>
   <content type="html">&lt;p&gt;我们可以通过onehost/onevm/onevnet等等 这些命令行工具来管理 OpenNebula 云计算平台，也可以通过OpenNebula项目组开发的web控制台来访问OpenNebula。OpenNebula项目组提供了两个web程序来管理OpenNebula，一个即本文提到的&lt;a href=&quot;http://dev.opennebula.org/projects/management-console&quot; target=&quot;_blank&quot;&gt;OpenNebula Management Console&lt;/a&gt;，一个是&lt;a href=&quot;http://opennebula.org/documentation:rel2.2:sunstone&quot; target=&quot;_blank&quot;&gt;The Cloud Operations Center&lt;/a&gt;，前者需要额外&lt;a href=&quot;http://dev.opennebula.org/attachments/download/128/onemc-1.0.0.tar.gz&quot; target=&quot;_blank&quot;&gt;下载&lt;/a&gt;，后者内嵌与OpenNebula安装包内。&lt;/p&gt;




&lt;p&gt;OpenNebula 2.2提供的文档相对较少并且零散，在网上可以找到一篇关于OpenNebula Management Console安装的文章：&lt;br /&gt;
《&lt;a href=&quot;http://www.vpsee.com/2011/03/install-opennebula-management-console-on-centos/&quot; target=&quot;_blank&quot;&gt;安装 OpenNebula 基于 Web 的管理控制台》&lt;/a&gt;，我的这篇文章参考了这篇文章并加以完善，这篇文章对我完成OpenNebula Management Console的安装起到很大帮助，感谢原文作者。&lt;/p&gt;




&lt;p&gt;我的安装环境：centos5.6 ，OpenNebula2.2，在安装OpenNebula2.2之前，我执行了yum update，即更新系统的软件。&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;!--more--&gt;以下来自&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki&quot;&gt;官方文档&lt;/a&gt;：&lt;/span&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;要求:&lt;/span&gt;&lt;/h3&gt;
&lt;ul&gt;
    &lt;li&gt;Apache or whatever webserver.&lt;/li&gt;
    &lt;li&gt;php5 (May work with php4 but not tested)&lt;/li&gt;
    &lt;li&gt;php-adodb&lt;br /&gt;
And you need a db driver for adodb: php-mysql or php-pgsql.&lt;/li&gt;
    &lt;li&gt;Mysql or postgresql database&lt;/li&gt;
    &lt;li&gt;php-curl&lt;/li&gt;
    &lt;li&gt;php-xmlrpc&lt;/li&gt;
    &lt;li&gt;php-pear: pecl install uploadprogress (Only if you want a nice upload progress bar)&lt;/li&gt;
&lt;/ul&gt;
如果你想查看更多资料，您可以去官网：&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki&quot;&gt;OpenNebula Management Console Wiki&lt;/a&gt;；如果你想在ubutun上安装OpenNebula Management Console，参照这篇文章：&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki/onemc_install_ubuntu&quot;&gt;Install onemc on ubuntu&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;以下为安装过程：&lt;/span&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;必要软件&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# yum -y install php mysql-server httpd mysql-connector-odbc mysql-devel libdbi-dbd-mysql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #ff0000; font-size: 15px;&quot;&gt;安装php-adodb&lt;/span&gt;&lt;/h3&gt;
从&lt;a href=&quot;http://sourceforge.net/projects/adodb/files/adodb-php5-only&quot;&gt;http://sourceforge.net/projects/adodb/files/adodb-php5-only&lt;/a&gt;下载
&lt;strong&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;注意：&lt;/span&gt;&lt;/strong&gt;将adobd包解压拷贝到/var/www/html/onemc/include/，将文件名改为adobd
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;安装php的扩展&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# yum -y install php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php-curl php-mysql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;安装apache扩展&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# yum -y install httpd-manual mod_ssl mod_perl mod_auth_mysql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;修改配置文件权限&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# chmod 644 /var/www/html/onemc/include/config.php&lt;/pre&gt;
我下载的是OpenNebula 2.2其中/config.php的权限很特别，如果你从浏览器访问onemc时候页面都是空白的，你可以看看日志（我使用的是httpd，日志在httpd.log），可以看到日志中提示没有权限访问/var/www/html/onemc/include/config.php
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;下载 onemc&lt;/span&gt;&lt;/h3&gt;
下载和解压 onemc-1.0.0.tar.gz 后直接放在 apache 的默认目录里：
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# cd /var/www/html
# wget http://dev.opennebula.org/attachments/download/128/onemc-1.0.0.tar.gz
# tar zxvf onemc-1.0.0.tar.gz
# cd onemc&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;配置数据库&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# mysql -uroot -p
Enter password:
mysql&amp;gt; create database onemc;
mysql&amp;gt; create user 'oneadmin'@'localhost' identified by 'oneadmin';
mysql&amp;gt; grant all privileges on onemc.* to 'oneadmin'@'localhost';
mysql&amp;gt; \q&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;初始化数据库&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# mysql -u oneadmin -p onemc &amp;lt; /var/www/html/onemc/include/mysql.sql&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;配置 onemc&lt;/span&gt;&lt;/h3&gt;
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# vi /var/www/html/onemc/include/config.php
...
// vmm: kvm or xen
$vmm = &quot;xen&quot;;
...
// ADODB settings
$adodb_type = &quot;mysql&quot;;
$adodb_server = &quot;localhost&quot;;
$adodb_user = &quot;oneadmin&quot;;
$adodb_pass = &quot;oneadmin&quot;;
$adodb_name = &quot;onemc&quot;;&lt;/pre&gt;
&lt;h3&gt;&lt;span style=&quot;color: #0000ff; font-size: 15px;&quot;&gt;登录&lt;/span&gt;&lt;/h3&gt;
如果系统设置了 http_proxy 环境变量的话一定要先关闭，然后重启 one 和 httpd：
&lt;pre escaped=&quot;true&quot; lang=&quot;shell&quot;&gt;# unset http_proxy
# one stop; one start
# /etc/init.d/httpd restar
&lt;/pre&gt;
访问地址为http://localhost/onemc/index.php，用户名和密码在one_auth 中。
&lt;h3&gt;&lt;span style=&quot;font-size: 15px;&quot;&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;总结&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
以上步骤最重要的是配置好centos的yum源，一次将php和mysql及相关组件安装成功，然后需要注意的是上面红色部分标出的部分。其实，除了红色那部分之外，其余和开头提到的那篇文章内容没什么差别。
&lt;h3&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;参考文章&lt;/span&gt;&lt;/h3&gt;
&lt;li&gt;
&lt;a href=&quot;http://www.javachen.com/?page_id=2073#date=2011-06-29 12:00:00,mode=month&quot; target=&quot;_blank&quot;&gt;Centos上安装 OpenNebula Management Console&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki&quot;&gt;OpenNebula Management Console Wiki&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dev.opennebula.org/projects/management-console/wiki/onemc_install_ubuntu&quot;&gt;Install onemc on ubuntu&lt;/a&gt;
&lt;/li&gt;
&lt;/p&gt;



</content>
 </entry>
 
 <entry>
   <title>OpenNebula 2.2的特性</title>
   <link href="http://blog.javachen.com/cloud/2011/06/26/opennebula-2-2-features"/>
   <updated>2011-06-26T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/26/opennebula-2-2-features</id>
   <content type="html">&lt;p&gt;以下这篇文章由&lt;a title=&quot;OpenNebula 2.2 Features&quot; href=&quot;http://opennebula.org/documentation:features&quot;&gt;OpenNebula 2.2 Features&lt;/a&gt;翻译而来。&lt;/p&gt;




&lt;p&gt;OpenNebula是一款为云计算而打造的开源工具箱。它允许你与Xen，KVM或VMware ESX一起建立和管理私有云，同时还提供Deltacloud适配器与Amazon EC2相配合来管理混合云。除了像Amazon一样的商业云服务提供商，在不同OpenNebula实例上运行私有云的Amazon合作伙伴也同样可以作为远程云服务供应商。&lt;/p&gt;




&lt;p&gt;目前版本，可支持XEN、KVM和VMware，以及实时存取EC2和 ElasticHosts，它也支持印象档的传输、复制和虚拟网络管理网络。
&lt;h2&gt;主要特点和优势&lt;/h2&gt;
&lt;strong&gt;私有云计算&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;




&lt;p&gt;为私有数据中心或集群（管理功能&lt;strong&gt;私有云计算&lt;/strong&gt;）上运行&lt;strong&gt;的&lt;/strong&gt;&lt;strong&gt;Xen&lt;/strong&gt;，&lt;strong&gt;KVM&lt;/strong&gt;和&lt;strong&gt;VMware&lt;/strong&gt;&lt;strong&gt;的&lt;/strong&gt;。
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;用户管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;用户管理，认证框架，多个云用户和管理员角色，会计，配额管理，安全的多租户。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;VM&lt;/strong&gt;&lt;strong&gt;图像管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;带目录的镜像仓库和镜像管理，访问控制，以及从正在运行的虚拟机创建镜像。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;虚拟网络管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;对互联的虚拟机;一定范围或固定的网络;虚拟网络共享;相关的第2层虚拟网络和网络隔离的通用属性定义提供虚拟网络管理。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;虚拟机管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;虚拟机管理功能，支持在同一物理结构中的多个hypervisors，分布式环境的多个hypervisor管理，虚拟机自动配置，以及脚本在虚拟机的状态变化时的触发管理。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;服务管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;部署由多层次的相互联系的虚拟机组成的群体服务;在启动时自动配置，以及对微软Windows和Linux镜像的支持。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;基础设施管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;管理物理主机;创建本地集群，占地面积小，占用空间不到700KB。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;存储管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;虚拟机映像管理，支持多种硬件平台（FibreChannel, iSCSI, NAS shared storage…）和存储后端传输镜像。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;信息管理&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;虚拟机和物理基础设施的监控，并与数据监测工具集成，如&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;调度&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;强大和灵活的竞价/排名调度、工作量和资源分配政策，如包装，分割，负载感知.....&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;用户界面&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;Unix类似的云基础设施管理命令行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;运营中心&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;图形化管理的云基础设施。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--more--&gt;&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;混合云计算&lt;/strong&gt;&lt;/p&gt;




&lt;p&gt;本地基础设施与远程云资源的扩展（&lt;strong&gt;混合云计算&lt;/strong&gt;）
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;449&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;&lt;strong&gt;Cloudbursting&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;449&quot;&gt;本地的基础设施，可以辅从外部云计算能力，以满足高峰需求，更好地服务用户的访问请求，或者为了实现高可用性策略。支持亚马逊EC2，并同时访问多个云。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;&lt;strong&gt;Federation&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;449&quot;&gt;不同的云实例以构建一个独立的虚拟化集群层次;更高水平的可扩展性。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;nbsp;&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;公共云计算&lt;/strong&gt;&lt;/p&gt;




&lt;p&gt;暴露云接口给私有的基础设施功能（&lt;strong&gt;公共云计算&lt;/strong&gt;）
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;云接口&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;通过提供给用户的REST接口;实现OGF OCCI和亚马逊EC2接口，使本地的基础架构转变为一个公开云;支持同时公开多种云API，客户端工具，以及安全访问。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;主要特点和集成优势&lt;/h2&gt;
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;基础设施抽象&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;无缝与任何操作平台的验证/授权，虚拟化，网络和存储平台融合，采用模块化结构，以适应任何数据中心。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;适应性和定制&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;启用任何云架构的部署：公共，私有，混合和联合;定制插件来访问虚拟化、存储、信息、认证/授权和远程云服务，新的插件可以很容易地在任何语言编写，配置和改变参数调整云管理实例的行为以满足环境和用例要求;钩机制，当虚拟机的状态改变使触发管理脚本的执行。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;互操作性和标准&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;开放标准为基础的架构，以避免厂商锁定，提高互操作性​​，以及开放的实施标准。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;开放&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;开源Apache许可下发布协议。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;编程接口&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;提供Ruby和Java XMLRPC的原生云API创建新的云接口和访问核心功能。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;主要特点和生产效益&lt;/h2&gt;
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;安全&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;验证框架的密码，或基于SSH的RSA密钥对LDAP，外部和内部通信通过SSL，安全的多​​租户;隔离的网络。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;健壮性&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;持久数据库后端存储主机、网络、虚拟机信息。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;容错&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;配置主机、虚拟机或OpenNebula实例故障事件。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;测试在大规模的核心和成千上万的基础设施;高度可扩展的后端，并为MySQL和SQLite支持。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;性能&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;非常高效的内核开发C++语言。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;可靠性&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;自动化的功能、可扩展性、性能、可靠性和稳定性测试过程。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;利用充满活力的云生态系统&lt;/h2&gt;
&lt;table width=&quot;100%&quot;&gt;
&lt;tbody&gt;
&lt;tr bgcolor=&quot;cornsilk&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr bgcolor=&quot;aliceblue&quot;&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;OpenNebula Ecosystem&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;充分利用&lt;a title=&quot;http://www.opennebula.org/software:ecosystem&quot; href=&quot;http://www.opennebula.org/software:ecosystem&quot;&gt;OpenNebula开放云生态系统&lt;/a&gt;与新元件加强了OpenNebula云工具包提供的功能并能够与其他产品的集成：vCloud的API、OpenNebula块、Haizea调度、 Libcloud、Deltacloud、Web管理控制台，Deltacloud的混合云适配器...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;107&quot;&gt;&lt;strong&gt;Other Cloud Ecosystems&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;453&quot;&gt;围绕Amazon AWS, OGC OCCI and VMware vCloud构建的生态系统。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Eucalyptus使用的技术</title>
   <link href="http://blog.javachen.com/cloud/2011/06/22/the-technology-used-in-eucalyptus"/>
   <updated>2011-06-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/22/the-technology-used-in-eucalyptus</id>
   <content type="html">&lt;p&gt;&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://libvirt.org/&quot;&gt;libvirt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Libvirt 库是一种实现 Linux 虚拟化功能的 Linux® API，它支持各种虚拟机监控程序，包括 Xen 和 KVM，以及 QEMU 和用于其他操作系统的一些虚拟产品。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.jboss.org/netty/&quot;&gt;Netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Netty 提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://ws.apache.org/axis2/&quot;&gt;Axis2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Axis2是下一代 Apache Axis。Axis2 虽然由 Axis 1.x 处理程序模型提供支持，但它具有更强的灵活性并可扩展到新的体系结构。Axis2 基于新的体系结构进行了全新编写，而且没有采用 Axis 1.x 的常用代码。支持开发 Axis2 的动力是探寻模块化更强、灵活性更高和更有效的体系结构，这种体系结构可以很容易地插入到其他相关 Web 服务标准和协议（如 WS-Security、WS-ReliableMessaging 等）的实现中。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://ws.apache.org/axis2/c/&quot;&gt;Axis2c&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Apache Axis2/C is a Web services engine implemented in the C programming language. It is based on the extensible and flexible &lt;a title=&quot;External Link&quot; href=&quot;http://ws.apache.org/axis2/1_2/Axis2ArchitectureGuide.html&quot;&gt;Axis2 architecture&lt;/a&gt;.
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://ws.apache.org/rampart/c/&quot;&gt;Rampart/C&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a title=&quot;External Link&quot; href=&quot;http://ws.apache.org/axis2/c/&quot;&gt;Apache Axis2/C&lt;/a&gt;的安全模块
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://jibx.sourceforge.net/&quot;&gt;JiBX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
JiBX是一款非常优秀的XML（Extensible Markup Language）数据绑定框架。它提供灵活的绑定映射文件实现数据对象与XML文件之间的转换；并不需要你修改既有的Java类。另外，另外，它的转换效率是目前很多开源项目都无法比拟的。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.bouncycastle.org/java.html&quot;&gt;Bouncy Castle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Bouncy Castle 是一种用于 Java 平台的开放源码的轻量级密码术包。它支持大量的密码术算法，并提供 JCE 1.2.1 的实现。因为 Bouncy Castle 被设计成轻量级的，所以从 J2SE 1.4 到 J2ME（包括 MIDP）平台，它都可以运行。它是在 MIDP 上运行的唯一完整的密码术包。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://mule.mulesource.org/display/MULE/Home&quot;&gt;Mule&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
它是一个轻量级的消息框架和整合平台，基于EIP（Enterprise Integeration Patterns,由Hohpe和Woolf编写的一本书）而实现的。Mule的核心组件是UMO(Universal Message Objects，从Mule2.0开始UMO这一概念已经被组件Componse所代替)，UMO实现整合逻辑。UMO可以是POJO,JavaBean等等。它支持20多种传输协议(file,FTP,UDP,SMTP,POP,HTTP,SOAP,JMS等)，并整合了许多流行的开源项目，比如Spring,ActiveMQ,CXF,Axis,Drools等。虽然Mule没有基于JBI来构建其架构，但是它为JBI容器提供了JBI适配器，应此可以很好地与JBI容器整合在一起。而 Mule更关注其灵活性，高效性以及易开发性。从2005年发表1.0版本以来，Mule吸引了越来越多的关注者，成为开源ESB中的一支独秀。目前许多公司都使用了Mule，比如Walmart,HP,Sony,Deutsche Bank 以及 CitiBank等公司。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.hibernate.org/&quot;&gt;Hibernate&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Hibernate是一个开放源代码的&lt;a href=&quot;http://baike.baidu.com/view/2387.htm&quot; target=&quot;_blank&quot;&gt;对象&lt;/a&gt;关系映射框架，它对JDBC进行了非常轻量级的对象封装，使得Java程序员可以随心所欲的使用对象编程思维来操纵&lt;a href=&quot;http://baike.baidu.com/view/1088.htm&quot; target=&quot;_blank&quot;&gt;数据库&lt;/a&gt;。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.hsqldb.org/&quot;&gt;HSQLDB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Hsqldb是一个开放源代码的JAVA数据库，其具有标准的SQL语法和JAVA接口，它可以自由使用和分发，非常简洁和快速的。在其官网可以获得最新的程序源代码及jar包文件
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://xen.org/&quot;&gt;Xen&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Xen 是一个开放源代码&lt;a href=&quot;http://baike.baidu.com/view/1132.htm&quot; target=&quot;_blank&quot;&gt;虚拟机&lt;/a&gt;监视器，由&lt;a href=&quot;http://baike.baidu.com/view/13714.htm&quot; target=&quot;_blank&quot;&gt;剑桥大学&lt;/a&gt;开发。它打算在单个计算机上运行多达100个满特征的&lt;a href=&quot;http://baike.baidu.com/view/880.htm&quot; target=&quot;_blank&quot;&gt;操作系统&lt;/a&gt;。操作系统必须进行显式地修改（“移植”）以在Xen上运行（但是提供对用户应用的兼容性）。这使得Xen无需特殊硬件支持，就能达到高性能的虚拟化。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://www.linux-kvm.org/page/Main_Page&quot;&gt;KVM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
基于内核的虚拟机(或简称为KVM)是一个由Qumrannet开发和赞助的开源项目.
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://code.google.com/webtoolkit/&quot;&gt;Google Web Toolkit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;em&gt; Google Web Toolkit&lt;/em&gt; (GWT) 允许开发人员使用Java 编程语言快速构建和维护复杂而又高性能的JavaScript 前端应用程序，从而降低了开发难度
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://sourceware.org/lvm2/&quot;&gt;LVM2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
LVM是 Logical Volume Manager(逻辑卷管理)的简写，它是Linux环境下对磁盘分区进行管理的一种机制，它由Heinz Mauelshagen在Linux 2.4内核上实现，目前最新版本为：稳定版1.0.5，开发版 1.1.0-rc2，以及LVM2开发版。
&lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;http://jetty.codehaus.org/jetty/&quot; target=&quot;_blank&quot;&gt;Jetty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
Jetty 是一个开源的servlet容器，它为基于Java的web内容，例如JSP和servlet提供运行环境。Jetty是使用&lt;a href=&quot;http://baike.baidu.com/view/229611.htm&quot; target=&quot;_blank&quot;&gt;Java语言&lt;/a&gt;编写的，它的API以一组JAR包的形式发布。开发人员可以将Jetty容器实例化成一个对象，可以迅速为一些独立运行（stand-alone）的Java应用提供网络和web连接。&lt;/p&gt;




&lt;p&gt;&amp;nbsp;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Eucalyptus EE的介绍及功能说明</title>
   <link href="http://blog.javachen.com/cloud/2011/06/22/the-introduction-of-eucalyptus-ee-features-and-functions"/>
   <updated>2011-06-22T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/22/the-introduction-of-eucalyptus-ee-features-and-functions</id>
   <content type="html">&lt;p&gt;Eucalyptus企业版2.0是一个基于Linux的软件架构，在企业现有的IT架构上实现一个可扩展的、提高效率的私有和混合云。Eucalyptus作为基础设施提供IaaS服务。这意味着用户可以通过Eucalyptus自助服务界面提供自己的资源（硬件、存储和网络）。一个Eucalyptus云是部署在企业的内部数据中心，由企业内部用户访问。因此，敏感数据可以在防火墙的保护下防止外部入侵。&lt;/p&gt;




&lt;p&gt;Eucalyptus的设计目的是从根本上易于安装和尽可能没有侵扰。该软件高度模块化，具有行业标准，和语言无关。它提供了可以与EC2兼容的云计算平台和与S3兼容的云存储平台。&lt;!--more--&gt;
&lt;h1&gt;功能亮点&lt;/h1&gt;
&lt;ul&gt;
    &lt;li&gt;无缝管理多个管理程序环境（Xen的，vSphere的，KVM，ESX，ESXi的）下一个管理控制台&lt;/li&gt;
    &lt;li&gt;启用跨平台的客户机操作系统包括微软Windows和Linux&lt;/li&gt;
    &lt;li&gt;高级存储集成器（iSCSI，SAN，NAS），您可以轻松地连接和管理Eucalyptus云内现有的存储系统&lt;/li&gt;
    &lt;li&gt;完善的用户和组管理，允许私有云资源的精确控制&lt;/li&gt;
    &lt;li&gt;测试，开发和部署能够顺利过渡到公共云或反之亦然，没有任何修改&lt;/li&gt;
    &lt;li&gt;快速，轻松地建立与基于VMware的虚拟化环境和其他公共云混合云&lt;/li&gt;
    &lt;li&gt;启用先进设备，最先进的企业，如可扩展的存储整合，监控，审计，报表&lt;/li&gt;
    &lt;li&gt;利用充满活力的生态系统围绕亚马逊AWS构建，提供解决方案，无缝地与Eucalyptus兼容&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;优点&lt;/h1&gt;
&lt;ul&gt;
    &lt;li&gt;建立一个私有云，让你接入到亚马逊AWS&lt;/li&gt;
    &lt;li&gt;允许云在原有的所有硬件和软件类型很容易的部署&lt;/li&gt;
    &lt;li&gt;客户可以利用其全球用户社区&lt;/li&gt;
    &lt;li&gt;Eucalyptus是与Linux和多个管理程序兼容&lt;/li&gt;
    &lt;li&gt;Eucalyptus还支持商业Linux发行版本：红帽企业Linux（RHEL）和SUSE Linux企业服务器（SLES）&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;对于IT管理员的好处&lt;/h1&gt;
&lt;ul&gt;
    &lt;li&gt;提供自助服务的IT基础设施供应到最终用户需要的IT资源迅速&lt;/li&gt;
    &lt;li&gt;没有额外的资金保持现有的基础设施费用，降低运营成本&lt;/li&gt;
    &lt;li&gt;保持防火墙后面的关键数据&lt;/li&gt;
    &lt;li&gt;技术是对现有的硬件和软件基础设施覆盖，而不是替代&lt;/li&gt;
    &lt;li&gt;避免锁定在第三方公共云供应商&lt;/li&gt;
    &lt;li&gt;可轻松转换之间来回私人和公共云&lt;/li&gt;
&lt;/ul&gt;
&amp;nbsp;
&lt;h1&gt;Eucalyptus EE新特性&lt;/h1&gt;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;对windows VM的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
1.  运行windows 虚拟机在Eucalyptus 云环境上运行，目前支持Windows 2003 Server,Windows 2008 Server和Windows 7。&lt;br /&gt;
2.  试用Euca2ools管理和控制windows虚拟机。&lt;br /&gt;
3.  试用EC2兼容的命令从正在运行的windows虚拟机创建新的虚拟机&lt;br /&gt;
4.  在Eucalyptus中通过标准的RDP客户端工具，使用AWS “get-password”访问虚拟机实例&lt;br /&gt;
5.  在多个hypervisors环境中部署windows虚拟机，包括Xen、Kvm、VMware（ESX/ESXi）&lt;br /&gt;
6.  基于windows 操作系统安装文件（ISO镜像、CD/DVD）创建新的windows虚拟机
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;对VMware的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
1.支持VMware vCenter 4.0,ESX/ESXi 4.0!&lt;br /&gt;
2.与VMware vSphere 客户端兼容&lt;br /&gt;
3.能够合并VMware(ESX/ESXi)和开源的hypervisors（Xen、Kvm）到一个单独的云环境&lt;br /&gt;
4.通过Eucalyptus的软件扩展一些云的基本特性（例如IPs，安全组，S3）到一个VMware基础架构&lt;/p&gt;




&lt;p&gt;&amp;nbsp;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;引入SAN的支持&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
Eucalyptus EE引入对SAN的支持，使你能够整合enterprise-grade SAN(Storage Area Network) 硬件设备到Eucalyptus云环境。SAN扩展SC并在Eucalyptus中运行的虚拟机和SAN设备之间提供高性能的数据通道。Eucalyptus EE的SAN支持为Eucalyptus云环境提供了一个企业级的EBS解决方案。&lt;/p&gt;




&lt;p&gt;&amp;nbsp;
&lt;h1&gt;Eucalyptus的功能&lt;/h1&gt;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;基本组成部分及功能&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; width=&quot;614&quot; align=&quot;left&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;模块&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;功能&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;说明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;云控制器（CLC）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.对外提供EC2和Web接口，管理各类组件中的可用虚拟资源（服务、网络、存储）。&lt;br /&gt;
2.资源抽象，决定哪个簇将提供给实例，分发请求给CC。&lt;br /&gt;
3.管理运行的实例。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;CLC是整个云结构的前端。CLC为客户工具提供与EC2/S3兼容的网络接口，与Eucalyptus的组件通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;存储控制器（SC）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.提供与EBS类似的存储功能，能够与大量的文件存储系统交互。&lt;br /&gt;
2.使用AoE或者iSCSI协议为实例提供块存储。&lt;br /&gt;
3.允许在存储系统中（如Walrus）建立快照。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;SC提供实例使用的块存储。&lt;br /&gt;
与EBS类似。&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/p&gt;




&lt;p&gt;&amp;nbsp;

&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;Walrus控制器（WS3）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.允许用户存储持久化的数据。&lt;br /&gt;
2.提供REST接口操作数据，设置数据访问策略。&lt;br /&gt;
3.使用S3 API存储和获取虚拟镜像和数据。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;WS3使用与S3 API兼容的REST和SOAP   API提供简单的存储服务&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;控制簇（CC）&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.接收CLC的请求，然后部署实例。&lt;br /&gt;
2.收集虚拟机的信息并决定在哪个节点控制上执行虚拟机。&lt;br /&gt;
3.为实例提供有效的虚拟网络。&lt;br /&gt;
4.收集NCs提交的信息，并报告给CLC。&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;CC管理NC，部署和管理在节点上的实例，在Eucalyptus联网模型的类型下管理在控制节点上运行的实例的联网。&lt;br /&gt;
CC连接着云控制器CLC和控制节点NC。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;节点控制器（NC）&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/p&gt;




&lt;p&gt;&amp;nbsp;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.托管虚拟机实例&lt;br /&gt;
2.收集节点上相关的数据资源的可用性和利用率，并报告给控制簇CC。&lt;br /&gt;
3.管理虚拟机的生命周期，能够获取和清除镜像的本地拷贝。&lt;br /&gt;
4.维护虚拟网络&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;UEC的节点使用虚拟化技术使KVM能作为管理程序在服务器上运行。当用户安装UEC节点时，UEC将自动安装KVM。UEC的实例就是在管理程序下运行的虚拟机。Eucalyptus支持其他管理程序，如Xen。&lt;br /&gt;
节点控制器在每一个节点上运行，控制着节点上实例的生命周期。&lt;/td&gt;

&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;VMware   Broker&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;允许 Eucalyptus直接地或通过 VMware&lt;strong&gt; &lt;/strong&gt;Vcenter在   VMware设备部署虚拟机，在CC和 VMware  hypervisors(ESX/ESXi)起一个连接作用&lt;strong&gt; &lt;/strong&gt;&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;Eucalyptus   EE额外的一个组件，用于对VMware的支持&lt;/td&gt;
&lt;/tr&gt;


&amp;nbsp;&lt;/p&gt;




&lt;p&gt;&lt;span style=&quot;font-size: 20px; font-weight: bold; color: #0000ff;&quot;&gt;管理员拥有的功能&lt;/span&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; width=&quot;614&quot; align=&quot;left&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;模块&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;功能&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;说明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;用户管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  添加用户（邮件通知，设置管理员）&lt;br /&gt;
2.  查看用户，设置账户是否激活&lt;br /&gt;
3.  删除用户&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;组管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  添加用户组&lt;br /&gt;
2.  查看用户组&lt;br /&gt;
3.  删除用户组&lt;br /&gt;
4.  添加/删除组员&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;权限管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.给组设置权限&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;Web接口&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  查看、下载证书&lt;br /&gt;
2.  查看上传的镜像，并能修改镜像状态&lt;br /&gt;
3.  配置管理。可以设置云主机IP、DNS、Walrus、Cluster和SAN&lt;br /&gt;
4.  审计报表。查看用户状态、资源使用率、系统日志、已注册的组件&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;这部分是web 管理界面提供的功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;组件管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  可以注册Cloud、Walrus、Storage、Node，并可以查看、删除&lt;br /&gt;
2.  启动、停止云服务&lt;br /&gt;
3.  允许转换卷的实现方式&lt;br /&gt;
4.  可以查看、修改配置文件&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;对外以SOAP和REST提供接口&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;nbsp;&lt;/p&gt;




&lt;p&gt;&amp;nbsp;
&lt;h2&gt;&lt;strong&gt;&lt;span style=&quot;color: #0000ff;&quot;&gt;使用者拥有的功能&lt;/span&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; width=&quot;614&quot; align=&quot;left&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;模块&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;功能&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;说明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;Web接口&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  用户可以注册帐号，修改信息及密码&lt;br /&gt;
2.  查看、下载证书&lt;br /&gt;
3.  查看上传的镜像&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;这部分是web 管理界面提供的功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;102&quot; valign=&quot;top&quot;&gt;组件管理&lt;/td&gt;
&lt;td width=&quot;279&quot; valign=&quot;top&quot;&gt;1.  启动、停止节点&lt;br /&gt;
2.  可以绑定、上传、注册、查看镜像，也可以删除、取消绑定镜像&lt;br /&gt;
3.  查看本地可用的资源&lt;br /&gt;
4.  可以查看、启动、停止、重启虚拟机&lt;br /&gt;
5.  可以登入到一个windows虚拟机实例&lt;br /&gt;
6.  创建、附件、脱离、删除快照和卷&lt;/td&gt;
&lt;td width=&quot;234&quot; valign=&quot;top&quot;&gt;通过Euca2ools工具完成这些功能&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&amp;nbsp;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>接触云服务环境Eucalyptus</title>
   <link href="http://blog.javachen.com/cloud/2011/06/16/touch-cloud-environment-which-it-is-eucalyptus"/>
   <updated>2011-06-16T00:00:00+08:00</updated>
   <id>http://blog.javachen.com/cloud/2011/06/16/touch-cloud-environment-which-it-is-eucalyptus</id>
   <content type="html">&lt;p&gt;最近在接触云计算平台，熟悉了&lt;a href=&quot;http://www.eucalyptus.com/&quot;&gt;Eucalyptus&lt;/a&gt;，并用其搭建云环境。通过网上的一些例子，逐渐的摸索出用&lt;a href=&quot;http://www.eucalyptus.com/&quot;&gt;Eucalyptus&lt;/a&gt;搭建云计算平台的方法。我所用的Eucalyptus是免费版，缺少很多企业版的功能。
&lt;h2&gt;Eucalyptus&lt;/h2&gt;
Elastic Utility Computing Architecture for Linking Your Programs To Useful Systems （Eucalyptus） 是一种开源的软件基础结构，用来通过&lt;span style=&quot;color: #ff0000;&quot;&gt;计算集群或工作站群实现弹性的、实用的云计算&lt;/span&gt;。它最初是美国加利福尼亚大学 Santa Barbara 计算机科学学院的一个研究项目，现在已经商业化，发展成为了 Eucalyptus Systems Inc。不过，Eucalyptus 仍然按开源项目那样维护和开发。Eucalyptus Systems 还在基于开源的 Eucalyptus 构建额外的产品；它还提供支持服务。
&lt;!--more--&gt; 它提供了如下这些高级特性：
&lt;blockquote&gt;与 EC2 和 S3 的接口兼容性（&lt;span style=&quot;color: #ff0000;&quot;&gt;SOAP 接口和 REST 接口&lt;/span&gt;）。使用这些接口的几乎所有现有工具都将可以与基于 Eucalyptus 的云协作。&lt;br /&gt;
支持运行在&lt;span style=&quot;color: #ff0000;&quot;&gt; Xen hypervisor&lt;/span&gt; 或 &lt;span style=&quot;color: #ff0000;&quot;&gt;KVM&lt;/span&gt; 之上的 VM 的运行。未来版本还有望支持其他类型的 VM，比如 VMware。&lt;br /&gt;
用来进行&lt;span style=&quot;color: #ff0000;&quot;&gt;系统管理和用户结算&lt;/span&gt;的云管理工具。&lt;br /&gt;
能够将多个分别具有各自私有的内部网络地址的&lt;span style=&quot;color: #ff0000;&quot;&gt;集群&lt;/span&gt;配置到一个云内。&lt;/blockquote&gt;
&lt;h2&gt;架构&lt;/h2&gt;
Eucalyptus 包含五个主要组件，它们能相互协作共同提供所需的云服务。这些组件使用具有 WS-Security 的 SOAP 消息传递安全地相互通信。&lt;/p&gt;




&lt;p&gt;&lt;strong&gt;Cloud Controller (CLC)&lt;/strong&gt;
在 Eucalyptus 云内，这是主要的控制器组件，负责管理整个系统。它是所有用户和管理员进入 Eucalyptus 云的主要入口。所有客户机通过基于 SOAP 或 REST 的 API 只与 CLC 通信。由 CLC 负责将请求传递给正确的组件、收集它们并将来自这些组件的响应发送回至该客户机。这是 Eucalyptus 云的对外 “窗口”。
&lt;strong&gt;Cluster Controller (CC)&lt;/strong&gt;
Eucalyptus 内的这个控制器组件负责管理整个虚拟实例网络。请求通过基于 SOAP 或 REST 的接口被送至 CC。CC 维护有关运行在系统内的 Node Controller 的全部信息，并负责控制这些实例的生命周期。它将开启虚拟实例的请求路由到具有可用资源的 Node Controller。
&lt;strong&gt;Node Controller (NC)&lt;/strong&gt;
它控制主机操作系统及相应的 hypervisor（Xen 或最近的 KVM，很快就会支持 VMWare）。必须在托管了实际的虚拟实例（根据来自 CC 的请求实例化）的每个机器上运行 NC 的一个实例。
&lt;strong&gt;Walrus (W)&lt;/strong&gt;
这个控制器组件管理对 Eucalyptus 内的存储服务的访问。请求通过基于 SOAP 或 REST 的接口传递至 Walrus。
&lt;strong&gt;Storage Controller (SC)&lt;/strong&gt;
Eucalyptus 内的这个存储服务实现 Amazon 的 S3 接口。SC 与 Walrus 联合工作，用于存储和访问虚拟机映像、内核映像、RAM 磁盘映像和用户数据。其中，VM 映像可以是公共的，也可以是私有的，并最初以压缩和加密的格式存储。这些映像只有在某个节点需要启动一个新的实例并请求访问此映像时才会被解密。&lt;br /&gt;
一个 Eucalyptus 云安装可以聚合和管理来自一个或多个集群的资源。一个集群 是连接到相同 LAN 的一组机器。在一个集群中，可以有一个或多个 NC 实例，每个实例管理虚拟实例的实例化和终止。
&lt;div class=&quot;info&quot;&gt;
&lt;h2&gt;参考文章&lt;/h2&gt;
在安装的过程中，参考了一些网上的文章：&lt;br /&gt;
&lt;li&gt;Eucalyptus 开启云端：
&lt;a href=&quot;http://blog.163.com/firstsko@126/blog/static/132168891201022935737810/&quot;&gt;http://blog.163.com/firstsko@126/blog/static/132168891201022935737810/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
Installing Eucalyptus (2.0) on Fedora 12
&lt;a href=&quot;http://open.eucalyptus.com/wiki/EucalyptusInstallationFedora_v2.0&quot;&gt;http://open.eucalyptus.com/wiki/EucalyptusInstallationFedora_v2.0&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
 在Fedora 13 上搭建Eucalyptus
&lt;a href=&quot;http://blog.csdn.net/hispania/archive/2010/09/24/5902926.aspx&quot;&gt;http://blog.csdn.net/hispania/archive/2010/09/24/5902926.aspx&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;ubuntu 9.04 (server)下 eucalyptus 安装（推荐）：
&lt;a href=&quot;http://bbs.chinacloud.cn/archiver/showtopic-230.aspx&quot;&gt;http://bbs.chinacloud.cn/archiver/showtopic-230.aspx&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;


&lt;p&gt;&lt;/li&gt;&lt;/p&gt;

&lt;p&gt;
&lt;h2&gt;Eucalyptus java源代码&lt;/h2&gt;
在安装过程中，我把Eucalyptus的java源代码（eucalyptus-2.0.3-src-offline.tar.gz）下下来了，并按照&lt;a href=&quot;http://open.eucalyptus.com/participate/sourcecode&quot;&gt;http://open.eucalyptus.com/participate/sourcecode&lt;/a&gt;的说明好不容易把java代码通过ant编译然后手动复制粘贴导入eclipse了，现在这些代码能够通过编译了，并能够清楚的看到Eucalyptus的java代码部分的实现方式。&lt;br /&gt;
以下是两个截图：&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/06/eucalyptus-2.0.3-src-01.png&quot;&gt;&lt;img class=&quot;size-medium wp-image-2097 alignleft&quot; title=&quot;eucalyptus-2.0.3-src-01&quot; src=&quot;http://blog.javachen.com/files/2011/06/eucalyptus-2.0.3-src-01-300x258.png&quot; alt=&quot;eucalyptus-2.0.3-src-01&quot; width=&quot;300&quot; height=&quot;258&quot; /&gt;&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;&lt;a href=&quot;http://blog.javachen.com/files/2011/06/eucalyptus-2.0.3-src-02.jpg&quot;&gt;&lt;img class=&quot;size-medium wp-image-2099 alignleft&quot; title=&quot;eucalyptus-2.0.3-src-02&quot; src=&quot;http://blog.javachen.com/files/2011/06/eucalyptus-2.0.3-src-02-214x300.jpg&quot; alt=&quot;eucalyptus-2.0.3-src-02&quot; width=&quot;214&quot; height=&quot;300&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 
</feed>